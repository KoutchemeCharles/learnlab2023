{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the FalconCode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"/scratch/work/koutchc1/datasets/falconcode/falconcode_v1_table_problems.csv\"\n",
    "problems_df = pd.read_csv(path)\n",
    "path = \"/scratch/work/koutchc1/datasets/falconcode/falconcode_v1_merged.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from cs110 import autograder\r\n",
      "import random, math\r\n",
      "\r\n",
      "meal_info = [\r\n",
      "    ['Hot Dogs', 600],\r\n",
      "    ['French Dip', 540],\r\n",
      "    ['Chicken Cordon Bleu', 300],\r\n",
      "    ['Turkey Sandwich', 350],\r\n",
      "    ['Mitch\\'s Mountain', 1100],\r\n",
      "    ['Shepherd\\'s Pie', 272],\r\n",
      "    ['Teriyaki Chicken', 250],\r\n",
      "    ]\r\n",
      "\r\n",
      "# Runs the Python script and sees if it passes the test(s)\r\n",
      "def test_passed():\r\n",
      "    inputs = []\r\n",
      "    expected_outputs = []\r\n",
      "    \r\n",
      "    meal_table = []\r\n",
      "    table_size = random.randint(3, 5)\r\n",
      "    total = 0\r\n",
      "    inputs.append(table_size)\r\n",
      "    \r\n",
      "    for meal in random.sample(meal_info, table_size):\r\n",
      "        total += meal[1]\r\n",
      "        inputs.append(meal[0])\r\n",
      "        inputs.append(meal[1])\r\n",
      "        meal_table.append([meal[0], meal[1]])\r\n",
      "    \r\n",
      "    average = total / len(meal_table)\r\n",
      "    expected_outputs.append(str(average))\r\n",
      "    \r\n",
      "    for m in meal_table:\r\n",
      "        if m[1] >= average-200 and m[1] <= average+200:\r\n",
      "            expected_outputs.append(m[0])\r\n",
      "    \r\n",
      "    output, errors = autograder.run_script(\"lsn24_mitches.py\", inputs)\r\n",
      "    lines = output.strip().split('\\n')\r\n",
      "    \r\n",
      "    lines_match = autograder.compare_strings(lines, expected_outputs)\r\n",
      "    \r\n",
      "    if lines_match == len(expected_outputs):\r\n",
      "        return 100.0\r\n",
      "    else:\r\n",
      "        return 0.0\r\n",
      "        \r\n",
      "# Runs your code in an IDE (for testing purposes)\r\n",
      "if __name__ == '__main__':    \r\n",
      "    result = test_passed()\r\n",
      "    print(\"Unit Test Returned:\", result)\n",
      "lsn24_mitches\n"
     ]
    }
   ],
   "source": [
    "testcase = problems_df[\"testcase\"][62]\n",
    "problem_id = problems_df[\"id\"][62]\n",
    "print(testcase)\n",
    "print(problem_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AUTOGRADER IMPORT REMOVED\n",
      "\n",
      "# ---------------------------------------------------------------------\n",
      "# Lab: REDACTED_NAME Hall Calorie Analysis (ugh)\n",
      "# Course: CS110, Fall 2021\n",
      "# ---------------------------------------------------------------------\n",
      "\n",
      "# ---------------------------------------------------------------------\n",
      "# Problem Statement: Write a Python Program that analyzes the food at\n",
      "# REDACTED_NAME Hall.  Your program will ask for the number of meals to analyze\n",
      "# and then get both the 1) name of the meal, as well as 2) the number of\n",
      "# calories per serving.  Your program should output the average calorie\n",
      "# count, as well as the names of all meals that are with 200 calories\n",
      "# of the average.\n",
      "# ---------------------------------------------------------------------\n",
      "calories = input()\n",
      "# meal_table = []\n",
      "# total = 0\n",
      "# number = int(input())\n",
      "# \n",
      "# for i in range(number):\n",
      "#     name = str(input())\n",
      "#     calories = int(input())\n",
      "#     row = [name, calories]\n",
      "#     meal_table.append(row)\n",
      "#     total += calories\n",
      "#     average = total/calories\n",
      "#     \n",
      "# print(average)\n",
      "# \n",
      "# for i in meal_table:\n",
      "#     if i[1] >= (average - 200) or i[1] < (average + 200):\n",
      "#         print(i[0])\n"
     ]
    }
   ],
   "source": [
    "code = df[(df[\"problem_id\"] == \"lsn24####mitches\") & (df[\"score\"] < 100)][\"source_code\"].iloc[1]\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_execution_string(problem_id, testcase):\n",
    "    unit_test_string = testcase\n",
    "    # Allow code execution not in the main clause\n",
    "    unit_test_string = unit_test_string.replace(\"if __name__ == '__main__':\", \"\")\n",
    "    unit_test_string = unit_test_string.replace(\"result = test_passed()\", \"\")\n",
    "    unit_test_string = unit_test_string.replace('print(\"Unit Test Returned:\", result)', \"\")\n",
    "    unit_test_string = unit_test_string.strip()\n",
    "    unit_test_string = unit_test_string + \"\\nresult = test_passed()\\n\"\n",
    "    unit_test_string = unit_test_string + 'print(\"Unit Test Returned:\", result)'\n",
    "    unit_test_string = unit_test_string.replace(\"from cs110 import autograder\", \"import autograder\")\n",
    "    \n",
    "    return unit_test_string\n",
    "\n",
    "def write_code(filepath, code):\n",
    "    with open(filepath, \"w\") as fp:\n",
    "        fp.write(code)\n",
    "        \n",
    "def check_correctness(problem_id, testcase, code):\n",
    "    exec_string = create_execution_string(problem_id, testcase)\n",
    "    write_code(problem_id + \".py\", code)\n",
    "    print(exec_string)\n",
    "    exec_globals = {}\n",
    "    exec(exec_string, exec_globals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import autograder\r\n",
      "import random, math\r\n",
      "\r\n",
      "meal_info = [\r\n",
      "    ['Hot Dogs', 600],\r\n",
      "    ['French Dip', 540],\r\n",
      "    ['Chicken Cordon Bleu', 300],\r\n",
      "    ['Turkey Sandwich', 350],\r\n",
      "    ['Mitch\\'s Mountain', 1100],\r\n",
      "    ['Shepherd\\'s Pie', 272],\r\n",
      "    ['Teriyaki Chicken', 250],\r\n",
      "    ]\r\n",
      "\r\n",
      "# Runs the Python script and sees if it passes the test(s)\r\n",
      "def test_passed():\r\n",
      "    inputs = []\r\n",
      "    expected_outputs = []\r\n",
      "    \r\n",
      "    meal_table = []\r\n",
      "    table_size = random.randint(3, 5)\r\n",
      "    total = 0\r\n",
      "    inputs.append(table_size)\r\n",
      "    \r\n",
      "    for meal in random.sample(meal_info, table_size):\r\n",
      "        total += meal[1]\r\n",
      "        inputs.append(meal[0])\r\n",
      "        inputs.append(meal[1])\r\n",
      "        meal_table.append([meal[0], meal[1]])\r\n",
      "    \r\n",
      "    average = total / len(meal_table)\r\n",
      "    expected_outputs.append(str(average))\r\n",
      "    \r\n",
      "    for m in meal_table:\r\n",
      "        if m[1] >= average-200 and m[1] <= average+200:\r\n",
      "            expected_outputs.append(m[0])\r\n",
      "    \r\n",
      "    output, errors = autograder.run_script(\"lsn24_mitches.py\", inputs)\r\n",
      "    lines = output.strip().split('\\n')\r\n",
      "    \r\n",
      "    lines_match = autograder.compare_strings(lines, expected_outputs)\r\n",
      "    \r\n",
      "    if lines_match == len(expected_outputs):\r\n",
      "        return 100.0\r\n",
      "    else:\r\n",
      "        return 0.0\r\n",
      "        \r\n",
      "# Runs your code in an IDE (for testing purposes)\n",
      "result = test_passed()\n",
      "print(\"Unit Test Returned:\", result)\n",
      "Unit Test Returned: 0.0\n"
     ]
    }
   ],
   "source": [
    "check_correctness(problem_id, testcase, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import import_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'autograder' from '/home/koutchc1/learnlab2023/notebooks/autograder.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import autograder\n",
    "a = import_module(\"autograder\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/koutchc1/learnlab2023/notebooks/autograder.py'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autograder.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': 'autograder',\n",
       " '__doc__': ' Copy of a set of utility functions that were used in the FalconCode project. ',\n",
       " '__package__': '',\n",
       " '__loader__': <_frozen_importlib_external.SourceFileLoader at 0x2b3fa667b290>,\n",
       " '__spec__': ModuleSpec(name='autograder', loader=<_frozen_importlib_external.SourceFileLoader object at 0x2b3fa667b290>, origin='/home/koutchc1/learnlab2023/notebooks/autograder.py'),\n",
       " '__file__': '/home/koutchc1/learnlab2023/notebooks/autograder.py',\n",
       " '__cached__': '/home/koutchc1/learnlab2023/notebooks/__pycache__/autograder.cpython-311.pyc',\n",
       " '__builtins__': {'__name__': 'builtins',\n",
       "  '__doc__': \"Built-in functions, types, exceptions, and other objects.\\n\\nThis module provides direct access to all 'built-in'\\nidentifiers of Python; for example, builtins.len is\\nthe full name for the built-in function len().\\n\\nThis module is not normally accessed explicitly by most\\napplications, but can be useful in modules that provide\\nobjects with the same name as a built-in value, but in\\nwhich the built-in of that name is also needed.\",\n",
       "  '__package__': '',\n",
       "  '__loader__': _frozen_importlib.BuiltinImporter,\n",
       "  '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'),\n",
       "  '__build_class__': <function __build_class__>,\n",
       "  '__import__': <function __import__(name, globals=None, locals=None, fromlist=(), level=0)>,\n",
       "  'abs': <function abs(x, /)>,\n",
       "  'all': <function all(iterable, /)>,\n",
       "  'any': <function any(iterable, /)>,\n",
       "  'ascii': <function ascii(obj, /)>,\n",
       "  'bin': <function bin(number, /)>,\n",
       "  'breakpoint': <function breakpoint>,\n",
       "  'callable': <function callable(obj, /)>,\n",
       "  'chr': <function chr(i, /)>,\n",
       "  'compile': <function compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1, *, _feature_version=-1)>,\n",
       "  'delattr': <function delattr(obj, name, /)>,\n",
       "  'dir': <function dir>,\n",
       "  'divmod': <function divmod(x, y, /)>,\n",
       "  'eval': <function eval(source, globals=None, locals=None, /)>,\n",
       "  'exec': <function exec(source, globals=None, locals=None, /, *, closure=None)>,\n",
       "  'format': <function format(value, format_spec='', /)>,\n",
       "  'getattr': <function getattr>,\n",
       "  'globals': <function globals()>,\n",
       "  'hasattr': <function hasattr(obj, name, /)>,\n",
       "  'hash': <function hash(obj, /)>,\n",
       "  'hex': <function hex(number, /)>,\n",
       "  'id': <function id(obj, /)>,\n",
       "  'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x2b3fa96a2390>>,\n",
       "  'isinstance': <function isinstance(obj, class_or_tuple, /)>,\n",
       "  'issubclass': <function issubclass(cls, class_or_tuple, /)>,\n",
       "  'iter': <function iter>,\n",
       "  'aiter': <function aiter(async_iterable, /)>,\n",
       "  'len': <function len(obj, /)>,\n",
       "  'locals': <function locals()>,\n",
       "  'max': <function max>,\n",
       "  'min': <function min>,\n",
       "  'next': <function next>,\n",
       "  'anext': <function anext>,\n",
       "  'oct': <function oct(number, /)>,\n",
       "  'ord': <function ord(c, /)>,\n",
       "  'pow': <function pow(base, exp, mod=None)>,\n",
       "  'print': <function print(*args, sep=' ', end='\\n', file=None, flush=False)>,\n",
       "  'repr': <function repr(obj, /)>,\n",
       "  'round': <function round(number, ndigits=None)>,\n",
       "  'setattr': <function setattr(obj, name, value, /)>,\n",
       "  'sorted': <function sorted(iterable, /, *, key=None, reverse=False)>,\n",
       "  'sum': <function sum(iterable, /, start=0)>,\n",
       "  'vars': <function vars>,\n",
       "  'None': None,\n",
       "  'Ellipsis': Ellipsis,\n",
       "  'NotImplemented': NotImplemented,\n",
       "  'False': False,\n",
       "  'True': True,\n",
       "  'bool': bool,\n",
       "  'memoryview': memoryview,\n",
       "  'bytearray': bytearray,\n",
       "  'bytes': bytes,\n",
       "  'classmethod': classmethod,\n",
       "  'complex': complex,\n",
       "  'dict': dict,\n",
       "  'enumerate': enumerate,\n",
       "  'filter': filter,\n",
       "  'float': float,\n",
       "  'frozenset': frozenset,\n",
       "  'property': property,\n",
       "  'int': int,\n",
       "  'list': list,\n",
       "  'map': map,\n",
       "  'object': object,\n",
       "  'range': range,\n",
       "  'reversed': reversed,\n",
       "  'set': set,\n",
       "  'slice': slice,\n",
       "  'staticmethod': staticmethod,\n",
       "  'str': str,\n",
       "  'super': super,\n",
       "  'tuple': tuple,\n",
       "  'type': type,\n",
       "  'zip': zip,\n",
       "  '__debug__': True,\n",
       "  'BaseException': BaseException,\n",
       "  'BaseExceptionGroup': BaseExceptionGroup,\n",
       "  'Exception': Exception,\n",
       "  'GeneratorExit': GeneratorExit,\n",
       "  'KeyboardInterrupt': KeyboardInterrupt,\n",
       "  'SystemExit': SystemExit,\n",
       "  'ArithmeticError': ArithmeticError,\n",
       "  'AssertionError': AssertionError,\n",
       "  'AttributeError': AttributeError,\n",
       "  'BufferError': BufferError,\n",
       "  'EOFError': EOFError,\n",
       "  'ImportError': ImportError,\n",
       "  'LookupError': LookupError,\n",
       "  'MemoryError': MemoryError,\n",
       "  'NameError': NameError,\n",
       "  'OSError': OSError,\n",
       "  'ReferenceError': ReferenceError,\n",
       "  'RuntimeError': RuntimeError,\n",
       "  'StopAsyncIteration': StopAsyncIteration,\n",
       "  'StopIteration': StopIteration,\n",
       "  'SyntaxError': SyntaxError,\n",
       "  'SystemError': SystemError,\n",
       "  'TypeError': TypeError,\n",
       "  'ValueError': ValueError,\n",
       "  'Warning': Warning,\n",
       "  'FloatingPointError': FloatingPointError,\n",
       "  'OverflowError': OverflowError,\n",
       "  'ZeroDivisionError': ZeroDivisionError,\n",
       "  'BytesWarning': BytesWarning,\n",
       "  'DeprecationWarning': DeprecationWarning,\n",
       "  'EncodingWarning': EncodingWarning,\n",
       "  'FutureWarning': FutureWarning,\n",
       "  'ImportWarning': ImportWarning,\n",
       "  'PendingDeprecationWarning': PendingDeprecationWarning,\n",
       "  'ResourceWarning': ResourceWarning,\n",
       "  'RuntimeWarning': RuntimeWarning,\n",
       "  'SyntaxWarning': SyntaxWarning,\n",
       "  'UnicodeWarning': UnicodeWarning,\n",
       "  'UserWarning': UserWarning,\n",
       "  'BlockingIOError': BlockingIOError,\n",
       "  'ChildProcessError': ChildProcessError,\n",
       "  'ConnectionError': ConnectionError,\n",
       "  'FileExistsError': FileExistsError,\n",
       "  'FileNotFoundError': FileNotFoundError,\n",
       "  'InterruptedError': InterruptedError,\n",
       "  'IsADirectoryError': IsADirectoryError,\n",
       "  'NotADirectoryError': NotADirectoryError,\n",
       "  'PermissionError': PermissionError,\n",
       "  'ProcessLookupError': ProcessLookupError,\n",
       "  'TimeoutError': TimeoutError,\n",
       "  'IndentationError': IndentationError,\n",
       "  'IndexError': IndexError,\n",
       "  'KeyError': KeyError,\n",
       "  'ModuleNotFoundError': ModuleNotFoundError,\n",
       "  'NotImplementedError': NotImplementedError,\n",
       "  'RecursionError': RecursionError,\n",
       "  'UnboundLocalError': UnboundLocalError,\n",
       "  'UnicodeError': UnicodeError,\n",
       "  'BrokenPipeError': BrokenPipeError,\n",
       "  'ConnectionAbortedError': ConnectionAbortedError,\n",
       "  'ConnectionRefusedError': ConnectionRefusedError,\n",
       "  'ConnectionResetError': ConnectionResetError,\n",
       "  'TabError': TabError,\n",
       "  'UnicodeDecodeError': UnicodeDecodeError,\n",
       "  'UnicodeEncodeError': UnicodeEncodeError,\n",
       "  'UnicodeTranslateError': UnicodeTranslateError,\n",
       "  'ExceptionGroup': ExceptionGroup,\n",
       "  'EnvironmentError': OSError,\n",
       "  'IOError': OSError,\n",
       "  'open': <function io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       "  'copyright': Copyright (c) 2001-2023 Python Software Foundation.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 2000 BeOpen.com.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
       "  All Rights Reserved.,\n",
       "  'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
       "      for supporting Python development.  See www.python.org for more information.,\n",
       "  'license': Type license() to see the full license text,\n",
       "  'help': Type help() for interactive help, or help(object) for help about object.,\n",
       "  'execfile': <function _pydev_bundle._pydev_execfile.execfile(file, glob=None, loc=None)>,\n",
       "  'runfile': <function _pydev_bundle.pydev_umd.runfile(filename, args=None, wdir=None, namespace=None)>,\n",
       "  '__IPYTHON__': True,\n",
       "  'display': <function IPython.core.display_functions.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, raw=False, clear=False, **kwargs)>,\n",
       "  'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x2b3fa96a3b10>>},\n",
       " 'builtins': <module 'builtins' (built-in)>,\n",
       " 'patch': <function unittest.mock.patch(target, new=sentinel.DEFAULT, spec=None, create=False, spec_set=None, autospec=None, new_callable=None, *, unsafe=False, **kwargs)>,\n",
       " 'StringIO': _io.StringIO,\n",
       " 'redirect_stdout': contextlib.redirect_stdout,\n",
       " 'redirect_stderr': contextlib.redirect_stderr,\n",
       " 'run_script': <function autograder.run_script(filepath, input_list)>,\n",
       " 'compare_strings': <function autograder.compare_strings(outputs, expected_outputs)>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem_id_to_testcase(problems_df):\n",
    "    return problems_df[[\"id\", \"testcase\"]].set_index(\"id\")[\"testcase\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'testcase': {'a3_3_animals': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nlist_of_animals = [\\'Tiger\\', \\'Deer\\', \\'Zebra\\', \\'Elephant\\', \\'Swordfish\\', \\'Giraffe\\', \\'Sloth\\']\\r\\n\\r\\ndef solution():\\r\\n    result = []\\r\\n    \\r\\n    for item in list_of_animals:\\r\\n        result.append(item)\\r\\n    \\r\\n    return result\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    output, error = autograder.run_script(\"a3_3_animals.py\", [])\\r\\n    expected_output = solution()\\r\\n    num_matches = autograder.compare_strings(output.strip().split(\\'\\\\n\\'), expected_output)\\r\\n    \\r\\n    return round(100 / len(expected_output) * num_matches, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_1_cargo': 'from cs110 import autograder\\nimport random, math\\n\\nsoln_list =  [\\n                \\'C-2\\', \\'C-5\\', \\'C-9\\', \\'C-12\\', \\'C-17\\', \\'UV-18\\', \\'C-20\\', \\'C-21\\', \\'C-22\\', \\'C-23\\', \\'C-26\\', \\'C-27\\',\\n                \\'C-35\\', \\'C-38\\', \\'CT-39\\', \\'C-40\\', \\'C-130\\', \\'C-135\\', \\'C-141\\', \\'ATT\\', \\'CSA\\', \\'NSA\\', \\'GRA\\', \\'CRAF\\'\\n            ] \\n             \\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    \\n    index_list = [1, random.randint(2, len(soln_list)-2), len(soln_list)]\\n    tests_passed = 0\\n\\n    for i in range(len(index_list)):\\n        print(\"----------------------------------------------------------\")\\n        print(\"Testing item #\" + str(index_list[i]) + \": \")\\n        print(\"----------------------------------------------------------\")\\n               \\n        # Runs the Script\\n        output, error_message = autograder.run_script(\"a3_1_cargo.py\", [index_list[i]])\\n\\n        # Test Goes Here\\n        lines = output.split(\"\\\\n\")\\n        \\n        if lines[0] == soln_list[index_list[i]-1]:\\n            print(\"Looks Good!\")\\n            tests_passed += 1\\n        elif error_message == \\'\\' and lines[0] != soln_list[index_list[i]-1]:\\n            print(\"Unexpected Output (Expected \" + str(soln_list[index_list[i]-1]) + \")\")\\n    \\n        print()\\n    \\n    return (100 / len(index_list)) * tests_passed\\n\\n\\n# ---------------------------------------------------------------------\\n# Optional\\n# Runs your code in an IDE (for testing purposes)\\n# ---------------------------------------------------------------------\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_3_games': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nlist_of_games = [\\'Monopoly\\', \\'Risk\\', \\'Clue\\', \\'Chess\\', \\'Operation\\', \\'Jenga\\', \\'Jumanji\\']\\r\\n\\r\\ndef solution():\\r\\n    result = []\\r\\n    \\r\\n    for item in list_of_games:\\r\\n        result.append(item)\\r\\n    \\r\\n    return result\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    output, error = autograder.run_script(\"a3_3_games.py\", [])\\r\\n    expected_output = solution()\\r\\n    num_matches = autograder.compare_strings(output.strip().split(\\'\\\\n\\'), expected_output)\\r\\n    \\r\\n    return round(100 / len(expected_output) * num_matches, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_4_heights': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nSTUDENT_FILE = \"a3_4_heights.py\"\\r\\nANSWER = 8942\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    output, error = autograder.run_script(STUDENT_FILE, [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    score = 0\\r\\n    \\r\\n    if len(lines) >= 1:           \\r\\n        if autograder.equals(lines[0], ANSWER):\\r\\n            print(\"CORRECT: Range Looks Good!\")\\r\\n            score += 100\\r\\n        else:\\r\\n            print(\"Incorrect range.  Remember that the range is the difference between the max and the min\")\\r\\n            \\r\\n    else:\\r\\n        print(\"More lines expected in your answer.  Make sure you are printing out the range.\")\\r\\n    \\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'pex3': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:\\r\\n        print(\"----------------------------------------------------------------------\")\\r\\n        print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n        print(\"----------------------------------------------------------------------\\\\n\")\\r\\n        print(\"Thank you for your submission. Your instructor will manually grade your scene.\")\\r\\n        print(\"Remember to try your program against both the 5x5 and 10x10 mars_map\\'s.\")\\r\\n        return 0.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'pex1': 'from cs110 import autograder\\nfrom itertools import permutations\\n\\nimport sys\\nimport subprocess\\nimport random\\n\\n# ---------------------------------------------------------------------\\n# PEX1 Unit Test\\n# ---------------------------------------------------------------------\\n#list of dictionaries corresponding to the tests contained in test tuples\\nanswers = [\\n    {\\n     \\'00 Enter your age upon commissioning:\\':\"\",\\n     \\'01 Enter the number of years you expect to serve:\\':\"\",\\n     \\'02 Enter your life expectancy (age):\\':\"\",\\n     \\'03 Enter percentage of base pay contributed to TSP (as decimal):\\':\"\",\\n     \\'04 Enter estimated annual return interest rate (as decimal):\\':\"\",\\n     \\'05 Total paid months in retirement:\\':444,\\n     \\'06 TSP government contribution percent for BRS:\\':0.05,\\n     \\'07 TSP value at retirement for BRS plan:\\':605892.71,\\n     \\'08 TSP value after growth throughout retirement for BRS plan:\\':5547881.1,\\n     \\'09 TSP value at retirement for Legacy plan:\\':454419.53,\\n     \\'10 TSP value after growth throughout retirement for Legacy plan:\\':4160910.83,\\n     \\'11 BRS Retirement Totals\\':\"\",\\n     \\'12 TSP Savings Total:\\':5547881.1,\\n     \\'13 Fed Pension Annuity Total:\\':1692528.0,\\n     \\'14 Total Retirement:\\':7240409.1,\\n     \\'15 Legacy Retirement Totals\\':\"\",\\n     \\'16 TSP Savings Total:\\':4160910.83,\\n     \\'17 Fed Pension Annuity Total:\\':2115660.0,\\n     \\'18 Total Retirement:\\':6276570.83,\\n     \\'19 BRS Retirement Total greater by\\' : 963838.28\\n    },\\n    # 2nd output\\n    {\\n     \\'00 Enter your age upon commissioning:\\':\"\",\\n     \\'01 Enter the number of years you expect to serve:\\':\"\",\\n     \\'02 Enter your life expectancy (age):\\':\"\",\\n     \\'03 Enter percentage of base pay contributed to TSP (as decimal):\\':\"\",\\n     \\'04 Enter estimated annual return interest rate (as decimal):\\':\"\",\\n     \\'05 Total paid months in retirement:\\':444,\\n     \\'06 TSP government contribution percent for BRS:\\':0.02,\\n     \\'07 TSP value at retirement for BRS plan:\\':90883.91,\\n     \\'08 TSP value after growth throughout retirement for BRS plan:\\':832182.17,\\n     \\'09 TSP value at retirement for Legacy plan:\\':30294.64,\\n     \\'10 TSP value after growth throughout retirement for Legacy plan:\\':277394.06,\\n     \\'11 BRS Retirement Totals\\':\"\",\\n     \\'12 TSP Savings Total:\\':832182.17,\\n     \\'13 Fed Pension Annuity Total:\\':1692528.0,\\n     \\'14 Total Retirement:\\':2524710.17,\\n     \\'15 Legacy Retirement Totals\\':\"\",\\n     \\'16 TSP Savings Total:\\':277394.06,\\n     \\'17 Fed Pension Annuity Total:\\':2115660.0,\\n     \\'18 Total Retirement:\\':2393054.06,\\n     \\'19 BRS Retirement Total greater by\\':131656.11\\n    },\\n    # 3rd output\\n    {\\n     \\'00 Enter your age upon commissioning:\\':\"\",\\n     \\'01 Enter the number of years you expect to serve:\\':\"\",\\n     \\'02 Enter your life expectancy (age):\\':\"\",\\n     \\'03 Enter percentage of base pay contributed to TSP (as decimal):\\':\"\",\\n     \\'04 Enter estimated annual return interest rate (as decimal):\\':\"\",\\n     \\'05 Total paid months in retirement:\\': 288,\\n     \\'06 TSP government contribution percent for BRS:\\': 0.02,\\n     \\'07 TSP value at retirement for BRS plan:\\':117137.36,\\n     \\'08 TSP value after growth throughout retirement for BRS plan:\\':387941.34,\\n     \\'09 TSP value at retirement for Legacy plan:\\':39045.79,\\n     \\'10 TSP value after growth throughout retirement for Legacy plan:\\':129313.78,\\n     \\'11 BRS Retirement Totals\\':\"\",\\n     \\'12 TSP Savings Total:\\':387941.34,\\n     \\'13 Fed Pension Annuity Total:\\':1372320.0,\\n     \\'14 Total Retirement:\\':1760261.34,\\n     \\'15 Legacy Retirement Totals\\':\"\",\\n     \\'16 TSP Savings Total:\\':129313.78,\\n     \\'17 Fed Pension Annuity Total:\\':1715400.0,\\n     \\'18 Total Retirement:\\':1844713.78,\\n     \\'19 Legacy Retirement Total greater by\\' :84452.44\\n    },\\n    #4th test case\\n    {\\'00 Enter your age upon commissioning:\\': \\'\\',\\n     \\'01 Enter the number of years you expect to serve:\\': \\'\\',\\n     \\'02 Enter your life expectancy (age):\\': \\'\\',\\n     \\'03 Enter percentage of base pay contributed to TSP (as decimal):\\': \\'\\',\\n     \\'04 Enter estimated annual return interest rate (as decimal):\\': \\'\\',\\n     \\'05 Total paid months in retirement:\\': 204.0,\\n     \\'06 TSP government contribution percent for BRS:\\': 0.03,\\n     \\'07 TSP value at retirement for BRS plan:\\': 120241.56,\\n     \\'08 TSP value after growth throughout retirement for BRS plan:\\': 237073.9,\\n     \\'09 TSP value at retirement for Legacy plan:\\': 48096.62,\\n     \\'10 TSP value after growth throughout retirement for Legacy plan:\\': 94829.56,\\n     \\'11 BRS Retirement Totals\\': \\'\\',\\n     \\'12 TSP Savings Total:\\': 237073.9,\\n     \\'13 Fed Pension Annuity Total:\\': 777648.0,\\n     \\'14 Total Retirement:\\': 1014721.9,\\n     \\'15 Legacy Retirement Totals\\': \\'\\',\\n     \\'16 TSP Savings Total:\\': 94829.56,\\n     \\'17 Fed Pension Annuity Total:\\': 972060.0,\\n     \\'18 Total Retirement:\\': 1066889.56,\\n     \\'19 Legacy Retirement Total greater by\\': 52167.66\\n     },\\n    #5th test case\\n    {\\n     \\'00 Enter your age upon commissioning:\\': \\'\\',\\n     \\'01 Enter the number of years you expect to serve:\\': \\'\\',\\n     \\'02 Enter your life expectancy (age):\\': \\'\\',\\n     \\'03 Enter percentage of base pay contributed to TSP (as decimal):\\': \\'\\',\\n     \\'04 Enter estimated annual return interest rate (as decimal):\\': \\'\\',\\n     \\'05 Total paid months in retirement:\\': 540.0,\\n     \\'06 TSP government contribution percent for BRS:\\': 0.02,\\n     \\'07 TSP value at retirement for BRS plan:\\': 52576.0,\\n     \\'08 TSP value after growth throughout retirement for BRS plan:\\': 496500.89,\\n     \\'09 TSP value at retirement for Legacy plan:\\': 17525.33,\\n     \\'10 TSP value after growth throughout retirement for Legacy plan:\\': 165500.3,\\n     \\'11 BRS Retirement Totals\\': \\'\\',\\n     \\'12 TSP Savings Total:\\': 496500.89,\\n     \\'13 Fed Pension Annuity Total:\\': 1543860.0,\\n     \\'14 Total Retirement:\\': 2040360.89,\\n     \\'15 Legacy Retirement Totals\\': \\'\\',\\n     \\'16 TSP Savings Total:\\': 165500.3,\\n     \\'17 Fed Pension Annuity Total:\\': 1929825.0,\\n     \\'18 Total Retirement:\\': 2095325.3,\\n     \\'19 Legacy Retirement Total greater by\\': 54964.41\\n    },\\n    #6th test case\\n    {\\'00 Enter your age upon commissioning:\\': \\'\\',\\n     \\'01 Enter the number of years you expect to serve:\\': \\'\\',\\n     \\'02 Enter your life expectancy (age):\\': \\'\\',\\n     \\'03 Enter percentage of base pay contributed to TSP (as decimal):\\': \\'\\',\\n     \\'04 Enter estimated annual return interest rate (as decimal):\\': \\'\\',\\n     \\'05 Total paid months in retirement:\\': 216.0,\\n     \\'06 TSP government contribution percent for BRS:\\': 0.05,\\n     \\'07 TSP value at retirement for BRS plan:\\': 206924.5,\\n     \\'08 TSP value after growth throughout retirement for BRS plan:\\': 424603.87,\\n     \\'09 TSP value at retirement for Legacy plan:\\': 103462.25,\\n     \\'10 TSP value after growth throughout retirement for Legacy plan:\\': 212301.93,\\n     \\'11 BRS Retirement Totals\\': \\'\\',\\n     \\'12 TSP Savings Total:\\': 424603.87,\\n     \\'13 Fed Pension Annuity Total:\\': 741052.8,\\n     \\'14 Total Retirement:\\': 1165656.67,\\n     \\'15 Legacy Retirement Totals\\': \\'\\',\\n     \\'16 TSP Savings Total:\\': 212301.93,\\n     \\'17 Fed Pension Annuity Total:\\': 926316.0,\\n     \\'18 Total Retirement:\\': 1138617.93,\\n     \\'19 BRS Retirement Total greater by\\': 27038.73\\n     }\\n    \\n]\\n\\n#helper function to check for numbers\\ndef has_number(_str):\\n    return any((x.isdigit() for x in _str))\\n\\n#takes a student output and returns a dictionary\\ndef parse_student_output(_list):\\n    ret_dict = {}\\n    sort_str = \"\"\\n    counter = 0\\n    for line_num, line in enumerate(_list):\\n        #make a unique key for the start of every line\\n        sort_str = \"{} \".format(line_num-counter)\\n        if line_num-counter < 10:\\n            sort_str = \"0\"+sort_str\\n        #ignore blank lines\\n        if line.strip() == \"\":\\n            counter+=1\\n        # If there is a number in the line it\\n        # is either a line with a dollar amount or\\n        # one of the calculated inputs\\n        elif has_number(line):\\n            if \"$\" in line:\\n                _spl = line.split(\"$\")\\n                try:\\n                    val = float(_spl[1].strip())\\n                except:\\n                    val = _spl[1].strip() + \" Could not be converted to float\"\\n                ret_dict[sort_str+_spl[0].strip()] = val\\n            # One of the calculated inputs\\n            else:\\n                if \"greater by\" in line and \"$\" not in line:\\n                    val = \"Error (Missing a \\'$\\' )\"\\n                    ret_dict[sort_str+line.strip()] = val\\n                # catches if a student simply prints out a number\\n                # which is incorrect\\n                else:\\n                    try:\\n                        idx = line.index(\":\")+1\\n                        val = float(line[idx:].strip())\\n                        ret_dict[sort_str+line[:idx].strip()] = val\\n                    #Catches if a student forgot a : a $ or has something that cannot be converted to a float\\n                    except:\\n                        val = \"Error (Missing a \\':\\' or \\'$\\' or Could not Convert to Float)\"\\n                        ret_dict[sort_str+line.strip()] = val\\n            #The input lines and some of the spacing need empty strings\\n        # as their keys\\n        else:\\n            ret_dict[sort_str+line.strip()] = \"\"\\n    return ret_dict\\n\\n# Helper function to compare two sets of strings\\ndef compare_strings(student_output_list, expected_output_list):\\n    num_matches = 0\\n    #Make a lookup table for the expected lines based on the\\n    #    number output that they should be ignoring spaces\\n    expected_lines = sorted(expected_output_list)\\n    #Iterate through the student output\\n    for num,line in enumerate(sorted(student_output_list)):\\n        # Make an expected output from the expected output dictionary\\n        exp = expected_lines[num][3:]+str(expected_output_list[expected_lines[num]])\\n        print(\"Line {}\".format(num),end=\\' \\')\\n        #check if the line is in the output list\\n        if line in expected_output_list:\\n            \\n            # if the key is a float do a number comparison\\n            if isinstance(student_output_list[line],float):\\n                if \"contrib\" in line:\\n                    contr_diff = abs(expected_output_list[line] - student_output_list[line])\\n                    if contr_diff > 0.001:\\n                        print(\"INCORRECT the value for {} {} does not match\".format(line[3:],student_output_list[line]))\\n                        print(\"Expected: \"+ exp)\\n                    else:\\n                        print(\"CORRECT\")\\n                        num_matches +=1\\n                elif \"greater\" in line:\\n                    if expected_output_list[line]-1 <= student_output_list[line] <= expected_output_list[line]+1:\\n                        print(\"CORRECT\")\\n                        num_matches += 1\\n                    else:\\n                        print(\"INCORRECT the value for {} $ {} is off by more than 1\".format(line[3:],student_output_list[line]))\\n                        print(\"Expected: \"+ expected_lines[num][3:]+ \" $ \" +str(expected_output_list[expected_lines[num]]))\\n                elif expected_output_list[line]-1 <= student_output_list[line] <= expected_output_list[line]+1:\\n                    print(\"CORRECT\")\\n                    num_matches +=1\\n                else:\\n                    print(\"INCORRECT the value for {} {} is off by more than 1\".format(line[3:],student_output_list[line]))\\n                    print(\"Expected: \"+ exp)\\n            #string matching\\n            elif student_output_list[line] == expected_output_list[line]:\\n                    print(\"CORRECT\")\\n                    num_matches += 1\\n            else:\\n                print(\"INCORRECT (Expected: \\'{}\\')\".format(exp))\\n                print(\"Is there a mispelling?       (Saw: \\'{} {}\\')\".format(line[3:],student_output_list[line]))\\n        #Found a line that should not be included in the output\\n        else:          \\n            print(\"INCORRECT (Unexpected Line: \\'{} {}\\')\".format(line[3:],student_output_list[line]))\\n            if \"greater\" in exp:\\n                print(\"Expected: \"+ expected_lines[num][3:]+ \" $ \" +str(expected_output_list[expected_lines[num]]))\\n            else:\\n                print(\"Expected: \"+ exp)\\n    \\n    print(num_matches, \"out of\", len(expected_output_list), \"lines match\")\\n    return num_matches\\n\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    #the input values for each of the 6 possible test cases\\n    test_tuples = ((21,20,78,.15,.06),(21,20,78,.01,.06),(21,25,70,.01,.05),(27,20,64,0.02,0.04),(25,15,85,0.01,0.05),(24,18,60,.05,.04))\\n    \\n    # Chooses the first four items from a random permutation\\n    # of the six test cases\\n    test_order = random.choice(tuple(permutations(range(len(test_tuples)))))[0:4]\\n    score = 0\\n    \\n    for i in test_order:\\n        print(\"--------------------------\")\\n        print(\"Test {} of {}\".format((i+1),len(test_tuples)))\\n        print(\"--------------------------\")\\n        \\n        # Runs the Script\\n        output, error_message = autograder.run_script(\"pex1.py\",\\n                                                      [\\n                                                       test_tuples[i][0],\\n                                                       test_tuples[i][1],\\n                                                       test_tuples[i][2],\\n                                                       test_tuples[i][3],\\n                                                       test_tuples[i][4]\\n                                                      ])\\n        _parsed_output = parse_student_output(output.strip().split(\"\\\\n\"))\\n        # Checks to See if the Program Passed the Test\\n        num_lines_match = compare_strings(_parsed_output,\\n                                          answers[i])\\n        num_lines_expected = len(answers[i])\\n        #Adds a static 25% for each of the 4 test cases\\n        if num_lines_match == num_lines_expected:\\n            score += 25\\n            print(\"\\\\nCORRECT\\\\n\")\\n        else:\\n            score += round((num_lines_match / num_lines_expected) * 25, 1)\\n            print(\\n\\'\\'\\'\\nTry Again\\nOne or more lines is incorrect for the following test case:\\nCommission Age: {},\\nYears Served: {},\\nDeath Age: {},\\nTSP Contribution: {},\\nAverage Return: {}\\'\\'\\'.format(test_tuples[i][0],\\n                                 test_tuples[i][1],\\n                                 test_tuples[i][2],\\n                                 test_tuples[i][3],\\n                                 test_tuples[i][4]))\\n    \\n    return score\\n\\n\\n\\n# Testbench (to be run in an IDE)\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result, \"of 100 points.\")\\n\\n#   Optional code for generating more test cases\\n#     output, error_message = autograder.run_script(\"pex1.py\",(24,18,60,.05,.04))\\n#     _parsed_output = parse_student_output(output.strip().split(\"\\\\n\"))\\n#     print(_parsed_output)\\n#     for k,v in _parsed_output.items():\\n#         print(k,v)\\n#\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn9_practice4': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef solution(area_1, area_2, area_3):\\r\\n    area_1 = area_1 * 0.0015625\\r\\n    area_3 = area_3 * 0.386102\\r\\n\\r\\n    if area_1 > area_2 and area_1 > area_3:\\r\\n        return \"Plot 1 is the biggest\"\\r\\n    elif area_2 > area_1 and area_2 > area_3:\\r\\n        return \"Plot 2 is the biggest\"\\r\\n    elif area_3 > area_1 and area_3 > area_2:\\r\\n        return \"Plot 3 is the biggest\"\\r\\n    \\r\\n    return \"This should never return\"\\r\\n\\r\\ndef run_test(area1, area2, area3):\\r\\n    global num_tests_run, num_tests_passed\\r\\n    \\r\\n    num_tests_run += 1\\r\\n    expected_output = solution(area1, area2, area3)\\r\\n        \\r\\n    print(\"--------------------------------------------\")\\r\\n    print(\"Comparing %1.1f acres, %1.1f sq miles, and %1.1f sq km\" % (area1, area2, area3))\\r\\n    print(\"--------------------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn9_practice4.py\", [area1, area2, area3])\\r\\n    \\r\\n    if output.strip() == expected_output:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", expected_output)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(random.uniform(100, 1000), random.uniform(0.1, 2.0), random.uniform(0.1, 5.0))\\r\\n    run_test(random.uniform(100, 1000), random.uniform(0.1, 2.0), random.uniform(0.1, 5.0))\\r\\n    run_test(random.uniform(100, 1000), random.uniform(0.1, 2.0), random.uniform(0.1, 5.0))\\r\\n\\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn9_practice3': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    \\r\\n    dollar_amount = round(random.uniform(1.00, 1000.00), 2)\\r\\n    pound_amount = dollar_amount / 1.25\\r\\n    won_amount = dollar_amount / 0.00083\\r\\n    peso_amount = won_amount / 53.81\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn9_practice3.py\", [dollar_amount])   \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], pound_amount):\\r\\n        print(\"Correct Pound Conversion\")\\r\\n        score += 33\\r\\n    else:\\r\\n        print(\"Incorrect Pound Conversion.  Expected\", pound_amount)\\r\\n        \\r\\n    if len(lines) > 1 and autograder.equals(lines[1], won_amount):\\r\\n        print(\"Correct Won Conversion\")\\r\\n        score += 33\\r\\n    else:\\r\\n        print(\"Incorrect Won Conversion.  Expected\", won_amount)\\r\\n        \\r\\n    if len(lines) > 2 and autograder.equals(lines[2], peso_amount):\\r\\n        print(\"Correct Peso Conversion\")\\r\\n        score += 34\\r\\n    else:\\r\\n        print(\"Incorrect Peso Conversion.  Expected\", peso_amount)\\r\\n    \\r\\n    return score\\r\\n        \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn9_practice2': 'from cs110 import autograder\\nimport random, math\\n\\nnum_tests_passed = 0\\nnum_tests_run = 0\\n\\ndef run_test():\\n    global num_tests_run, num_tests_passed\\n    \\n    x1 = round(random.uniform(-10, 10), 1)\\n    y1 = round(random.uniform(-10, 10), 1)\\n    x2 = round(random.uniform(-10, 10), 1)\\n    y2 = round(random.uniform(-10, 10), 1)\\n    \\n    num_tests_run += 1\\n    solution = math.sqrt(abs(x1-x2)**2 + abs(y1-y2)**2)\\n    \\n    print(\"--------------------------------------------\")\\n    print(\"Calculating distance between (%1.1f, %1.1f) and (%1.1f, %1.1f)\" % (x1, y1, x2, y2))\\n    print(\"--------------------------------------------\")\\n    output, error_message = autograder.run_script(\"lsn9_practice2.py\", [x1, y1, x2, y2], False)\\n    print(\"Your Output:\", output.strip())\\n    \\n    if autograder.equals(output, solution):\\n        print(\"CORRECT!\\\\n\")\\n        num_tests_passed += 1\\n    else:\\n        print(\"INCORRECT\")    \\n        print(\"Expected:\", solution)\\n        print(\"\\\\n\")\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    run_test()\\n    run_test()\\n\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\n\\n        \\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn9_practice1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(class_year):\\r\\n    global num_tests_run, num_tests_passed\\r\\n    \\r\\n    num_tests_run += 1\\r\\n    solution = \"Members of the class of \" + str(class_year) + \" arrived at USAFA in \" + str(class_year - 4)\\r\\n    \\r\\n    print(\"--------------------------------------------\")\\r\\n    print(\"Testing Class Year =\", class_year)\\r\\n    print(\"--------------------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn9_practice1.py\", [class_year], False)\\r\\n        \\r\\n    if output.strip() == solution:\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT\")\\r\\n        print(\"Your Output:\", output.strip())\\r\\n        print(\"Expected:\", solution)\\r\\n        if \".0\" in output.strip():\\r\\n            print(\"*** HINT:  Is year a floating point number? ***\")\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(random.randint(1959, 2024))\\r\\n    run_test(random.randint(1959, 2024))\\r\\n\\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn8_uod': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\n\\r\\n# The Actual Solution\\r\\ndef solution(temp, wind):\\r\\n    if temp < 40:\\r\\n        if wind < 15:\\r\\n            return \"Parkas\"\\r\\n        else:\\r\\n            return \"ABUs\"\\r\\n    elif temp == 40:\\r\\n        if wind < 15:\\r\\n            return \\'A-Jackets\\'\\r\\n        else:\\r\\n            return \\'ABUs\\'\\r\\n    elif temp > 40 and temp <= 60:\\r\\n        if wind < 15:\\r\\n            return \\'A-Jackets\\'\\r\\n        else:\\r\\n            return \\'Parkas\\'\\r\\n    else:\\r\\n        if wind <= 15:\\r\\n            return \\'Blues\\'\\r\\n        else:\\r\\n            return \\'A-Jackets\\'\\r\\n\\r\\n\\r\\ndef run_test(temp, wind):\\r\\n    global num_tests_passed\\r\\n    \\r\\n    print(\"Testing Temp =\", temp, \\'and Wind =\\', wind)\\r\\n    output, error_message = autograder.run_script(\"lsn8_uod.py\", [temp, wind], False)\\r\\n    \\r\\n    print(\"Output:\", output.strip())\\r\\n    \\r\\n    if output.strip() == solution(temp, wind):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\", solution(temp, wind), \"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(39, 14)\\r\\n    run_test(39, 15)\\r\\n    run_test(39, 16)\\r\\n    run_test(40, 14)\\r\\n    run_test(40, 15)\\r\\n    run_test(40, 16)\\r\\n    run_test(50, 14)\\r\\n    run_test(50, 15)\\r\\n    run_test(50, 16)\\r\\n    run_test(60, 14)\\r\\n    run_test(60, 15)\\r\\n    run_test(60, 16)\\r\\n    run_test(61, 14)\\r\\n    run_test(61, 15)\\r\\n    run_test(61, 16)\\r\\n    \\r\\n    return round(num_tests_passed * (100 / 15), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn8_speeding': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# The Actual Solution\\r\\ndef solution(speed):\\r\\n    # Determines what to return based on the table\\r\\n    if (speed <= 65):\\r\\n        return \"No Ticket\"\\r\\n    elif (speed >65 and speed <= 70):\\r\\n        return \"Warning\"\\r\\n    elif (speed > 70 and speed <= 75):\\r\\n        return \"Speeding\"  \\r\\n    elif (speed >75 and speed <= 80):\\r\\n        return \"Reckless Driving\"\\r\\n    elif (speed > 80):\\r\\n        return \"Reckless Endangerment\"\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    num_tests_passed = 0\\r\\n    \\r\\n    SPEEDS_TO_TEST = [random.randint(0, 65),\\r\\n                      65,\\r\\n                      random.randint(66, 70),\\r\\n                      70,\\r\\n                      random.randint(71, 75),\\r\\n                      75,\\r\\n                      random.randint(76, 80),\\r\\n                      80,\\r\\n                      random.randint(81, 100)]\\r\\n    \\r\\n    for i in range(0, len(SPEEDS_TO_TEST)):\\r\\n        print(\"-------------------------------\")\\r\\n        print(\"Test\", i+1)\\r\\n        print(\"-------------------------------\")\\r\\n        speed = SPEEDS_TO_TEST[i]\\r\\n        output, error_message = autograder.run_script(\"lsn8_speeding.py\", [speed])\\r\\n        \\r\\n        if output.strip() == solution(speed):\\r\\n            print(\"SUCCESS!\\\\n\")\\r\\n            num_tests_passed += 1\\r\\n        else:\\r\\n            print(\"INCORRECT.  Expected:\", solution(speed), \"\\\\n\")\\r\\n    \\r\\n    return round(num_tests_passed * (100 / len(SPEEDS_TO_TEST)), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn8_skill2': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n# The Actual Solution\\r\\ndef solution(gpa, apa, mpa):\\r\\n    if gpa < 2.0 or apa < 2.0 or mpa < 2.0:\\r\\n        return \"Probation\"\\r\\n    else:\\r\\n        return \"No Probation\"\\r\\n\\r\\n\\r\\ndef run_test(gpa, apa, mpa):\\r\\n    global num_tests_run, num_tests_passed\\r\\n    \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"--------------------------------------------\")\\r\\n    print(\"Testing GPA =\", str(gpa) + \";\", \"APA =\", str(apa) + \";\", \"MPA =\", mpa)\\r\\n    print(\"--------------------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn8_skill2.py\", [gpa, apa, mpa], False)\\r\\n        \\r\\n    print(output.strip())\\r\\n        \\r\\n    if output.strip() == solution(gpa, apa, mpa):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\", solution(gpa, apa, mpa), \"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    #round(random.uniform(0.1, 1.9),1)\\r\\n    #round(random.uniform(2.1, 4.0),1)\\r\\n    run_test(round(random.uniform(2.1, 4.0),1), round(random.uniform(2.1, 4.0),1), round(random.uniform(2.1, 4.0),1))\\r\\n    run_test(round(random.uniform(0.1, 1.9),1), round(random.uniform(2.1, 4.0),1), round(random.uniform(2.1, 4.0),1))\\r\\n    run_test(round(random.uniform(2.1, 4.0),1), round(random.uniform(0.1, 1.9),1), round(random.uniform(2.1, 4.0),1))\\r\\n    run_test(round(random.uniform(2.1, 4.0),1), round(random.uniform(2.1, 4.0),1), round(random.uniform(0.1, 1.9),1))\\r\\n\\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn8_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n# The Actual Solution\\r\\ndef solution(body_temperature):\\r\\n    if body_temperature >= 97 and body_temperature <= 99:\\r\\n        return \"Normal\"\\r\\n    else:\\r\\n        return \"Abnormal\"\\r\\n\\r\\n\\r\\ndef run_test(body_temperature):\\r\\n    global num_tests_run, num_tests_passed\\r\\n    \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"--------------------------------------------\")\\r\\n    print(\"Testing Temperature =\", body_temperature)\\r\\n    print(\"--------------------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn8_skill1.py\", [body_temperature], False)\\r\\n        \\r\\n    if output.strip() == solution(body_temperature):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\", solution(body_temperature), \"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(96.9)\\r\\n    run_test(97)\\r\\n    run_test(98.5)\\r\\n    run_test(99)\\r\\n    run_test(99.1)\\r\\n\\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn8_roundtrip': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    points_earned = 0\\r\\n            \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 1\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn8_roundtrip.py\", [100,10,30])\\r\\n    \\r\\n    if output.strip() == \"No Refueling Needed\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 33\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: No Refueling Needed\\\\n\")\\r\\n        \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 2\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn8_roundtrip.py\", [100,5,20])\\r\\n    \\r\\n    if output.strip() == \"Refuel on Way Back\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 33\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Refuel on Way Back\\\\n\")\\r\\n    \\r\\n        # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 3\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn8_roundtrip.py\", [100,7,10])\\r\\n    \\r\\n    if output.strip() == \"Refuel En Route\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 34\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Refuel En Route\\\\n\")\\r\\n\\r\\n    return points_earned\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn8_lists': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\n\\r\\n# The Actual Solution\\r\\ndef solution(gpa, apa, mpa):\\r\\n    answer = \"\"\\r\\n    \\r\\n    # Determines what output to present (note how we are using the \" character because of the \\'s)\\r\\n    if (gpa < 3.0 and apa < 3.0 and mpa < 3.0):\\r\\n        answer += \"No List\\\\n\"\\r\\n    elif (gpa >= 3.0 and apa >= 3.0 and mpa >= 3.0):\\r\\n        answer += \"Superintendent\\'s List\\\\n\"\\r\\n    else:\\r\\n        # Note that these are 3 separate if statements; we do this because we don\\'t know what list(s) the cadet is on\\r\\n        if (gpa >= 3.0):\\r\\n            answer += \"Dean\\'s List\\\\n\"\\r\\n        \\r\\n        if (apa >= 3.0):\\r\\n            answer += \"Athletic Director\\'s List\\\\n\"\\r\\n        \\r\\n        if (mpa >= 3.0):\\r\\n            answer += \"Commandant\\'s List\\\\n\"\\r\\n\\r\\n    return answer.strip()\\r\\n\\r\\n\\r\\ndef run_test(gpa, apa, mpa):\\r\\n    global num_tests_passed\\r\\n    \\r\\n    print(\"--------------------------------------------\")\\r\\n    print(\"Testing GPA =\", str(gpa) + \";\", \"APA =\", str(apa) + \";\", \"MPA =\", mpa)\\r\\n    print(\"--------------------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn8_lists.py\", [gpa, apa, mpa])\\r\\n        \\r\\n    if output.strip() == solution(gpa, apa, mpa):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\", solution(gpa, apa, mpa), \"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(2.8, 2.6, 2.5)\\r\\n    run_test(3.5, 3.2, 2.8)\\r\\n    run_test(3.3, 2.8, 3.4)\\r\\n    run_test(3.6, 3.8, 3.2)\\r\\n    run_test(2.8, 3.5, 3.8)\\r\\n    \\r\\n    return round(num_tests_passed * (100 / 5), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn8_fuel': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    points_earned = 0\\r\\n            \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 1\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn8_fuel.py\", [30,60])\\r\\n    \\r\\n    if output.strip() == \"Return to base\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 25\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Return to base\\\\n\")\\r\\n        \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 2\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn8_fuel.py\", [60,60])\\r\\n    \\r\\n    if output.strip() == \"Resume flight\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 25\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Resume flight\\\\n\")\\r\\n    \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 3\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn8_fuel.py\", [40,80])\\r\\n    \\r\\n    if output.strip() == \"Resume flight\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 25\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Resume flight\\\\n\")\\r\\n\\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 4\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn8_fuel.py\", [60,80])\\r\\n    \\r\\n    if output.strip() == \"Resume flight\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 25\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Resume flight\\\\n\")\\r\\n\\r\\n    return points_earned\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn7_skill2': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    points_earned = 0\\r\\n            \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 1 - CS110\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn7_skill2.py\", [\"CS110\"])\\r\\n    \\r\\n    if output.strip() == \"You get to program!\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 50\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: You get to program!\\\\n\")\\r\\n        \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 2 - Another Class\")\\r\\n    print(\"-------------------------------\")\\r\\n    classes = [\\'Math 151\\', \\'English 111\\', \\'Physics 110\\']\\r\\n    random_class = classes[random.randint(0, len(classes)-1)]\\r\\n    output, error_message = autograder.run_script(\"lsn7_skill2.py\", [random_class])\\r\\n    \\r\\n    if output.strip() == \"Boo, no programming.\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 50\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Boo, no programming.\\\\n\")\\r\\n\\r\\n    return points_earned\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn7_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0.0\\r\\n    \\r\\n    if autograder.code_compiles(\"lsn7_skill1.py\"):\\r\\n        file = open(\"lsn7_skill1.py\", \"r\")\\r\\n        file_contents = file.read()\\r\\n    \\r\\n        print(\"----------------------------------------------------------------------\")\\r\\n        print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n        print(\"----------------------------------------------------------------------\\\\n\")\\r\\n    \\r\\n        if \"open_window(\" in file_contents:\\r\\n            print(\"open_window Called\")\\r\\n            score += 33\\r\\n        else:\\r\\n            print(\"open_window does not appear to be called\")\\r\\n        \\r\\n        if \"draw_circle(\" in file_contents:\\r\\n            print(\"draw_circle Called\")\\r\\n            score += 34\\r\\n        else:\\r\\n            print(\"draw_circle does not appear to be called\")\\r\\n            \\r\\n        if \"wait_for_close(\" in file_contents:\\r\\n            print(\"wait_for_close Called\")\\r\\n            score += 33\\r\\n        else:\\r\\n            print(\"wait_for_close does not appear to be called\")\\r\\n            \\r\\n    else:\\r\\n        print(\"There appears to be an error in your python Script that is preventing it from running\")\\r\\n    \\r\\n    return score        \\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn7_positive': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    points_earned = 0\\r\\n    \\r\\n    # Generates Random Values\\r\\n    negative_value = random.randint(-100, -1)\\r\\n    positive_value = random.randint(1, 100)\\r\\n        \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"# Test 1 - Positive Number\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn7_positive.py\", [positive_value])\\r\\n    \\r\\n    if output.strip() == \"POSITIVE\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 33\\r\\n    else:\\r\\n        print(\"Incorrect Output:\", output)\\r\\n        print(\"Expected POSITIVE\\\\n\")\\r\\n        \\r\\n    \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"# Test 2 - Negative Number\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn7_positive.py\", [negative_value])\\r\\n    \\r\\n    if output.strip() == \"NOT POSITIVE\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 33\\r\\n    else:\\r\\n        print(\"Incorrect Output:\", output)\\r\\n        print(\"Expected NOT POSITIVE\\\\n\")\\r\\n        \\r\\n    \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"# Test 3 - Zero\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn7_positive.py\", [0])\\r\\n    \\r\\n    if output.strip() == \"NOT POSITIVE\":\\r\\n        print(\"CORRECT\")\\r\\n        points_earned += 34\\r\\n    else:\\r\\n        print(\"Incorrect Output:\", output)\\r\\n        print(\"Expected NOT POSITIVE\\\\n\")\\r\\n\\r\\n    return points_earned\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn7_largest': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef run_test(num1, num2, num3):\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"# Testing: \" + str(num1) + \" \" + str(num2) + \" \" + str(num3))\\r\\n    print(\"-------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn7_largest.py\", [num1, num2, num3])\\r\\n    \\r\\n    if autograder.equals(output, max(num1, num2, num3)):\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected\", max(num1, num2, num3))\\r\\n        return False\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    tests_passed = 0\\r\\n    \\r\\n    # Generate 3 Random Numbers\\r\\n    num1 = 0\\r\\n    num2 = 0\\r\\n    num3 = 0\\r\\n    \\r\\n    # Ensures that the 3 Numbers are Different\\r\\n    while num1 == num2 or num1 == num3 or num2 == num3:\\r\\n        num1 = random.randint(0, 100)\\r\\n        num2 = random.randint(0, 100)\\r\\n        num3 = random.randint(0, 100)\\r\\n    \\r\\n    # Sorts the numbers\\r\\n    # This is needed so that we can test relationships between numbers\\r\\n    numbers = [num1, num2, num3]\\r\\n    numbers.sort()\\r\\n    num1 = numbers[0]\\r\\n    num2 = numbers[1]\\r\\n    num3 = numbers[2]\\r\\n    \\r\\n    # Test 1:  num1, num2, num3\\r\\n    if run_test(num1, num2, num3):\\r\\n        tests_passed += 1\\r\\n\\r\\n    # Test 2:  num1, num3, num2\\r\\n    if run_test(num1, num3, num2):\\r\\n        tests_passed += 1\\r\\n        \\r\\n    # Test 3:  num2, num3, num1\\r\\n    if run_test(num2, num3, num1):\\r\\n        tests_passed += 1\\r\\n    \\r\\n    # Test 4:  num3, num1, num2\\r\\n    if run_test(num3, num1, num2):\\r\\n        tests_passed += 1\\r\\n\\r\\n    # Test 5:  num2, num1, num3\\r\\n    if run_test(num2, num1, num3):\\r\\n        tests_passed += 1\\r\\n    \\r\\n    # Test 6:  3 Equal Numbers\\r\\n    if run_test(num1, num1, num1):\\r\\n        tests_passed += 1\\r\\n            \\r\\n    print(\"Passed \" + str(tests_passed) + \" out of 6 tests\")\\r\\n    return round(tests_passed * (100 / 6), 1)\\r\\n    \\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn7_classyear': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(class_year):\\r\\n    if class_year < 2021:\\r\\n        return \"Graduate\"\\r\\n    elif class_year == 2021:\\r\\n        return \"Firstie\"\\r\\n    elif class_year == 2022:\\r\\n        return \"Two Degree\"\\r\\n    elif class_year == 2023:\\r\\n        return \"Three Degree\"\\r\\n    elif class_year == 2024:\\r\\n        return \"Four Degree\"\\r\\n    else:\\r\\n        return \"Not a Cadet\"\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    START_YEAR = 2020\\r\\n    END_YEAR = 2025\\r\\n    number_correct = 0\\r\\n    \\r\\n    for year in range(START_YEAR, END_YEAR + 1):\\r\\n        print(\"------------------------------\")\\r\\n        print(\"Testing: \" + str(year))\\r\\n        print(\"------------------------------\")\\r\\n        \\r\\n        # Runs the Script\\r\\n        output, error_message = autograder.run_script(\"lsn7_classyear.py\", [year])\\r\\n                \\r\\n        lines = output.split(\"\\\\n\")\\r\\n               \\r\\n        if lines[0] == solution(year):\\r\\n            print(\"PASS\\\\n\")\\r\\n            number_correct += 1\\r\\n        else:\\r\\n            print(\"FAIL\\\\n\")\\r\\n    \\r\\n    print(\"Passed \" + str(number_correct) + \" out of \" + str(END_YEAR - START_YEAR + 1) + \" tests\")\\r\\n    return round(number_correct * (100 / (END_YEAR - START_YEAR + 1)), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn7_atmosphere': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(altitude):\\r\\n    if altitude >= 0:\\r\\n        if altitude <= 10:\\r\\n            return \"Troposphere\"\\r\\n    if altitude >= 11:\\r\\n        if altitude <= 50:\\r\\n            return \"Stratosphere\"\\r\\n    if altitude >= 51:\\r\\n        if altitude <= 85:\\r\\n            return \"Mesosphere\"\\r\\n    if altitude >= 86:\\r\\n        if altitude <= 1000:\\r\\n            return \"Thermosphere\"\\r\\n    if altitude >= 1001:\\r\\n        if altitude <= 100000:\\r\\n            return \"Exosphere\"\\r\\n        else:\\r\\n            return \"Space\"\\r\\n        \\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    TEST_VALUES = [0, 1, 10, 11, 50, 51, 85, 86, 1000, 1001, 100000, 100001]\\r\\n    tests_passed = 0\\r\\n    \\r\\n    for altitude in TEST_VALUES:\\r\\n        print(\"--------------------------\")\\r\\n        print(\"Testing \" + str(altitude) + \" km\")\\r\\n        print(\"--------------------------\")\\r\\n        \\r\\n        # Runs the Script\\r\\n        output, error_message = autograder.run_script(\"lsn7_atmosphere.py\", [altitude])\\r\\n                               \\r\\n        # Your Test Goes Here (Return True if Pass, False Otherwise)   \\r\\n        if output.strip() == solution(altitude):\\r\\n            print(\"Passed\\\\n\")\\r\\n            tests_passed += 1\\r\\n        else:\\r\\n            print(\"Failed (Expected: \" + solution(altitude) + \")\\\\n\")\\r\\n    \\r\\n    print(\"Passed\", tests_passed, \"out of\", len(TEST_VALUES), \"tests.\")\\r\\n    return round(tests_passed * (100 / len(TEST_VALUES)), 2)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n',\n",
       "  'lsn6_temperature': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    degrees_farenheit = random.random() * 451.0\\r\\n    degrees_celsius = (degrees_farenheit - 32.0) * 5/9\\r\\n    degrees_kelvin = degrees_celsius + 273.15\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn6_temperature.py\", [degrees_farenheit])\\r\\n    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if autograder.equals(lines[0], degrees_kelvin):\\r\\n        print(\"Conversion to Kelvin looks good.\")\\r\\n        if autograder.equals(lines[1], degrees_celsius):\\r\\n            print(\"Conversion to Celsius looks good.\")\\r\\n            return 100.0\\r\\n        else:\\r\\n            print(\"Conversion to Celsius incorrect.\\\\nYour result: \" + str(lines[1]) + \"\\\\nExpected: \" + str(degrees_celsius))\\r\\n            return 50.0\\r\\n    else:\\r\\n        if autograder.equals(lines[0], degrees_celsius):\\r\\n            print(\"Looks like you swapped the order of your output. Look at the Problem Statement and try again.\")\\r\\n        else:\\r\\n            print(\"Conversion to Kelvin incorrect.\\\\nYour result: \" + str(lines[0]) + \"\\\\nExpected: \" + str(degrees_kelvin))\\r\\n        return 0.0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn6_skill2': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n# The Actual Solution\\r\\ndef solution(gpa, apa, mpa):\\r\\n    if gpa < 2.0 or apa < 2.0 or mpa < 2.0:\\r\\n        return \"Probation\"\\r\\n    else:\\r\\n        return \"No Probation\"\\r\\n\\r\\n\\r\\ndef run_test(gpa, apa, mpa):\\r\\n    global num_tests_run, num_tests_passed\\r\\n    \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"--------------------------------------------\")\\r\\n    print(\"Testing GPA =\", str(gpa) + \";\", \"APA =\", str(apa) + \";\", \"MPA =\", mpa)\\r\\n    print(\"--------------------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn6_skill2.py\", [gpa, apa, mpa])\\r\\n        \\r\\n    print(output.strip())\\r\\n        \\r\\n    if output.strip() == solution(gpa, apa, mpa):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\", solution(gpa, apa, mpa), \"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    #round(random.uniform(0.1, 1.9),1)\\r\\n    #round(random.uniform(2.1, 4.0),1)\\r\\n    run_test(round(random.uniform(2.1, 4.0),1), round(random.uniform(2.1, 4.0),1), round(random.uniform(2.1, 4.0),1))\\r\\n    run_test(round(random.uniform(0.1, 1.9),1), round(random.uniform(2.1, 4.0),1), round(random.uniform(2.1, 4.0),1))\\r\\n    run_test(round(random.uniform(2.1, 4.0),1), round(random.uniform(0.1, 1.9),1), round(random.uniform(2.1, 4.0),1))\\r\\n    run_test(round(random.uniform(2.1, 4.0),1), round(random.uniform(2.1, 4.0),1), round(random.uniform(0.1, 1.9),1))\\r\\n\\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn6_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n# The Actual Solution\\r\\ndef solution(body_temperature):\\r\\n    if body_temperature >= 97 and body_temperature <= 99:\\r\\n        return \"Normal\"\\r\\n    else:\\r\\n        return \"Abnormal\"\\r\\n\\r\\n\\r\\ndef run_test(body_temperature):\\r\\n    global num_tests_run, num_tests_passed\\r\\n    \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"--------------------------------------------\")\\r\\n    print(\"Testing Temperature =\", body_temperature)\\r\\n    print(\"--------------------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn6_skill1.py\", [body_temperature])\\r\\n        \\r\\n    if output.strip() == solution(body_temperature):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\", solution(body_temperature), \"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(96.9)\\r\\n    run_test(97)\\r\\n    run_test(98.5)\\r\\n    run_test(99)\\r\\n    run_test(99.1)\\r\\n\\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn6_projectile': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 5\\r\\n    num_correct = 0\\r\\n    \\r\\n    for i in range(NUM_TESTS):\\r\\n        # Generates Random Values\\r\\n        velocity = random.randint(400, 900)\\r\\n        theta = random.random() * 90.0\\r\\n        answer = (velocity**2 * math.sin(2 * theta * math.pi/180.0)) / 9.8   \\r\\n            \\r\\n        print(\"----------------------------------------\")\\r\\n        print(\"TEST CASE\", i+1)\\r\\n        print(\"----------------------------------------\")\\r\\n        \\r\\n        # Runs the Script\\r\\n        output, error_message = autograder.run_script(\"lsn6_projectile.py\", [velocity, theta])\\r\\n\\r\\n        # Optional:  Displays the Error Message (if one is provided)\\r\\n        if error_message != \\'\\':\\r\\n            print(\"Error Occurred: \" + error_message)    \\r\\n        \\r\\n        lines = output.split(\\'\\\\n\\')\\r\\n        \\r\\n        if autograder.equals(lines[0], answer):\\r\\n            print(\"CORRECT.\\\\n\\\\n\")\\r\\n            num_correct += 1\\r\\n        else:\\r\\n            print(\"INCORRECT (Expected: \" + str(answer) + \")\\\\n\\\\n\")\\r\\n    \\r\\n    return (100 / NUM_TESTS) * num_correct\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn6_math': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num1 = random.random() * 100.0\\r\\n    num2 = random.random() * 100.0\\r\\n    num3 = random.random() * 10.0\\r\\n    \\r\\n    part1 = round(math.sqrt(num1), 2)\\r\\n    part2 = round(math.fabs(num2 - num3), 2)\\r\\n    part3 = round(math.factorial(math.ceil(num3)), 2)\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn6_math.py\", [num1, num2, num3])\\r\\n    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if autograder.equals(lines[0], part1, 0.001) and autograder.equals(lines[1], part2, 0.001) and autograder.equals(lines[2], part3, 0.001):\\r\\n        print(\"Looks Good!\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"One or more calculations did not work. Expected:\\\\n\" + str(part1) + \"\\\\n\" + str(part2) + \"\\\\n\" + str(part3))\\r\\n        return 0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn6_calories': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    age_years = random.randint(10, 99)\\r\\n    weight_pounds = random.randint(80, 400)\\r\\n    heart_bpm = random.randint(50, 140)\\r\\n    time_minutes = random.randint(15, 90)\\r\\n    \\r\\n    calories_man   = ( (age_years * 0.2017) + (weight_pounds * 0.09036) + (heart_bpm * 0.6309) - 55.0969 )  * time_minutes / 4.184\\r\\n    calories_woman = ( (age_years * 0.074)  - (weight_pounds * 0.05741) + (heart_bpm * 0.4472) - 20.4022 ) * time_minutes / 4.184\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn6_calories.py\", [age_years, weight_pounds, heart_bpm, time_minutes])\\r\\n      \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n      \\r\\n    if autograder.equals(lines[0], calories_man):\\r\\n        print(\"Male Calorie Calculations Look Good.\")\\r\\n        if autograder.equals(lines[1], calories_woman):\\r\\n            print(\"Female Calorie Calculations Look Good.\")\\r\\n            return 100.0\\r\\n        else:\\r\\n            print(\"Female Calorie Calculation is Incorrect.\\\\nExpected: \" + str(calories_woman))\\r\\n            return 50.0\\r\\n    else:\\r\\n        print(\"Male Calorie Calculation is Incorrect.\\\\nExpected: \" + str(calories_man))\\r\\n        return 0.0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn6_bits_to_kmg': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num_bits = random.randint(1, 1000000)\\r\\n    num_bytes = num_bits / 8\\r\\n    num_kb = num_bytes / 1024\\r\\n    num_mb = num_kb / 1024\\r\\n    num_gb = num_mb / 1024\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn6_bits_to_kmg.py\", [num_bits])\\r\\n      \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n      \\r\\n    if autograder.equals(lines[0], num_kb):\\r\\n        print(\"Kilobyte Conversion Looks Good.\")\\r\\n        if autograder.equals(lines[1], num_mb):\\r\\n            print(\"Megabyte Conversion Looks Good.\")\\r\\n            if autograder.equals(lines[2], num_gb):\\r\\n                print(\"Gigabyte Conversion Looks Good.\")\\r\\n                return 100.0\\r\\n            else:\\r\\n                print(\"Num GB is Incorrect.\\\\n  Expected: \" + str(num_gb))\\r\\n                return 67.0\\r\\n        else:\\r\\n            print(\"Num MB is Incorrect.\\\\n  Expected: \" + str(num_mb))\\r\\n            return 33.0\\r\\n    else:\\r\\n        print(\"Num KB is Incorrect.\\\\n  Expected: \" + str(num_kb))\\r\\n        return 0.0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n',\n",
       "  'lsn6_bits_to_bytes': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num_bits = random.randint(1, 1000000)\\r\\n    num_bytes = num_bits / 8\\r\\n\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn6_bits_to_bytes.py\", [num_bits])\\r\\n      \\r\\n    if autograder.equals(output, num_bytes):\\r\\n        print(\"Num Bytes Looks Good.\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"Num Bytes is Incorrect.\\\\nExpected: \" + str(num_bytes))\\r\\n        return 0.0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n',\n",
       "  'lsn6_bit_representation': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num_bits = random.randint(1, 32)\\r\\n    num_colors = 2 ** num_bits\\r\\n\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn6_bit_representation.py\", [num_bits])\\r\\n      \\r\\n    if autograder.equals(output, num_colors):\\r\\n        print(\"Num Colors Looks Good.\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"Num Colors is Incorrect.\\\\nExpected: \" + str(num_colors))\\r\\n        return 0.0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn5_skill2': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    points_earned = 0\\r\\n            \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 1 - CS110\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn5_skill2.py\", [\"CS110\"])\\r\\n    \\r\\n    if output.strip() == \"You get to program!\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 50\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: You get to program!\\\\n\")\\r\\n        \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 2 - Another Class\")\\r\\n    print(\"-------------------------------\")\\r\\n    classes = [\\'Math 151\\', \\'English 111\\', \\'Physics 110\\']\\r\\n    random_class = classes[random.randint(0, len(classes)-1)]\\r\\n    output, error_message = autograder.run_script(\"lsn5_skill2.py\", [random_class])\\r\\n    \\r\\n    if output.strip() == \"Boo, no programming.\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 50\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Boo, no programming.\\\\n\")\\r\\n\\r\\n    return points_earned\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn5_skill1': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    points_earned = 0\\r\\n    \\r\\n    # Generates Random Values\\r\\n    above_freezing = random.uniform(33, 100)\\r\\n    below_freezing = random.uniform(-100, 31)\\r\\n    at_freezing    = 32\\r\\n        \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 1 - Below Freezing\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn5_skill1.py\", [below_freezing])\\r\\n    \\r\\n    if output.strip() == \"Water Has Frozen\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 33\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Water Has Frozen\\\\n\")\\r\\n        \\r\\n    \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 2 - Above Freezing\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn5_skill1.py\", [above_freezing])\\r\\n    \\r\\n    if output.strip() == \"Above Water\\'s Freezing Point\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 33\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Above Water\\'s Freezing Point\\\\n\")\\r\\n        \\r\\n    \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 3 - Exactly 32 Degrees\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn5_skill1.py\", [32])\\r\\n    \\r\\n    if output.strip() == \"Water Has Frozen\":\\r\\n        print(\"CORRECT\")\\r\\n        points_earned += 34\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Water Has Frozen\\\\n\")\\r\\n\\r\\n    return points_earned\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn5_scoreaverage': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    score1 = random.randint(0, 100)\\r\\n    score2 = random.randint(0, 100)\\r\\n    score3 = random.randint(0, 100)\\r\\n    average = (score1 + score2 + score3) / 3.0\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn5_scoreaverage.py\", [score1, score2, score3])\\r\\n    \\r\\n    if autograder.equals(output, average):\\r\\n        print(\"PASSED!\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"Value doesn\\'t match.\\\\nExpected: \" + str(average))\\r\\n        return 0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn5_pointspread': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    score1 = random.randint(0, 50)\\r\\n    score2 = random.randint(score1, 100)\\r\\n    spread = abs(score1 - score2)\\r\\n\\r\\n    points_earned = 0\\r\\n\\r\\n    # Trial #1:  score 1 > score2\\r\\n    print(\"Testing when score 1 is bigger than score 2 . . .\")\\r\\n    output, error_message = autograder.run_script(\"lsn5_pointspread.py\", [score1, score2])\\r\\n    \\r\\n    if autograder.equals(output, spread):\\r\\n        print(\"PASSED!\\\\n\")\\r\\n        points_earned += 50\\r\\n    else:\\r\\n        print(\"Value doesn\\'t match.\\\\nExpected: \" + str(spread)  + \"\\\\n\")\\r\\n        \\r\\n    # Trial #2:  score 2 > score1\\r\\n    print(\"Testing when score 2 is bigger than score 1 . . .\")\\r\\n    output, error_message = autograder.run_script(\"lsn5_pointspread.py\", [score2, score1])\\r\\n    \\r\\n    if autograder.equals(output, spread):\\r\\n        print(\"PASSED!\")\\r\\n        points_earned += 50\\r\\n    else:\\r\\n        print(\"Value doesn\\'t match.\\\\nExpected: \" + str(spread))\\r\\n    \\r\\n    return points_earned\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n',\n",
       "  'lsn5_madlib': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    first_names = [\\'Adrian\\', \\'Troy\\', \\'Dave\\', \\'Paul\\', \\'Kelly\\', \\'Steve\\', \\'Barry\\']\\r\\n    generic_locations = [\\'Best Buy\\', \\'AAFES\\', \\'Target\\', \\'THE Walmart\\', \\'Home Depot\\']\\r\\n    nouns = [\\'Video Games\\', \\'Board Games\\', \\'Nintendo Switches\\', \\'Sony PS4s\\', \\'Microsoft (Ugh) Xbox Ones\\']\\r\\n    \\r\\n    first_name = first_names[random.randint(0, len(first_names) - 1)]\\r\\n    generic_location = generic_locations[random.randint(0, len(generic_locations) - 1)]\\r\\n    whole_number = random.randint(0, 100)\\r\\n    plural_noun = nouns[random.randint(0, len(nouns) - 1)]\\r\\n\\r\\n    expected_output = first_name + \\' went to \\' + generic_location + \\' to buy \\' + str(whole_number) + \\' different types of \\' + plural_noun + \"\\\\n\"\\r\\n\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn5_madlib.py\", [first_name, generic_location, whole_number, plural_noun])\\r\\n    \\r\\n    if output == expected_output:\\r\\n        print(\"PASSED!\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"String doesn\\'t match.\\\\nExpected: \" + expected_output)\\r\\n        return 0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn5_girlscouts': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    dollar_amount = round(random.uniform(10.00, 100.00), 2)\\r\\n    super_six_amount = (dollar_amount // 5)\\r\\n    specialty_amount = (dollar_amount // 6)\\r\\n    score = 0\\r\\n    \\r\\n    line_1 = str(int(super_six_amount)) + \" boxes of Thin Mints, Samoas, Tagalongs, Do-Si-Dos, Trefoils, or Savannah Smiles\"\\r\\n    line_2 = str(int(specialty_amount)) + \" boxes of S\\'mores and Toffee-tastic\"\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn5_girlscouts.py\", [dollar_amount])\\r\\n    output_lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if line_1 == output_lines[0]:\\r\\n        print(\"First Line is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"First Line is Incorrect.  Expected:\", line_1)\\r\\n    \\r\\n    if line_2 == output_lines[1]:\\r\\n        print(\"Second Line is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Second Line is Incorrect.  Expected:\", line_2)\\r\\n    \\r\\n    return score\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn5_arrivaltime': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    distance = round(random.random() * 1000, 1)\\r\\n    speed = round(random.random() * 60, 1)\\r\\n    time = distance / speed\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn5_arrivaltime.py\", [distance, speed])\\r\\n    \\r\\n    if autograder.equals(output, time):\\r\\n        print(\"PASSED!\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"Value doesn\\'t match.\\\\nExpected: \" + str(time))\\r\\n        return 0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn4_printpractice': 'from cs110 import autograder\\r\\n\\r\\ndef test_passed():\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_printpractice.py\", [])\\r\\n\\r\\n    student_output = output.strip().split(\\'\\\\n\\')\\r\\n    expected_output = [\\'Welcome to Computer Science 110!\\', \\'921600.0\\', \\'Liam is 8 years old\\', \\'F-15  Eagle\\', \\'F-16  Fighting Falcon\\', \\'B-2   Spirit\\', \\'C-141 Starlifter\\']\\r\\n    num_matches = autograder.compare_strings(student_output, expected_output)\\r\\n    \\r\\n    return round(num_matches * (100 / len(expected_output)), 1)\\r\\n\\r\\n\\r\\n# Testbench (to be run in an IDE)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n',\n",
       "  'lsn4_parking': 'from cs110 import autograder\\r\\n\\r\\ndef test_passed():\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_parking.py\", [])\\r\\n        \\r\\n    if output.startswith(\"  NO PARKING\\\\n\"):\\r\\n        if output == \"  NO PARKING\\\\n1:00 - 5:00 a.m.\\\\n\":\\r\\n            print(\"Passed!\")\\r\\n            return 100\\r\\n        else:\\r\\n            print(\"Something is wrong with the second line.\")\\r\\n            return 50\\r\\n    else:\\r\\n        print(\"Something is wrong with the first line.\")\\r\\n        return 0\\r\\n\\r\\n# Testbench (to be run in an IDE)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn4_ascii': 'from cs110 import autograder\\r\\n\\r\\ndef test_passed():\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_ascii.py\", [])\\r\\n    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    # Checks for the Cat\\r\\n    if lines[0].rstrip() == \\'/\\\\\\\\   /\\\\\\\\\\':\\r\\n        #test_feedback.write(\\'1\\')\\r\\n        if lines[1].rstrip() == \\'  o o\\':\\r\\n            #test_feedback.write(\\'2\\')\\r\\n            if lines[2].rstrip() == \\' =   =\\':\\r\\n                #test_feedback.write(\\'3\\')\\r\\n                if lines[3].rstrip() == \\'  ---\\':\\r\\n                    #test_feedback.write(\\'4\\')\\r\\n                    print(\\'Cat Looks Good!\\\\n\\')\\r\\n                    return 100\\r\\n                else:\\r\\n                    print(\\'Problem in the fourth line of the cat\\') \\r\\n            else:\\r\\n                print(\\'Problem in the third line of the cat\\')  \\r\\n        else:\\r\\n            print(\\'Problem in the second line of the cat\\')  \\r\\n    else:\\r\\n        print(\\'Problem in the first line of the cat\\')\\r\\n    \\r\\n    return 0\\r\\n\\r\\n# Testbench (to be run in an IDE)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n',\n",
       "  'lsn33_practice8': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ninputs  = [[1994, 2010], [1955, 1979], [1960, 1969]]\\r\\noutputs = [[\\'29\\', \\'Nicolas Cage\\', \\'Adrien Brody\\'],\\r\\n           [\\'30\\', \\'Marlon Brando\\', \\'Maximilian Schell\\', \\'Richard Dreyfuss\\'],\\r\\n           [\\'31\\', \\'Charlton Heston\\', \\'Maximilian Schell\\']]\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_index = random.randint(0, len(inputs)-1)\\r\\n    print(random_index)\\r\\n    input_list = inputs[random_index]\\r\\n    expected_output = outputs[random_index]\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn33_practice8.py\", input_list)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_output)\\r\\n       \\r\\n    return round(num_matches * (100.0 / len(expected_output)), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn33_practice7': 'import webbrowser\\r\\n\\r\\nprint(\"That\\'s it, the video is the joke. Feel free to practice this problem but there\\'s not an actual score.\")\\r\\n\\r\\nwebbrowser.open(\\'https://www.youtube.com/watch?v=dQw4w9WgXcQ\\')\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn33_practice6': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(temp, precip, humidity):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"--------------------------------------------------------------\")\\r\\n    print(\"Testing temperature =\", temp, \"precipitation =\", precip, \"humidity =\", humidity)\\r\\n    print(\"--------------------------------------------------------------\")\\r\\n    \\r\\n    # SOLUTION\\r\\n    if temp > 84.9 and (humidity == \\'high\\' or humidity == \\'medium\\'):\\r\\n        solution = \\'Walk slowly\\'\\r\\n    elif precip == \\'snow\\' or precip == \\'rain\\':\\r\\n        solution = \\'Do not run!\\'\\r\\n    else:\\r\\n        solution = \\'Move quickly\\'\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn33_practice6.py\", [temp, precip, humidity])\\r\\n    \\r\\n    if output.strip() == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    # options for random test cases\\r\\n    humidity_list = [\\'high\\', \\'medium\\', \\'low\\']\\r\\n    precip_list = [\\'snow\\', \\'rain\\', \\'none\\']\\r\\n    \\r\\n    # pick random sample for each test case\\r\\n    for i in range(10):\\r\\n        humidity = random.choice(humidity_list)\\r\\n        precip = random.choice(precip_list)\\r\\n        if precip == \\'snow\\':\\r\\n            temp_list = [12, 14, 20, 32, 41]\\r\\n        else:\\r\\n            temp_list = [77, 84.9, 92]\\r\\n        temp = random.choice(temp_list)\\r\\n        \\r\\n        # run test\\r\\n        run_test(temp, precip, humidity)\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn33_practice5': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(p1, v1, v2):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"--------------------------------------------------------------\")\\r\\n    print(\"Testing pressure 1 =\", p1, \"volume 1 =\", v1, \"volume 2 =\", v2)\\r\\n    print(\"--------------------------------------------------------------\")\\r\\n    \\r\\n    # SOLUTION\\r\\n    solution = p1 * v1 / v2 \\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn33_practice5.py\", [p1, v1, v2])\\r\\n    \\r\\n    if float(output.strip()) == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    for i in range(5):\\r\\n        run_test(round(random.uniform(0, 100),2), round(random.uniform(0, 100),2), round(random.uniform(0, 100),2))\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn33_practice4': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ninput_list = [\"Statue of Liberty\",\\r\\n              \"New York City\",\\r\\n              \"Grand Canyon\",\\r\\n              \"Airzona\",\\r\\n              \"Tower of Pisa\",\\r\\n              \"Italy\",\\r\\n              \"Pikes Peak\",\\r\\n              \"Colorado\",\\r\\n              \"Liberty Bell\",\\r\\n              \"Pennsylvania\",\\r\\n              \"Sears Tower\",\\r\\n              \"Chicago\",\\r\\n              \"DONE\",\\r\\n              \"Statue of Liberty\"]\\r\\n\\r\\nexpected_output = [\"New York City\"]\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn33_practice4.py\", input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_output)\\r\\n       \\r\\n    return round(num_matches * (100.0 / len(expected_output)), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn33_practice3': 'from cs110 import autograder\\r\\nimport random, statistics\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    # Hard Coded Test Cases . . . the best\\r\\n    test_cases = [\\r\\n                    [[\\'Audi\\'], [\"Dealer 3\"]],\\r\\n                    [[\\'Toyota\\'], [\"Dealer 2\", \"Dealer 3\"]],\\r\\n                    [[\\'Acura\\'], [\"All Dealers\"]],\\r\\n                 ]\\r\\n    \\r\\n    for test_case in test_cases:\\r\\n        print(\"----------------------\")\\r\\n        print(\"Test Case\", test_cases.index(test_case) + 1)\\r\\n        print(\"----------------------\")\\r\\n        \\r\\n        # Runs the Script\\r\\n        input_list = test_case[0]\\r\\n        expected_output = test_case[1]\\r\\n        output, error_message = autograder.run_script(\"lsn33_practice3.py\", input_list)\\r\\n        \\r\\n        output_list = output.split(\\'\\\\n\\')\\r\\n        \\r\\n        if len(output_list) - 1 != len(expected_output):\\r\\n            print(\"Your program\\'s output does not have the expected number of lines\")\\r\\n        else:\\r\\n            lines_correct = 0\\r\\n            for i in range(len(expected_output)):\\r\\n                if str(expected_output[i]) == output_list[i]:\\r\\n                    print(\"Line\", i+1, \"is correct\")\\r\\n                    lines_correct += 1\\r\\n                else:\\r\\n                    print(\"Line\", i+1, \"is incorrect (Expected:\" + str(expected_output[i]) + \")\")\\r\\n            \\r\\n            score += (100 / len(test_cases)) * (lines_correct / len(expected_output))\\r\\n        \\r\\n        print()\\r\\n        \\r\\n    return round(score, 1)\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn33_practice2': 'from cs110 import autograder\\r\\nimport random, statistics\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    # Hard Coded Test Cases . . . the best\\r\\n    test_cases = [\\r\\n                    [[3, 1.0, \"USS Enterprise-D\", 9.6, \"USS Voyager\", 9.975, \"USS Rubicon\", 4.0],\\r\\n                        [0.2, \"USS Enterprise-D\", \"USS Voyager\", \"USS Rubicon\"]],\\r\\n                    [[5, 100, \"USS Discovery\", 7.5, \"USS Enterprise-A\", 8, \"USS Constellation\", 9.2, \"USS Farragut\", 9.4, \"USS Stargazer\", 6.0],\\r\\n                        [20.8, \"USS Constellation\", \"USS Farragut\"]],\\r\\n                 ]\\r\\n    \\r\\n    for test_case in test_cases:\\r\\n        print(\"----------------------\")\\r\\n        print(\"Test Case\", test_cases.index(test_case) + 1)\\r\\n        print(\"----------------------\")\\r\\n        \\r\\n        # Runs the Script\\r\\n        input_list = test_case[0]\\r\\n        expected_output = test_case[1]\\r\\n        output, error_message = autograder.run_script(\"lsn33_practice2.py\", input_list)\\r\\n        \\r\\n        output_list = output.split(\\'\\\\n\\')\\r\\n        \\r\\n        if len(output_list) - 1 != len(expected_output):\\r\\n            print(\"Your program\\'s output does not have the expected number of lines\")\\r\\n        else:\\r\\n            lines_correct = 0\\r\\n            for i in range(len(expected_output)):\\r\\n                if str(expected_output[i]) == output_list[i]:\\r\\n                    print(\"Line\", i+1, \"is correct\")\\r\\n                    lines_correct += 1\\r\\n                else:\\r\\n                    print(\"Line\", i+1, \"is incorrect (Expected:\" + str(expected_output[i]) + \")\")\\r\\n            \\r\\n            score += (100 / len(test_cases)) * (lines_correct / len(expected_output))\\r\\n        \\r\\n        print()\\r\\n        \\r\\n    return round(score, 1)\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn33_practice1': 'from cs110 import autograder\\r\\nimport random, statistics\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    # Hard Coded Test Cases . . . the best\\r\\n    test_cases = [ [[2, 4, 6, 8, 10, -1], [5, 6, 0, 0]],\\r\\n                   [[1, 3, 5, 7, 9, -1], [0, 0, 5, 5.0]],\\r\\n                   [[23, 45, 81, 1, 29, 35, 44, 76, 23, -1], [2, 60.0, 7, 33.857142857142854]]]\\r\\n    \\r\\n    for test_case in test_cases:\\r\\n        # Runs the Script\\r\\n        input_list = test_case[0]\\r\\n        expected_output = test_case[1]\\r\\n        output, error_message = autograder.run_script(\"lsn33_practice1.py\", input_list)\\r\\n        \\r\\n        output_list = output.split(\\'\\\\n\\')\\r\\n        \\r\\n        if len(output_list) - 1 != len(expected_output):\\r\\n            print(\"Your program\\'s output does not have the expected number of lines\")\\r\\n        else:\\r\\n            lines_correct = 0\\r\\n            for i in range(len(expected_output)):\\r\\n                if autograder.equals(str(expected_output[i]), output_list[i]):\\r\\n                    print(\"Line\", i+1, \"is correct\")\\r\\n                    lines_correct += 1\\r\\n                else:\\r\\n                    print(\"Line\", i+1, \"is incorrect (Expected:\" + str(expected_output[i]) + \")\")\\r\\n            \\r\\n            score += (100 / len(test_cases)) * (lines_correct / len(expected_output))\\r\\n            \\r\\n        \\r\\n    return round(score, 1)\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn26_plots': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn26_plots.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn26_percentile': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport numpy as np\\r\\n\\r\\ndef solution(list_of_scores):\\r\\n    \\r\\n    result = []\\r\\n    num_90th_percentile = 0\\r\\n    within_std = 0\\r\\n\\r\\n    scores_array = np.array(list_of_scores)\\r\\n    percentile_90 = np.percentile(scores_array, 90)\\r\\n    stdev = np.std(scores_array)\\r\\n    average = np.average(scores_array)\\r\\n\\r\\n    for s in list_of_scores:\\r\\n        if s >= percentile_90:\\r\\n            num_90th_percentile += 1\\r\\n        if s <= average + stdev and s >= average - stdev:\\r\\n            within_std += 1\\r\\n\\r\\n    result.append(str(average) + \\'\\\\n\\')\\r\\n    result.append(str(num_90th_percentile) + \"\\\\n\")\\r\\n    result.append(str(within_std) + \"\\\\n\")\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n        \\r\\n    num_values = random.randint(5, 10)\\r\\n    values = []\\r\\n    input_list = [ num_values ]\\r\\n    \\r\\n    for i in range(num_values):\\r\\n        value = random.randint(50, 100)\\r\\n        values.append(value)\\r\\n        input_list.append(value)\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn26_percentile.py\", input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_output = solution(values)\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_output)\\r\\n       \\r\\n    return round(num_matches * (100.0 / len(expected_output)), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn26_calculus': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nexpected_output = [\\r\\n\"    4      2\",\\r\\n\"18 x + 12 x + 3 x + 1\",\\r\\n\"343\",\\r\\n\"[ 0.14325174+0.80294311j  0.14325174-0.80294311j -0.14325174+0.25098038j\",\\r\\n\" -0.14325174-0.25098038j]\",\\r\\n\"    3\",\\r\\n\"72 x + 24 x + 3\",\\r\\n\"-93\",\\r\\n\"     5     3       2\",\\r\\n\"3.6 x + 4 x + 1.5 x + 1 x\",\\r\\n\"352367.5\",\\r\\n]\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn26_calculus.py\", [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_output)\\r\\n       \\r\\n    return round(num_matches * (100.0 / len(expected_output)), 1)\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn25_tokens': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(filename, t):\\r\\n    # Opens the file\\r\\n    file = open(filename, \"r\")\\r\\n\\r\\n    # Extracts ALL of the text as one big string\\r\\n    file_contents = file.read()\\r\\n\\r\\n    # Splits the entire document into tokens\\r\\n    list_of_tokens = file_contents.split(\\' \\')\\r\\n\\r\\n    # Creates a Dictionary to Store All Tokens\\r\\n    token_dictionary = {}\\r\\n\\r\\n    for token in list_of_tokens:\\r\\n        if token not in token_dictionary:\\r\\n            token_dictionary[token] = 1\\r\\n        else:\\r\\n            token_dictionary[token] = token_dictionary[token] + 1\\r\\n    \\r\\n    if t in token_dictionary:\\r\\n        return token_dictionary[t]\\r\\n    else:\\r\\n        return 0\\r\\n    \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_correct = 0\\r\\n    \\r\\n    # Test #1:\\r\\n    print(\"------------------------------------------\")\\r\\n    print(\"Test 1\")\\r\\n    print(\"------------------------------------------\")\\r\\n    answer, error = autograder.run_script(\"lsn25_tokens.py\", [\"review.txt\", \"Fit\"])\\r\\n    expected_answer = solution(\"review.txt\", \"Fit\")\\r\\n    \\r\\n    if autograder.equals(answer, expected_answer):\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        num_correct += 1\\r\\n    else:\\r\\n        print(\"INCORRECT, Expected:\", expected_answer, \"\\\\n\")\\r\\n    \\r\\n    \\r\\n    # Test #2:\\r\\n    print(\"------------------------------------------\")\\r\\n    print(\"Test 2\")\\r\\n    print(\"------------------------------------------\")\\r\\n    answer, error = autograder.run_script(\"lsn25_tokens.py\", [\"article.txt\", \"plastic\"])\\r\\n    expected_answer = solution(\"article.txt\", \"plastic\")\\r\\n    \\r\\n    if autograder.equals(answer, expected_answer):\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        num_correct += 1\\r\\n    else:\\r\\n        print(\"INCORRECT, Expected:\", expected_answer, \"\\\\n\")\\r\\n        \\r\\n    # Test #3:\\r\\n    print(\"------------------------------------------\")\\r\\n    print(\"Test 3\")\\r\\n    print(\"------------------------------------------\")\\r\\n    answer, error = autograder.run_script(\"lsn25_tokens.py\", [\"article2.txt\", \"environment\"])\\r\\n    expected_answer = solution(\"article2.txt\", \"environment\")\\r\\n    \\r\\n    if autograder.equals(answer, expected_answer):\\r\\n        print(\"CORRECT\")\\r\\n        num_correct += 1\\r\\n    else:\\r\\n        print(\"INCORRECT, Expected:\", expected_answer)\\r\\n    \\r\\n    return round(100 / 3 * num_correct, 1)\\r\\n    \\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn25_skill2': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn25_skill2\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    a = random.randint(0, 5)\\r\\n    b = random.randint(6, 10)\\r\\n    c = random.randint(100, 200)\\r\\n    d = random.randint(0, 99)\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    print(\"Test #1.  Calling mini_sort(%d, %d)\" % (a, b))\\r\\n    output = lsn25_skill2.mini_sort(a, b)\\r\\n    print(\"  Your Function Returned:\", output)\\r\\n    if output == (a, b):\\r\\n        print(\"  CORRECT\\\\n\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"  INCORRECT.  Expected\", (a, b), \"\\\\n\")\\r\\n        \\r\\n    print(\"Test #2.  Calling mini_sort(%d, %d)\" % (c, d))\\r\\n    output = lsn25_skill2.mini_sort(c, d)\\r\\n    print(\"  Your Function Returned:\", output)\\r\\n    if output == (d, c):\\r\\n        print(\"  CORRECT\\\\n\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"  INCORRECT.  Expected\", (d, c), \"\\\\n\")\\r\\n    \\r\\n    return score\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn25_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    aircraft_dictionary = {\"F-16\":\"Fighting Falcon\", \"F-22\":\"Raptor\", \"B-2\":\"Spirit\", \"F-15\":\"Eagle\"}\\r\\n    \\r\\n    aircraft = [(\"C-141\", \"Starlifter\"), (\"C-5\", \"Galaxy\"), (\"MQ-9\", \"Reaper\")]\\r\\n    random_aircraft = aircraft[random.randint(0, len(aircraft)-1)]\\r\\n    aircraft_dictionary[random_aircraft[0]] = random_aircraft[1]\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn25_skill1.py\", random_aircraft)\\r\\n    \\r\\n    if output.strip() == str(aircraft_dictionary):\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\")\\r\\n        print(aircraft_dictionary)\\r\\n        return 0.0\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn25_rectangle': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn25_rectangle\\r\\n\\r\\n# Solution\\r\\ndef solution(corner1, corner2):\\r\\n    width = abs(corner1[0] - corner2[0])\\r\\n    height = abs(corner1[1] - corner2[1])\\r\\n    largest_side = max(width, height)\\r\\n    shortest_side = min(width, height)\\r\\n    area = width * height\\r\\n    perimeter = width * 2 + height * 2\\r\\n    \\r\\n    return (area, perimeter, largest_side, shortest_side)\\r\\n\\r\\n\\r\\n# Runs the test\\r\\ndef run_test(corner1, corner2):\\r\\n    global tests_passed\\r\\n    \\r\\n    result = lsn25_rectangle.get_rectangle_info(corner1, corner2)\\r\\n    expected_value = solution(corner1, corner2)\\r\\n    \\r\\n    if result is None:\\r\\n        print(\"Failed with inputs\", corner1, corner2, \"-- Your function did not return anything\")\\r\\n    elif type(result) is not tuple:\\r\\n        print(\"Failed with inputs\", corner1, corner2, \"-- Your function did not return a tuple\")\\r\\n    elif len(result) != 4:\\r\\n        print(\"Failed with inputs\", corner1, corner2, \"-- Your function did not return a tuple with 4 items in it\")\\r\\n    elif result == expected_value:\\r\\n        print(\"Passed with inputs\", corner1, corner2, \"-- Your function correctly returned\", result)\\r\\n        return True\\r\\n    else:\\r\\n        print(\"Failed with inputs\", corner1, corner2, \"-- Your function returned\", result, \"instead of\", expected_value)\\r\\n\\r\\n    return False\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 5\\r\\n    tests_passed = 0\\r\\n    \\r\\n    for i in range(NUM_TESTS):\\r\\n        # Generate 4 Random Numbers\\r\\n        x1 = random.randint(-100, 100)\\r\\n        y1 = random.randint(-100, 100)\\r\\n        x2 = random.randint(-100, 100)\\r\\n        y2 = random.randint(-100, 100)\\r\\n        \\r\\n        # Makes sure that I didn\\'t accidentally generate a line\\r\\n        while (x1 == x2):\\r\\n            x1 = random.randint(-100, 100)            \\r\\n        while (y1 == y2):\\r\\n            y1 = random.randint(-100, 100)\\r\\n    \\r\\n        if run_test((x1, y1), (x2, y2)):\\r\\n            tests_passed += 1\\r\\n    \\r\\n    return 100/NUM_TESTS * tests_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn25_midpoint': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn25_midpoint\\r\\n\\r\\n# Runs the test\\r\\ndef run_test(x1, y1, x2, y2):\\r\\n    global tests_passed\\r\\n    \\r\\n    result = lsn25_midpoint.get_midpoint(x1, y1, x2, y2)\\r\\n    expected_value = ((x1+x2)/2, (y1+y2)/2)\\r\\n    \\r\\n    if result is None:\\r\\n        print(\"Failed with values %d, %d, %d, and %d.  Your function did not return anything.\" % (x1, y1, x2, y2))\\r\\n    elif type(result) is not tuple:\\r\\n        print(\"Failed with values %d, %d, %d, and %d.  Your function did not return a tuple.\" % (x1, y1, x2, y2))\\r\\n    elif len(result) != 2:\\r\\n        print(\"Failed with values %d, %d, %d, and %d.  Your function did not return a tuple of length 2.\" % (x1, y1, x2, y2))\\r\\n    elif result == expected_value:\\r\\n        print(\"Passed Test Using values %d, %d, %d, and %d. Received (%d, %d)\" % (x1, y1, x2, y2, result[0], result[1]))\\r\\n        return True\\r\\n    else:\\r\\n        print(\"Failed Test Using values %d, %d, %d, and %d. Received (%d, %d), but Expected (%d, %d)\" % (x1, y1, x2, y2, result[0], result[1], expected_value[0], expected_value[1]))\\r\\n\\r\\n    return False\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 5\\r\\n    tests_passed = 0\\r\\n    \\r\\n    for i in range(NUM_TESTS):\\r\\n        # Generate 4 Random Numbers\\r\\n        x1 = random.randint(-100, 100)\\r\\n        y1 = random.randint(-100, 100)\\r\\n        x2 = random.randint(-100, 100)\\r\\n        y2 = random.randint(-100, 100)\\r\\n        \\r\\n        if run_test(x1, y1, x2, y2):\\r\\n            tests_passed += 1\\r\\n    \\r\\n    return (100 / NUM_TESTS) * tests_passed\\r\\n        \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn25_crashes': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn25_crashes\\r\\n\\r\\ndef solution(filename):\\r\\n    # Opens the file\\r\\n    file = open(filename, \"r\")\\r\\n\\r\\n    # Extracts ALL of the text as one big string\\r\\n    file_contents = file.read()\\r\\n\\r\\n    # Splits the big string into individual lines\\r\\n    lines = file_contents.split(\\'\\\\n\\')\\r\\n\\r\\n    # Creates a Set\\r\\n    collision_types = set()\\r\\n\\r\\n    # Looks at every row, and adds the collision type to the set\\r\\n    # The set automagically prevents duplicates from being added!\\r\\n    for line in lines:\\r\\n        columns = line.split(\\',\\')\\r\\n        collision_types.add(columns[4])\\r\\n\\r\\n    # Returns the set\\r\\n    return collision_types\\r\\n\\r\\n# Runs the test\\r\\ndef run_test(filename):\\r\\n    global tests_passed\\r\\n    \\r\\n    result = lsn25_crashes.get_accident_types(filename)\\r\\n    expected_value = solution(filename)\\r\\n    \\r\\n    if result is None:\\r\\n        print(\"Failed on file %s.  Your function did not return anything.\" % (filename))\\r\\n    elif type(result) is not set:\\r\\n        print(\"Failed on file %s.  Your function did not return a set.\" % (filename))\\r\\n    elif result == expected_value:\\r\\n        print(\"Passed Test on file\", filename, \"-- set =\", result)\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"Passed Test on file\", filename, \"-- Your function returned \", result, \", but the answer is\", expected_value)\\r\\n\\r\\n    return 0.0\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    return run_test(\"crashdata_2003.csv\") and run_test(\"crashdata_2011.csv\") and run_test(\"crashdata_2015.csv\")\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn25_crashanalysis': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn25_crashanalysis\\r\\n\\r\\ndef get_accident_types(filename):\\r\\n    # Opens the file\\r\\n    file = open(filename, \"r\")\\r\\n\\r\\n    # Extracts ALL of the text as one big string\\r\\n    file_contents = file.read()\\r\\n\\r\\n    # Splits the big string into individual lines\\r\\n    lines = file_contents.split(\\'\\\\n\\')\\r\\n\\r\\n    # Creates a Set\\r\\n    collision_types = set()\\r\\n\\r\\n    # Looks at every row, and adds the collision type to the set\\r\\n    # The set automagically prevents duplicates from being added!\\r\\n    for line in lines:\\r\\n        columns = line.split(\\',\\')\\r\\n        collision_types.add(columns[4])\\r\\n\\r\\n    # Returns the set\\r\\n    return collision_types\\r\\n\\r\\ndef solution(filename1, filename2):\\r\\n    accident_types_1 = get_accident_types(filename1)\\r\\n    accident_types_2 = get_accident_types(filename2)\\r\\n    result = set()\\r\\n    \\r\\n    for accident_type in accident_types_1:\\r\\n        if accident_type in accident_types_2:\\r\\n            result.add(accident_type)\\r\\n    \\r\\n    return result\\r\\n\\r\\n# Runs the test\\r\\ndef run_test(filename1, filename2):\\r\\n    global tests_passed\\r\\n    \\r\\n    result = lsn25_crashanalysis.get_common_accidents(filename1, filename2)\\r\\n    expected_value = solution(filename1, filename2)\\r\\n    \\r\\n    if result is None:\\r\\n        print(\"Failed on files %s and %s.  Your function did not return anything.\" % (filename1, filename2))\\r\\n    elif type(result) is not set:\\r\\n        print(\"Failed on files %s and %s.  Your function did not return a set.\" % (filename1, filename2))\\r\\n    elif result == expected_value:\\r\\n        print(\"Passed Test on file\", filename1, \"and\", filename2, \"-- set =\", result)\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"Passed Test on file\", filename1, \"and\", filename2, \"-- Your function returned \", result, \", but the answer is\", expected_value)\\r\\n\\r\\n    return 0\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    return (run_test(\"crashdata_2003.csv\", \"crashdata_2011.csv\") and\\r\\n            run_test(\"crashdata_2008.csv\", \"crashdata_2003.csv\") and\\r\\n            run_test(\"crashdata_2003.csv\", \"crashdata_2015.csv\"))\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn25_contactlist': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ninput_list = [\"Kirk\",\\r\\n\"555-5555\",\\r\\n\"Spock\",\\r\\n\"666-6666\",\\r\\n\"McCoy\",\\r\\n\"777-7777\",\\r\\n\"DONE\",\\r\\n\"Kirk\",\\r\\n\"Spock\",\\r\\n\"Mccoy\",\\r\\n\"DONE\"]\\r\\n\\r\\nexpected_output = [\\r\\n\"555-5555\",\\r\\n\"666-6666\",\\r\\n\"NOT FOUND\",\\r\\n]\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn25_contactlist.py\", input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_output)\\r\\n       \\r\\n    return round(num_matches * (100.0 / len(expected_output)), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn24_nasa': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nmission_info = [\\r\\n    [\\'Apollo 1\\', 1967],\\r\\n    [\\'Apollo 7\\', 1968],\\r\\n    [\\'Apollo 8\\', 1968],\\r\\n    [\\'Apollo 9\\', 1969],\\r\\n    [\\'Apollo 10\\', 1969],\\r\\n    [\\'Apollo 11\\', 1969],\\r\\n    [\\'Apollo 12\\', 1969],\\r\\n    [\\'Apollo 13\\', 1970],\\r\\n    [\\'Apollo 14\\', 1971],\\r\\n    [\\'Apollo 15\\', 1971],\\r\\n    [\\'Apollo 16\\', 1972],\\r\\n    [\\'Apollo 17\\', 1972],\\r\\n    ]\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    inputs = []\\r\\n    expected_outputs = []\\r\\n    \\r\\n    mission_table = []\\r\\n    \\r\\n    for mission in random.sample(mission_info, 5):\\r\\n        inputs.append(mission[0])\\r\\n        inputs.append(mission[1])\\r\\n        mission_table.append([int(mission[1]), mission[0]])\\r\\n    inputs.append(\"DONE\")\\r\\n    \\r\\n    max_row = max(mission_table)\\r\\n    expected_outputs.append(str(max_row[0]))\\r\\n    \\r\\n    for m in mission_table:\\r\\n        if (int(m[0]) >= int(max_row[0]) - 3):\\r\\n            expected_outputs.append(m[1])\\r\\n    \\r\\n    output, errors = autograder.run_script(\"lsn24_nasa.py\", inputs)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    lines_match = autograder.compare_strings(lines, expected_outputs)\\r\\n    \\r\\n    if lines_match == len(expected_outputs):\\r\\n        return 100.0\\r\\n    else:\\r\\n        return 0.0\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn24_mitches': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nmeal_info = [\\r\\n    [\\'Hot Dogs\\', 600],\\r\\n    [\\'French Dip\\', 540],\\r\\n    [\\'Chicken Cordon Bleu\\', 300],\\r\\n    [\\'Turkey Sandwich\\', 350],\\r\\n    [\\'Mitch\\\\\\'s Mountain\\', 1100],\\r\\n    [\\'Shepherd\\\\\\'s Pie\\', 272],\\r\\n    [\\'Teriyaki Chicken\\', 250],\\r\\n    ]\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    inputs = []\\r\\n    expected_outputs = []\\r\\n    \\r\\n    meal_table = []\\r\\n    table_size = random.randint(3, 5)\\r\\n    total = 0\\r\\n    inputs.append(table_size)\\r\\n    \\r\\n    for meal in random.sample(meal_info, table_size):\\r\\n        total += meal[1]\\r\\n        inputs.append(meal[0])\\r\\n        inputs.append(meal[1])\\r\\n        meal_table.append([meal[0], meal[1]])\\r\\n    \\r\\n    average = total / len(meal_table)\\r\\n    expected_outputs.append(str(average))\\r\\n    \\r\\n    for m in meal_table:\\r\\n        if m[1] >= average-200 and m[1] <= average+200:\\r\\n            expected_outputs.append(m[0])\\r\\n    \\r\\n    output, errors = autograder.run_script(\"lsn24_mitches.py\", inputs)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    lines_match = autograder.compare_strings(lines, expected_outputs)\\r\\n    \\r\\n    if lines_match == len(expected_outputs):\\r\\n        return 100.0\\r\\n    else:\\r\\n        return 0.0\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn24_education': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ntest_inputs = [[\\'Canada\\', \\'M\\'], [\\'Egypt\\', \\'F\\']]\\r\\nexpected_outputs = [[\\'7.140344827586206\\', \\'1945\\', \\'1950\\', \\'1955\\', \\'1960\\', \\'1965\\', \\'1970\\', \\'1975\\', \\'1980\\', \\'1985\\', \\'1990\\', \\'1995\\', \\'2000\\', \\'2005\\', \\'2010\\'],\\r\\n                    [\\'1.1858620689655173\\', \\'1980\\', \\'1985\\', \\'1990\\', \\'1995\\', \\'2000\\', \\'2005\\', \\'2010\\']]\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    test_case_to_run = random.randint(0, len(test_inputs)-1)\\r\\n    inputs = test_inputs[test_case_to_run]\\r\\n    outputs = expected_outputs[test_case_to_run]\\r\\n    \\r\\n    output, errors = autograder.run_script(\"lsn24_education.py\", inputs)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    lines_match = autograder.compare_strings(lines, outputs)\\r\\n    \\r\\n    if lines_match == len(outputs):\\r\\n        return 100.0\\r\\n    else:\\r\\n        return 0.0\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn24_airspeed': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ntest_cases = [[3, 400, \\'F-15\\', 450, \\'F-16\\', 425, \\'F-22\\', 600],\\r\\n              [4, 230, \\'C-130\\', 250, \\'F-35\\', 450, \\'B-52\\', 390, \\'C-141\\', 375]]\\r\\nanswers    = [[\\'2\\', \\'F-15\\', \\'F-16\\'],\\r\\n              [\\'1\\', \\'C-130\\']]\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    test_to_run = random.randint(0, len(test_cases)-1)\\r\\n    inputs = test_cases[test_to_run]\\r\\n    expected_output = answers[test_to_run]    \\r\\n    \\r\\n    output, errors = autograder.run_script(\"lsn24_airspeed.py\", inputs)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    lines_match = autograder.compare_strings(lines, expected_output)\\r\\n    \\r\\n    if lines_match == len(expected_output):\\r\\n        return 100.0\\r\\n    else:\\r\\n        return 0.0\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn23_soundboard': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn23_soundboard.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn23_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    aircraft_dictionary = {\"F-16\":\"Fighting Falcon\", \"F-22\":\"Raptor\", \"B-2\":\"Spirit\", \"F-15\":\"Eagle\"}\\r\\n    \\r\\n    aircraft = [(\"C-141\", \"Starlifter\"), (\"C-5\", \"Galaxy\"), (\"MQ-9\", \"Reaper\")]\\r\\n    random_aircraft = aircraft[random.randint(0, len(aircraft)-1)]\\r\\n    aircraft_dictionary[random_aircraft[0]] = random_aircraft[1]\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn23_skill1.py\", random_aircraft)\\r\\n    \\r\\n    if output.strip() == str(aircraft_dictionary):\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\")\\r\\n        print(aircraft_dictionary)\\r\\n        return 0.0\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn23_paint': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn23_paint.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn22_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0.0\\r\\n    \\r\\n    if autograder.code_compiles(\"lsn22_skill1.py\"):\\r\\n        file = open(\"lsn22_skill1.py\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        \\r\\n        if \"get_mouse_x(\" in file_contents:\\r\\n            print(\"get_mouse_x called\")\\r\\n            score += 33\\r\\n        else:\\r\\n            print(\"get_mouse_x does not appear to be called.\")\\r\\n            \\r\\n        if \"get_mouse_y(\" in file_contents:\\r\\n            print(\"get_mouse_y called\")\\r\\n            score += 33\\r\\n        else:\\r\\n            print(\"get_mouse_y does not appear to be called.\")\\r\\n            \\r\\n        if \"draw_circle(\" in file_contents:\\r\\n            print(\"draw_circle called\")\\r\\n            score += 34\\r\\n        else:\\r\\n            print(\"draw_circle does not appear to be called.\")\\r\\n            \\r\\n    else:\\r\\n        print(\"There appears to be an error in your python Script that is preventing it from running\")\\r\\n    \\r\\n    print(\"\\\\nThank you for your submission.  Your instructor will let you know if there is an issue.\")\\r\\n    return score        \\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn22_bouncingtriangle': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn22_bouncingtriangle.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn22_bouncingballs': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn22_bouncingballs.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn22_bouncingball': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn22_bouncingball.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn21_triangle': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn21_triangle.py\", doraise=True)\\r\\n        print(\"----------------------------------------------------------------------\")\\r\\n        print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n        print(\"----------------------------------------------------------------------\\\\n\")\\r\\n        \\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn21_stamp': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn21_stamp.py\", doraise=True)\\r\\n        print(\"----------------------------------------------------------------------\")\\r\\n        print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n        print(\"----------------------------------------------------------------------\\\\n\")\\r\\n        \\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn21_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0.0\\r\\n    \\r\\n    if autograder.code_compiles(\"lsn21_skill1.py\"):\\r\\n        file = open(\"lsn21_skill1.py\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        \\r\\n        if \"draw_circle(\" in file_contents:\\r\\n            print(\"draw_circle called\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"draw_circle does not appear to be called.  You need to call it in the draw() function\")\\r\\n            \\r\\n        if file_contents.count(\"ball_x\") + file_contents.count(\"ball_y\") > 5:\\r\\n            print(\"Looks like you are using ball_x and/or ball_y\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"Make sure you are changing the value of ball_x and ball_y in update().\")\\r\\n            \\r\\n    else:\\r\\n        print(\"There appears to be an error in your python Script that is preventing it from running\")\\r\\n    \\r\\n    print(\"\\\\nThank you for your submission.  Your instructor will let you know if there is an issue.\")\\r\\n    return score        \\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn21_simpledrawing': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    drawing_functions = [\"draw_arc\", \"draw_image\", \"draw_rectangle\", \"draw_circle\", \"draw_ellipse\", \"draw_line\", \"draw_pixel\", \"draw_text\", \"write_text\"]\\r\\n    drawing_functions_called = []\\r\\n    \\r\\n    print(\"----------------------------------------------------------------------\")\\r\\n    print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n    print(\"----------------------------------------------------------------------\\\\n\")\\r\\n    \\r\\n    file = open(\"lsn21_simpledrawing.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    for f in drawing_functions:\\r\\n        if f in file_contents and f not in drawing_functions_called:\\r\\n            drawing_functions_called.append(f)\\r\\n    \\r\\n    if len(drawing_functions_called) >= 4 and \"draw_image\" in drawing_functions_called:\\r\\n        print(\"Good Job!\")\\r\\n        return 100.0\\r\\n    elif len(drawing_functions_called) >= 4 and \"draw_image\" not in drawing_functions_called:\\r\\n        print(\"Missing at least one call of draw_image\")\\r\\n        return 90.0\\r\\n    else:\\r\\n        print(\"Not enough different drawing functions.  Need 4 unique (including draw_image) calls.\")\\r\\n        return 25 * len(drawing_functions_called)\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn21_randomcircles': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:\\r\\n        py_compile.compile(\"lsn21_randomcircles.py\", doraise=True)\\r\\n        print(\"----------------------------------------------------------------------\")\\r\\n        print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n        print(\"----------------------------------------------------------------------\\\\n\")\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn20_unpopularnames': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nexpected_output_male = [\"ALDO\", \"ALIJAH\", \"ALLAN\", \"ANGEL\", \"ARTURO\", \"AUGUSTUS\", \"BENNETT\", \"BERISH\", \"CADEN\", \"CHRIS\", \"CODY\", \"COREY\", \"DERRICK\", \"DEVON\", \"DONOVAN\", \"EASON\", \"EDWARD\", \"ELLIS\", \"GIOVANI\", \"HASSAN\",]\\r\\nexpected_output_female = [\"ABBY\", \"AIZA\", \"ALISHA\", \"ANGELICA\", \"ANGIE\", \"ARIANNY\", \"ARIELA\", \"ATARA\", \"AUBREY\", \"AUTUMN\", \"AYLA\", \"BIANCA\", \"BONNIE\", \"BRIANNY\", \"CASSANDRA\", \"CELIA\", \"CHAVY\", \"CHEYENNE\", \"CORA\", \"CRISTINA\"]\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    if (random.random() > 0.5):\\r\\n        gender = \"MALE\"\\r\\n        expected_output = expected_output_male\\r\\n    else:\\r\\n        gender = \"FEMALE\"\\r\\n        expected_output = expected_output_female\\r\\n        \\r\\n    num_to_print = random.randint(5, 20)\\r\\n    output, error = autograder.run_script(\"lsn20_unpopularnames.py\", [gender, num_to_print])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    num_matches = autograder.compare_strings(lines, expected_output[:num_to_print])\\r\\n    \\r\\n    print()\\r\\n    \\r\\n    if len(lines) == 0:\\r\\n        return 0\\r\\n    elif len(lines) > len(expected_output[:num_to_print]):\\r\\n        print(\"Your program printed more lines than we expected\")\\r\\n        return round(100 * num_matches / len(lines), 1)\\r\\n    else:\\r\\n        return round(100.0/len(expected_output[:num_to_print]) * num_matches, 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn20_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0.0\\r\\n    \\r\\n    if autograder.code_compiles(\"lsn20_skill1.py\"):\\r\\n        file = open(\"lsn20_skill1.py\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        \\r\\n        if \"get_mouse_x(\" in file_contents:\\r\\n            print(\"get_mouse_x called\")\\r\\n            score += 33\\r\\n        else:\\r\\n            print(\"get_mouse_x does not appear to be called.\")\\r\\n            \\r\\n        if \"get_mouse_y(\" in file_contents:\\r\\n            print(\"get_mouse_y called\")\\r\\n            score += 33\\r\\n        else:\\r\\n            print(\"get_mouse_y does not appear to be called.\")\\r\\n            \\r\\n        if \"draw_circle(\" in file_contents:\\r\\n            print(\"draw_circle called\")\\r\\n            score += 34\\r\\n        else:\\r\\n            print(\"draw_circle does not appear to be called.\")\\r\\n            \\r\\n    else:\\r\\n        print(\"There appears to be an error in your python Script that is preventing it from running\")\\r\\n    \\r\\n    print(\"\\\\nThank you for your submission.  Your instructor will let you know if there is an issue.\")\\r\\n    return score        \\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn20_sat': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution():  \\r\\n    result = \\'\\'\\r\\n    file = open(\"sat.csv\", \"r\")\\r\\n    contents = file.read()\\r\\n    lines = contents.split(\"\\\\n\")\\r\\n\\r\\n    sat_table = []\\r\\n    total = 0\\r\\n\\r\\n    for line in lines:\\r\\n        line_components = line.split(\\',\\')\\r\\n        \\r\\n        school = line_components[0]\\r\\n        sat_score = int(line_components[1]) + int(line_components[2]) + int(line_components[3])\\r\\n        total += sat_score\\r\\n        row = [school, sat_score]\\r\\n        sat_table.append(row)\\r\\n\\r\\n    average = total / len(sat_table)\\r\\n\\r\\n    for row in sat_table:\\r\\n        if row[1] < average:\\r\\n            result += str(row[0]) + \"\\\\n\"\\r\\n\\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    expected_output = solution().strip().split(\\'\\\\n\\')\\r\\n    output, error = autograder.run_script(\"lsn20_sat.py\", [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    num_matches = autograder.compare_strings(lines, expected_output)\\r\\n    \\r\\n    print()\\r\\n    \\r\\n    if len(lines) == 0:\\r\\n        return 0\\r\\n    elif len(lines) > len(expected_output):\\r\\n        print(\"Your program printed more lines than we expected\")\\r\\n        return round(100 * num_matches / len(lines), 1)\\r\\n    else:\\r\\n        return round(100.0/len(expected_output) * num_matches, 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn20_popularnames': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nexpected_output = [\\r\\n\"ISABELLA\",\\r\\n\"MIA\",\\r\\n\"MOSHE\",\\r\\n\"ESTHER\",\\r\\n\"SOPHIA\",\\r\\n\"EMMA\",\\r\\n\"CAMILA\",\\r\\n\"CHAYA\",\\r\\n\"ETHAN\",\\r\\n\"JAYDEN\",\\r\\n\"SOFIA\",\\r\\n\"AVA\",\\r\\n\"JEREMIAH\",\\r\\n\"CHAIM\",\\r\\n\"JOSE\",\\r\\n\"CHANA\",\\r\\n\"LUIS\",\\r\\n\"ELLA\",\\r\\n\"CHARLOTTE\",\\r\\n\"HAILEY\",\\r\\n\"LEAH\",\\r\\n\"MADISON\"]\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    num_to_print = random.randint(5, 15)\\r\\n    output, error = autograder.run_script(\"lsn20_popularnames.py\", [num_to_print])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    num_matches = autograder.compare_strings(lines, expected_output[:num_to_print])\\r\\n    \\r\\n    print()\\r\\n    \\r\\n    if len(lines) == 0:\\r\\n        return 0\\r\\n    elif len(lines) > len(expected_output[:num_to_print]):\\r\\n        print(\"Your program printed more lines than we expected\")\\r\\n        return round(100 * num_matches / len(lines), 1)\\r\\n    else:\\r\\n        return round(100.0/len(expected_output[:num_to_print]) * num_matches, 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn20_lowvolume': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nexpected_output = [\\r\\n\"700\",\\r\\n\"Harbor Ave\",\\r\\n\"Woodlawn Ave\",\\r\\n\"Root St\",\\r\\n\"Calumet Ave\",\\r\\n\"Financial PL\",\\r\\n\"16th St\",\\r\\n\"Racine Ave\",\\r\\n\"60th St\",\\r\\n\"Wentworth Ave\",\\r\\n\"Parnell Ave\",\\r\\n\"Ashland Ave\",\\r\\n\"Federal St\",\\r\\n\"Hamlin Ave\",\\r\\n\"Pitney Ct\",\\r\\n\"109th St\",\\r\\n\"Loomis St\",\\r\\n\"Harrison St\",\\r\\n\"24th St\",\\r\\n\"La Salle St\",\\r\\n\"83rd Pl\",\\r\\n\"Homan Ave\"]\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    output, error = autograder.run_script(\"lsn20_lowvolume.py\", [])\\r\\n    lines = set(output.split(\\'\\\\n\\'))\\r\\n    matches = (len(lines.intersection(expected_output)))\\r\\n    return (round((matches/22)*100,1))\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn20_averagetraffic': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nexpected_output = [\"525\"]\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn20_averagetraffic.py\", [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_output)\\r\\n       \\r\\n    return round(num_matches * (100.0 / len(expected_output)), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn19_skill2': 'from cs110 import autograder\\r\\nimport random, math\\r\\nfrom lsn19_skill2 import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    if len(squadron_table) >= 2:\\r\\n        print(\"Squadron Table has at least 2 things in them.  Let\\'s see what\\'s inside!\")\\r\\n        score += 20\\r\\n        \\r\\n        if (squadron_table[0][0] == \"Dogs of War\" and squadron_table[0][1] == 3):\\r\\n            print(\"First Row Added Correctly\")\\r\\n            score += 40\\r\\n        else:\\r\\n            print(\"Something is wrong with the first row.  Make sure you are appending a list!\")\\r\\n        \\r\\n        if (squadron_table[1][0] == \"Wolverines\" and squadron_table[1][1] == 19):\\r\\n            print(\"Second Row Added Correctly\")\\r\\n            score += 40\\r\\n        else:\\r\\n            print(\"Something is wrong with the second row.  Make sure you are appending a list!\")\\r\\n    else:\\r\\n        print(\"Squadron Table does not appear to have (at least) 2 rows\")\\r\\n        \\r\\n    return score\\r\\n        \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn19_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\nfrom lsn19_skill1 import *\\r\\n\\r\\nanswer= [[37, \\'USA\\'],\\r\\n        [23, \\'Britain\\'],\\r\\n        [18, \\'China\\'],\\r\\n        [17, \\'Russia\\'],\\r\\n        [10, \\'Germany\\'],\\r\\n        [8, \\'Japan\\'],\\r\\n        [18, \\'France\\'],\\r\\n        [3, \\'South Korea\\'],\\r\\n        [12, \\'Italy\\'],\\r\\n        [11, \\'Australia\\']]\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_matches = 0\\r\\n    count_vals_as_str = 0\\r\\n    \\r\\n    for i in range(len(my_table)):\\r\\n        print(\"Row \" + str(i+1) + \": \", end=\\'\\')\\r\\n        if i < len(answer):\\r\\n            if my_table[i] == answer[i]:\\r\\n                print(\"CORRECT\")\\r\\n                num_matches += 1\\r\\n            else:\\r\\n                if type(my_table[i][0]) is str:\\r\\n                    count_vals_as_str += 1\\r\\n                print(\"INCORRECT (Expected: \" + str(answer[i]) + \" instead of \" + str(my_table[i]) + \")\")\\r\\n        else:\\r\\n            print(\"INCORRECT (Unexpected Row: \\'\" + str(my_table[i]) + \"\\')\")\\r\\n    \\r\\n    print()\\r\\n    print(num_matches, \"out of\", len(answer), \"rows match\")\\r\\n    if count_vals_as_str > 0:\\r\\n        print(\"Looks like your medal numbers are strings not integers.\")\\r\\n    \\r\\n    if len(answer) < num_matches:\\r\\n        return 100 * num_matches / len(answer)\\r\\n    else:\\r\\n        return num_matches * (100 / len(answer))\\r\\n    \\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn19_population': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\ndef solution(population):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    cities_table = [\\r\\n        [\\'Tokyo\\', 37435191],\\r\\n        [\\'Delhi\\', 29399141],\\r\\n        [\\'Shanghai\\', 25647805],\\r\\n        [\\'Sao Paulo\\', 21846507],\\r\\n        [\\'Mexico City\\', 21671908],\\r\\n        [\\'Cairo\\', 20484965],\\r\\n        [\\'Dhaka\\', 20283552],\\r\\n        [\\'Mumbai\\', 20185064],\\r\\n        [\\'Beijing\\', 20035455],\\r\\n        [\\'Osaka\\', 19222665]]\\r\\n    \\r\\n    for row in cities_table:\\r\\n        if row[1] >= population:\\r\\n            result += row[0] + \\'\\\\n\\'\\r\\n    \\r\\n    return result.strip()\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    random_population_size = random.randint(19, 30) * 1000000\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn19_population.py\", [random_population_size])\\r\\n    answer = solution(random_population_size)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, answer.strip().split(\\'\\\\n\\'))\\r\\n    \\r\\n    if num_matches == len(lines):\\r\\n        print(\"\\\\nCORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"\\\\nOne or more outputs were incorrect.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn19_movies': 'from cs110 import autograder\\r\\nimport random\\r\\nimport lsn19_movies\\r\\n\\r\\ndef solution(movies_table, rating, runtime):\\r\\n    count = 0\\r\\n    \\r\\n    for row in movies_table:\\r\\n        if row[2] == rating and row[3] >= runtime:\\r\\n            count += 1\\r\\n    \\r\\n    return count\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    ratings = [\\'PG\\', \\'PG-13\\', \\'R\\']\\r\\n    num_passed = 0\\r\\n    \\r\\n    for rating in ratings:\\r\\n        movies_table = [\\r\\n            [\"Star Wars: A New Hope\", 1977, \"PG\", 121],\\r\\n            [\"Star Trek: The Motion Picture\", 1979, \"G\", 132],\\r\\n            [\"Raiders of the Lost Ark\", 1989, \"PG\", 115],\\r\\n            [\"Indiana Jones and the Temple of Doom\", 1984, \"PG\", 118],\\r\\n            [\"Indiana Jones and the Last Crusade\", 1989, \"PG-13\", 127],\\r\\n            [\"Serenity\", 2005, \"PG-13\", 119],\\r\\n            [\"Joker\", 2019, \"R\", 122],\\r\\n            [\"The Terminator\", 1984, \"R\", 107]\\r\\n            ]\\r\\n        test_table = []\\r\\n        runtime = random.randint(90, 120)\\r\\n        \\r\\n        for j in range(random.randint(2, 5)):\\r\\n            index = random.randint(0, len(movies_table)-1)\\r\\n            test_table.append(movies_table[index])\\r\\n            movies_table.remove(movies_table[index])\\r\\n        \\r\\n        print(\"Testing (Rating = \" + rating + \"):\\\\n\" + \"  Movie Table: \" + str(test_table) + \"\\\\n\" + \"  Runtime: \" + str(runtime))\\r\\n        print(\"  Expecting: \" + str(solution(test_table, rating, runtime)) + \"\\\\n  Your Function\\'s Output: \" + str(lsn19_movies.get_movies(test_table, rating, runtime)))\\r\\n        \\r\\n        if solution(test_table, rating, runtime) == lsn19_movies.get_movies(test_table, rating, runtime):\\r\\n            print(\"PASSED!\\\\n\")\\r\\n            num_passed += 1\\r\\n        else:\\r\\n            print(\"INCORRECT\\\\n\")\\r\\n            \\r\\n    \\r\\n    return (num_passed / len(ratings)) * 100.0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn19_golf': 'from cs110 import autograder\\r\\nimport random, statistics\\r\\n\\r\\nrandom_names = [\\'Mcllroy\\', \\'Koepka\\', \\'Rahm\\', \\'Woods\\', \\'Thomas\\', \\'Johnson\\', \\'Cantlay\\', \\'Simpson\\']\\r\\n\\r\\ndef get_random_name():\\r\\n    global random_names\\r\\n    name = random_names[random.randint(0, len(random_names)-1)]\\r\\n    random_names.remove(name)\\r\\n    return name\\r\\n\\r\\n\\r\\ndef solution(data):\\r\\n    min_value = 99999\\r\\n    min_name = \"\"\\r\\n    count = 0\\r\\n    \\r\\n    for row in data:\\r\\n        if row[1] < min_value:\\r\\n            min_value = row[1]\\r\\n            min_name = row[0]\\r\\n    \\r\\n    for row in data:\\r\\n        if row[1] <= min_value + 5:\\r\\n            count += 1\\r\\n\\r\\n    return min_name, (count / len(data) * 100.0)\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num_inputs = random.randint(2, 5)\\r\\n    input_list = []\\r\\n    data = []\\r\\n        \\r\\n    for i in range(num_inputs):\\r\\n        new_row = [get_random_name(), random.randint(70, 90)]\\r\\n        input_list.append(new_row[0])\\r\\n        input_list.append(new_row[1])\\r\\n        data.append(new_row)\\r\\n    input_list.append(\"END\")\\r\\n    \\r\\n    lowest_name, percent = solution(data)\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn19_golf.py\", input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    # Checks Min\\r\\n    if len(lines) < 2:\\r\\n        print(\"Number of output lines does not match\")\\r\\n        return 0\\r\\n    else:\\r\\n        if not lowest_name == lines[0]:\\r\\n            print(\"Incorrect Name.  Expected \" + str(lowest_name))\\r\\n            return 0\\r\\n        if not autograder.equals(percent, lines[1]):\\r\\n            print(\"Incorrect Percent.  Expected \" + str(percent))\\r\\n            return 50\\r\\n        \\r\\n    print(\"PASSED!\")\\r\\n    return 100\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn19_credit': 'from cs110 import autograder\\r\\nimport random, statistics\\r\\n\\r\\nrandom_names = [\\'Gates\\', \\'Bezos\\', \\'Zuckerberg\\', \\'Ellison\\', \\'Page\\', \\'Brin\\', \\'Huateng\\', \\'Dell\\', \\'Musk\\', \\'Allen\\']\\r\\n\\r\\ndef get_random_name():\\r\\n    global random_names\\r\\n    name = random_names[random.randint(0, len(random_names)-1)]\\r\\n    random_names.remove(name)\\r\\n    return name\\r\\n\\r\\n\\r\\ndef solution(data):\\r\\n    highest_value = -99999\\r\\n    highest_name = \"\"\\r\\n    count = 0\\r\\n    \\r\\n    for row in data:\\r\\n        if row[1] > highest_value:\\r\\n            highest_value = row[1]\\r\\n            highest_name = row[0]\\r\\n    \\r\\n    for row in data:\\r\\n        if row[1] >= highest_value - 10000:\\r\\n            count += 1\\r\\n\\r\\n    return highest_name, (count / len(data) * 100.0)\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num_inputs = random.randint(5, 7)\\r\\n    input_list = []\\r\\n    data = []\\r\\n        \\r\\n    for i in range(num_inputs):\\r\\n        new_row = [get_random_name(), random.randint(5000, 35000)]\\r\\n        input_list.append(new_row[0])\\r\\n        input_list.append(new_row[1])\\r\\n        data.append(new_row)\\r\\n    input_list.append(\"DONE\")\\r\\n    \\r\\n    highest_balance, percent = solution(data)\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn19_credit.py\", input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    # Checks Min\\r\\n    if len(lines) < 2:\\r\\n        print(\"Number of output lines does not match\")\\r\\n        return 0\\r\\n    else:\\r\\n        if not highest_balance == lines[0]:\\r\\n            print(\"Incorrect Highest Balance.  Expected \" + str(highest_balance))\\r\\n            return 0\\r\\n        if not autograder.equals(percent, lines[1]):\\r\\n            print(\"Incorrect Percent.  Expected \" + str(percent))\\r\\n            return 50\\r\\n        \\r\\n    print(\"PASSED!\")\\r\\n    return 100\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn19_100m': 'from cs110 import autograder\\r\\nimport random, statistics\\r\\n\\r\\nrandom_names = [\\'Alice\\', \\'Bob\\', \\'Courtney\\', \\'Devon\\', \\'Frank\\', \\'Genie\\']\\r\\n\\r\\ndef get_random_name():\\r\\n    global random_names\\r\\n    name = random_names[random.randint(0, len(random_names)-1)]\\r\\n    random_names.remove(name)\\r\\n    return name\\r\\n\\r\\ndef solution(data):\\r\\n    fastest_time = 99999\\r\\n    fastest_squadron = 0\\r\\n    total = 0\\r\\n    count = 0\\r\\n    \\r\\n    for row in data:\\r\\n        total += row[2]\\r\\n        if row[2] <= fastest_time:\\r\\n            fastest_time = row[2]\\r\\n            fastest_squadron = row[1]\\r\\n            \\r\\n    average = total / len(data)\\r\\n    \\r\\n    for row in data:\\r\\n        if row[2] <= average:\\r\\n            count += 1\\r\\n    \\r\\n    return fastest_squadron, fastest_time, count\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num_inputs = random.randint(2, 5)\\r\\n    input_list = [num_inputs]\\r\\n    data = []\\r\\n        \\r\\n    for i in range(num_inputs):\\r\\n        new_row = [get_random_name(), random.randint(1, 40), round(random.uniform(12, 18), 1)]\\r\\n        input_list.append(new_row[0])\\r\\n        input_list.append(new_row[1])\\r\\n        input_list.append(new_row[2])\\r\\n        data.append(new_row)\\r\\n    \\r\\n    fastest_squadron, fastest_time, count = solution(data)\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn19_100m.py\", input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    # Checks Min\\r\\n    if len(lines) != 3:\\r\\n        print(\"Number of output lines does not match\")\\r\\n        return 0\\r\\n    else:\\r\\n        if not autograder.equals(fastest_squadron, lines[0]):\\r\\n            print(\"Incorrect Squadron.  Expected \" + str(fastest_squadron))\\r\\n            return 0\\r\\n        if not autograder.equals(fastest_time, lines[1]):\\r\\n            print(\"Incorrect Time.  Expected \" + str(fastest_time))\\r\\n            return 33\\r\\n        if not autograder.equals(count, lines[2]):\\r\\n            print(\"Incorrect Count.  Expected \" + str(count))\\r\\n            return 67\\r\\n        \\r\\n    print(\"PASSED!\")\\r\\n    return 100\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn18_swimstats': 'from cs110 import autograder\\r\\nimport random, statistics\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    list_of_swim_times = []\\r\\n    for i in range(6):\\r\\n        list_of_swim_times.append(random.randint(40, 60))\\r\\n    min_time = min(list_of_swim_times)\\r\\n    max_time = max(list_of_swim_times)\\r\\n    range_time = max_time - min_time\\r\\n    average = sum(list_of_swim_times) / len(list_of_swim_times)\\r\\n    \\r\\n    # There are multiple standard deviations; this unit test accepts either one\\r\\n    stdev = statistics.stdev(list_of_swim_times)\\r\\n    pstdev = statistics.pstdev(list_of_swim_times)\\r\\n    \\r\\n    list_of_swim_times.append(-1)\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn18_swimstats.py\", list_of_swim_times)\\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n\\r\\n    # Checks Min\\r\\n    if len(lines) != 4:\\r\\n        print(\"Number of output lines does not match\")\\r\\n        return 0\\r\\n    else:\\r\\n        if not autograder.equals(average, lines[0]):\\r\\n            print(\"Invalid Average.  Expected \" + str(average))\\r\\n            return 0\\r\\n        if not autograder.equals(range_time, lines[1]):\\r\\n            print(\"Invalid Range.  Expected \" + str(range_time))\\r\\n            return 33\\r\\n        if not (autograder.equals(stdev, lines[2]) or equals(pstdev, lines[2])):\\r\\n            print(\"Invalid Std Dev.  Expected \" + str(stdev))\\r\\n            return 67\\r\\n        \\r\\n    print(\"PASSED!\")\\r\\n    return 100\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn18_skill2': 'from cs110 import autograder\\r\\nimport random, math\\r\\nfrom lsn18_skill2 import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    if len(squadron_table) >= 2:\\r\\n        print(\"Squadron Table has at least 2 things in them.  Let\\'s see what\\'s inside!\")\\r\\n        score += 20\\r\\n        \\r\\n        if (squadron_table[0][0] == \"Dogs of War\" and squadron_table[0][1] == 3):\\r\\n            print(\"First Row Added Correctly\")\\r\\n            score += 40\\r\\n        else:\\r\\n            print(\"Something is wrong with the first row.  Make sure you are appending a list!\")\\r\\n        \\r\\n        if (squadron_table[1][0] == \"Wolverines\" and squadron_table[1][1] == 19):\\r\\n            print(\"Second Row Added Correctly\")\\r\\n            score += 40\\r\\n        else:\\r\\n            print(\"Something is wrong with the second row.  Make sure you are appending a list!\")\\r\\n    else:\\r\\n        print(\"Squadron Table does not appear to have (at least) 2 rows\")\\r\\n        \\r\\n    return score\\r\\n        \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn18_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nstarship_table = [[\\'Constitution\\', 288.6,  127.1,  72.6],\\r\\n                  [\\'Galaxy\\',       642.5,  463.73, 135.26],\\r\\n                  [\\'Intrepid\\',     343.0,  133.0,  66],\\r\\n                  [\\'Sovereign\\',   685.3,  250.6,  88.2]]\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    row_to_print = random.randint(0, len(starship_table) - 1)\\r\\n    col_to_print = random.randint(0, len(starship_table[0]) - 1)\\r\\n    value_from_table = str(starship_table[row_to_print][col_to_print])\\r\\n    value_from_table_flipped = str(starship_table[col_to_print][row_to_print])\\r\\n    output, error = autograder.run_script(\"lsn18_skill1.py\", [row_to_print, col_to_print])\\r\\n    \\r\\n    if output.strip() == value_from_table:\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    elif output.strip() == value_from_table_flipped:\\r\\n        print(\"INCORRECT. Expected\", value_from_table)\\r\\n        print(\"It looks like you flipped columns and rows.  Remember that the format is list_name[row][col]\")\\r\\n        return 25.0\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected\", value_from_table)\\r\\n        print(\"Try again.  Remember that the format is list_name[row][col]\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn18_namesreverse': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\ndef solution(name_list):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    for i in range(len(name_list) - 1, -1, -1):\\r\\n        result += name_list[i] + \"\\\\n\"\\r\\n\\r\\n    return result.strip()\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    name_list = [\"Alice\", \"Bob\", \"Catrina\", \"Dennis\", \"Felix\", \"Garfield\", \"Henry\", \"Ignis\", \"Jack\", \"Kelly\"]\\r\\n    num_names = random.randint(3, len(name_list))\\r\\n    input_list = []\\r\\n    random_names = []\\r\\n    \\r\\n    for i in range(num_names):\\r\\n        random_name = name_list[random.randint(0, len(name_list)-1)]\\r\\n        input_list.append(random_name)\\r\\n        random_names.append(random_name)\\r\\n        name_list.remove(random_name)\\r\\n    \\r\\n    input_list.append(\"END\")\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn18_namesreverse.py\", input_list)\\r\\n    expected_output = solution(random_names)\\r\\n    \\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n',\n",
       "  'lsn18_names': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\ndef solution(name_list):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    name_list.sort()\\r\\n    \\r\\n    for name in name_list:\\r\\n        result += name + \"\\\\n\"\\r\\n    \\r\\n    return result.strip()\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    name_list = [\"Alice\", \"Bob\", \"Catrina\", \"Dennis\", \"Felix\", \"Garfield\", \"Henry\", \"Ignis\", \"Jack\", \"Kelly\"]\\r\\n    num_names = random.randint(3, len(name_list))\\r\\n    input_list = [num_names]\\r\\n    random_names = []\\r\\n    \\r\\n    for i in range(num_names):\\r\\n        random_name = name_list[random.randint(0, len(name_list)-1)]\\r\\n        input_list.append(random_name)\\r\\n        random_names.append(random_name)\\r\\n        name_list.remove(random_name)\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn18_names.py\", input_list)\\r\\n    expected_output = solution(random_names)\\r\\n    \\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n',\n",
       "  'lsn18_grades': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\ndef solution(grade_list):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    average = sum(grade_list) / len(grade_list)\\r\\n    \\r\\n    for grade in grade_list:\\r\\n        if (grade >= (average + 10)):\\r\\n            result += str(grade) + \"\\\\n\"\\r\\n    \\r\\n    return result.strip()\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    num_grades = random.randint(3, 7)\\r\\n    input_list = [num_grades]\\r\\n    random_grades = []\\r\\n    \\r\\n    for i in range(num_grades):\\r\\n        random_grade = random.randint(0, 100)\\r\\n        input_list.append(random_grade)\\r\\n        random_grades.append(random_grade)\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn18_grades.py\", input_list)\\r\\n    expected_output = solution(random_grades)\\r\\n    \\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n',\n",
       "  'lsn18_combinations': 'from cs110 import autograder\\r\\nimport random, lsn18_combinations\\r\\n\\r\\nSTUDENT_SCRIPT = \"lsn18_combinations.py\"\\r\\n\\r\\n\\r\\ndef solution(list_of_characters):\\r\\n    result = []\\r\\n    \\r\\n    for character1 in list_of_characters:\\r\\n        for character2 in list_of_characters:\\r\\n            result.append(character2 + character1)\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    possible_characters = [\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\', \\'f\\', \\'g\\']\\r\\n    list_size = random.randint(2, len(possible_characters))\\r\\n    test_input = []\\r\\n    \\r\\n    for i in range(list_size):\\r\\n        random_index = int(random.random() * len(possible_characters))\\r\\n        random_character = possible_characters[random_index]\\r\\n        test_input.append(random_character)\\r\\n        possible_characters.remove(random_character)\\r\\n\\r\\n    # Runs the Script\\r\\n    answer = solution(test_input)\\r\\n    student_answer = lsn18_combinations.get_combinations(test_input)\\r\\n    \\r\\n    print(\"Letters Provided:\\\\n\", test_input, \"\\\\n\")\\r\\n    print(\"Expected:\\\\n\" + str(answer) + \"\\\\n\")\\r\\n    print(\"Your List:\\\\n\" + str(student_answer) + \"\\\\n\")\\r\\n\\r\\n    if len(answer) == len(student_answer):\\r\\n        for combo in answer:\\r\\n            if student_answer.count(combo) != 1:\\r\\n                print(\"Missing Combo Value: \" + combo)\\r\\n                return 0\\r\\n    else:\\r\\n        print(\"Lists are not the same size\")\\r\\n        return 0\\r\\n    \\r\\n    print(\"CORRECT\")\\r\\n    return 100\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn16_practice4': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n\\r\\n    num_tests_passed = 0\\r\\n    test_cases = [(\"Regular\", 37, 2.938), (\"Midgrade\", 37, 3.098), (\"Premium\", 37, 3.208), (\"Diesel\", 32, 3.242)]\\r\\n\\r\\n    for test_case in test_cases:\\r\\n        print(\"# -----------------------------------\")\\r\\n        print(\"# Testing\", test_case[0])\\r\\n        print(\"# -----------------------------------\")\\r\\n        output, error = autograder.run_script(\"lsn16_practice4.py\", [test_case[0]])\\r\\n    \\r\\n        lines = output.strip().split(\\'\\\\n\\')\\r\\n        \\r\\n        if len(lines) > 0:\\r\\n            if autograder.equals(lines[0], test_case[2]):\\r\\n                print(\"CORRECT\")\\r\\n                num_tests_passed += 1\\r\\n            elif len(lines) > 1 and autograder.equals(lines[0], test_case[1]) and autograder.equals(lines[1], test_case[2]):\\r\\n                print(\"CORRECT\")\\r\\n                num_tests_passed += 1\\r\\n            else:\\r\\n                print(\"INCORRECT\")\\r\\n            print()\\r\\n                    \\r\\n    return round(100 / len(test_cases), 1) * num_tests_passed\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn16_practice3': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(weights, heights):\\r\\n    num_thin = 0\\r\\n    num_healthy = 0\\r\\n    num_overweight = 0\\r\\n    num_obese = 0\\r\\n    \\r\\n    for i in range(len(weights)):\\r\\n        bmi = 703 * (weights[i] / heights[i]**2)\\r\\n\\r\\n        if bmi <= 18.5:\\r\\n            num_thin += 1\\r\\n        elif bmi <= 25:\\r\\n            num_healthy += 1\\r\\n        elif bmi <= 30:\\r\\n            num_overweight += 1\\r\\n        else:\\r\\n            num_obese += 1\\r\\n    \\r\\n    return (num_thin, num_healthy, num_overweight, num_obese)\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n\\r\\n    score = 0\\r\\n\\r\\n    # Generates the Test Set\\r\\n    num_students = random.randint(5, 10)\\r\\n    inputs = [num_students]\\r\\n    weights = []\\r\\n    heights = []\\r\\n    \\r\\n    for i in range(num_students):\\r\\n        random_weight = random.randint(120, 200)\\r\\n        random_height = random.randint(55, 76)\\r\\n        \\r\\n        weights.append(random_weight)\\r\\n        heights.append(random_height)\\r\\n        \\r\\n        inputs.append(random_weight)\\r\\n        inputs.append(random_height)\\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn16_practice3.py\", inputs)\\r\\n    expected_output = solution(weights, heights)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Thin is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Thin is Incorrect.  Expected\", expected_output[0])\\r\\n\\r\\n    if len(lines) > 1 and autograder.equals(lines[1], expected_output[1]):\\r\\n        print(\"Healthy is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Healthy is Incorrect.  Expected\", expected_output[1])\\r\\n    \\r\\n    if len(lines) > 2 and autograder.equals(lines[2], expected_output[2]):\\r\\n        print(\"Overweight is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Overweight is Incorrect.  Expected\", expected_output[2])\\r\\n    \\r\\n    if len(lines) > 3 and autograder.equals(lines[3], expected_output[3]):\\r\\n        print(\"Obese is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Obese is Incorrect.  Expected\", expected_output[0])\\r\\n        \\r\\n    return score\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn16_practice2': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef get_value(n):\\r\\n    return (2 * n) + 1\\r\\n\\r\\n\\r\\ndef solution(x):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    for i in range(x, x+6):\\r\\n        result += str(get_value(i)) + \"\\\\n\"\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n    random_value = random.randint(5, 15)\\r\\n    output, error = autograder.run_script(\"lsn16_practice2.py\", [random_value])\\r\\n    expected_output = solution(random_value)\\r\\n    \\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn16_practice1': 'from cs110 import autograder\\r\\nimport lsn16_practice1\\r\\n\\r\\ndef add_values(x, y, z):\\r\\n    return x + y + z\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    if \\'add_values\\' in dir(lsn16_practice1) and add_values(1, 2, 3) == lsn16_practice1.add_values(1, 2, 3):\\r\\n        print(\"PASSED\")\\r\\n        return 100.0\\r\\n    elif \\'add_values\\' not in dir(lsn16_practice1):\\r\\n        print(\"FAILED.  Could not find function \\'add_values\\'\")\\r\\n    elif result != solution:\\r\\n        print(\"FAILED.  Function \\'add_values\\' did not return the correct value\")\\r\\n    else:\\r\\n        print(\"FAILED.  Something unexpected happened.\")\\r\\n    \\r\\n    return 0.0\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn15_titanicsurvivor': 'from cs110 import autograder\\r\\nimport random, math, os.path\\r\\n\\r\\nlowest_fare = 9999999\\r\\nlowest_fare_name = \\'\\'\\r\\n\\r\\ndef solution(filename):\\r\\n    global lowest_fare, lowest_fare_name\\r\\n\\r\\n    file = open(filename, \\'r\\')\\r\\n    file_contents = file.read()\\r\\n    lines_in_file = file_contents.split(\\'\\\\n\\')\\r\\n    result = \\'\\'\\r\\n\\r\\n    for line in lines_in_file:\\r\\n        line_components = line.split(\\',\\')\\r\\n        \\r\\n        survived = line_components[0] == \\'1\\'\\r\\n        name = line_components[2]\\r\\n        fare = float(line_components[7])\\r\\n        \\r\\n        if survived == True:\\r\\n            if fare < lowest_fare:\\r\\n                lowest_fare = fare\\r\\n                lowest_fare_name = name\\r\\n\\r\\n    file.close()\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n   \\r\\n    \\r\\n    # Deletes Result.txt if it already exists\\r\\n    if (os.path.exists(\"result.txt\")):\\r\\n        os.remove(\"result.txt\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn15_titanicsurvivor.py\", [\"titanic2.csv\"])\\r\\n    \\r\\n    # Checks to see if the file was created by the program\\r\\n    if (not os.path.exists(\"result.txt\")):\\r\\n        print(\"result.txt is missing\")\\r\\n    else:\\r\\n        solution(\"titanic2.csv\")\\r\\n        \\r\\n        file = open(\"result.txt\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        lines = file_contents.strip().split(\\'\\\\n\\')\\r\\n        \\r\\n        if lines[0] == lowest_fare_name:\\r\\n            print(\"Correct Passenger\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"Incorrect Passenger\", lowest_fare_name)\\r\\n        \\r\\n        if autograder.equals(lines[1], lowest_fare):\\r\\n            print(\"Correct Lowest Fare\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"Incorrect Lowest Fare.\", lowest_fare)\\r\\n    \\r\\n    return score\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn15_titanicfares': 'from cs110 import autograder\\r\\nimport random, math, os.path\\r\\n\\r\\nhighest_fare = 0\\r\\nlowest_fare = 9999999\\r\\n\\r\\ndef solution(filename, passenger_class):\\r\\n    global highest_fare, lowest_fare\\r\\n\\r\\n    file = open(filename, \\'r\\')\\r\\n    file_contents = file.read()\\r\\n    lines_in_file = file_contents.split(\\'\\\\n\\')\\r\\n    result = \\'\\'\\r\\n\\r\\n    for line in lines_in_file:\\r\\n        line_components = line.split(\\',\\')\\r\\n        \\r\\n        p_class = int(line_components[1])\\r\\n        fare = float(line_components[7])\\r\\n        \\r\\n        if passenger_class == p_class:\\r\\n            if fare > highest_fare:\\r\\n                highest_fare = fare\\r\\n            if fare < lowest_fare:\\r\\n                lowest_fare = fare\\r\\n\\r\\n    file.close()\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    random_passenger_class = random.randint(1, 3)\\r\\n    \\r\\n    # Deletes Result.txt if it already exists\\r\\n    if (os.path.exists(\"result.txt\")):\\r\\n        os.remove(\"result.txt\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn15_titanicfares.py\", [\"titanic2.csv\", random_passenger_class])\\r\\n    \\r\\n    # Checks to see if the file was created by the program\\r\\n    if (not os.path.exists(\"result.txt\")):\\r\\n        print(\"result.txt is missing\")\\r\\n    else:\\r\\n        solution(\"titanic2.csv\", random_passenger_class)\\r\\n        \\r\\n        file = open(\"result.txt\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        lines = file_contents.strip().split(\\'\\\\n\\')\\r\\n        if len(lines) < 2:\\r\\n            print(\"Not enough lines in result.txt\")\\r\\n        \\r\\n        if autograder.equals(lines[0], highest_fare):\\r\\n            print(\"Correct Highest Fare\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"Incorrect Highest Fare.  Expected:\", highest_fare)\\r\\n        \\r\\n        if autograder.equals(lines[1], lowest_fare):\\r\\n            print(\"Correct Lowest Fare\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"Incorrect Lowest Fare.  Expected:\", lowest_fare)\\r\\n    \\r\\n    return score\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn15_survivors_by_gender': 'from cs110 import autograder\\r\\nimport random, math, os.path\\r\\n\\r\\nnum_males = 0\\r\\nnum_females = 0\\r\\n\\r\\ndef solution(filename):\\r\\n    global num_males, num_females\\r\\n\\r\\n    input_file = open(filename, \"r\")\\r\\n    contents = input_file.read()\\r\\n    lines = contents.split(\"\\\\n\")\\r\\n\\r\\n    for line in lines:\\r\\n        line_components = line.split(\\',\\')\\r\\n        \\r\\n        if line_components[0] == \\'1\\' and line_components[3] == \\'male\\':\\r\\n            num_males += 1\\r\\n        if line_components[0] == \\'1\\' and line_components[3] == \\'female\\':\\r\\n            num_females += 1\\r\\n\\r\\n    input_file.close()\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    # Deletes Result.txt if it already exists\\r\\n    if (os.path.exists(\"result.txt\")):\\r\\n        os.remove(\"result.txt\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn15_survivors_by_gender.py\", [\"titanic.csv\"])\\r\\n    \\r\\n    # Checks to see if the file was created by the program\\r\\n    if (not os.path.exists(\"result.txt\")):\\r\\n        print(\"result.txt is missing\")\\r\\n    else:\\r\\n        solution(\"titanic.csv\")\\r\\n        \\r\\n        file = open(\"result.txt\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        lines = file_contents.strip().split(\\'\\\\n\\')\\r\\n        if len(lines) < 2:\\r\\n            print(\"Not enough lines in result.txt\")\\r\\n        else:    \\r\\n            if autograder.equals(lines[0], num_males):\\r\\n                print(\"Correct Number of Males:\")\\r\\n                score += 50\\r\\n            else:\\r\\n                print(\"Incorrect Number of Males\")\\r\\n            \\r\\n            if autograder.equals(lines[1], num_females):\\r\\n                print(\"Correct Number of Females\")\\r\\n                score += 50\\r\\n            else:\\r\\n                print(\"Incorrect Number of Females\")\\r\\n    \\r\\n    return score\\r\\n    \\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn15_skill2': 'from cs110 import autograder\\r\\nimport random, math, os\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0.0\\r\\n    \\r\\n    # Deletes Result.txt if it already exists\\r\\n    if (os.path.exists(\"output.txt\")):\\r\\n        os.remove(\"output.txt\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn15_skill2.py\", [])\\r\\n    \\r\\n    if (os.path.exists(\"output.txt\")):\\r\\n        print(\"File Found!\")\\r\\n        score += 50\\r\\n        file = open(\"output.txt\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        if (len(file_contents) > 0):\\r\\n            print(\"File has Something in it!\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"output.txt appears to be empty.  Did you forget to close the file or write to it?\")\\r\\n    else:\\r\\n        print(\"File output.txt does not appear to exist\")\\r\\n    \\r\\n    return score\\r\\n        \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn15_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    expected_output = \"Lorem ipsum dolor sit amet, qui at luptatum efficiantur, ne autem offendit expetendis mel. Nec augue assentior ea, ne debet virtute mel. Integre vivendo id usu, ne primis repudiandae ullamcorper cum. Harum prompta appellantur vix ut. Ius voluptatibus definitiones te, eius scribentur referrentur mei at. Suas tota velit in usu, ex has complectitur signiferumque, sale lorem dolore ei ius. Perpetua scriptorem mei ex, ex est illum summo consul.\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn15_skill1.py\", [])\\r\\n        \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_lines)\\r\\n    \\r\\n    if num_matches == len(lines):\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT\")\\r\\n        return 0.0\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn15_runways': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(filename, length, width):\\r\\n    file = open(filename, \\'r\\')\\r\\n    file_contents = file.read()\\r\\n    lines_in_file = file_contents.split(\\'\\\\n\\')\\r\\n    result = \\'\\'\\r\\n\\r\\n    for line in lines_in_file:\\r\\n        columns = line.split(\\',\\')\\r\\n        if length <= float(columns[2]) and width <= float(columns[3]):\\r\\n            result += columns[0] + \"\\\\n\"\\r\\n\\r\\n    file.close()\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_length = random.randint(3000, 4000)\\r\\n    random_width = random.randint(100, 200)\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn15_runways.py\", [\"runways.csv\", random_length, random_width])\\r\\n    expected_output = solution(\"runways.csv\", random_length, random_width)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_lines)\\r\\n    \\r\\n    if num_matches == len(lines):\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT\")\\r\\n        return 0.0\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn15_echo': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(filename, letter):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    file = open(filename, \"r\")\\r\\n    contents = file.read()\\r\\n    lines = contents.split(\"\\\\n\")\\r\\n\\r\\n    for line in lines:\\r\\n        if line[0] == letter:\\r\\n            result += line + \"\\\\n\"\\r\\n\\r\\n    file.close()\\r\\n\\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_letter = chr(random.randint(97, 122))\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn15_echo.py\", [\"file.txt\", random_letter])\\r\\n    expected_output = solution(\"file.txt\", random_letter)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_lines)\\r\\n    \\r\\n    if num_matches == len(lines):\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT\")\\r\\n        return 0.0\\r\\n        \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn14_timestable': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(multiple):\\r\\n    result = \\'\\'\\r\\n    i = 1\\r\\n    \\r\\n    while i <= 10:\\r\\n        result += str(i * multiple) + \"\\\\n\"\\r\\n        i += 1\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_multiple = random.randint(1, 20)\\r\\n\\r\\n    output, error_message = autograder.run_script(\"lsn14_timestable.py\", [random_multiple])\\r\\n    expected_output = solution(random_multiple)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn14_skill2': 'from cs110 import autograder\\r\\nimport random, math, os\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0.0\\r\\n    \\r\\n    # Deletes Result.txt if it already exists\\r\\n    if (os.path.exists(\"output.txt\")):\\r\\n        os.remove(\"output.txt\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn14_skill2.py\", [])\\r\\n    \\r\\n    if (os.path.exists(\"output.txt\")):\\r\\n        print(\"File Found!\")\\r\\n        score += 50\\r\\n        file = open(\"output.txt\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        if (len(file_contents) > 0):\\r\\n            print(\"File has Something in it!\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"output.txt appears to be empty.  Did you forget to close the file or write to it?\")\\r\\n    else:\\r\\n        print(\"File output.txt does not appear to exist\")\\r\\n    \\r\\n    return score\\r\\n        \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn14_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    expected_output = \"Lorem ipsum dolor sit amet, qui at luptatum efficiantur, ne autem offendit expetendis mel. Nec augue assentior ea, ne debet virtute mel. Integre vivendo id usu, ne primis repudiandae ullamcorper cum. Harum prompta appellantur vix ut. Ius voluptatibus definitiones te, eius scribentur referrentur mei at. Suas tota velit in usu, ex has complectitur signiferumque, sale lorem dolore ei ius. Perpetua scriptorem mei ex, ex est illum summo consul.\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn14_skill1.py\", [])\\r\\n        \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_lines)\\r\\n    \\r\\n    if num_matches == len(lines):\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT\")\\r\\n        return 0.0\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn14_printchars': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(start_char, end_char):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    start_char = ord(start_char)\\r\\n    end_char = ord(end_char)\\r\\n    \\r\\n    if start_char < end_char:\\r\\n        for i in range(start_char, end_char+1, 1):\\r\\n            result += chr(i) + \\'\\\\n\\'\\r\\n    else:\\r\\n        for i in range(start_char, end_char-1, -1):\\r\\n            result += chr(i) + \\'\\\\n\\'\\r\\n\\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    print(\"# ------------------------------------------\")\\r\\n    print(\"# Test 1:  First letter lower than second\")\\r\\n    print(\"# ------------------------------------------\")\\r\\n    start_char = chr(random.randint(65, 85))\\r\\n    end_char   = chr(random.randint(ord(start_char), 90))\\r\\n\\r\\n    output, error_message = autograder.run_script(\"lsn14_printchars.py\", [start_char, end_char])\\r\\n    expected_output = solution(start_char, end_char)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n        \\r\\n    \\r\\n    print(\"# ------------------------------------------\")\\r\\n    print(\"# Test 2:  First letter higher than second\")\\r\\n    print(\"# ------------------------------------------\")\\r\\n    start_char = chr(random.randint(85, 90))\\r\\n    end_char   = chr(random.randint(65, 84))\\r\\n\\r\\n    output, error_message = autograder.run_script(\"lsn14_printchars.py\", [start_char, end_char])\\r\\n    expected_output = solution(start_char, end_char)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn14_football': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    num_entries = random.randint(1, 6)\\r\\n    num_above_5000 = random.randint(0, num_entries)\\r\\n    list_of_values = [num_entries]\\r\\n    \\r\\n    for i in range(num_entries):\\r\\n        if i < num_above_5000:\\r\\n            list_of_values.append(random.randint(5001, 8000))\\r\\n        elif i == num_above_5000:\\r\\n            list_of_values.append(5000)\\r\\n        else:\\r\\n            list_of_values.append(random.randint(1, 5000))\\r\\n    \\r\\n    average = sum(list_of_values[1:])/num_entries\\r\\n    min_value = min(list_of_values[1:])\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn14_football.py\", list_of_values)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if len(lines) >= 1 and autograder.equals(lines[0], num_above_5000):\\r\\n        print(\"Number Above 5000 Looks Good\")\\r\\n        score += 33\\r\\n    else:\\r\\n        print(\"Number Above 5000 is Incorrect (or Missing)\")\\r\\n    \\r\\n    if len(lines) >= 2 and autograder.equals(lines[1], average):\\r\\n        print(\"Average Looks Good\")\\r\\n        score += 33\\r\\n    else:\\r\\n        print(\"Average is Incorrect (or Missing)\")\\r\\n    \\r\\n    if len(lines) >= 3 and autograder.equals(lines[2], min_value):\\r\\n        print(\"Min Value Looks Good\")\\r\\n        score += 34\\r\\n    else:\\r\\n        print(\"Min Value is Incorrect (or Missing)\")\\r\\n        \\r\\n    return score\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn14_counting': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(random_start, random_end, random_increment):\\r\\n    result = \\'\\'\\r\\n\\r\\n    for i in range(random_start, random_end+1, random_increment):\\r\\n        result += str(i) + \"\\\\n\"\\r\\n\\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_start = random.randint(0, 10)\\r\\n    random_end = random.randint(50, 100)\\r\\n    random_increment = random.randint(2, 9)\\r\\n\\r\\n    output, error_message = autograder.run_script(\"lsn14_counting.py\", [random_start, random_end, random_increment])\\r\\n    expected_output = solution(random_start, random_end, random_increment)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn14_coordinates': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(start_x, end_x, start_y, end_y):\\r\\n    result = \\'\\'\\r\\n\\r\\n    for y in range(start_y, end_y+1):\\r\\n        for x in range(start_x, end_x+1):\\r\\n            result += str(x) + \" \" + str(y) + \"\\\\n\"\\r\\n\\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    start_x = random.randint(-2, -1)\\r\\n    end_x = random.randint(1, 2)\\r\\n    start_y = random.randint(-3, -1)\\r\\n    end_y = random.randint(1, 3)\\r\\n\\r\\n    output, error_message = autograder.run_script(\"lsn14_coordinates.py\", [start_x, end_x, start_y, end_y])\\r\\n    expected_output = solution(start_x, end_x, start_y, end_y)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    num_matches = autograder.compare_strings(lines, expected_output.strip().split(\\'\\\\n\\'))\\r\\n\\r\\n    return 100 * (num_matches / len(lines))\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn14_class2017': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    num_entries = random.randint(1, 6)\\r\\n    num_in_2017 = random.randint(0, num_entries)\\r\\n    list_of_values = [num_entries]\\r\\n    \\r\\n    for i in range(num_entries):\\r\\n        if i < num_in_2017:\\r\\n            list_of_values.append(2017)\\r\\n        else:\\r\\n            list_of_values.append(random.randint(2018, 2024))\\r\\n        \\r\\n    output, error_message = autograder.run_script(\"lsn14_class2017.py\", list_of_values)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    if len(lines) >= 1 and autograder.equals(lines[0], num_in_2017):\\r\\n        print(\"CORRECT\")\\r\\n        score += 100\\r\\n    else:\\r\\n        print(\"Expected\", num_in_2017)\\r\\n        \\r\\n    return score\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn13_waittimes': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0.0\\r\\n    \\r\\n    possible_tests = [[30, 45, 15, 5, 5, -999], [15, 30, 31, 29, 120, 90, -999]]\\r\\n    possible_output = [[5, 1], [15, 3]]\\r\\n    \\r\\n    # Generates a Random Test\\r\\n    random_index = random.randint(0, len(possible_tests)-1)\\r\\n    random_test = possible_tests[random_index]\\r\\n    expected_output = possible_output[random_index]\\r\\n            \\r\\n    output, error = autograder.run_script(\"lsn13_waittimes.py\", random_test)\\r\\n    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Min Wait Time is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Min Wait Time is Incorrect.  Expected\", expected_output[0])\\r\\n        \\r\\n    if len(lines) > 1 and autograder.equals(lines[1], expected_output[1]):\\r\\n        print(\"Number of Lines With Over 30 Minute Wait Times is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Number of Lines With Over 30 Minute Wait Times is Incorrect.  Expected\", expected_output[1])\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn13_squadrons': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0.0\\r\\n    \\r\\n    possible_tests = [[5, 10, 20, 30, 40, 19], [8, 3, 1, 23, 37, 40, 7, 6, 25]]\\r\\n    possible_output = [[1, 2, 1, 1], [4, 0, 2, 2]]\\r\\n    \\r\\n    # Generates a Random Test\\r\\n    random_index = random.randint(0, len(possible_tests)-1)\\r\\n    random_test = possible_tests[random_index]\\r\\n    expected_output = possible_output[random_index]\\r\\n            \\r\\n    output, error = autograder.run_script(\"lsn13_squadrons.py\", random_test)\\r\\n    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Num in Group One is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Num in Group One is Incorrect.  Expected\", expected_output[0])\\r\\n        \\r\\n    if len(lines) > 1 and autograder.equals(lines[1], expected_output[1]):\\r\\n        print(\"Num in Group Two is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Num in Group Two is Incorrect.  Expected\", expected_output[1])\\r\\n    \\r\\n    if len(lines) > 2 and autograder.equals(lines[2], expected_output[2]):\\r\\n        print(\"Num in Group Three is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Num in Group Three is Incorrect.  Expected\", expected_output[2])\\r\\n    \\r\\n    if len(lines) > 3 and autograder.equals(lines[3], expected_output[3]):\\r\\n        print(\"Num in Group Four is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Num in Group Four is Incorrect.  Expected\", expected_output[3])\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn13_skill2': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution():\\r\\n    result = \\'\\'\\r\\n    i = 10\\r\\n    \\r\\n    while i >= 0:\\r\\n        result += str(2 ** i) + \"\\\\n\"\\r\\n        i -= 1\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn13_skill2.py\", [])\\r\\n    expected_output = solution()\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn13_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_multiple = random.randint(1, 10)\\r\\n\\r\\n    output, error_message = autograder.run_script(\"lsn13_skill1.py\", [random_multiple])\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    if len(lines) == random_multiple:\\r\\n        print(\"CORRECT\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"INCORRECT.  Make sure your loop is repeating num_times_to_loop times\")\\r\\n    \\r\\n    return 0\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn13_dvc': 'from lsn13_dvc import get_years_until\\r\\nfrom cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nNUM_SUBTESTS = 5\\r\\n\\r\\ndef soln(target_value):\\r\\n    maintenance_fee = 623.00\\r\\n    interest_rate = 0.015\\r\\n    count = 0\\r\\n\\r\\n    while maintenance_fee < target_value:\\r\\n        count += 1\\r\\n        maintenance_fee = maintenance_fee * (1 + interest_rate)\\r\\n    \\r\\n    return count\\r\\n\\r\\ndef test_passed():\\r\\n    passed = 0\\r\\n    for i in range(NUM_SUBTESTS):\\r\\n        print(\\'Running test %d of %d:\\' % (i+1 , NUM_SUBTESTS), end=\\'\\')\\r\\n        target_amount = random.randint(650, 1100)\\r\\n        if autograder.equals(get_years_until(target_amount), soln(target_amount)):\\r\\n            print(\"  It will take \" + str(get_years_until(target_amount)) + \" years until the maintenance fee exceeds $\" + str(target_amount))\\r\\n            passed += 1\\r\\n        else:\\r\\n            print(\\'  get_years_until(%d) incorrectly returned %d instead of %d\\\\n\\' % (target_amount, get_years_until(target_amount), soln(target_amount)))\\r\\n    \\r\\n    return round((100 / NUM_SUBTESTS), 1) * passed\\r\\n\\r\\n\\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn13_countby10s': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(starting_value, value_to_count_to):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    if value_to_count_to < starting_value:\\r\\n        return \"Second integer can\\'t be less than the first.\"\\r\\n    else:\\r\\n        i = starting_value\\r\\n        \\r\\n        while i <= value_to_count_to:\\r\\n            result += str(i) + \"\\\\n\"\\r\\n            i += 10\\r\\n        \\r\\n        return result\\r\\n\\r\\ndef run_test(random_starting_number, random_ending_number):\\r\\n    print(\"#--------------------------------------------\")\\r\\n    print(\"# Testing\", random_starting_number, \"to\", random_ending_number)\\r\\n    print(\"#--------------------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn13_countby10s.py\", [random_starting_number, random_ending_number])\\r\\n    expected_output = solution(random_starting_number, random_ending_number)\\r\\n    \\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n        print()\\r\\n    \\r\\n    return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    \\r\\n    if run_test(10 * random.randint(1, 5), 60 + 10 * random.randint(1, 20)):\\r\\n        score += 40\\r\\n        \\r\\n    if run_test(random.randint(0, 30), random.randint(31, 200)):\\r\\n        score += 40\\r\\n    \\r\\n    if run_test(random.randint(50, 100), random.randint(0, 10)):\\r\\n        score += 20\\r\\n    \\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn13_count': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(value_to_count_to, increment):\\r\\n    result = \\'\\'\\r\\n    i = 0\\r\\n    \\r\\n    while i <= value_to_count_to:\\r\\n        result += str(i) + \"\\\\n\"\\r\\n        i += increment\\r\\n    \\r\\n    return result\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_ending_number = 10 + 2 * random.randint(1, 10)\\r\\n    random_increment = 2\\r\\n\\r\\n    output, error_message = autograder.run_script(\"lsn13_count.py\", [random_ending_number, random_increment])\\r\\n    expected_output = solution(random_ending_number, random_increment)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\nif __name__ == \\'__main__\\':   \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn13_cargocapacity': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0.0\\r\\n    \\r\\n    possible_tests = [[8000, 12000, 25000, 10000, 7500, -1], [5000, 9000, 22000, 10000, 8700, -1], [9999, 5000, 3000, -1]]\\r\\n    possible_output = [[7500, 25000, 3], [5000, 22000, 2], [3000, 9999, 0]]\\r\\n    \\r\\n    # Generates a Random Test\\r\\n    random_index = random.randint(0, len(possible_tests)-1)\\r\\n    random_test = possible_tests[random_index]\\r\\n    expected_output = possible_output[random_index]\\r\\n            \\r\\n    output, error = autograder.run_script(\"lsn13_cargocapacity.py\", random_test)\\r\\n    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Min Value is Correct\")\\r\\n        score += 30\\r\\n    else:\\r\\n        print(\"Min Value is Incorrect.  Expected\", expected_output[0])\\r\\n    \\r\\n    if len(lines) > 1 and autograder.equals(lines[1], expected_output[1]):\\r\\n        print(\"Max Value is Correct\")\\r\\n        score += 30\\r\\n    else:\\r\\n        print(\"Max Value is Incorrect.  Expected\", expected_output[1])\\r\\n        \\r\\n    if len(lines) > 2 and autograder.equals(lines[2], expected_output[2]):\\r\\n        print(\"Number of Aircraft with At Least 10000 lbs is Correct\")\\r\\n        score += 40\\r\\n    else:\\r\\n        print(\"Number of Aircraft with At Least 10000 lbs is Incorrect.  Expected\", expected_output[2])\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn13_averagerun': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 5\\r\\n    num_tests_passed = 0\\r\\n\\r\\n    for i in range(NUM_TESTS):\\r\\n        print(\"Running Test \" + str(i) + \":\")\\r\\n        \\r\\n        num_inputs = random.randint(2, 11)\\r\\n        inputs = [num_inputs]\\r\\n        sum = 0\\r\\n        \\r\\n        for j in range(num_inputs):\\r\\n            value = random.randint(70, 130)\\r\\n            sum += value\\r\\n            inputs.append(value)\\r\\n               \\r\\n        avg = sum / (len(inputs) - 1)   \\r\\n               \\r\\n        # Runs the Script\\r\\n        output, error_message = autograder.run_script(\"lsn13_averagerun.py\", inputs)\\r\\n        \\r\\n        # Extracts the Output\\r\\n        lines = output.split(\"\\\\n\")\\r\\n        \\r\\n        if (len(lines) > 0):            \\r\\n            if (autograder.equals(lines[0], avg)):\\r\\n                print(\"CORRECT\\\\n\")\\r\\n                num_tests_passed += 1\\r\\n            else:\\r\\n                print(\"INCORRECT.  Expected: \" + str(avg) + \"\\\\n\")\\r\\n\\r\\n    # Result\\r\\n    return (100 / NUM_TESTS) * num_tests_passed\\r\\n            \\r\\n\\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn12_skill2': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(value_to_count_to, increment):\\r\\n    result = \\'\\'\\r\\n    i = 10\\r\\n    \\r\\n    while i >= value_to_count_to:\\r\\n        result += str(i) + \"\\\\n\"\\r\\n        i += increment\\r\\n    \\r\\n    return result\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_ending_number = 0\\r\\n    random_increment = -1\\r\\n\\r\\n    output, error_message = autograder.run_script(\"lsn12_skill2.py\", [])\\r\\n    expected_output = solution(random_ending_number, random_increment)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0\\r\\n\\r\\n        \\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn12_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(value_to_count_to, increment):\\r\\n    result = \\'\\'\\r\\n    i = 0\\r\\n    \\r\\n    while i <= value_to_count_to:\\r\\n        result += str(i) + \"\\\\n\"\\r\\n        i += increment\\r\\n    \\r\\n    return result\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_ending_number = 10\\r\\n    random_increment = 2\\r\\n\\r\\n    output, error_message = autograder.run_script(\"lsn12_skill1.py\", [])\\r\\n    expected_output = solution(random_ending_number, random_increment)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0\\r\\n\\r\\n        \\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn12_in_circle': 'import lsn12_in_circle\\nfrom cs110 import autograder\\nimport random, math\\n\\nNUM_SUBTESTS = 5\\n   \\ndef soln(x, y, cir_x, cir_y, radius):\\n    distance = math.sqrt((cir_x - x)**2 + (cir_y - y)**2)\\n    return distance <= radius\\n\\ndef test_passed():\\n    \\n    passed = 0\\n    for i in range(NUM_SUBTESTS):\\n        print(\\'Running sub test %d of %d: \\' % (i+1 , NUM_SUBTESTS), end=\\'\\')\\n        if i == 0:\\n            x = 6.04\\n            y = 2.43\\n            cir_x = 43.4\\n            cir_y = 52.2\\n            radius = 74.1\\n        else:\\n            x = random.random() * 10.0\\n            y = random.random() * 10.0\\n            cir_x = random.random() * 100.0\\n            cir_y = random.random() * 100.0\\n            radius = random.random() * 100.0\\n        #print(in_circle(x, y, cir_x, cir_y, radius), soln(x, y, cir_x, cir_y, radius))\\n        if lsn12_in_circle.in_circle(x, y, cir_x, cir_y, radius) == soln(x, y, cir_x, cir_y, radius):\\n            print(\"CORRECT!\")\\n            passed += 1\\n        else:\\n            print(\\'INCORRECT:  in_circle(%f, %f, %f, %f, %f) incorrectly returned %s\\' % (x, y, cir_x, cir_y, radius, lsn12_in_circle.in_circle(x, y, cir_x, cir_y, radius)))\\n    \\n    return (100 / NUM_SUBTESTS) * passed\\n\\n\\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn12_distance': 'from lsn12_distance import dist_points\\r\\nfrom cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nNUM_SUBTESTS = 5\\r\\n\\r\\ndef soln(x1, y1, x2, y2):\\r\\n    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    passed = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    \\r\\n    for i in range(NUM_SUBTESTS):\\r\\n        print(\\'Running sub test %d of %d: \\' % (i+1 , NUM_SUBTESTS), end=\\'\\')\\r\\n        x1 = round(random.uniform(-10, 10), 1)\\r\\n        y1 = round(random.uniform(-10, 10), 1)\\r\\n        x2 = round(random.uniform(-10, 10), 1)\\r\\n        y2 = round(random.uniform(-10, 10), 1)\\r\\n        if autograder.equals(dist_points(x1, y1, x2, y2), soln(x1, y1, x2, y2)):\\r\\n            print(\"PASSED!\")\\r\\n            passed += 1\\r\\n        else:\\r\\n            print(\\'FAILED: dist_point(%1.1f, %1.1f, %1.1f, %1.1f) incorrectly returned\\' % (x1, y1, x2, y2), dist_points(x1, y1, x2, y2))\\r\\n    \\r\\n    return round(100 / NUM_SUBTESTS, 1) * passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn12_circle': 'import lsn12_circle\\r\\nfrom cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nNUM_SUBTESTS = 5\\r\\n\\r\\n# Helper method to see if a numeric value is within a specified delta\\r\\ndef soln(radius):\\r\\n    return math.pi * radius * radius\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    passed = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    \\r\\n    for i in range(NUM_SUBTESTS):\\r\\n        print(\\'Running sub test %d of %d: \\' % (i+1 , NUM_SUBTESTS), end=\\'\\')\\r\\n        radius = random.random() * 100.0\\r\\n        if autograder.equals(lsn12_circle.area_circle(radius), soln(radius)):\\r\\n            print(\"CORRECT!\")\\r\\n            passed += 1\\r\\n        else:\\r\\n            print(\\'area_circle(%d) incorrectly returned\\' % (radius), lsn12_circle.area_circle(radius))\\r\\n        \\r\\n    return round(100 / NUM_SUBTESTS, 1) * passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n',\n",
       "  'lsn12_asteroids': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn12_asteroids \\r\\n\\r\\ndef soln(ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r):\\r\\n    distance = math.sqrt((ship_x - asteroid_x)**2 + (ship_y - asteroid_y)**2)\\r\\n    return distance < asteroid_r + ship_r\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 4\\r\\n    num_tests_passed = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    score = 0\\r\\n        \\r\\n    if \"dist_points\" in dir(lsn12_asteroids):\\r\\n        score += 20\\r\\n        print(\"dist_points function found\")\\r\\n    else:\\r\\n        print(\"dist_points function not being utilized.  Don\\'t reinvent the wheel!\")\\r\\n        #score += 20\\r\\n        \\r\\n    for i in range(NUM_TESTS):\\r\\n        print(\\'Running test %d of %d: \\' % (i+1 , NUM_TESTS), end=\\'\\')\\r\\n        \\r\\n        if i == 0:\\r\\n            ship_x = 2.3\\r\\n            ship_y = 0.2\\r\\n            ship_r = 3\\r\\n            asteroid_x = -4\\r\\n            asteroid_y = 3.4\\r\\n            asteroid_r = 6\\r\\n        else:\\r\\n            ship_x = round(random.uniform(-50, 50), 1)\\r\\n            ship_y = round(random.uniform(-50, 50), 1)\\r\\n            ship_r = 3\\r\\n            asteroid_x = round(random.uniform(-50, 50), 1)\\r\\n            asteroid_y = round(random.uniform(-50, 50), 1)\\r\\n            asteroid_r = 6\\r\\n        \\r\\n        #print(in_circle(x, y, cir_x, cir_y, radius), soln(x, y, cir_x, cir_y, radius))\\r\\n        if lsn12_asteroids.detect_collision(ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r) == soln(ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r):\\r\\n            print(\"CORRECT\")\\r\\n            score += 20\\r\\n        else:\\r\\n            print(\\'detect_collision(%f, %f, %f, %f, %f, %f) incorrectly returned %s\\' % (ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r, lsn12_asteroids.detect_collision(ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r)))\\r\\n    \\r\\n    return score\\r\\n            \\r\\n            \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn11_triangle': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn11_triangle\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    base = round(random.uniform(1.0, 10.0), 1)\\r\\n    height = round(random.uniform(1.0, 10.0), 1)\\r\\n    output, error_message = autograder.run_script(\"lsn11_triangle.py\", [base, height])\\r\\n    \\r\\n    area = (base * height) / 2.0\\r\\n    score = 0\\r\\n    \\r\\n    if \"area_triangle\" in dir(lsn11_triangle):\\r\\n        print(\"Function Correctly Defined\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function does not exist.  Check to make sure the name matches the prompt\")\\r\\n    \\r\\n    if autograder.equals(output, area):\\r\\n        print(\"Function produces correct output\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function produces incorrect output. Expected:\", area)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn11_skill3': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn11_skill3\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    output, error = autograder.run_script(\"lsn11_skill3.py\", [])\\r\\n    score = 0\\r\\n    \\r\\n    if \"print_hello\" in dir(lsn11_skill3):\\r\\n        print(\"Function found!\")\\r\\n        score += 50\\r\\n        \\r\\n        if len(output) > 0:\\r\\n            print(\"Output Found!\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"Function does not appear to be printing out anything\")\\r\\n    else:\\r\\n        print(\"Function does not appear to be defined.  Check the name and make sure it matches the prompt\")\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn11_skill2': 'from cs110 import autograder\\r\\nimport random, math\\r\\nfrom lsn11_skill2 import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    if \\'my_value\\' in globals():\\r\\n        print(\"Looking for my_value . . . FOUND!\")\\r\\n        if my_value == my_list[2]:\\r\\n            print(\"Looking inside my_value . . . VALUE MATCHES THE 3rd VALUE IN THE LIST\")\\r\\n            return 100\\r\\n        elif my_value == my_list[3]:\\r\\n            print(\"Looking inside my_value . . . VALUE MATCHES THE 4th VALUE INSTEAD OF THE THIRD!\")\\r\\n            print(\"** HINT:  The index starts at 0 **\")\\r\\n            return 50\\r\\n        else:\\r\\n            print(\"Looking inside my_value . . . VALUE DOES NOT MATCH.  EXPECTED\", my_list[2])\\r\\n            return 50\\r\\n    else:\\r\\n        print(\"Looking for my_value . . . NOT FOUND!\")\\r\\n        return 0\\r\\n        \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn11_skill1': 'from cs110 import autograder\\r\\nimport random\\r\\nfrom lsn11_skill1 import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    if \\'my_list\\' in globals():\\r\\n        print(\"Looking for my_list . . . FOUND!\")\\r\\n        if len(my_list) == 3:\\r\\n            print(\"Looking inside my_list . . . FOUND 3 ITEMS!\")\\r\\n            return 100\\r\\n        else:\\r\\n            print(\"Looking inside my_list . . . FOUND\", len(my_list), \"INSTEAD OF 3 ITEMS\")\\r\\n            return 50\\r\\n    else:\\r\\n        print(\"Looking for my_list . . . NOT FOUND!\")\\r\\n        return0\\r\\n        \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn11_imagesize': 'from cs110 import autograder\\r\\nimport lsn11_imagesize, random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    base = random.randint(1024, 1980)\\r\\n    height = random.randint(1024, 1980)\\r\\n    bd = 2**random.randint(3, 7)\\r\\n    output, error_message = autograder.run_script(\"lsn11_imagesize.py\", [base, height, bd])\\r\\n    \\r\\n    filesize = (base * height * bd) / 8 / 1024\\r\\n    score = 0\\r\\n    \\r\\n    if \"calculate_size_of_image\" in dir(lsn11_imagesize):\\r\\n        print(\"Function Correctly Defined\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function does not exist.  Check to make sure the name matches the prompt\")\\r\\n    \\r\\n    if autograder.equals(output, filesize):\\r\\n        print(\"Function produces correct output\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function produces incorrect output. Expected:\", filesize)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'lsn11_callme': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# This function takes a string and prints it backwards\\r\\ndef get_reverse(s):\\r\\n    result = \\'\\'\\r\\n    for i in range(len(s)-1, -1, -1):\\r\\n        result += s[i]\\r\\n    return result\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    base = round(random.uniform(1.0, 100.0), 1)\\r\\n    height = round(random.uniform(1.0, 100.0), 1)\\r\\n\\r\\n    string_list = [\\'abcde\\', \\'defgh\\', \\'xzy\\', \\'abba\\']\\r\\n    test_string = string_list[random.randint(0, len(string_list)-1)]\\r\\n\\r\\n    file = open(\"lsn11_callme.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    num_calls_area_rectangle = file_contents.count(\"area_rectangle\")\\r\\n    num_calls_print_backwards = file_contents.count(\"print_backwards\")\\r\\n    num_calls_positive = file_contents.count(\"positive_or_negative\")\\r\\n\\r\\n    output, error_message = autograder.run_script(\"lsn11_callme.py\", [base, height, test_string])\\r\\n    \\r\\n    area = (base * height)\\r\\n    score = 0\\r\\n    \\r\\n    lines = output.split(\"\\\\n\")\\r\\n    \\r\\n    if autograder.equals(lines[0], area) and num_calls_area_rectangle > 1:\\r\\n        print(\"area_rectangle called successfully\")\\r\\n        score += 33\\r\\n    else:\\r\\n        print(\"area_rectangle was not called successfully\")\\r\\n    \\r\\n    if len(lines) > 1 and lines[1].strip() == get_reverse(test_string) and num_calls_print_backwards > 1:\\r\\n        print(\"print_backwards called successfully\")\\r\\n        score += 33\\r\\n    else:\\r\\n        print(\"print_backwards was not called successfully\")\\r\\n    \\r\\n    if len(lines) > 2 and lines[2].strip() == \"Positive\" and num_calls_positive > 1:\\r\\n        print(\"positive_or_negative called successfully\")\\r\\n        score += 34\\r\\n    else:\\r\\n        print(\"positive_or_negative was not called successfully\")\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn1_helloworld': 'import sys, subprocess, random\\r\\nfrom cs110 import autograder\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Hello World Unit Test\\r\\n# ---------------------------------------------------------------------\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn1_helloworld.py\", [])\\r\\n    \\r\\n    # Checks to See if the Program Passed the Test\\r\\n    if output.strip() == \"Hello World\":\\r\\n        print(\"SUCCESS!\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"Try Again.  Just have it print the words \\'Hello World\\'!\")\\r\\n        return 0.0\\r\\n    \\r\\n    \\r\\n# Testbench (to be run in an IDE)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'caesar': 'from cs110 import autograder\\r\\nimport os\\r\\nimport random\\r\\n\\r\\ntest_name = \\'caesar\\'\\r\\n\\r\\n#-------------------------------------------------------------------------\\r\\n# Helper functions\\r\\n#-------------------------------------------------------------------------\\r\\n\\r\\nELF = [ 0.08200, 0.01500, # A, B\\r\\n    0.02800, 0.04300, 0.12581, 0.02200, 0.02000, # C, D, E, F, G\\r\\n    0.06100, 0.07000, 0.00150, 0.00770, 0.04000, # H, I, J, K, L\\r\\n    0.02400, 0.06700, 0.07500, 0.01900, 0.00095, # M, N, O, P, Q\\r\\n    0.06000, 0.06300, 0.09100, 0.02800, 0.00980, # R, S, T, U, V\\r\\n    0.02400, 0.00150, 0.02000, 0.00074]          # W, X, Y, Z\\r\\nAS = len(ELF)\\r\\ndef ch(i): return chr(i + ord(\\'A\\'))\\r\\ndef ind(l): return ord(l) - ord(\\'A\\')\\r\\ndef sh(l, sa):\\r\\n    if l.isupper(): return ch((ind(l) + sa) % AS)\\r\\n    return ch((ind(l.upper()) + sa) % AS).lower()\\r\\ndef en(s, k):\\r\\n    sa = ind(k); ct = \"\"\\r\\n    for sy in s:\\r\\n        if not sy.isalpha(): ct += sy\\r\\n        else: ct += sh(sy, sa)\\r\\n    return ct\\r\\ndef de(s, k):\\r\\n    sa = -ind(k); pt = \"\"\\r\\n    for sy in s:\\r\\n        if not sy.isalpha(): pt += sy\\r\\n        else: pt += sh(sy, sa)\\r\\n    return pt\\r\\ndef ef(pfn, k, cfn):\\r\\n    pf = open(pfn, \"r\"); pt = pf.read(); pf.close()\\r\\n    ct = en(pt, key)\\r\\n    cf = open(cfn, \"w\"); cf.write(ct); cf.close()\\r\\ndef df(cfn, key, pfn):\\r\\n    cf = open(cfn, \"r\"); ct = cf.read(); cf.close()\\r\\n    pt = de(ct, key)\\r\\n    pf = open(pfn, \"w\"); pf.write(pt); pf.close()\\r\\ndef ds(s):\\r\\n    fl = []\\r\\n    for i in range(AS): fl.append(0)\\r\\n    tlc = 0\\r\\n    for l in s:\\r\\n        if l.isalpha(): fl[ind(l.upper())] += 1; tlc += 1\\r\\n    for i in range(AS): fl[i] /= tlc\\r\\n    return fl\\r\\ndef ce(fd):\\r\\n    c = 0.0\\r\\n    for i in range(AS): c += fd[i] * ELF[i]\\r\\n    return c\\r\\ndef fk(fd):\\r\\n    mc = 0; ki = 0\\r\\n    for ls in range(AS):\\r\\n        c = ce(fd)\\r\\n        if c > mc: ki = ls; mc = c\\r\\n        fd = fd[1:] + fd[:1]\\r\\n    k = ch(ki)\\r\\n    return k\\r\\ndef cr(ct): fd = ds(ct); k = fk(fd); return k\\r\\ndef cf(cfn):\\r\\n    cf = open(cfn, \"r\")\\r\\n    ct = cf.read()\\r\\n    cf.close()\\r\\n    return cr(ct)\\r\\n\\r\\ndef cumulative_elf():\\r\\n    cdf = []\\r\\n    for i in range(AS):\\r\\n        if i == 0:\\r\\n            cum = 0\\r\\n        else:\\r\\n            cum = cdf[i-1]\\r\\n        cdf.append(cum + ELF[i])\\r\\n    cdf[AS-1] = 1.0\\r\\n    return cdf\\r\\n\\r\\ncum_elf = cumulative_elf()\\r\\n\\r\\n#-------------------------------------------------------------------------\\r\\n# Test Functions for caesar_gc\\r\\n#-------------------------------------------------------------------------\\r\\n\\r\\ndef test_gc_character():\\r\\n    print(\"Testing character()\")\\r\\n    \\r\\n    upper_bad = 0\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    \\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    for test_input in range(0,26):\\r\\n\\r\\n        tests += 1\\r\\n        try:\\r\\n            result = caesar_gc.character(test_input)\\r\\n            answer = ch(test_input)\\r\\n            \\r\\n            if result == answer:\\r\\n                correct += 1\\r\\n            else:\\r\\n                upper_bad += 1\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            exceptions += 1\\r\\n\\r\\n    \\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", upper_bad, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\ndef test_gc_index():\\r\\n\\r\\n    print(\"Testing index()\")\\r\\n    \\r\\n    upper_bad = 0\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    \\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    for code in range(ord(\\'A\\'),ord(\\'Z\\')+1):\\r\\n        \\r\\n        test_input = chr(code)\\r\\n        \\r\\n        tests += 1\\r\\n        try:\\r\\n            result = caesar_gc.index(test_input)\\r\\n            answer = ind(test_input)\\r\\n            \\r\\n            if result == answer:\\r\\n                correct += 1\\r\\n            else:\\r\\n                upper_bad += 1\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            exceptions += 1\\r\\n\\r\\n    \\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", upper_bad, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_gc_shift():\\r\\n\\r\\n    print(\"Testing shift()\")\\r\\n    \\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    exceptions = 0\\r\\n    exception_set = set()    \\r\\n    \\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    for code in range(0,26):\\r\\n        test_input = ch(code)\\r\\n        \\r\\n        for shift_amount in range(-25, 26):\\r\\n            \\r\\n            tests += 1\\r\\n            try:\\r\\n                response = caesar_gc.shift(test_input, shift_amount)\\r\\n                answer = sh(test_input, shift_amount)\\r\\n                if response == answer:\\r\\n                    correct += 1\\r\\n                else:\\r\\n                    upper_bad += 1\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    exception_set.add(str(e))\\r\\n                exceptions += 1\\r\\n\\r\\n            tests += 1\\r\\n            try:\\r\\n                response = caesar_gc.shift(test_input.lower(), shift_amount)\\r\\n                answer = sh(test_input.lower(), shift_amount)\\r\\n                if response == answer:\\r\\n                    correct += 1\\r\\n                else:\\r\\n                    lower_bad += 1\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    exception_set.add(str(e))\\r\\n                exceptions += 1\\r\\n\\r\\n    \\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value for uppercase letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value for lowercase letters\", lower_bad, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_gc_encrypt():\\r\\n    \\r\\n    print(\"Testing encrypt()\")\\r\\n\\r\\n    string = \"\"\\r\\n    \\r\\n    for c in range(0,128):\\r\\n        string += chr(c)\\r\\n    \\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    wrong_length = 0\\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    other_bad = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    \\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n\\r\\n        answer = en(string, key)\\r\\n        try:\\r\\n            response = caesar_gc.encrypt(string, key)\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            wrong_length += 1\\r\\n            continue\\r\\n    \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    upper_bad += 1\\r\\n                elif answer[i].islower():\\r\\n                    lower_bad += 1\\r\\n                else:\\r\\n                    other_bad += 1\\r\\n                    \\r\\n    \\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted upper case letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted lower case letters\", lower_bad, \"time(s).\")\\r\\n    if other_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted non-letters\", other_bad, \"time(s).\")\\r\\n    if wrong_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", wrong_length, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_gc_decrypt():\\r\\n    \\r\\n    print(\"Testing decrypt()\")\\r\\n\\r\\n    string = \"\"\\r\\n    \\r\\n    for c in range(0,128):\\r\\n        string += chr(c)\\r\\n    \\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    wrong_length = 0\\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    other_bad = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    \\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n\\r\\n        answer = de(string, key)\\r\\n        try:\\r\\n            response = caesar_gc.decrypt(string, key)\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            wrong_length += 1\\r\\n            continue\\r\\n    \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    upper_bad += 1\\r\\n                elif answer[i].islower():\\r\\n                    lower_bad += 1\\r\\n                else:\\r\\n                    other_bad += 1\\r\\n                    \\r\\n    \\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly decrypted upper case letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly decrypted lower case letters\", lower_bad, \"time(s).\")\\r\\n    if other_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly decrypted non-letters\", other_bad, \"time(s).\")\\r\\n    if wrong_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", wrong_length, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_gc_encrypt_file():\\r\\n    \\r\\n    print(\"Testing encrypt_file()\")\\r\\n\\r\\n    pt_file = \"xkiwjd\"\\r\\n    ct_file = \"ekvuim\"\\r\\n\\r\\n    string = \"\"\\r\\n    for c in range(32,128):\\r\\n        string += chr(c)\\r\\n    plaintext = string + \\'\\\\n\\' + string + \\'\\\\n\\'\\r\\n    \\r\\n    fp = open(pt_file, \"w\"); fp.write(plaintext); fp.close()\\r\\n\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    wrong_length = 0\\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    other_bad = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    \\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n        \\r\\n        answer = en(plaintext, key)\\r\\n        try:\\r\\n            caesar_gc.encrypt_file(pt_file, key, ct_file)\\r\\n            fp = open(ct_file, \"r\"); response = fp.read(); fp.close()\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            wrong_length += 1\\r\\n            continue\\r\\n        \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    upper_bad += 1\\r\\n                elif answer[i].islower():\\r\\n                    lower_bad += 1\\r\\n                else:\\r\\n                    other_bad += 1\\r\\n\\r\\n    \\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n    if wrong_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", wrong_length, \"time(s).\")\\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted upper case letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted lower case letters\", lower_bad, \"time(s).\")\\r\\n    if other_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted non-letters\", other_bad, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    if os.path.exists(pt_file):\\r\\n        os.remove(pt_file)\\r\\n    if os.path.exists(ct_file):\\r\\n        os.remove(ct_file)\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_gc_decrypt_file():\\r\\n    \\r\\n    print(\"Testing decrypt_file()\")\\r\\n\\r\\n    pt_file = \"kgbjw45df\"\\r\\n    ct_file = \"iuwmndfuh\"\\r\\n\\r\\n    string = \"\"\\r\\n    for c in range(32,128):\\r\\n        string += chr(c)\\r\\n    ciphertext = string + \\'\\\\n\\' + string + \\'\\\\n\\'\\r\\n    \\r\\n    fp = open(ct_file, \"w\"); fp.write(ciphertext); fp.close()\\r\\n\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_length = 0\\r\\n    bad_upper = 0\\r\\n    bad_lower = 0\\r\\n    bad_other = 0\\r\\n\\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n        \\r\\n        answer = de(ciphertext, key)\\r\\n        try:\\r\\n            caesar_gc.decrypt_file(ct_file, key, pt_file)\\r\\n            fp = open(pt_file, \"r\"); response = fp.read(); fp.close()\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            bad_length += 1\\r\\n            continue\\r\\n        \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    bad_upper += 1\\r\\n                elif answer[i].islower():\\r\\n                    bad_lower += 1\\r\\n                else:\\r\\n                    bad_other += 1\\r\\n\\r\\n    \\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n    if bad_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", bad_length, \"time(s).\")\\r\\n    if bad_upper > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted upper case letters\", bad_upper, \"time(s).\")\\r\\n    if bad_lower > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted lower case letters\", bad_lower, \"time(s).\")\\r\\n    if bad_other > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted non-letters\", bad_other, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    if os.path.exists(pt_file):\\r\\n        os.remove(pt_file)\\r\\n    if os.path.exists(ct_file):\\r\\n        os.remove(ct_file)\\r\\n    \\r\\n    return score\\r\\n\\r\\n#-------------------------------------------------------------------------\\r\\n# Test Functions for caesar\\r\\n#-------------------------------------------------------------------------\\r\\n\\r\\ndef test_character():\\r\\n    print(\"Testing character()\")\\r\\n    \\r\\n    upper_bad = 0\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    \\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    for test_input in range(0,26):\\r\\n\\r\\n        tests += 1\\r\\n        try:\\r\\n            result = caesar.character(test_input)\\r\\n            answer = ch(test_input)\\r\\n            \\r\\n            if result == answer:\\r\\n                correct += 1\\r\\n            else:\\r\\n                upper_bad += 1\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            exceptions += 1\\r\\n\\r\\n    \\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", upper_bad, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\ndef test_index():\\r\\n\\r\\n    print(\"Testing index()\")\\r\\n    \\r\\n    upper_bad = 0\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    \\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    for code in range(ord(\\'A\\'),ord(\\'Z\\')+1):\\r\\n        \\r\\n        test_input = chr(code)\\r\\n        \\r\\n        tests += 1\\r\\n        try:\\r\\n            result = caesar.index(test_input)\\r\\n            answer = ind(test_input)\\r\\n            \\r\\n            if result == answer:\\r\\n                correct += 1\\r\\n            else:\\r\\n                upper_bad += 1\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            exceptions += 1\\r\\n\\r\\n    \\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", upper_bad, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_shift():\\r\\n\\r\\n    print(\"Testing shift()\")\\r\\n    \\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    \\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    for code in range(0,26):\\r\\n        test_input = ch(code)\\r\\n        \\r\\n        for shift_amount in range(-25, 26):\\r\\n            \\r\\n            tests += 1\\r\\n            try:\\r\\n                response = caesar.shift(test_input, shift_amount)\\r\\n                answer = sh(test_input, shift_amount)\\r\\n                if response == response:\\r\\n                    correct += 1\\r\\n                else:\\r\\n                    upper_bad += 1\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    exception_set.add(str(e))\\r\\n                exceptions += 1\\r\\n\\r\\n            tests += 1\\r\\n            try:\\r\\n                response = caesar.shift(test_input.lower(), shift_amount)\\r\\n                answer = sh(test_input.lower(), shift_amount)\\r\\n                if response == answer:\\r\\n                    correct += 1\\r\\n                else:\\r\\n                    lower_bad += 1\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    exception_set.add(str(e))\\r\\n                exceptions += 1\\r\\n\\r\\n    \\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value for uppercase letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value for lowercase letters\", lower_bad, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_encrypt():\\r\\n    \\r\\n    print(\"Testing encrypt()\")\\r\\n\\r\\n    string = \"\"\\r\\n    \\r\\n    for c in range(0,128):\\r\\n        string += chr(c)\\r\\n    \\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    wrong_length = 0\\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    other_bad = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    \\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n\\r\\n        answer = en(string, key)\\r\\n        try:\\r\\n            response = caesar.encrypt(string, key)\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            wrong_length += 1\\r\\n            continue\\r\\n    \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    upper_bad += 1\\r\\n                elif answer[i].islower():\\r\\n                    lower_bad += 1\\r\\n                else:\\r\\n                    other_bad += 1\\r\\n                    \\r\\n    \\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted upper case letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted lower case letters\", lower_bad, \"time(s).\")\\r\\n    if other_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted non-letters\", other_bad, \"time(s).\")\\r\\n    if wrong_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", wrong_length, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_decrypt():\\r\\n    \\r\\n    print(\"Testing decrypt()\")\\r\\n\\r\\n    string = \"\"\\r\\n    \\r\\n    for c in range(0,128):\\r\\n        string += chr(c)\\r\\n    \\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    wrong_length = 0\\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    other_bad = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    \\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n\\r\\n        answer = de(string, key)\\r\\n        try:\\r\\n            response = caesar.decrypt(string, key)\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            wrong_length += 1\\r\\n            continue\\r\\n    \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    upper_bad += 1\\r\\n                elif answer[i].islower():\\r\\n                    lower_bad += 1\\r\\n                else:\\r\\n                    other_bad += 1\\r\\n                    \\r\\n    \\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly decrypted upper case letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly decrypted lower case letters\", lower_bad, \"time(s).\")\\r\\n    if other_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly decrypted non-letters\", other_bad, \"time(s).\")\\r\\n    if wrong_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", wrong_length, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_encrypt_file():\\r\\n    \\r\\n    print(\"Testing encrypt_file()\")\\r\\n\\r\\n    pt_file = \"xkiwjd\"\\r\\n    ct_file = \"ekvuim\"\\r\\n\\r\\n    string = \"\"\\r\\n    for c in range(32,128):\\r\\n        string += chr(c)\\r\\n    plaintext = string + \\'\\\\n\\' + string + \\'\\\\n\\'\\r\\n    \\r\\n    fp = open(pt_file, \"w\"); fp.write(plaintext); fp.close()\\r\\n\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    wrong_length = 0\\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    other_bad = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    \\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n        \\r\\n        answer = en(plaintext, key)\\r\\n        try:\\r\\n            caesar.encrypt_file(pt_file, key, ct_file)\\r\\n            fp = open(ct_file, \"r\"); response = fp.read(); fp.close()\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            wrong_length += 1\\r\\n            continue\\r\\n        \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    upper_bad += 1\\r\\n                elif answer[i].islower():\\r\\n                    lower_bad += 1\\r\\n                else:\\r\\n                    other_bad += 1\\r\\n\\r\\n    \\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n    if wrong_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", wrong_length, \"time(s).\")\\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted upper case letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted lower case letters\", lower_bad, \"time(s).\")\\r\\n    if other_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted non-letters\", other_bad, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    if os.path.exists(pt_file):\\r\\n        os.remove(pt_file)\\r\\n    if os.path.exists(ct_file):\\r\\n        os.remove(ct_file)\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_decrypt_file():\\r\\n    \\r\\n    print(\"Testing decrypt_file()\")\\r\\n\\r\\n    pt_file = \"kgbjw45df\"\\r\\n    ct_file = \"iuwmndfuh\"\\r\\n\\r\\n    string = \"\"\\r\\n    for c in range(32,128):\\r\\n        string += chr(c)\\r\\n    ciphertext = string + \\'\\\\n\\' + string + \\'\\\\n\\'\\r\\n    \\r\\n    fp = open(ct_file, \"w\"); fp.write(ciphertext); fp.close()\\r\\n\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_length = 0\\r\\n    bad_upper = 0\\r\\n    bad_lower = 0\\r\\n    bad_other = 0\\r\\n\\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n        \\r\\n        answer = de(ciphertext, key)\\r\\n        try:\\r\\n            caesar.decrypt_file(ct_file, key, pt_file)\\r\\n            fp = open(pt_file, \"r\"); response = fp.read(); fp.close()\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            bad_length += 1\\r\\n            continue\\r\\n        \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    bad_upper += 1\\r\\n                elif answer[i].islower():\\r\\n                    bad_lower += 1\\r\\n                else:\\r\\n                    bad_other += 1\\r\\n\\r\\n    \\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n    if bad_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", bad_length, \"time(s).\")\\r\\n    if bad_upper > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted upper case letters\", bad_upper, \"time(s).\")\\r\\n    if bad_lower > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted lower case letters\", bad_lower, \"time(s).\")\\r\\n    if bad_other > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted non-letters\", bad_other, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    if os.path.exists(pt_file):\\r\\n        os.remove(pt_file)\\r\\n    if os.path.exists(ct_file):\\r\\n        os.remove(ct_file)\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef random_ptchar():\\r\\n    \\r\\n    if random.random() < 1/80:\\r\\n        return \\'\\\\n\\'\\r\\n    \\r\\n    x = random.random()\\r\\n    \\r\\n    i = 0\\r\\n    while cum_elf[i] < x:\\r\\n        i += 1\\r\\n    c = ch(i)\\r\\n    if random.random() < 0.5:\\r\\n        c = c.lower()\\r\\n        \\r\\n    return c\\r\\n\\r\\ndef random_pt(length):\\r\\n    \\r\\n    pt = \"\"\\r\\n    for i in range(length):\\r\\n        pt += random_ptchar()\\r\\n    return pt\\r\\n        \\r\\ndef test_distribution():\\r\\n    \\r\\n    print(\"Testing distribution()\")\\r\\n\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_length = 0\\r\\n    bad_value = 0\\r\\n\\r\\n    for i in range(100):\\r\\n        \\r\\n        big_pt = random_pt(1000)\\r\\n        answer = ds(big_pt)\\r\\n\\r\\n        try:\\r\\n            response = caesar.distribution(big_pt)\\r\\n            \\r\\n            if response == None or (len(response) != len(answer)):\\r\\n                tests += len(answer)\\r\\n                bad_length += 1\\r\\n            else:\\r\\n                for i in range(len(answer)):\\r\\n                    if abs(answer[i] - response[i]) > 0.001*answer[i]:\\r\\n                        bad_value += 1\\r\\n                    else:\\r\\n                        correct += 1\\r\\n                    tests += 1\\r\\n\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                exception_set.add(str(e))\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n    \\r\\n    \\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n    if bad_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length of distribution\", bad_length, \"time(s).\")\\r\\n    if bad_value > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", bad_value, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_compare_to_english():\\r\\n\\r\\n    print(\"Testing compare_to_english()\")\\r\\n\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_length = 0\\r\\n    bad_value = 0\\r\\n\\r\\n    for i in range(50):\\r\\n        \\r\\n        big_pt = random_pt(100)\\r\\n        \\r\\n        for k in range(AS):\\r\\n            ct = en(big_pt, ch(k))\\r\\n            answer = ce(ds(ct))\\r\\n\\r\\n            try:\\r\\n                resp_dist = caesar.distribution(ct)\\r\\n                response = caesar.compare_to_english(resp_dist)\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    exception_set.add(str(e))\\r\\n                tests += 1\\r\\n                exceptions += 1\\r\\n                continue\\r\\n\\r\\n            if response == None or (abs(answer - response) > 0.001*answer):\\r\\n                bad_value += 1\\r\\n            else:\\r\\n                correct += 1\\r\\n            tests += 1\\r\\n\\r\\n\\r\\n    \\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n    if bad_value > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", bad_value, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_find_key():\\r\\n    \\r\\n    print(\"Testing find_key()\")\\r\\n\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_value = 0\\r\\n    \\r\\n    for i in range(50):\\r\\n        \\r\\n        big_pt = random_pt(100)\\r\\n        \\r\\n        for k in range(AS):\\r\\n            ct = en(big_pt, ch(k))\\r\\n            answer = fk(ds(ct))\\r\\n\\r\\n            try:\\r\\n                resp_dist = caesar.distribution(ct)\\r\\n                response = caesar.find_key(resp_dist)\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    exception_set.add(str(e))\\r\\n                tests += 1\\r\\n                exceptions += 1\\r\\n                continue\\r\\n\\r\\n            if answer != response:\\r\\n                bad_value += 1\\r\\n            else:\\r\\n                correct += 1\\r\\n            tests += 1\\r\\n\\r\\n\\r\\n    \\r\\n    \\r\\n    if exceptions > 0:        \\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n    if bad_value > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", bad_value, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_crack():\\r\\n    \\r\\n    print(\"Testing crack()\")\\r\\n\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_value = 0\\r\\n\\r\\n    for i in range(50):\\r\\n        \\r\\n        big_pt = random_pt(100)\\r\\n        \\r\\n        for k in range(AS):\\r\\n            ct = en(big_pt, ch(k))\\r\\n            answer = cr(ct)\\r\\n\\r\\n            try:\\r\\n                response = caesar.crack(ct)\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    exception_set.add(str(e))\\r\\n                tests += 1\\r\\n                exceptions += 1\\r\\n                continue\\r\\n\\r\\n            if answer != response:\\r\\n                bad_value += 1\\r\\n            else:\\r\\n                correct += 1\\r\\n            tests += 1\\r\\n\\r\\n    \\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n    if bad_value > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", bad_value, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_crack_file():\\r\\n\\r\\n    print(\"Testing crack_file()\")\\r\\n\\r\\n    pt_file = \"in5842p\"\\r\\n    ct_file = \"Pw7vj2R\"\\r\\n\\r\\n    exceptions = 0\\r\\n    exception_set = set()\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_value = 0\\r\\n\\r\\n    for i in range(10):\\r\\n        \\r\\n        big_pt = random_pt(1000)\\r\\n\\r\\n        for k in range(AS):\\r\\n            key = ch(k)\\r\\n            \\r\\n            ct = en(big_pt, key)\\r\\n            fp = open(ct_file, \"w\"); fp.write(ct); fp.close()\\r\\n\\r\\n            answer = cr(ct)\\r\\n            \\r\\n            try:\\r\\n                response = caesar.crack_file(ct_file)\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    exception_set.add(str(e))\\r\\n                tests += 1\\r\\n                exceptions += 1\\r\\n                continue\\r\\n            \\r\\n            if response != answer:\\r\\n                tests += 1\\r\\n                bad_value += 1\\r\\n                continue\\r\\n            \\r\\n            correct += 1\\r\\n            tests += 1\\r\\n        \\r\\n    \\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        print(\"\\\\n\".join([str(i) for i in exception_set]))\\r\\n    if bad_value > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong key\", bad_value, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    if os.path.exists(ct_file):\\r\\n        os.remove(ct_file)\\r\\n    \\r\\n    return score\\r\\n\\r\\n#-------------------------------------------------------------------------\\r\\n# Main test driver function\\r\\n#-------------------------------------------------------------------------\\r\\n\\r\\nif test_name == \\'caesar_gc\\':\\r\\n    import caesar_gc\\r\\n\\r\\nif test_name == \\'caesar\\':\\r\\n    import caesar\\r\\n\\r\\nprint_exceptions = True;\\r\\n\\r\\ndef test_passed():\\r\\n\\r\\n    overall_score = 0.0\\r\\n\\r\\n    if test_name == \\'caesar_gc\\':\\r\\n        tests = [[test_gc_character,       \"character()\",               0.05],\\r\\n                 [test_gc_index,           \"index()\",                   0.20],\\r\\n                 [test_gc_shift,           \"test_shift()\",              0.20],\\r\\n                 [test_gc_encrypt,         \"test_encrypt()\",            0.05],\\r\\n                 [test_gc_decrypt,         \"test_decrypt()\",            0.20],\\r\\n                 [test_gc_encrypt_file,    \"test_encrypt_file()\",       0.20],\\r\\n                 [test_gc_decrypt_file,    \"test_decrypt_file()\",       0.10]]\\r\\n    \\r\\n    if test_name == \\'caesar\\':\\r\\n        tests = [[test_character,          \"character()\",               0.01],\\r\\n                 [test_index,              \"index()\",                   0.03],\\r\\n                 [test_shift,              \"test_shift()\",              0.03],\\r\\n                 [test_encrypt,            \"test_encrypt()\",            0.01],\\r\\n                 [test_decrypt,            \"test_decrypt()\",            0.03],\\r\\n                 [test_encrypt_file,       \"test_encrypt_file()\",       0.03],\\r\\n                 [test_decrypt_file,       \"test_decrypt_file()\",       0.01],\\r\\n                 [test_distribution,       \"test_distribution()\",       0.20],\\r\\n                 [test_compare_to_english, \"test_compare_to_english()\", 0.20],\\r\\n                 [test_find_key,           \"test_find_key()\",           0.20],\\r\\n                 [test_crack,              \"test_crack()\",              0.20],\\r\\n                 [test_crack_file,         \"test_crack_file()\",         0.05]]\\r\\n    \\r\\n    if test_name in [\\'caesar\\', \\'caesar_gc\\']:\\r\\n        for test in tests:\\r\\n            print(\"-------------------------------------------------------\")\\r\\n            print(\"Test: \", test[1])\\r\\n            print(\"-------------------------------------------------------\")\\r\\n            overall_score += test[2] * test[0]()\\r\\n\\r\\n    if test_name == \\'pex2_gc\\':\\r\\n        print(\"******************************************************************************\")\\r\\n        print(\"**  To run the tests against the Autograder, run the \\'caesar_gc.py\\' file.  ***\")\\r\\n        print(\"****  ----- See the Errata tab on the PEX 2 Write Up for details. ------  ****\")\\r\\n        print(\"******************************************************************************\")\\r\\n\\r\\n    if test_name == \\'pex2\\':\\r\\n        print(\"******************************************************************************\")\\r\\n        print(\"****  To run the tests against the Autograder, run the \\'caesar.py\\' file.  ****\")\\r\\n        print(\"****  ----- See the Errata tab on the PEX 2 Write Up for details. ------  ****\")\\r\\n        print(\"******************************************************************************\")\\r\\n    \\r\\n    return round(overall_score, 1)\\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'caesar_gc': 'from cs110 import autograder\\r\\nimport os\\r\\nimport random\\r\\n\\r\\ntest_name = \\'caesar_gc\\'\\r\\n\\r\\n#-------------------------------------------------------------------------\\r\\n# Helper functions\\r\\n#-------------------------------------------------------------------------\\r\\n\\r\\nELF = [ 0.08200, 0.01500, # A, B\\r\\n    0.02800, 0.04300, 0.12581, 0.02200, 0.02000, # C, D, E, F, G\\r\\n    0.06100, 0.07000, 0.00150, 0.00770, 0.04000, # H, I, J, K, L\\r\\n    0.02400, 0.06700, 0.07500, 0.01900, 0.00095, # M, N, O, P, Q\\r\\n    0.06000, 0.06300, 0.09100, 0.02800, 0.00980, # R, S, T, U, V\\r\\n    0.02400, 0.00150, 0.02000, 0.00074]          # W, X, Y, Z\\r\\nAS = len(ELF)\\r\\ndef ch(i): return chr(i + ord(\\'A\\'))\\r\\ndef ind(l): return ord(l) - ord(\\'A\\')\\r\\ndef sh(l, sa):\\r\\n    if l.isupper(): return ch((ind(l) + sa) % AS)\\r\\n    return ch((ind(l.upper()) + sa) % AS).lower()\\r\\ndef en(s, k):\\r\\n    sa = ind(k); ct = \"\"\\r\\n    for sy in s:\\r\\n        if not sy.isalpha(): ct += sy\\r\\n        else: ct += sh(sy, sa)\\r\\n    return ct\\r\\ndef de(s, k):\\r\\n    sa = -ind(k); pt = \"\"\\r\\n    for sy in s:\\r\\n        if not sy.isalpha(): pt += sy\\r\\n        else: pt += sh(sy, sa)\\r\\n    return pt\\r\\ndef ef(pfn, k, cfn):\\r\\n    pf = open(pfn, \"r\"); pt = pf.read(); pf.close()\\r\\n    ct = en(pt, key)\\r\\n    cf = open(cfn, \"w\"); cf.write(ct); cf.close()\\r\\ndef df(cfn, key, pfn):\\r\\n    cf = open(cfn, \"r\"); ct = cf.read(); cf.close()\\r\\n    pt = de(ct, key)\\r\\n    pf = open(pfn, \"w\"); pf.write(pt); pf.close()\\r\\ndef ds(s):\\r\\n    fl = []\\r\\n    for i in range(AS): fl.append(0)\\r\\n    tlc = 0\\r\\n    for l in s:\\r\\n        if l.isalpha(): fl[ind(l.upper())] += 1; tlc += 1\\r\\n    for i in range(AS): fl[i] /= tlc\\r\\n    return fl\\r\\ndef ce(fd):\\r\\n    c = 0.0\\r\\n    for i in range(AS): c += fd[i] * ELF[i]\\r\\n    return c\\r\\ndef fk(fd):\\r\\n    mc = 0; ki = 0\\r\\n    for ls in range(AS):\\r\\n        c = ce(fd)\\r\\n        if c > mc: ki = ls; mc = c\\r\\n        fd = fd[1:] + fd[:1]\\r\\n    k = ch(ki)\\r\\n    return k\\r\\ndef cr(ct): fd = ds(ct); k = fk(fd); return k\\r\\ndef cf(cfn):\\r\\n    cf = open(cfn, \"r\")\\r\\n    ct = cf.read()\\r\\n    cf.close()\\r\\n    return cr(ct)\\r\\n\\r\\ndef cumulative_elf():\\r\\n    cdf = []\\r\\n    for i in range(AS):\\r\\n        if i == 0:\\r\\n            cum = 0\\r\\n        else:\\r\\n            cum = cdf[i-1]\\r\\n        cdf.append(cum + ELF[i])\\r\\n    cdf[AS-1] = 1.0\\r\\n    return cdf\\r\\n\\r\\ncum_elf = cumulative_elf()\\r\\n\\r\\n#-------------------------------------------------------------------------\\r\\n# Test Functions for caesar_gc\\r\\n#-------------------------------------------------------------------------\\r\\n\\r\\ndef test_gc_character():\\r\\n    print(\"Testing character()\")\\r\\n    \\r\\n    upper_bad = 0\\r\\n    exceptions = 0\\r\\n    \\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    for test_input in range(0,26):\\r\\n\\r\\n        tests += 1\\r\\n        try:\\r\\n            result = caesar_gc.character(test_input)\\r\\n            answer = ch(test_input)\\r\\n            \\r\\n            if result == answer:\\r\\n                correct += 1\\r\\n            else:\\r\\n                upper_bad += 1\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            exceptions += 1\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", upper_bad, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\ndef test_gc_index():\\r\\n\\r\\n    print(\"Testing index()\")\\r\\n    \\r\\n    upper_bad = 0\\r\\n    exceptions = 0\\r\\n    \\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    for code in range(ord(\\'A\\'),ord(\\'Z\\')+1):\\r\\n        \\r\\n        test_input = chr(code)\\r\\n        \\r\\n        tests += 1\\r\\n        try:\\r\\n            result = caesar_gc.index(test_input)\\r\\n            answer = ind(test_input)\\r\\n            \\r\\n            if result == answer:\\r\\n                correct += 1\\r\\n            else:\\r\\n                upper_bad += 1\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            exceptions += 1\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", upper_bad, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_gc_shift():\\r\\n\\r\\n    print(\"Testing shift()\")\\r\\n    \\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    exceptions = 0\\r\\n    \\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    for code in range(0,26):\\r\\n        test_input = ch(code)\\r\\n        \\r\\n        for shift_amount in range(-25, 26):\\r\\n            \\r\\n            tests += 1\\r\\n            try:\\r\\n                response = caesar_gc.shift(test_input, shift_amount)\\r\\n                answer = sh(test_input, shift_amount)\\r\\n                if response == answer:\\r\\n                    correct += 1\\r\\n                else:\\r\\n                    upper_bad += 1\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    print(e)\\r\\n                exceptions += 1\\r\\n\\r\\n            tests += 1\\r\\n            try:\\r\\n                response = caesar_gc.shift(test_input.lower(), shift_amount)\\r\\n                answer = sh(test_input.lower(), shift_amount)\\r\\n                if response == answer:\\r\\n                    correct += 1\\r\\n                else:\\r\\n                    lower_bad += 1\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    print(e)\\r\\n                exceptions += 1\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value for uppercase letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value for lowercase letters\", lower_bad, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_gc_encrypt():\\r\\n    \\r\\n    print(\"Testing encrypt()\")\\r\\n\\r\\n    string = \"\"\\r\\n    \\r\\n    for c in range(0,128):\\r\\n        string += chr(c)\\r\\n    \\r\\n    exceptions = 0\\r\\n    wrong_length = 0\\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    other_bad = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    \\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n\\r\\n        answer = en(string, key)\\r\\n        try:\\r\\n            response = caesar_gc.encrypt(string, key)\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            wrong_length += 1\\r\\n            continue\\r\\n    \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    upper_bad += 1\\r\\n                elif answer[i].islower():\\r\\n                    lower_bad += 1\\r\\n                else:\\r\\n                    other_bad += 1\\r\\n                    \\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted upper case letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted lower case letters\", lower_bad, \"time(s).\")\\r\\n    if other_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted non-letters\", other_bad, \"time(s).\")\\r\\n    if wrong_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", wrong_length, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_gc_decrypt():\\r\\n    \\r\\n    print(\"Testing decrypt()\")\\r\\n\\r\\n    string = \"\"\\r\\n    \\r\\n    for c in range(0,128):\\r\\n        string += chr(c)\\r\\n    \\r\\n    exceptions = 0\\r\\n    wrong_length = 0\\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    other_bad = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    \\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n\\r\\n        answer = de(string, key)\\r\\n        try:\\r\\n            response = caesar_gc.decrypt(string, key)\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            wrong_length += 1\\r\\n            continue\\r\\n    \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    upper_bad += 1\\r\\n                elif answer[i].islower():\\r\\n                    lower_bad += 1\\r\\n                else:\\r\\n                    other_bad += 1\\r\\n                    \\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly decrypted upper case letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly decrypted lower case letters\", lower_bad, \"time(s).\")\\r\\n    if other_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly decrypted non-letters\", other_bad, \"time(s).\")\\r\\n    if wrong_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", wrong_length, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_gc_encrypt_file():\\r\\n    \\r\\n    print(\"Testing encrypt_file()\")\\r\\n\\r\\n    pt_file = \"xkiwjd\"\\r\\n    ct_file = \"ekvuim\"\\r\\n\\r\\n    string = \"\"\\r\\n    for c in range(32,128):\\r\\n        string += chr(c)\\r\\n    plaintext = string + \\'\\\\n\\' + string + \\'\\\\n\\'\\r\\n    \\r\\n    fp = open(pt_file, \"w\"); fp.write(plaintext); fp.close()\\r\\n\\r\\n    exceptions = 0\\r\\n    wrong_length = 0\\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    other_bad = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    \\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n        \\r\\n        answer = en(plaintext, key)\\r\\n        try:\\r\\n            caesar_gc.encrypt_file(pt_file, key, ct_file)\\r\\n            fp = open(ct_file, \"r\"); response = fp.read(); fp.close()\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            wrong_length += 1\\r\\n            continue\\r\\n        \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    upper_bad += 1\\r\\n                elif answer[i].islower():\\r\\n                    lower_bad += 1\\r\\n                else:\\r\\n                    other_bad += 1\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n    if wrong_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", wrong_length, \"time(s).\")\\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted upper case letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted lower case letters\", lower_bad, \"time(s).\")\\r\\n    if other_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted non-letters\", other_bad, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    if os.path.exists(pt_file):\\r\\n        os.remove(pt_file)\\r\\n    if os.path.exists(ct_file):\\r\\n        os.remove(ct_file)\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_gc_decrypt_file():\\r\\n    \\r\\n    print(\"Testing decrypt_file()\")\\r\\n\\r\\n    pt_file = \"kgbjw45df\"\\r\\n    ct_file = \"iuwmndfuh\"\\r\\n\\r\\n    string = \"\"\\r\\n    for c in range(32,128):\\r\\n        string += chr(c)\\r\\n    ciphertext = string + \\'\\\\n\\' + string + \\'\\\\n\\'\\r\\n    \\r\\n    fp = open(ct_file, \"w\"); fp.write(ciphertext); fp.close()\\r\\n\\r\\n    exceptions = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_length = 0\\r\\n    bad_upper = 0\\r\\n    bad_lower = 0\\r\\n    bad_other = 0\\r\\n\\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n        \\r\\n        answer = de(ciphertext, key)\\r\\n        try:\\r\\n            caesar_gc.decrypt_file(ct_file, key, pt_file)\\r\\n            fp = open(pt_file, \"r\"); response = fp.read(); fp.close()\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            bad_length += 1\\r\\n            continue\\r\\n        \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    bad_upper += 1\\r\\n                elif answer[i].islower():\\r\\n                    bad_lower += 1\\r\\n                else:\\r\\n                    bad_other += 1\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n    if bad_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", bad_length, \"time(s).\")\\r\\n    if bad_upper > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted upper case letters\", bad_upper, \"time(s).\")\\r\\n    if bad_lower > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted lower case letters\", bad_lower, \"time(s).\")\\r\\n    if bad_other > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted non-letters\", bad_other, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    if os.path.exists(pt_file):\\r\\n        os.remove(pt_file)\\r\\n    if os.path.exists(ct_file):\\r\\n        os.remove(ct_file)\\r\\n    \\r\\n    return score\\r\\n\\r\\n#-------------------------------------------------------------------------\\r\\n# Test Functions for caesar\\r\\n#-------------------------------------------------------------------------\\r\\n\\r\\ndef test_character():\\r\\n    print(\"Testing character()\")\\r\\n    \\r\\n    upper_bad = 0\\r\\n    exceptions = 0\\r\\n    \\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    for test_input in range(0,26):\\r\\n\\r\\n        tests += 1\\r\\n        try:\\r\\n            result = caesar.character(test_input)\\r\\n            answer = ch(test_input)\\r\\n            \\r\\n            if result == answer:\\r\\n                correct += 1\\r\\n            else:\\r\\n                upper_bad += 1\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            exceptions += 1\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", upper_bad, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\ndef test_index():\\r\\n\\r\\n    print(\"Testing index()\")\\r\\n    \\r\\n    upper_bad = 0\\r\\n    exceptions = 0\\r\\n    \\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    for code in range(ord(\\'A\\'),ord(\\'Z\\')+1):\\r\\n        \\r\\n        test_input = chr(code)\\r\\n        \\r\\n        tests += 1\\r\\n        try:\\r\\n            result = caesar.index(test_input)\\r\\n            answer = ind(test_input)\\r\\n            \\r\\n            if result == answer:\\r\\n                correct += 1\\r\\n            else:\\r\\n                upper_bad += 1\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            exceptions += 1\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", upper_bad, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_shift():\\r\\n\\r\\n    print(\"Testing shift()\")\\r\\n    \\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    exceptions = 0\\r\\n    \\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    for code in range(0,26):\\r\\n        test_input = ch(code)\\r\\n        \\r\\n        for shift_amount in range(-25, 26):\\r\\n            \\r\\n            tests += 1\\r\\n            try:\\r\\n                response = caesar.shift(test_input, shift_amount)\\r\\n                answer = sh(test_input, shift_amount)\\r\\n                if response == response:\\r\\n                    correct += 1\\r\\n                else:\\r\\n                    upper_bad += 1\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    print(e)\\r\\n                exceptions += 1\\r\\n\\r\\n            tests += 1\\r\\n            try:\\r\\n                response = caesar.shift(test_input.lower(), shift_amount)\\r\\n                answer = sh(test_input.lower(), shift_amount)\\r\\n                if response == answer:\\r\\n                    correct += 1\\r\\n                else:\\r\\n                    lower_bad += 1\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    print(e)\\r\\n                exceptions += 1\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value for uppercase letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value for lowercase letters\", lower_bad, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_encrypt():\\r\\n    \\r\\n    print(\"Testing encrypt()\")\\r\\n\\r\\n    string = \"\"\\r\\n    \\r\\n    for c in range(0,128):\\r\\n        string += chr(c)\\r\\n    \\r\\n    exceptions = 0\\r\\n    wrong_length = 0\\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    other_bad = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    \\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n\\r\\n        answer = en(string, key)\\r\\n        try:\\r\\n            response = caesar.encrypt(string, key)\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            wrong_length += 1\\r\\n            continue\\r\\n    \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    upper_bad += 1\\r\\n                elif answer[i].islower():\\r\\n                    lower_bad += 1\\r\\n                else:\\r\\n                    other_bad += 1\\r\\n                    \\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted upper case letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted lower case letters\", lower_bad, \"time(s).\")\\r\\n    if other_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted non-letters\", other_bad, \"time(s).\")\\r\\n    if wrong_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", wrong_length, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_decrypt():\\r\\n    \\r\\n    print(\"Testing decrypt()\")\\r\\n\\r\\n    string = \"\"\\r\\n    \\r\\n    for c in range(0,128):\\r\\n        string += chr(c)\\r\\n    \\r\\n    exceptions = 0\\r\\n    wrong_length = 0\\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    other_bad = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    \\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n\\r\\n        answer = de(string, key)\\r\\n        try:\\r\\n            response = caesar.decrypt(string, key)\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            wrong_length += 1\\r\\n            continue\\r\\n    \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    upper_bad += 1\\r\\n                elif answer[i].islower():\\r\\n                    lower_bad += 1\\r\\n                else:\\r\\n                    other_bad += 1\\r\\n                    \\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly decrypted upper case letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly decrypted lower case letters\", lower_bad, \"time(s).\")\\r\\n    if other_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly decrypted non-letters\", other_bad, \"time(s).\")\\r\\n    if wrong_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", wrong_length, \"time(s).\")\\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_encrypt_file():\\r\\n    \\r\\n    print(\"Testing encrypt_file()\")\\r\\n\\r\\n    pt_file = \"xkiwjd\"\\r\\n    ct_file = \"ekvuim\"\\r\\n\\r\\n    string = \"\"\\r\\n    for c in range(32,128):\\r\\n        string += chr(c)\\r\\n    plaintext = string + \\'\\\\n\\' + string + \\'\\\\n\\'\\r\\n    \\r\\n    fp = open(pt_file, \"w\"); fp.write(plaintext); fp.close()\\r\\n\\r\\n    exceptions = 0\\r\\n    wrong_length = 0\\r\\n    upper_bad = 0\\r\\n    lower_bad = 0\\r\\n    other_bad = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    \\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n        \\r\\n        answer = en(plaintext, key)\\r\\n        try:\\r\\n            caesar.encrypt_file(pt_file, key, ct_file)\\r\\n            fp = open(ct_file, \"r\"); response = fp.read(); fp.close()\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            wrong_length += 1\\r\\n            continue\\r\\n        \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    upper_bad += 1\\r\\n                elif answer[i].islower():\\r\\n                    lower_bad += 1\\r\\n                else:\\r\\n                    other_bad += 1\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n    if wrong_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", wrong_length, \"time(s).\")\\r\\n    if upper_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted upper case letters\", upper_bad, \"time(s).\")\\r\\n    if lower_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted lower case letters\", lower_bad, \"time(s).\")\\r\\n    if other_bad > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted non-letters\", other_bad, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    if os.path.exists(pt_file):\\r\\n        os.remove(pt_file)\\r\\n    if os.path.exists(ct_file):\\r\\n        os.remove(ct_file)\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_decrypt_file():\\r\\n    \\r\\n    print(\"Testing decrypt_file()\")\\r\\n\\r\\n    pt_file = \"kgbjw45df\"\\r\\n    ct_file = \"iuwmndfuh\"\\r\\n\\r\\n    string = \"\"\\r\\n    for c in range(32,128):\\r\\n        string += chr(c)\\r\\n    ciphertext = string + \\'\\\\n\\' + string + \\'\\\\n\\'\\r\\n    \\r\\n    fp = open(ct_file, \"w\"); fp.write(ciphertext); fp.close()\\r\\n\\r\\n    exceptions = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_length = 0\\r\\n    bad_upper = 0\\r\\n    bad_lower = 0\\r\\n    bad_other = 0\\r\\n\\r\\n    for k in range(0,26):\\r\\n        key = ch(k)\\r\\n        \\r\\n        answer = de(ciphertext, key)\\r\\n        try:\\r\\n            caesar.decrypt_file(ct_file, key, pt_file)\\r\\n            fp = open(pt_file, \"r\"); response = fp.read(); fp.close()\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n            continue\\r\\n        \\r\\n        if response == None or (len(response) != len(answer)):\\r\\n            tests += len(answer)\\r\\n            bad_length += 1\\r\\n            continue\\r\\n        \\r\\n        for i in range(len(answer)):\\r\\n            tests += 1\\r\\n            if response[i] == answer[i]:\\r\\n                correct += 1\\r\\n            else:\\r\\n                if answer[i].isupper():\\r\\n                    bad_upper += 1\\r\\n                elif answer[i].islower():\\r\\n                    bad_lower += 1\\r\\n                else:\\r\\n                    bad_other += 1\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n    if bad_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length string\", bad_length, \"time(s).\")\\r\\n    if bad_upper > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted upper case letters\", bad_upper, \"time(s).\")\\r\\n    if bad_lower > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted lower case letters\", bad_lower, \"time(s).\")\\r\\n    if bad_other > 0:\\r\\n        print(\"        *** ERROR *** Incorrectly encrypted non-letters\", bad_other, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    if os.path.exists(pt_file):\\r\\n        os.remove(pt_file)\\r\\n    if os.path.exists(ct_file):\\r\\n        os.remove(ct_file)\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef random_ptchar():\\r\\n    \\r\\n    if random.random() < 1/80:\\r\\n        return \\'\\\\n\\'\\r\\n    \\r\\n    x = random.random()\\r\\n    \\r\\n    i = 0\\r\\n    while cum_elf[i] < x:\\r\\n        i += 1\\r\\n    c = ch(i)\\r\\n    if random.random() < 0.5:\\r\\n        c = c.lower()\\r\\n        \\r\\n    return c\\r\\n\\r\\ndef random_pt(length):\\r\\n    \\r\\n    pt = \"\"\\r\\n    for i in range(length):\\r\\n        pt += random_ptchar()\\r\\n    return pt\\r\\n        \\r\\ndef test_distribution():\\r\\n    \\r\\n    print(\"Testing distribution()\")\\r\\n\\r\\n    exceptions = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_length = 0\\r\\n    bad_value = 0\\r\\n\\r\\n    for i in range(100):\\r\\n        \\r\\n        big_pt = random_pt(1000)\\r\\n        answer = ds(big_pt)\\r\\n\\r\\n        try:\\r\\n            response = caesar.distribution(big_pt)\\r\\n            \\r\\n            if response == None or (len(response) != len(answer)):\\r\\n                tests += len(answer)\\r\\n                bad_length += 1\\r\\n            else:\\r\\n                for i in range(len(answer)):\\r\\n                    if abs(answer[i] - response[i]) > 0.001*answer[i]:\\r\\n                        bad_value += 1\\r\\n                    else:\\r\\n                        correct += 1\\r\\n                    tests += 1\\r\\n\\r\\n        except BaseException as e:\\r\\n            if print_exceptions:\\r\\n                print(e)\\r\\n            tests += len(answer)\\r\\n            exceptions += 1\\r\\n    \\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n    if bad_length > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong length of distribution\", bad_length, \"time(s).\")\\r\\n    if bad_value > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", bad_value, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_compare_to_english():\\r\\n\\r\\n    print(\"Testing compare_to_english()\")\\r\\n\\r\\n    exceptions = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_length = 0\\r\\n    bad_value = 0\\r\\n\\r\\n    for i in range(50):\\r\\n        \\r\\n        big_pt = random_pt(100)\\r\\n        \\r\\n        for k in range(AS):\\r\\n            ct = en(big_pt, ch(k))\\r\\n            answer = ce(ds(ct))\\r\\n\\r\\n            try:\\r\\n                resp_dist = caesar.distribution(ct)\\r\\n                response = caesar.compare_to_english(resp_dist)\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    print(e)\\r\\n                tests += 1\\r\\n                exceptions += 1\\r\\n                continue\\r\\n\\r\\n            if response == None or (abs(answer - response) > 0.001*answer):\\r\\n                bad_value += 1\\r\\n            else:\\r\\n                correct += 1\\r\\n            tests += 1\\r\\n\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n    if bad_value > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", bad_value, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_find_key():\\r\\n    \\r\\n    print(\"Testing find_key()\")\\r\\n\\r\\n    exceptions = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_value = 0\\r\\n    \\r\\n    for i in range(50):\\r\\n        \\r\\n        big_pt = random_pt(100)\\r\\n        \\r\\n        for k in range(AS):\\r\\n            ct = en(big_pt, ch(k))\\r\\n            answer = fk(ds(ct))\\r\\n\\r\\n            try:\\r\\n                resp_dist = caesar.distribution(ct)\\r\\n                response = caesar.find_key(resp_dist)\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    print(e)\\r\\n                tests += 1\\r\\n                exceptions += 1\\r\\n                continue\\r\\n\\r\\n            if answer != response:\\r\\n                bad_value += 1\\r\\n            else:\\r\\n                correct += 1\\r\\n            tests += 1\\r\\n\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n    if bad_value > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", bad_value, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_crack():\\r\\n    \\r\\n    print(\"Testing crack()\")\\r\\n\\r\\n    exceptions = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_value = 0\\r\\n\\r\\n    for i in range(50):\\r\\n        \\r\\n        big_pt = random_pt(100)\\r\\n        \\r\\n        for k in range(AS):\\r\\n            ct = en(big_pt, ch(k))\\r\\n            answer = cr(ct)\\r\\n\\r\\n            try:\\r\\n                response = caesar.crack(ct)\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    print(e)\\r\\n                tests += 1\\r\\n                exceptions += 1\\r\\n                continue\\r\\n\\r\\n            if answer != response:\\r\\n                bad_value += 1\\r\\n            else:\\r\\n                correct += 1\\r\\n            tests += 1\\r\\n\\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n    if bad_value > 0:\\r\\n        print(\"        *** ERROR *** Returned incorrect value\", bad_value, \"time(s).\")\\r\\n        \\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    return score\\r\\n\\r\\ndef test_crack_file():\\r\\n\\r\\n    print(\"Testing crack_file()\")\\r\\n\\r\\n    pt_file = \"in5842p\"\\r\\n    ct_file = \"Pw7vj2R\"\\r\\n\\r\\n    exceptions = 0\\r\\n    tests = 0\\r\\n    correct = 0\\r\\n    bad_value = 0\\r\\n\\r\\n    for i in range(10):\\r\\n        \\r\\n        big_pt = random_pt(1000)\\r\\n\\r\\n        for k in range(AS):\\r\\n            key = ch(k)\\r\\n            \\r\\n            ct = en(big_pt, key)\\r\\n            fp = open(ct_file, \"w\"); fp.write(ct); fp.close()\\r\\n\\r\\n            answer = cr(ct)\\r\\n            \\r\\n            try:\\r\\n                response = caesar.crack_file(ct_file)\\r\\n            except BaseException as e:\\r\\n                if print_exceptions:\\r\\n                    print(e)\\r\\n                tests += 1\\r\\n                exceptions += 1\\r\\n                continue\\r\\n            \\r\\n            if response != answer:\\r\\n                tests += 1\\r\\n                bad_value += 1\\r\\n                continue\\r\\n            \\r\\n            correct += 1\\r\\n            tests += 1\\r\\n        \\r\\n    #print(\"    Feedback:\")\\r\\n    \\r\\n    if exceptions > 0:\\r\\n        print(\"        *** ERROR *** Threw an exception\", exceptions, \"time(s).\")\\r\\n    if bad_value > 0:\\r\\n        print(\"        *** ERROR *** Returned wrong key\", bad_value, \"time(s).\")\\r\\n\\r\\n    score = round(100 * correct / tests, 1)\\r\\n    print(\"    Function score = %.1f%% (passed %d out of %d)\" % (score, correct, tests))\\r\\n    \\r\\n    if os.path.exists(ct_file):\\r\\n        os.remove(ct_file)\\r\\n    \\r\\n    return score\\r\\n\\r\\n#-------------------------------------------------------------------------\\r\\n# Main test driver function\\r\\n#-------------------------------------------------------------------------\\r\\n\\r\\nif test_name == \\'caesar_gc\\':\\r\\n    import caesar_gc\\r\\n\\r\\nif test_name == \\'caesar\\':\\r\\n    import caesar\\r\\n\\r\\nprint_exceptions = True;\\r\\n\\r\\ndef test_passed():\\r\\n\\r\\n    overall_score = 0.0\\r\\n\\r\\n    if test_name == \\'caesar_gc\\':\\r\\n        tests = [[test_gc_character,       \"character()\",          0.05],\\r\\n                 [test_gc_index,           \"index()\",              0.20],\\r\\n                 [test_gc_shift,           \"shift()\",              0.20],\\r\\n                 [test_gc_encrypt,         \"encrypt()\",            0.05],\\r\\n                 [test_gc_decrypt,         \"decrypt()\",            0.20],\\r\\n                 [test_gc_encrypt_file,    \"encrypt_file()\",       0.20],\\r\\n                 [test_gc_decrypt_file,    \"decrypt_file()\",       0.10]]\\r\\n    \\r\\n    if test_name == \\'caesar\\':\\r\\n        tests = [[test_character,          \"character()\",          0.01],\\r\\n                 [test_index,              \"index()\",              0.03],\\r\\n                 [test_shift,              \"shift()\",              0.03],\\r\\n                 [test_encrypt,            \"encrypt()\",            0.01],\\r\\n                 [test_decrypt,            \"decrypt()\",            0.03],\\r\\n                 [test_encrypt_file,       \"encrypt_file()\",       0.03],\\r\\n                 [test_decrypt_file,       \"decrypt_file()\",       0.01],\\r\\n                 [test_distribution,       \"distribution()\",       0.20],\\r\\n                 [test_compare_to_english, \"compare_to_english()\", 0.20],\\r\\n                 [test_find_key,           \"find_key()\",           0.20],\\r\\n                 [test_crack,              \"crack()\",              0.20],\\r\\n                 [test_crack_file,         \"crack_file()\",         0.05]]\\r\\n    \\r\\n    if test_name in [\\'caesar\\', \\'caesar_gc\\']:\\r\\n        for test in tests:\\r\\n            print(\"-------------------------------------------------------\")\\r\\n            print(\"Test: \", test[1])\\r\\n            print(\"-------------------------------------------------------\")\\r\\n            overall_score += test[2] * test[0]()\\r\\n\\r\\n    if test_name == \\'pex2_gc\\':\\r\\n        print(\"******************************************************************************\")\\r\\n        print(\"**  To run the tests against the Autograder, run the \\'caesar_gc.py\\' file.  ***\")\\r\\n        print(\"****  ----- See the Errata tab on the PEX 2 Write Up for details. ------  ****\")\\r\\n        print(\"******************************************************************************\")\\r\\n\\r\\n    if test_name == \\'pex2\\':\\r\\n        print(\"******************************************************************************\")\\r\\n        print(\"****  To run the tests against the Autograder, run the \\'caesar.py\\' file.  ****\")\\r\\n        print(\"****  ----- See the Errata tab on the PEX 2 Write Up for details. ------  ****\")\\r\\n        print(\"******************************************************************************\")\\r\\n    \\r\\n    return round(overall_score, 1)\\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a4_7_fit_u': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nfilename = \"a4_7_fit_u.py\"\\r\\nexpected_output = [\"39\"]\\r\\n\\r\\n# Function checks for known shortcuts\\r\\ndef shortcut_detected():\\r\\n    file = open(filename, \"r\")\\r\\n    contents = file.read()\\r\\n    file.close()\\r\\n\\r\\n    # Looks for a short\\r\\n    if \"print(\\'39\\')\" in contents or \\'print(\"39\")\\' in contents or \\'print(39)\\' in contents:\\r\\n        print(\"WARNING:  You cannot just print out the answer.\")\\r\\n        return True\\r\\n    \\r\\n    return False\\r\\n\\r\\n# Unit Test Function\\r\\ndef test_passed():    \\r\\n    output, error = autograder.run_script(filename, [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    if shortcut_detected() == True:\\r\\n        print(\"Invalid Code Detected.  Contact your instructor.\")\\r\\n    elif len(lines) == 1:\\r\\n        if autograder.equals(lines[0], expected_output[0]):\\r\\n            print(\"Count of Unsatisfactory scores is Correct\")\\r\\n            return 100.0\\r\\n        else:\\r\\n            print(\"Count of Unsatisfactory scores is Incorrect\")\\r\\n    else:\\r\\n        print(\"Missing Output (or too many lines)\")\\r\\n\\r\\n    return 0.0\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a4_7_fit_e': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nfilename = \"a4_7_fit_e.py\"\\r\\nexpected_output = [\"9\"]\\r\\n\\r\\n# Function checks for known shortcuts\\r\\ndef shortcut_detected():\\r\\n    file = open(filename, \"r\")\\r\\n    contents = file.read()\\r\\n    file.close()\\r\\n\\r\\n    # Looks for a short\\r\\n    if \"print(\\'9\\')\" in contents or \\'print(\"9\")\\' in contents or \\'print(9)\\' in contents:\\r\\n        print(\"WARNING:  You cannot just print out the answer.\")\\r\\n        return True\\r\\n    \\r\\n    return False\\r\\n\\r\\n# Unit Test Function\\r\\ndef test_passed():    \\r\\n    output, error = autograder.run_script(filename, [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    if shortcut_detected() == True:\\r\\n        print(\"Invalid Code Detected.  Contact your instructor.\")\\r\\n    elif len(lines) == 1:\\r\\n        if autograder.equals(lines[0], expected_output[0]):\\r\\n            print(\"# of Excellents is Correct\")\\r\\n            return 100.0\\r\\n        else:\\r\\n            print(\"# of Excellents is Incorrect\")\\r\\n    else:\\r\\n        print(\"Missing Output (or too many lines)\")\\r\\n    \\r\\n    return 0.0\\r\\n    \\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_6_scores': 'from cs110 import autograder\\r\\nimport random, math\\r\\nfrom itertools import combinations\\r\\n\\r\\nrandom_names = [\"Marvel\", \"Bucky\", \"Mouse\",\\r\\n                \"Goose\", \"Jimmy\", \"Dice\",\\r\\n                \"Upshot\", \"Twain\", \"Ballpark\",\\r\\n                \"Hammer\", \"Pixel\", \"Billy\",\\r\\n                \"Lance\",\"Bong\",\"Eddie\",\\r\\n                \"Patton\",\"Tooey\",\"Gus\",\\r\\n                \"Karl\",\"Hub\",\"Luke\",\\r\\n                \"Olds\",\"Hap\",\"Zeamer\"]\\r\\n\\r\\nnum_names = random.randint(3,6)\\r\\n\\r\\n\\r\\n\\r\\ndef same_case():\\r\\n    print(\"Test Case 1\")\\r\\n    table = []\\r\\n    input_list = []\\r\\n    random_score = int(random.uniform(25, 100))\\r\\n    for name in random.choice(list(combinations(random_names,num_names))):\\r\\n        input_list.append(name)\\r\\n        input_list.append(random_score)\\r\\n        table.append([random_score, name])\\r\\n    \\r\\n    input_list.append(\"DONE\")\\r\\n    \\r\\n    output, error = autograder.run_script(\"a4_6_scores.py\", input_list)\\r\\n    \\r\\n    max_time = max(table)[0] \\r\\n    expected_output = [str(max_time)]\\r\\n    \\r\\n    for row in table:\\r\\n        if row[0] > max_time-10:\\r\\n            expected_output.append(row[1])\\r\\n\\r\\n    num_matches = autograder.compare_strings(output.strip().split(\\'\\\\n\\'), expected_output)\\r\\n    \\r\\n    if len(expected_output) != len(output.strip().split(\"\\\\n\")):\\r\\n        print(\"Too many or too few outputs\")\\r\\n        return 0.0\\r\\n    elif num_matches == len(expected_output):\\r\\n        print(\"Test Case 1 Correct\\\\n\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"One or more lines in your output is incorrect\")\\r\\n        return 0.0\\r\\n\\r\\ndef random_case():\\r\\n    print(\"Test Case 2\")\\r\\n    table = []\\r\\n    input_list = []\\r\\n    \\r\\n    for name in random.choice(list(combinations(random_names,num_names))):\\r\\n        random_score = int(random.uniform(25, 100))\\r\\n        input_list.append(name)\\r\\n        input_list.append(random_score)\\r\\n        table.append([random_score, name])\\r\\n    \\r\\n    input_list.append(\"DONE\")\\r\\n    \\r\\n    output, error = autograder.run_script(\"a4_6_scores.py\", input_list)\\r\\n    \\r\\n    max_time = max(table)[0] \\r\\n    expected_output = [str(max_time)]\\r\\n    \\r\\n    for row in table:\\r\\n        if row[0] > max_time-10:\\r\\n            expected_output.append(row[1])\\r\\n\\r\\n    num_matches = autograder.compare_strings(output.strip().split(\\'\\\\n\\'), expected_output)\\r\\n    if len(expected_output) != len(output.strip().split(\"\\\\n\")):\\r\\n        print(\"Too many or too few outputs\")\\r\\n        return 0.0\\r\\n    elif num_matches == len(expected_output):\\r\\n        print(\"Test Case 2 Correct\\\\n\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"One or more lines in your output is incorrect\")\\r\\n        return 0.0\\r\\n\\r\\ndef test_passed():\\r\\n    return same_case()*.1+random_case()*.9\\r\\n\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_6_flighthours': 'from cs110 import autograder\\r\\nimport random, math\\r\\nfrom itertools import combinations\\r\\n\\r\\n\\r\\nrandom_names = [\"Marvel\", \"Bucky\", \"Mouse\",\\r\\n                \"Goose\", \"Jimmy\", \"Dice\",\\r\\n                \"Upshot\", \"Twain\", \"Ballpark\",\\r\\n                \"Hammer\", \"Pixel\", \"Billy\",\\r\\n                \"Lance\",\"Bong\",\"Eddie\",\\r\\n                \"Patton\",\"Tooey\",\"Gus\",\\r\\n                \"Karl\",\"Hub\",\"Luke\",\\r\\n                \"Olds\",\"Hap\",\"Zeamer\"]\\r\\nnum_names = random.randint(3,6)\\r\\n\\r\\ndef same_case():\\r\\n    print(\"Test Case 1\")\\r\\n    table = []\\r\\n    input_list = []\\r\\n    random_score = int(random.uniform(60, 100))\\r\\n    for name in random.choice(list(combinations(random_names,num_names))):\\r\\n        \\r\\n        input_list.append(name)\\r\\n        input_list.append(random_score)\\r\\n        table.append([random_score, name])\\r\\n    \\r\\n    input_list.append(\"DONE\")\\r\\n    \\r\\n    output, error = autograder.run_script(\"a4_6_flighthours.py\", input_list)\\r\\n    \\r\\n    avg_hours = int(sum([x[0] for x in table])/len(table))\\r\\n    expected_output = [str(avg_hours)]\\r\\n    \\r\\n    for row in table:\\r\\n        if row[0] < avg_hours:\\r\\n            expected_output.append(row[1])\\r\\n\\r\\n    num_matches = autograder.compare_strings(output.strip().split(\\'\\\\n\\'), expected_output)\\r\\n    \\r\\n    if len(expected_output) != len(output.strip().split(\"\\\\n\")):\\r\\n        print(\"Too many or too few outputs\")\\r\\n        return 0.0\\r\\n    elif num_matches == len(expected_output):\\r\\n        print(\"Test Case 1 Correct\\\\n\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"One or more lines in your output is incorrect\")\\r\\n        return 0.0\\r\\n\\r\\ndef random_case():\\r\\n    print(\"Test Case 2\")\\r\\n    table = []\\r\\n    input_list = []\\r\\n    \\r\\n    for name in random.choice(list(combinations(random_names,num_names))):\\r\\n        random_score = int(random.uniform(60, 100))\\r\\n        input_list.append(name)\\r\\n        input_list.append(random_score)\\r\\n        table.append([random_score, name])\\r\\n    \\r\\n    input_list.append(\"DONE\")\\r\\n    \\r\\n    output, error = autograder.run_script(\"a4_6_flighthours.py\", input_list)\\r\\n    \\r\\n    avg_hours = int(sum([x[0] for x in table])/len(table))\\r\\n    expected_output = [str(avg_hours)]\\r\\n    \\r\\n    for row in table:\\r\\n        if row[0] < avg_hours:\\r\\n            expected_output.append(row[1])\\r\\n\\r\\n    num_matches = autograder.compare_strings(output.strip().split(\\'\\\\n\\'), expected_output)\\r\\n    \\r\\n    if len(expected_output) != len(output.strip().split(\"\\\\n\")):\\r\\n        print(\"Too many or too few outputs\")\\r\\n        return 0.0\\r\\n    elif num_matches == len(expected_output):\\r\\n        print(\"Test Case 2 Correct\\\\n\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"One or more lines in your output is incorrect\")\\r\\n        return 0.0\\r\\n\\r\\ndef test_passed():\\r\\n    return same_case()*.1+random_case()*.9\\r\\n    \\r\\n    \\r\\n        \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_6_aft': 'from cs110 import autograder\\r\\nimport random, math\\r\\nfrom itertools import combinations\\r\\n\\r\\nrandom_names = [\"Marvel\", \"Bucky\", \"Mouse\",\\r\\n                \"Goose\", \"Jimmy\", \"Dice\",\\r\\n                \"Upshot\", \"Twain\", \"Ballpark\",\\r\\n                \"Hammer\", \"Pixel\", \"Billy\",\\r\\n                \"Lance\",\"Bong\",\"Eddie\",\\r\\n                \"Patton\",\"Tooey\",\"Gus\",\\r\\n                \"Karl\",\"Hub\",\"Luke\",\\r\\n                \"Olds\",\"Hap\",\"Zeamer\"]\\r\\n\\r\\nnum_names = random.randint(3,6)\\r\\n\\r\\ndef same_case():\\r\\n    print(\"Test Case 1\")\\r\\n    table = []\\r\\n    input_list = []\\r\\n    random_score = int(random.uniform(540.0, 720.0))\\r\\n    for name in random.choice(list(combinations(random_names,num_names))):\\r\\n        input_list.append(name)\\r\\n        input_list.append(random_score)\\r\\n        table.append([random_score, name])\\r\\n    \\r\\n    input_list.append(\"DONE\")\\r\\n    \\r\\n    output, error = autograder.run_script(\"a4_6_aft.py\", input_list)\\r\\n    \\r\\n    min_time = min(table)[0] \\r\\n    expected_output = [str(min_time)]\\r\\n    \\r\\n    for row in table:\\r\\n        if row[0] < min_time+30:\\r\\n            expected_output.append(row[1])\\r\\n\\r\\n    num_matches = autograder.compare_strings(output.strip().split(\\'\\\\n\\'), expected_output)\\r\\n    \\r\\n    if len(expected_output) != len(output.strip().split(\"\\\\n\")):\\r\\n        print(\"Too many or too few outputs\")\\r\\n        return 0.0\\r\\n    elif num_matches == len(expected_output):\\r\\n        print(\"Test Case 1 Correct\\\\n\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"One or more lines in your output is incorrect\")\\r\\n        return 0.0\\r\\n\\r\\ndef random_case():\\r\\n    print(\"Test Case 2\")\\r\\n    table = []\\r\\n    input_list = []\\r\\n    \\r\\n    for name in random.choice(list(combinations(random_names,num_names))):\\r\\n        random_score = int(random.uniform(540.0, 720.0))\\r\\n        input_list.append(name)\\r\\n        input_list.append(random_score)\\r\\n        table.append([random_score, name])\\r\\n    \\r\\n    input_list.append(\"DONE\")\\r\\n    \\r\\n    output, error = autograder.run_script(\"a4_6_aft.py\", input_list)\\r\\n    \\r\\n    min_time = min(table)[0] \\r\\n    expected_output = [str(min_time)]\\r\\n    \\r\\n    for row in table:\\r\\n        if row[0] < min_time+30:\\r\\n            expected_output.append(row[1])\\r\\n\\r\\n    num_matches = autograder.compare_strings(output.strip().split(\\'\\\\n\\'), expected_output)\\r\\n    \\r\\n    if len(expected_output) != len(output.strip().split(\"\\\\n\")):\\r\\n        print(\"Too many or too few outputs\")\\r\\n        return 0.0\\r\\n    elif num_matches == len(expected_output):\\r\\n        print(\"Test Case 2 Correct\\\\n\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"One or more lines in your output is incorrect\")\\r\\n        return 0.0\\r\\n\\r\\ndef test_passed():\\r\\n    return same_case()*.1+random_case()*.9\\r\\n\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_5_translate': 'from cs110 import autograder\\r\\nimport random, math, ast\\r\\nfrom a4_5_translate import get_english_word\\r\\n\\r\\nbad_key = \"\"\\r\\n\\r\\ndef create_dictionary(size):\\r\\n    global bad_key\\r\\n    \\r\\n    values = [(\"Militar\", \"Military\"), (\"cadete\", \"Cadet\"), (\"Universidad\", \"University\"),\\r\\n              (\"Halcon\", \"Falcon\"), (\"montana\", \"Mountain\"), (\"computadora\", \"computer\"), (\"piton\", \"python\"),\\r\\n              (\"graduado\", \"graduated\")]\\r\\n    spanish_dictionary = {}\\r\\n    \\r\\n    print(\"Test Dictionary Contains the Following Words:\")\\r\\n    \\r\\n    for i in range(size):\\r\\n        random_value = values[random.randint(0, len(values)-1)]\\r\\n        values.remove(random_value)\\r\\n        spanish_dictionary[random_value[0]] = random_value[1]\\r\\n        print(random_value[0], \"(Translation\", str(random_value[1]) + \")\")\\r\\n    \\r\\n    bad_key = values[0][0]\\r\\n    \\r\\n    return spanish_dictionary\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n    tests = 5\\r\\n    \\r\\n    num_passed = 0\\r\\n    \\r\\n    spanish_dictionary = create_dictionary(tests)\\r\\n    \\r\\n    print()\\r\\n    \\r\\n    # Checking All of the Keys in our Dictionary\\r\\n    for key in spanish_dictionary.keys():\\r\\n        print(\"Using Function to get Translation for:\", key, \". . . \", end=\"\")\\r\\n        returned_value = get_english_word(key, spanish_dictionary)\\r\\n        print(\"Your Function Returned\", returned_value, \". . . \", end=\"\")\\r\\n        if returned_value == spanish_dictionary[key]:\\r\\n            print(\"Correct!\")\\r\\n            num_passed += 1\\r\\n        else:\\r\\n            print(\"Incorrect.  Returned\", returned_value, \"instead of\", spanish_dictionary[key])\\r\\n    \\r\\n#     print(\"Using Function to get Translation for a Word Not in the Dictionary:\", bad_key, \". . . \", end=\"\")\\r\\n#     \\r\\n#     try:\\r\\n#         returned_value = get_english_word(bad_key, spanish_dictionary)\\r\\n#         if returned_value == \"Unknown\":\\r\\n#             print(\"Correctly Handled\")\\r\\n#             num_passed += 1\\r\\n#         else:\\r\\n#             print(\"Incorrect.  Returned\", returned_value, \"instead of \\'Unknown\\'\")\\r\\n#     except:\\r\\n#         print(\"Program crashed trying to access a key that does not exist in the dictionary\")\\r\\n        \\r\\n    return (100/tests) * num_passed;\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a4_5_password': 'from cs110 import autograder\\r\\nimport random, math, ast\\r\\nfrom a4_5_password import get_password\\r\\n\\r\\nbad_key = \"\"\\r\\n\\r\\ndef create_dictionary(size):\\r\\n    global bad_key\\r\\n    \\r\\n    values = [(\"CarMax\", \"B-1IsBest\"), (\"YouTube\", \"MyCatisthecoolest\"), (\"Gmail\", \"thisIsMyPassword\"),\\r\\n              (\"Outlook\", \"MSDOSwasBAD!\"), (\"Blackboard\", \"SkoolRulez\"), (\"Canvas\", \"beststudentEvA\"), (\"REI\", \"MountainClimber\"),\\r\\n              (\"UnitedAirlines\", \"gimmeDemMiles\")]\\r\\n    dictionary = {}\\r\\n    \\r\\n    print(\"Test Dictionary Contains the Following Words:\")\\r\\n    \\r\\n    for i in range(size):\\r\\n        random_value = values[random.randint(0, len(values)-1)]\\r\\n        values.remove(random_value)\\r\\n        dictionary[random_value[0]] = random_value[1]\\r\\n        print(random_value[0], \"(Password\", str(random_value[1]) + \")\")\\r\\n    \\r\\n    bad_key = values[0][0]\\r\\n    \\r\\n    return dictionary\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n    tests = 5\\r\\n    num_passed = 0\\r\\n    \\r\\n    dictionary = create_dictionary(tests)\\r\\n    \\r\\n    print()\\r\\n    \\r\\n    # Checking All of the Keys in our Dictionary\\r\\n    for key in dictionary.keys():\\r\\n        print(\"Using Function to get Password for:\", key, \". . . \", end=\"\")\\r\\n        returned_value = get_password(key, dictionary)\\r\\n        print(\"Your Function Returned\", returned_value, \". . . \", end=\"\")\\r\\n        if returned_value == dictionary[key]:\\r\\n            print(\"Correct!\")\\r\\n            num_passed += 1\\r\\n        else:\\r\\n            print(\"Incorrect.  Returned\", returned_value, \"instead of\", dictionary[key])\\r\\n    \\r\\n#     print(\"Using Function to get Password for a Website Not in the Dictionary:\", bad_key, \". . . \", end=\"\")\\r\\n#     \\r\\n#     try:\\r\\n#         returned_value = get_password(bad_key, dictionary)\\r\\n#         if returned_value == \"Unknown\":\\r\\n#             print(\"Correctly Handled\")\\r\\n#             num_passed += 1\\r\\n#         else:\\r\\n#             print(\"Incorrect.  Returned\", returned_value, \"instead of \\'Unknown\\'\")\\r\\n#     except:\\r\\n#         print(\"Program crashed trying to access a key that does not exist in the dictionary\")\\r\\n        \\r\\n    return (100/tests) * num_passed;\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a4_5_areacode': 'from cs110 import autograder\\r\\nimport random, math, ast\\r\\nfrom a4_5_areacode import get_area_code\\r\\n\\r\\nbad_key = \"\"\\r\\n\\r\\ndef create_dictionary(size):\\r\\n    global bad_key\\r\\n    \\r\\n    values = [(\"California\", 209), (\"Texas\", 214), (\"Michigan\", 248), (\"Iowa\", 319), (\"Utah\", 358), (\"Colorado\", 719), (\"Alabama\", 334), (\"Alaska\", 907)]\\r\\n    area_code_dictionary = {}\\r\\n    \\r\\n    print(\"Test Dictionary Contains Area Codes for the Following States:\")\\r\\n    \\r\\n    for i in range(size):\\r\\n        random_value = values[random.randint(0, len(values)-1)]\\r\\n        values.remove(random_value)\\r\\n        area_code_dictionary[random_value[0]] = random_value[1]\\r\\n        print(random_value[0], \"(Area Code:\", str(random_value[1]) + \")\")\\r\\n    \\r\\n    bad_key = values[0][0]\\r\\n    \\r\\n    return area_code_dictionary\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n    tests = 5\\r\\n\\r\\n    num_passed = 0\\r\\n    area_code_dictionary = create_dictionary(tests)\\r\\n    \\r\\n    print()\\r\\n    output, error = autograder.run_script(\"a4_5_areacode.py\", [])\\r\\n    output_lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    # Checking All of the Keys in our Dictionary\\r\\n    for key in area_code_dictionary.keys():\\r\\n        print(\"Using Function to get Area Code for:\", key, \". . . \", end=\"\")\\r\\n        returned_value = get_area_code(key, area_code_dictionary)\\r\\n        print(\"Your Function Returned\", returned_value, \". . . \", end=\"\")\\r\\n        if returned_value == area_code_dictionary[key]:\\r\\n            print(\"Correct!\")\\r\\n            num_passed += 1\\r\\n        else:\\r\\n            print(\"Incorrect.  Returned\", returned_value, \"instead of\", area_code_dictionary[key])\\r\\n    \\r\\n#     print(\"Using Function to get Area Code for a State Not in the Dictionary:\", bad_key, \". . . \", end=\"\")\\r\\n#     \\r\\n#     try:\\r\\n#         returned_value = get_area_code(bad_key, area_code_dictionary)\\r\\n#         if returned_value == \"Unknown\":\\r\\n#             print(\"Correctly Handled\")\\r\\n#             num_passed += 1\\r\\n#         else:\\r\\n#             print(\"Incorrect.  Returned\", returned_value, \"instead of \\'Unknown\\'\")\\r\\n#     except:\\r\\n#         print(\"Program crashed trying to access a key that does not exist in the dictionary\")\\r\\n        \\r\\n    return (100/tests) * num_passed;\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a4_4_year': 'from cs110 import autograder\\r\\nimport random, math, ast\\r\\n\\r\\n# Flag scores\\r\\n# 0.1 Template only (not always detectable)\\r\\n# 0.2 Error thrown during run\\r\\n# 0.3 Floor when scoring a run that appears to complete\\r\\n\\r\\ndef script_name():\\r\\n    #return \"a4_4_names.py\"\\r\\n    #return \"a4_4_squadrons.py\"\\r\\n    return \"a4_4_year.py\"\\r\\n    #return \"a4_4_template.py\"\\r\\n\\r\\n\\r\\n\\'\\'\\'\\r\\nitem = [a,b,c] (what should be in this entry)\\r\\nentry = [d,e,f] (what is in this entry)\\r\\n\\r\\nFor each value in item, if it is in entry:\\r\\n   Of the right type in the right place: 100\\r\\n   Of the wrong type in the right place: 80\\r\\n   Of the right type but in the wrong place: 80\\r\\n   Of the wrong type in the wrong place: 64\\r\\nIf entry and item are not the same length, 20% penalty\\r\\n\\r\\nNote that this has issues if there are duplicate values in the correct item.\\r\\n\\'\\'\\'\\r\\ndef score_value_against_value(v1, v2):\\r\\n    score = 0\\r\\n    if v1 == v2:\\r\\n        return 100\\r\\n    try:\\r\\n        if float(v1) == float(v2):\\r\\n            score = 80\\r\\n    except:\\r\\n        pass\\r\\n    return score\\r\\n\\r\\ndef score_list_against_list(correct, scored):\\r\\n    score = 0\\r\\n    for i in range(len(correct)):\\r\\n        col_score = []\\r\\n        for j in range(len(scored)):\\r\\n            t_score = score_value_against_value(correct[i], scored[j])\\r\\n            if i != j:\\r\\n                t_score *= 0.80\\r\\n            col_score.append(t_score)\\r\\n        score += max(col_score)\\r\\n    score /= len(correct)\\r\\n\\r\\n    if len(correct) != len(scored):\\r\\n        score *= 0.80\\r\\n    return score\\r\\n\\r\\ndef score_list_against_table(item_list, table):\\r\\n    score_list = []\\r\\n    for entry in table:\\r\\n        score = 0\\r\\n        if item_list == entry:\\r\\n            score = 100\\r\\n        else:\\r\\n            score = score_list_against_list(item_list, entry)\\r\\n        score_list.append(score)\\r\\n    return score_list\\r\\n\\r\\ndef score_correct_against_scored(correct_table, scored_table, weights):\\r\\n    # normalize weights\\r\\n    norm_wt = []\\r\\n    sum_of_weights = sum(weights)\\r\\n    for weight in weights:\\r\\n        norm_wt.append(weight / sum_of_weights)\\r\\n        \\r\\n    # score each item separately againt table\\r\\n    cum_score = 0\\r\\n    for i in range(len(correct_table)):\\r\\n        # Check if this item is in the table correctly and in the correct position\\r\\n        if (i < len(scored_table)) and (correct_table[i] == scored_table[i]):\\r\\n            score = 100\\r\\n        # Score this item against each item in the table\\r\\n        else:\\r\\n            score_list = score_list_against_table(correct_table[i], scored_table)\\r\\n            if len(score_list) > 0:\\r\\n                score = 0.50 * max(score_list)\\r\\n            else:\\r\\n                score = 0\\r\\n            if i < len(score_list):\\r\\n                score = max([score, score_list[i]])\\r\\n        cum_score += score * norm_wt[i]\\r\\n        \\r\\n    return cum_score\\r\\n    \\r\\ndef item_in_table(item, table):\\r\\n    if item in table:\\r\\n        print(\"Item Found\")\\r\\n        return 100\\r\\n    print(item, \"not found in\", table)\\r\\n    return 50\\r\\n\\r\\ndef given_table():\\r\\n    return []\\r\\n\\r\\ndef user_inputs():\\r\\n    return [[]]\\r\\n\\r\\ndef get_correct_output(inputs):\\r\\n\\r\\n    if script_name() == \"a4_4_names.py\":\\r\\n        file_name = \"cadets.csv\"\\r\\n    if script_name() == \"a4_4_squadrons.py\":\\r\\n        file_name = \"cadets.csv\"\\r\\n    if script_name() == \"a4_4_year.py\":\\r\\n        file_name = \"cadets.csv\"\\r\\n        \\r\\n    file = open(file_name, \"r\")\\r\\n    file_contents = file.read()\\r\\n    file_lines = file_contents.split(\\'\\\\n\\')\\r\\n\\r\\n    if script_name() == \"a4_4_names.py\":\\r\\n        index = 0\\r\\n    if script_name() == \"a4_4_squadrons.py\":\\r\\n        index = 2\\r\\n    if script_name() == \"a4_4_year.py\":\\r\\n        index = 3\\r\\n        \\r\\n    output_list = []\\r\\n    weights = []\\r\\n    for line in file_lines:\\r\\n        col = line.split(\\',\\')\\r\\n        output_list.append(col[index])\\r\\n        weights.append(1)\\r\\n    return (output_list, weights)\\r\\n\\r\\ndef test_passed():    \\r\\n    \\'\\'\\'\\r\\n    # Template-only check\\r\\n    output, error = autograder.run_script(script_name(), [])\\r\\n    if len(error) == 0:\\r\\n        print(\"Be sure that you are not running just the template file\")\\r\\n        return 0.1\\r\\n    \\'\\'\\'\\r\\n    # Run Data Sets\\r\\n    run_data = user_inputs()\\r\\n    \\r\\n    # Set the weights for the individual runs\\r\\n    relative_weights = []\\r\\n    for i in range(len(run_data)):         \\r\\n        relative_weights.append(1)\\r\\n    sum_of_relative_weights = sum(relative_weights)\\r\\n    run_weight = []\\r\\n    for weight in relative_weights:\\r\\n        run_weight.append(weight / sum_of_relative_weights)\\r\\n    \\r\\n    # Runs the Script for each data set\\r\\n    cum_score = 0\\r\\n    for run in range(1):\\r\\n        print(\"-------------------------------------------------\")\\r\\n        print(\"Test #\" + str(run + 1))\\r\\n        print(\"-------------------------------------------------\")\\r\\n\\r\\n        input_lists = run_data[run]\\r\\n        score = 0\\r\\n        \\r\\n        input_list_for_this_run = []\\r\\n        (correct, weights) = get_correct_output(input_list_for_this_run)\\r\\n\\r\\n        output, error = autograder.run_script(script_name(), input_list_for_this_run)\\r\\n        output_lines = output.strip().split(\\'\\\\n\\')\\r\\n        \\r\\n        output_is_right_length = len(output_lines) == len(correct)\\r\\n        print(len(output_lines), len(correct))\\r\\n        \\r\\n        done = False\\r\\n        # Deal with the case of errors occuring during run\\r\\n        if len(error) > 0:\\r\\n            print(\"Error during run\")\\r\\n            score = 0.02\\r\\n            done = True\\r\\n        \\r\\n        # Attempt to detect running just the template code\\r\\n        if not done and len(output_lines) == 0:\\r\\n            print(\"Be sure that you are not running just the template file\")\\r\\n            score = 0.01\\r\\n            done = True\\r\\n            \\r\\n        # Deal with case of no errors occurring during run\\r\\n        if not done:\\r\\n            score = score_list_against_list(correct, output_lines)\\r\\n            if score == 100:\\r\\n                done = True\\r\\n        \\r\\n        if not done:\\r\\n            # If the number of output lines is more than the number of lines in the file, the\\r\\n            # file was likely parsed on something other than \\\\n (probably the comma)\\r\\n            if len(output_lines) > len(correct):\\r\\n                score = 40\\r\\n                done = True\\r\\n        \\r\\n        if not done:\\r\\n            if len(output_lines) == 1:\\r\\n                if \\',\\' in output_lines[0]:\\r\\n                    score = 20\\r\\n                    done = True\\r\\n                elif score > 0:\\r\\n                    score = max([score, 40])\\r\\n                    done = True\\r\\n                \\r\\n        if not done:\\r\\n            # If they split each line on the comma, then the individual lines will not contain commas.\\r\\n            # If this is the case, then it will be assumed that they did everything except print\\r\\n            # the correct information provided the number of lines is correct.\\r\\n            if output_is_right_length:\\r\\n                if \\',\\' in output_lines[0]:\\r\\n                    score = 20\\r\\n                else:\\r\\n                    score = 80\\r\\n                done = True\\r\\n                \\r\\n        if not done:\\r\\n            score = 0.3            \\r\\n            \\r\\n        print(\"This test score:\", round(score,1), \"% (weight =\", round(100*run_weight[run],1), \"%)\")\\r\\n        cum_score += score * run_weight[run]\\r\\n        print()\\r\\n        \\r\\n    return max([round(cum_score, 1), 0.1])\\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_4_squadrons': 'from cs110 import autograder\\r\\nimport random, math, ast\\r\\n\\r\\n# Flag scores\\r\\n# 0.1 Template only (not always detectable)\\r\\n# 0.2 Error thrown during run\\r\\n# 0.3 Floor when scoring a run that appears to complete\\r\\n\\r\\ndef script_name():\\r\\n    #return \"a4_4_names.py\"\\r\\n    return \"a4_4_squadrons.py\"\\r\\n    #return \"a4_4_year.py\"\\r\\n    #return \"a4_4_template.py\"\\r\\n\\r\\n\\r\\n\\'\\'\\'\\r\\nitem = [a,b,c] (what should be in this entry)\\r\\nentry = [d,e,f] (what is in this entry)\\r\\n\\r\\nFor each value in item, if it is in entry:\\r\\n   Of the right type in the right place: 100\\r\\n   Of the wrong type in the right place: 80\\r\\n   Of the right type but in the wrong place: 80\\r\\n   Of the wrong type in the wrong place: 64\\r\\nIf entry and item are not the same length, 20% penalty\\r\\n\\r\\nNote that this has issues if there are duplicate values in the correct item.\\r\\n\\'\\'\\'\\r\\ndef score_value_against_value(v1, v2):\\r\\n    score = 0\\r\\n    if v1 == v2:\\r\\n        return 100\\r\\n    try:\\r\\n        if float(v1) == float(v2):\\r\\n            score = 80\\r\\n    except:\\r\\n        pass\\r\\n    return score\\r\\n\\r\\ndef score_list_against_list(correct, scored):\\r\\n    score = 0\\r\\n    for i in range(len(correct)):\\r\\n        col_score = []\\r\\n        for j in range(len(scored)):\\r\\n            t_score = score_value_against_value(correct[i], scored[j])\\r\\n            if i != j:\\r\\n                t_score *= 0.80\\r\\n            col_score.append(t_score)\\r\\n        score += max(col_score)\\r\\n    score /= len(correct)\\r\\n\\r\\n    if len(correct) != len(scored):\\r\\n        score *= 0.80\\r\\n    return score\\r\\n\\r\\ndef score_list_against_table(item_list, table):\\r\\n    score_list = []\\r\\n    for entry in table:\\r\\n        score = 0\\r\\n        if item_list == entry:\\r\\n            score = 100\\r\\n        else:\\r\\n            score = score_list_against_list(item_list, entry)\\r\\n        score_list.append(score)\\r\\n    return score_list\\r\\n\\r\\ndef score_correct_against_scored(correct_table, scored_table, weights):\\r\\n    # normalize weights\\r\\n    norm_wt = []\\r\\n    sum_of_weights = sum(weights)\\r\\n    for weight in weights:\\r\\n        norm_wt.append(weight / sum_of_weights)\\r\\n        \\r\\n    # score each item separately againt table\\r\\n    cum_score = 0\\r\\n    for i in range(len(correct_table)):\\r\\n        # Check if this item is in the table correctly and in the correct position\\r\\n        if (i < len(scored_table)) and (correct_table[i] == scored_table[i]):\\r\\n            score = 100\\r\\n        # Score this item against each item in the table\\r\\n        else:\\r\\n            score_list = score_list_against_table(correct_table[i], scored_table)\\r\\n            if len(score_list) > 0:\\r\\n                score = 0.50 * max(score_list)\\r\\n            else:\\r\\n                score = 0\\r\\n            if i < len(score_list):\\r\\n                score = max([score, score_list[i]])\\r\\n        cum_score += score * norm_wt[i]\\r\\n        \\r\\n    return cum_score\\r\\n    \\r\\ndef item_in_table(item, table):\\r\\n    if item in table:\\r\\n        print(\"Item Found\")\\r\\n        return 100\\r\\n    print(item, \"not found in\", table)\\r\\n    return 50\\r\\n\\r\\ndef given_table():\\r\\n    return []\\r\\n\\r\\ndef user_inputs():\\r\\n    return [[]]\\r\\n\\r\\ndef get_correct_output(inputs):\\r\\n\\r\\n    if script_name() == \"a4_4_names.py\":\\r\\n        file_name = \"cadets.csv\"\\r\\n    if script_name() == \"a4_4_squadrons.py\":\\r\\n        file_name = \"cadets.csv\"\\r\\n    if script_name() == \"a4_4_year.py\":\\r\\n        file_name = \"cadets.csv\"\\r\\n        \\r\\n    file = open(file_name, \"r\")\\r\\n    file_contents = file.read()\\r\\n    file_lines = file_contents.split(\\'\\\\n\\')\\r\\n\\r\\n    if script_name() == \"a4_4_names.py\":\\r\\n        index = 0\\r\\n    if script_name() == \"a4_4_squadrons.py\":\\r\\n        index = 2\\r\\n    if script_name() == \"a4_4_year.py\":\\r\\n        index = 3\\r\\n        \\r\\n    output_list = []\\r\\n    weights = []\\r\\n    for line in file_lines:\\r\\n        col = line.split(\\',\\')\\r\\n        output_list.append(col[index])\\r\\n        weights.append(1)\\r\\n    return (output_list, weights)\\r\\n\\r\\ndef test_passed():    \\r\\n    \\'\\'\\'\\r\\n    # Template-only check\\r\\n    output, error = autograder.run_script(script_name(), [])\\r\\n    if len(error) == 0:\\r\\n        print(\"Be sure that you are not running just the template file\")\\r\\n        return 0.1\\r\\n    \\'\\'\\'\\r\\n    # Run Data Sets\\r\\n    run_data = user_inputs()\\r\\n    \\r\\n    # Set the weights for the individual runs\\r\\n    relative_weights = []\\r\\n    for i in range(len(run_data)):         \\r\\n        relative_weights.append(1)\\r\\n    sum_of_relative_weights = sum(relative_weights)\\r\\n    run_weight = []\\r\\n    for weight in relative_weights:\\r\\n        run_weight.append(weight / sum_of_relative_weights)\\r\\n    \\r\\n    # Runs the Script for each data set\\r\\n    cum_score = 0\\r\\n    for run in range(1):\\r\\n        print(\"-------------------------------------------------\")\\r\\n        print(\"Test #\" + str(run + 1))\\r\\n        print(\"-------------------------------------------------\")\\r\\n\\r\\n        input_lists = run_data[run]\\r\\n        score = 0\\r\\n        \\r\\n        input_list_for_this_run = []\\r\\n        (correct, weights) = get_correct_output(input_list_for_this_run)\\r\\n\\r\\n        output, error = autograder.run_script(script_name(), input_list_for_this_run)\\r\\n        output_lines = output.strip().split(\\'\\\\n\\')\\r\\n        \\r\\n        output_is_right_length = len(output_lines) == len(correct)\\r\\n        print(len(output_lines), len(correct))\\r\\n        \\r\\n        done = False\\r\\n        # Deal with the case of errors occuring during run\\r\\n        if len(error) > 0:\\r\\n            print(\"Error during run\")\\r\\n            score = 0.02\\r\\n            done = True\\r\\n        \\r\\n        # Attempt to detect running just the template code\\r\\n        if not done and len(output_lines) == 0:\\r\\n            print(\"Be sure that you are not running just the template file\")\\r\\n            score = 0.01\\r\\n            done = True\\r\\n            \\r\\n        # Deal with case of no errors occurring during run\\r\\n        if not done:\\r\\n            score = score_list_against_list(correct, output_lines)\\r\\n            if score == 100:\\r\\n                done = True\\r\\n        \\r\\n        if not done:\\r\\n            # If the number of output lines is more than the number of lines in the file, the\\r\\n            # file was likely parsed on something other than \\\\n (probably the comma)\\r\\n            if len(output_lines) > len(correct):\\r\\n                score = 40\\r\\n                done = True\\r\\n        \\r\\n        if not done:\\r\\n            if len(output_lines) == 1:\\r\\n                if \\',\\' in output_lines[0]:\\r\\n                    score = 20\\r\\n                    done = True\\r\\n                elif score > 0:\\r\\n                    score = max([score, 40])\\r\\n                    done = True\\r\\n                \\r\\n        if not done:\\r\\n            # If they split each line on the comma, then the individual lines will not contain commas.\\r\\n            # If this is the case, then it will be assumed that they did everything except print\\r\\n            # the correct information provided the number of lines is correct.\\r\\n            if output_is_right_length:\\r\\n                if \\',\\' in output_lines[0]:\\r\\n                    score = 20\\r\\n                else:\\r\\n                    score = 80\\r\\n                done = True\\r\\n                \\r\\n        if not done:\\r\\n            score = 0.3            \\r\\n            \\r\\n        print(\"This test score:\", round(score,1), \"% (weight =\", round(100*run_weight[run],1), \"%)\")\\r\\n        cum_score += score * run_weight[run]\\r\\n        print()\\r\\n        \\r\\n    return max([round(cum_score, 1), 0.1])\\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_4_names': 'from cs110 import autograder\\r\\nimport random, math, ast\\r\\n\\r\\n# Flag scores\\r\\n# 0.1 Template only (not always detectable)\\r\\n# 0.2 Error thrown during run\\r\\n# 0.3 Floor when scoring a run that appears to complete\\r\\n\\r\\ndef script_name():\\r\\n    return \"a4_4_names.py\"\\r\\n    #return \"a4_4_squadrons.py\"\\r\\n    #return \"a4_4_year.py\"\\r\\n    #return \"a4_4_template.py\"\\r\\n\\r\\n\\r\\n\\'\\'\\'\\r\\nitem = [a,b,c] (what should be in this entry)\\r\\nentry = [d,e,f] (what is in this entry)\\r\\n\\r\\nFor each value in item, if it is in entry:\\r\\n   Of the right type in the right place: 100\\r\\n   Of the wrong type in the right place: 80\\r\\n   Of the right type but in the wrong place: 80\\r\\n   Of the wrong type in the wrong place: 64\\r\\nIf entry and item are not the same length, 20% penalty\\r\\n\\r\\nNote that this has issues if there are duplicate values in the correct item.\\r\\n\\'\\'\\'\\r\\ndef score_value_against_value(v1, v2):\\r\\n    score = 0\\r\\n    if v1 == v2:\\r\\n        return 100\\r\\n    try:\\r\\n        if float(v1) == float(v2):\\r\\n            score = 80\\r\\n    except:\\r\\n        pass\\r\\n    return score\\r\\n\\r\\ndef score_list_against_list(correct, scored):\\r\\n    score = 0\\r\\n    for i in range(len(correct)):\\r\\n        col_score = []\\r\\n        for j in range(len(scored)):\\r\\n            t_score = score_value_against_value(correct[i], scored[j])\\r\\n            if i != j:\\r\\n                t_score *= 0.80\\r\\n            col_score.append(t_score)\\r\\n        score += max(col_score)\\r\\n    score /= len(correct)\\r\\n\\r\\n    if len(correct) != len(scored):\\r\\n        score *= 0.80\\r\\n    return score\\r\\n\\r\\ndef score_list_against_table(item_list, table):\\r\\n    score_list = []\\r\\n    for entry in table:\\r\\n        score = 0\\r\\n        if item_list == entry:\\r\\n            score = 100\\r\\n        else:\\r\\n            score = score_list_against_list(item_list, entry)\\r\\n        score_list.append(score)\\r\\n    return score_list\\r\\n\\r\\ndef score_correct_against_scored(correct_table, scored_table, weights):\\r\\n    # normalize weights\\r\\n    norm_wt = []\\r\\n    sum_of_weights = sum(weights)\\r\\n    for weight in weights:\\r\\n        norm_wt.append(weight / sum_of_weights)\\r\\n        \\r\\n    # score each item separately againt table\\r\\n    cum_score = 0\\r\\n    for i in range(len(correct_table)):\\r\\n        # Check if this item is in the table correctly and in the correct position\\r\\n        if (i < len(scored_table)) and (correct_table[i] == scored_table[i]):\\r\\n            score = 100\\r\\n        # Score this item against each item in the table\\r\\n        else:\\r\\n            score_list = score_list_against_table(correct_table[i], scored_table)\\r\\n            if len(score_list) > 0:\\r\\n                score = 0.50 * max(score_list)\\r\\n            else:\\r\\n                score = 0\\r\\n            if i < len(score_list):\\r\\n                score = max([score, score_list[i]])\\r\\n        cum_score += score * norm_wt[i]\\r\\n        \\r\\n    return cum_score\\r\\n    \\r\\ndef item_in_table(item, table):\\r\\n    if item in table:\\r\\n        print(\"Item Found\")\\r\\n        return 100\\r\\n    print(item, \"not found in\", table)\\r\\n    return 50\\r\\n\\r\\ndef given_table():\\r\\n    return []\\r\\n\\r\\ndef user_inputs():\\r\\n    return [[]]\\r\\n\\r\\ndef get_correct_output(inputs):\\r\\n\\r\\n    if script_name() == \"a4_4_names.py\":\\r\\n        file_name = \"cadets.csv\"\\r\\n    if script_name() == \"a4_4_squadrons.py\":\\r\\n        file_name = \"cadets.csv\"\\r\\n    if script_name() == \"a4_4_year.py\":\\r\\n        file_name = \"cadets.csv\"\\r\\n        \\r\\n    file = open(file_name, \"r\")\\r\\n    file_contents = file.read()\\r\\n    file_lines = file_contents.split(\\'\\\\n\\')\\r\\n\\r\\n    if script_name() == \"a4_4_names.py\":\\r\\n        index = 0\\r\\n    if script_name() == \"a4_4_squadrons.py\":\\r\\n        index = 2\\r\\n    if script_name() == \"a4_4_year.py\":\\r\\n        index = 3\\r\\n        \\r\\n    output_list = []\\r\\n    weights = []\\r\\n    for line in file_lines:\\r\\n        col = line.split(\\',\\')\\r\\n        output_list.append(col[index])\\r\\n        weights.append(1)\\r\\n    return (output_list, weights)\\r\\n\\r\\ndef test_passed():    \\r\\n    \\'\\'\\'\\r\\n    # Template-only check\\r\\n    output, error = autograder.run_script(script_name(), [])\\r\\n    if len(error) == 0:\\r\\n        print(\"Be sure that you are not running just the template file\")\\r\\n        return 0.1\\r\\n    \\'\\'\\'\\r\\n    # Run Data Sets\\r\\n    run_data = user_inputs()\\r\\n    \\r\\n    # Set the weights for the individual runs\\r\\n    relative_weights = []\\r\\n    for i in range(len(run_data)):         \\r\\n        relative_weights.append(1)\\r\\n    sum_of_relative_weights = sum(relative_weights)\\r\\n    run_weight = []\\r\\n    for weight in relative_weights:\\r\\n        run_weight.append(weight / sum_of_relative_weights)\\r\\n    \\r\\n    # Runs the Script for each data set\\r\\n    cum_score = 0\\r\\n    for run in range(1):\\r\\n        print(\"-------------------------------------------------\")\\r\\n        print(\"Test #\" + str(run + 1))\\r\\n        print(\"-------------------------------------------------\")\\r\\n\\r\\n        input_lists = run_data[run]\\r\\n        score = 0\\r\\n        \\r\\n        input_list_for_this_run = []\\r\\n        (correct, weights) = get_correct_output(input_list_for_this_run)\\r\\n\\r\\n        output, error = autograder.run_script(script_name(), input_list_for_this_run)\\r\\n        output_lines = output.strip().split(\\'\\\\n\\')\\r\\n        \\r\\n        output_is_right_length = len(output_lines) == len(correct)\\r\\n        print(len(output_lines), len(correct))\\r\\n        \\r\\n        done = False\\r\\n        # Deal with the case of errors occuring during run\\r\\n        if len(error) > 0:\\r\\n            print(\"Error during run\")\\r\\n            score = 0.02\\r\\n            done = True\\r\\n        \\r\\n        # Attempt to detect running just the template code\\r\\n        if not done and len(output_lines) == 0:\\r\\n            print(\"Be sure that you are not running just the template file\")\\r\\n            score = 0.01\\r\\n            done = True\\r\\n            \\r\\n        # Deal with case of no errors occurring during run\\r\\n        if not done:\\r\\n            score = score_list_against_list(correct, output_lines)\\r\\n            if score == 100:\\r\\n                done = True\\r\\n        \\r\\n        if not done:\\r\\n            # If the number of output lines is more than the number of lines in the file, the\\r\\n            # file was likely parsed on something other than \\\\n (probably the comma)\\r\\n            if len(output_lines) > len(correct):\\r\\n                score = 40\\r\\n                done = True\\r\\n        \\r\\n        if not done:\\r\\n            if len(output_lines) == 1:\\r\\n                if \\',\\' in output_lines[0]:\\r\\n                    score = 20\\r\\n                    done = True\\r\\n                elif score > 0:\\r\\n                    score = max([score, 40])\\r\\n                    done = True\\r\\n                \\r\\n        if not done:\\r\\n            # If they split each line on the comma, then the individual lines will not contain commas.\\r\\n            # If this is the case, then it will be assumed that they did everything except print\\r\\n            # the correct information provided the number of lines is correct.\\r\\n            if output_is_right_length:\\r\\n                if \\',\\' in output_lines[0]:\\r\\n                    score = 20\\r\\n                else:\\r\\n                    score = 80\\r\\n                done = True\\r\\n                \\r\\n        if not done:\\r\\n            score = 0.3            \\r\\n            \\r\\n        print(\"This test score:\", round(score,1), \"% (weight =\", round(100*run_weight[run],1), \"%)\")\\r\\n        cum_score += score * run_weight[run]\\r\\n        print()\\r\\n        \\r\\n    return max([round(cum_score, 1), 0.1])\\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_3_parks': 'from cs110 import autograder\\r\\nimport random, math, ast\\r\\n\\r\\ndef script_name():\\r\\n    return \"a4_3_parks.py\"\\r\\n\\r\\n\\r\\n\\'\\'\\'\\r\\nitem = [a,b,c] (what should be in this entry)\\r\\nentry = [d,e,f] (what is in this entry)\\r\\n\\r\\nFor each value in item, if it is in entry:\\r\\n   Of the right type in the right place: 100\\r\\n   Of the wrong type in the right place: 80\\r\\n   Of the right type but in the wrong place: 80\\r\\n   Of the wrong type in the wrong place: 64\\r\\nIf entry and item are not the same length, 20% penalty\\r\\n\\r\\nNote that this has issues if there are duplicate values in the correct item.\\r\\n\\'\\'\\'\\r\\ndef score_value_against_value(v1, v2):\\r\\n    score = 0\\r\\n    if v1 == v2:\\r\\n        return 100\\r\\n    try:\\r\\n        if float(v1) == float(v2):\\r\\n            score = 80\\r\\n    except:\\r\\n        pass\\r\\n    return score\\r\\n\\r\\ndef score_list_against_list(correct, scored):\\r\\n    score = 0\\r\\n    for i in range(len(correct)):\\r\\n        col_score = []\\r\\n        for j in range(len(scored)):\\r\\n            t_score = score_value_against_value(correct[i], scored[j])\\r\\n            if i != j:\\r\\n                t_score *= 0.80\\r\\n            col_score.append(t_score)\\r\\n        score += max(col_score)\\r\\n    score /= len(correct)\\r\\n\\r\\n    if len(correct) != len(scored):\\r\\n        score *= 0.80\\r\\n    return score\\r\\n\\r\\ndef score_list_against_table(item_list, table):\\r\\n    score_list = []\\r\\n    for entry in table:\\r\\n        score = 0\\r\\n        if item_list == entry:\\r\\n            score = 100\\r\\n        else:\\r\\n            score = score_list_against_list(item_list, entry)\\r\\n        score_list.append(score)\\r\\n    return score_list\\r\\n\\r\\ndef score_correct_against_scored(correct_table, scored_table, weights):\\r\\n    # normalize weights\\r\\n    norm_wt = []\\r\\n    sum_of_weights = sum(weights)\\r\\n    for weight in weights:\\r\\n        norm_wt.append(weight / sum_of_weights)\\r\\n        \\r\\n    # score each item separately against table\\r\\n    cum_score = 0\\r\\n    for i in range(len(correct_table)):\\r\\n        # Check if this item is in the table correctly and in the correct position\\r\\n        if (i < len(scored_table)) and (correct_table[i] == scored_table[i]):\\r\\n            score = 100\\r\\n        # Score this item against each item in the table\\r\\n        else:\\r\\n            score_list = score_list_against_table(correct_table[i], scored_table)\\r\\n            if len(score_list) > 0:\\r\\n                score = 0.50 * max(score_list)\\r\\n            else:\\r\\n                score = 0\\r\\n            if i < len(score_list):\\r\\n                score = max([score, score_list[i]])\\r\\n        cum_score += score * norm_wt[i]\\r\\n    \\r\\n    # penalty for wrong number of items in table.\\r\\n    if len(correct_table) != len(scored_table):\\r\\n        cum_score = max([cum_score - 20, 0])\\r\\n    return cum_score\\r\\n    \\r\\ndef item_in_table(item, table):\\r\\n    if item in table:\\r\\n        print(\"Item Found\")\\r\\n        return 100\\r\\n    print(item, \"not found in\", table)\\r\\n    return 50\\r\\n\\r\\ndef given_table():\\r\\n    if script_name() == \"a4_3_aircraft.py\":\\r\\n        return [[218, \"C-17 Globemaster\", \"Boeing\"],\\r\\n                [14.6, \"F-16 Falcon\", \"General Dynamics\"],\\r\\n                [16.9, \"MQ-9 Reaper\", \"General Atomics\"],\\r\\n                [737, \"B-2 Spirit\", \"Northrop Grumman\"]]\\r\\n    if script_name() == \"a4_3_new_cars.py\":\\r\\n        return [[26660, \"Bronco\", \"Ford\"],\\r\\n                [36340, \"4Runner\", \"Toyota\"],\\r\\n                [68200, \"Q8\", \"Audi\"],\\r\\n                [48475, \"Silverado\", \"Cheverolet\"]]\\r\\n    if script_name() == \"a4_3_parks.py\":\\r\\n        return [[154.0, \"Disneyland\", \"California\"],\\r\\n                [169.34, \"Disney World\", \"Florida\"],\\r\\n                [79.99, \"Six Flags Great America\", \"California\"],\\r\\n                [73.00, \"Cedar Point\", \"Ohio\"]]\\r\\n    return []\\r\\n\\r\\ndef user_inputs():\\r\\n    if script_name() == \"a4_3_aircraft.py\":\\r\\n        return [ [\\'B-52 Stratofortress\\', \\'Boeing\\', 14.4], [\\'T-6 Texan\\', \\'North American Aviation\\', 4] ]\\r\\n    if script_name() == \"a4_3_new_cars.py\":\\r\\n        return [ [\\'Model 3\\', \\'Tesla\\', 34999.99], [\\'Cayenne\\', \\'Porche\\', 67500] ]\\r\\n    if script_name() == \"a4_3_parks.py\":\\r\\n        return [ [\\'Elitch Gardens\\', \\'Colorado\\', 69.99], [\\'Euro Disney\\', \\'France\\', 189] ]\\r\\n    return []\\r\\n\\r\\ndef get_correct_output(inputs):\\r\\n    table = given_table()\\r\\n    weights = []\\r\\n    for i in range(len(table)):\\r\\n        weights.append(0.1)\\r\\n    table.append([inputs[2], inputs[0], inputs[1]])\\r\\n    for i in range(len(table)-len(weights)):\\r\\n        weights.append(1)\\r\\n    return (table, weights)\\r\\n\\r\\ndef test_passed():    \\r\\n    \\r\\n    # Template-only check\\r\\n    print(\"-------------------------------------------------\")\\r\\n    print(\"Test #\" + str(0))\\r\\n    print(\"-------------------------------------------------\")\\r\\n    output, error = autograder.run_script(script_name(), [])\\r\\n    if len(error) == 0:\\r\\n        print(\"Be sure that you are not running just the template file.\")\\r\\n        return 0.2\\r\\n    else:\\r\\n        print(\"Ignore the errors for this run.\")\\r\\n        \\r\\n    # Run Data Sets\\r\\n    run_data = user_inputs()\\r\\n    \\r\\n    # Set the weights for the individual runs\\r\\n    relative_weights = []\\r\\n    for i in range(len(run_data)):         \\r\\n        relative_weights.append(1)\\r\\n    relative_weights = [1,19] #(override evenly weighted)\\r\\n    sum_of_relative_weights = sum(relative_weights)\\r\\n    run_weight = []\\r\\n    for weight in relative_weights:\\r\\n        run_weight.append(weight / sum_of_relative_weights)\\r\\n    \\r\\n    # Runs the Script for each data set\\r\\n    cum_score = 0\\r\\n    for run in range(len(run_data)):\\r\\n        print(\"-------------------------------------------------\")\\r\\n        print(\"Test #\" + str(run + 1))\\r\\n        print(\"-------------------------------------------------\")\\r\\n\\r\\n        inputs_for_this_run = run_data[run]\\r\\n\\r\\n        input_list = []\\r\\n        (correct, weights) = get_correct_output(inputs_for_this_run)\\r\\n        \\r\\n        output, error = autograder.run_script(script_name(), inputs_for_this_run)\\r\\n        \\r\\n        score = 0\\r\\n        # Deal with the case of errors occuring during run\\r\\n        if (run == 1): # Cost is a float\\r\\n            if len(error) > 0:\\r\\n                print(\"Error when handling a float cost\")\\r\\n                score = 0\\r\\n                \\r\\n        if (run == 2): # Cost is an integer\\r\\n            if len(error) > 0:\\r\\n                print(\"Error when handling an integer cost\")\\r\\n                score = 0\\r\\n\\r\\n        # Deal with case of no errors occurring during run\\r\\n        if len(error) == 0:\\r\\n            lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n            if len(lines) >= 1 and len(lines[0]) > 0:                    \\r\\n                output_table = ast.literal_eval(lines[0])\\r\\n            \\r\\n                score = score_correct_against_scored(correct, output_table, weights)\\r\\n\\r\\n            else:\\r\\n                score = 0\\r\\n                \\r\\n\\r\\n        print(\"This test score:\", round(score,1), \"% (weight =\", round(100*run_weight[run],1), \"%)\")\\r\\n        cum_score += score * run_weight[run]\\r\\n        print()\\r\\n        \\r\\n    return max([round(cum_score, 1), 0.1])\\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_3_new_cars': 'from cs110 import autograder\\r\\nimport random, math, ast\\r\\n\\r\\ndef script_name():\\r\\n    return \"a4_3_new_cars.py\"\\r\\n\\r\\n\\r\\n\\'\\'\\'\\r\\nitem = [a,b,c] (what should be in this entry)\\r\\nentry = [d,e,f] (what is in this entry)\\r\\n\\r\\nFor each value in item, if it is in entry:\\r\\n   Of the right type in the right place: 100\\r\\n   Of the wrong type in the right place: 80\\r\\n   Of the right type but in the wrong place: 80\\r\\n   Of the wrong type in the wrong place: 64\\r\\nIf entry and item are not the same length, 20% penalty\\r\\n\\r\\nNote that this has issues if there are duplicate values in the correct item.\\r\\n\\'\\'\\'\\r\\ndef score_value_against_value(v1, v2):\\r\\n    score = 0\\r\\n    if v1 == v2:\\r\\n        return 100\\r\\n    try:\\r\\n        if float(v1) == float(v2):\\r\\n            score = 80\\r\\n    except:\\r\\n        pass\\r\\n    return score\\r\\n\\r\\ndef score_list_against_list(correct, scored):\\r\\n    score = 0\\r\\n    for i in range(len(correct)):\\r\\n        col_score = []\\r\\n        for j in range(len(scored)):\\r\\n            t_score = score_value_against_value(correct[i], scored[j])\\r\\n            if i != j:\\r\\n                t_score *= 0.80\\r\\n            col_score.append(t_score)\\r\\n        score += max(col_score)\\r\\n    score /= len(correct)\\r\\n\\r\\n    if len(correct) != len(scored):\\r\\n        score *= 0.80\\r\\n    return score\\r\\n\\r\\ndef score_list_against_table(item_list, table):\\r\\n    score_list = []\\r\\n    for entry in table:\\r\\n        score = 0\\r\\n        if item_list == entry:\\r\\n            score = 100\\r\\n        else:\\r\\n            score = score_list_against_list(item_list, entry)\\r\\n        score_list.append(score)\\r\\n    return score_list\\r\\n\\r\\ndef score_correct_against_scored(correct_table, scored_table, weights):\\r\\n    # normalize weights\\r\\n    norm_wt = []\\r\\n    sum_of_weights = sum(weights)\\r\\n    for weight in weights:\\r\\n        norm_wt.append(weight / sum_of_weights)\\r\\n        \\r\\n    # score each item separately against table\\r\\n    cum_score = 0\\r\\n    for i in range(len(correct_table)):\\r\\n        # Check if this item is in the table correctly and in the correct position\\r\\n        if (i < len(scored_table)) and (correct_table[i] == scored_table[i]):\\r\\n            score = 100\\r\\n        # Score this item against each item in the table\\r\\n        else:\\r\\n            score_list = score_list_against_table(correct_table[i], scored_table)\\r\\n            if len(score_list) > 0:\\r\\n                score = 0.50 * max(score_list)\\r\\n            else:\\r\\n                score = 0\\r\\n            if i < len(score_list):\\r\\n                score = max([score, score_list[i]])\\r\\n        cum_score += score * norm_wt[i]\\r\\n    \\r\\n    # penalty for wrong number of items in table.\\r\\n    if len(correct_table) != len(scored_table):\\r\\n        cum_score = max([cum_score - 20, 0])\\r\\n    return cum_score\\r\\n    \\r\\ndef item_in_table(item, table):\\r\\n    if item in table:\\r\\n        print(\"Item Found\")\\r\\n        return 100\\r\\n    print(item, \"not found in\", table)\\r\\n    return 50\\r\\n\\r\\ndef given_table():\\r\\n    if script_name() == \"a4_3_aircraft.py\":\\r\\n        return [[218, \"C-17 Globemaster\", \"Boeing\"],\\r\\n                [14.6, \"F-16 Falcon\", \"General Dynamics\"],\\r\\n                [16.9, \"MQ-9 Reaper\", \"General Atomics\"],\\r\\n                [737, \"B-2 Spirit\", \"Northrop Grumman\"]]\\r\\n    if script_name() == \"a4_3_new_cars.py\":\\r\\n        return [[26660, \"Bronco\", \"Ford\"],\\r\\n                [36340, \"4Runner\", \"Toyota\"],\\r\\n                [68200, \"Q8\", \"Audi\"],\\r\\n                [48475, \"Silverado\", \"Cheverolet\"]]\\r\\n    if script_name() == \"a4_3_parks.py\":\\r\\n        return [[154.0, \"Disneyland\", \"California\"],\\r\\n                [169.34, \"Disney World\", \"Florida\"],\\r\\n                [79.99, \"Six Flags Great America\", \"California\"],\\r\\n                [73.00, \"Cedar Point\", \"Ohio\"]]\\r\\n    return []\\r\\n\\r\\ndef user_inputs():\\r\\n    if script_name() == \"a4_3_aircraft.py\":\\r\\n        return [ [\\'B-52 Stratofortress\\', \\'Boeing\\', 14.4], [\\'T-6 Texan\\', \\'North American Aviation\\', 4] ]\\r\\n    if script_name() == \"a4_3_new_cars.py\":\\r\\n        return [ [\\'Model 3\\', \\'Tesla\\', 34999.99], [\\'Cayenne\\', \\'Porche\\', 67500] ]\\r\\n    if script_name() == \"a4_3_parks.py\":\\r\\n        return [ [\\'Elitch Gardens\\', \\'Colorado\\', 69.99], [\\'Euro Disney\\', \\'France\\', 189] ]\\r\\n    return []\\r\\n\\r\\ndef get_correct_output(inputs):\\r\\n    table = given_table()\\r\\n    weights = []\\r\\n    for i in range(len(table)):\\r\\n        weights.append(0.1)\\r\\n    table.append([inputs[2], inputs[0], inputs[1]])\\r\\n    for i in range(len(table)-len(weights)):\\r\\n        weights.append(1)\\r\\n    return (table, weights)\\r\\n\\r\\ndef test_passed():    \\r\\n    \\r\\n    # Template-only check\\r\\n    print(\"-------------------------------------------------\")\\r\\n    print(\"Test #\" + str(0))\\r\\n    print(\"-------------------------------------------------\")\\r\\n    output, error = autograder.run_script(script_name(), [])\\r\\n    if len(error) == 0:\\r\\n        print(\"Be sure that you are not running just the template file.\")\\r\\n        return 0.2\\r\\n    else:\\r\\n        print(\"Ignore the errors for this run.\")\\r\\n        \\r\\n    # Run Data Sets\\r\\n    run_data = user_inputs()\\r\\n    \\r\\n    # Set the weights for the individual runs\\r\\n    relative_weights = []\\r\\n    for i in range(len(run_data)):         \\r\\n        relative_weights.append(1)\\r\\n    relative_weights = [1,19] #(override evenly weighted)\\r\\n    sum_of_relative_weights = sum(relative_weights)\\r\\n    run_weight = []\\r\\n    for weight in relative_weights:\\r\\n        run_weight.append(weight / sum_of_relative_weights)\\r\\n    \\r\\n    # Runs the Script for each data set\\r\\n    cum_score = 0\\r\\n    for run in range(len(run_data)):\\r\\n        print(\"-------------------------------------------------\")\\r\\n        print(\"Test #\" + str(run + 1))\\r\\n        print(\"-------------------------------------------------\")\\r\\n\\r\\n        inputs_for_this_run = run_data[run]\\r\\n\\r\\n        input_list = []\\r\\n        (correct, weights) = get_correct_output(inputs_for_this_run)\\r\\n        \\r\\n        output, error = autograder.run_script(script_name(), inputs_for_this_run)\\r\\n        \\r\\n        score = 0\\r\\n        # Deal with the case of errors occuring during run\\r\\n        if (run == 1): # Cost is a float\\r\\n            if len(error) > 0:\\r\\n                print(\"Error when handling a float cost\")\\r\\n                score = 0\\r\\n                \\r\\n        if (run == 2): # Cost is an integer\\r\\n            if len(error) > 0:\\r\\n                print(\"Error when handling an integer cost\")\\r\\n                score = 0\\r\\n\\r\\n        # Deal with case of no errors occurring during run\\r\\n        if len(error) == 0:\\r\\n            lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n            if len(lines) >= 1 and len(lines[0]) > 0:                    \\r\\n                output_table = ast.literal_eval(lines[0])\\r\\n            \\r\\n                score = score_correct_against_scored(correct, output_table, weights)\\r\\n\\r\\n            else:\\r\\n                score = 0\\r\\n                \\r\\n\\r\\n        print(\"This test score:\", round(score,1), \"% (weight =\", round(100*run_weight[run],1), \"%)\")\\r\\n        cum_score += score * run_weight[run]\\r\\n        print()\\r\\n        \\r\\n    return max([round(cum_score, 1), 0.1])\\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_3_aircraft': 'from cs110 import autograder\\r\\nimport random, math, ast\\r\\n\\r\\ndef script_name():\\r\\n    return \"a4_3_aircraft.py\"\\r\\n\\r\\n\\r\\n\\'\\'\\'\\r\\nitem = [a,b,c] (what should be in this entry)\\r\\nentry = [d,e,f] (what is in this entry)\\r\\n\\r\\nFor each value in item, if it is in entry:\\r\\n   Of the right type in the right place: 100\\r\\n   Of the wrong type in the right place: 80\\r\\n   Of the right type but in the wrong place: 80\\r\\n   Of the wrong type in the wrong place: 64\\r\\nIf entry and item are not the same length, 20% penalty\\r\\n\\r\\nNote that this has issues if there are duplicate values in the correct item.\\r\\n\\'\\'\\'\\r\\ndef score_value_against_value(v1, v2):\\r\\n    score = 0\\r\\n    if v1 == v2:\\r\\n        return 100\\r\\n    try:\\r\\n        if float(v1) == float(v2):\\r\\n            score = 80\\r\\n    except:\\r\\n        pass\\r\\n    return score\\r\\n\\r\\ndef score_list_against_list(correct, scored):\\r\\n    score = 0\\r\\n    for i in range(len(correct)):\\r\\n        col_score = []\\r\\n        for j in range(len(scored)):\\r\\n            t_score = score_value_against_value(correct[i], scored[j])\\r\\n            if i != j:\\r\\n                t_score *= 0.80\\r\\n            col_score.append(t_score)\\r\\n        score += max(col_score)\\r\\n    score /= len(correct)\\r\\n\\r\\n    if len(correct) != len(scored):\\r\\n        score *= 0.80\\r\\n    return score\\r\\n\\r\\ndef score_list_against_table(item_list, table):\\r\\n    score_list = []\\r\\n    for entry in table:\\r\\n        score = 0\\r\\n        if item_list == entry:\\r\\n            score = 100\\r\\n        else:\\r\\n            score = score_list_against_list(item_list, entry)\\r\\n        score_list.append(score)\\r\\n    return score_list\\r\\n\\r\\ndef score_correct_against_scored(correct_table, scored_table, weights):\\r\\n    # normalize weights\\r\\n    norm_wt = []\\r\\n    sum_of_weights = sum(weights)\\r\\n    for weight in weights:\\r\\n        norm_wt.append(weight / sum_of_weights)\\r\\n        \\r\\n    # score each item separately against table\\r\\n    cum_score = 0\\r\\n    for i in range(len(correct_table)):\\r\\n        # Check if this item is in the table correctly and in the correct position\\r\\n        if (i < len(scored_table)) and (correct_table[i] == scored_table[i]):\\r\\n            score = 100\\r\\n        # Score this item against each item in the table\\r\\n        else:\\r\\n            score_list = score_list_against_table(correct_table[i], scored_table)\\r\\n            if len(score_list) > 0:\\r\\n                score = 0.50 * max(score_list)\\r\\n            else:\\r\\n                score = 0\\r\\n            if i < len(score_list):\\r\\n                score = max([score, score_list[i]])\\r\\n        cum_score += score * norm_wt[i]\\r\\n    \\r\\n    # penalty for wrong number of items in table.\\r\\n    if len(correct_table) != len(scored_table):\\r\\n        cum_score = max([cum_score - 20, 0])\\r\\n    return cum_score\\r\\n    \\r\\ndef item_in_table(item, table):\\r\\n    if item in table:\\r\\n        print(\"Item Found\")\\r\\n        return 100\\r\\n    print(item, \"not found in\", table)\\r\\n    return 50\\r\\n\\r\\ndef given_table():\\r\\n    if script_name() == \"a4_3_aircraft.py\":\\r\\n        return [[218, \"C-17 Globemaster\", \"Boeing\"],\\r\\n                [14.6, \"F-16 Falcon\", \"General Dynamics\"],\\r\\n                [16.9, \"MQ-9 Reaper\", \"General Atomics\"],\\r\\n                [737, \"B-2 Spirit\", \"Northrop Grumman\"]]\\r\\n    if script_name() == \"a4_3_new_cars.py\":\\r\\n        return [[26660, \"Bronco\", \"Ford\"],\\r\\n                [36340, \"4Runner\", \"Toyota\"],\\r\\n                [68200, \"Q8\", \"Audi\"],\\r\\n                [48475, \"Silverado\", \"Cheverolet\"]]\\r\\n    if script_name() == \"a4_3_parks.py\":\\r\\n        return [[154.0, \"Disneyland\", \"California\"],\\r\\n                [169.34, \"Disney World\", \"Florida\"],\\r\\n                [79.99, \"Six Flags Great America\", \"California\"],\\r\\n                [73.00, \"Cedar Point\", \"Ohio\"]]\\r\\n    return []\\r\\n\\r\\ndef user_inputs():\\r\\n    if script_name() == \"a4_3_aircraft.py\":\\r\\n        return [ [\\'B-52 Stratofortress\\', \\'Boeing\\', 14.4], [\\'T-6 Texan\\', \\'North American Aviation\\', 4] ]\\r\\n    if script_name() == \"a4_3_new_cars.py\":\\r\\n        return [ [\\'Model 3\\', \\'Tesla\\', 34999.99], [\\'Cayenne\\', \\'Porche\\', 67500] ]\\r\\n    if script_name() == \"a4_3_parks.py\":\\r\\n        return [ [\\'Elitch Gardens\\', \\'Colorado\\', 69.99], [\\'Euro Disney\\', \\'France\\', 189] ]\\r\\n    return []\\r\\n\\r\\ndef get_correct_output(inputs):\\r\\n    table = given_table()\\r\\n    weights = []\\r\\n    for i in range(len(table)):\\r\\n        weights.append(0.1)\\r\\n    table.append([inputs[2], inputs[0], inputs[1]])\\r\\n    for i in range(len(table)-len(weights)):\\r\\n        weights.append(1)\\r\\n    return (table, weights)\\r\\n\\r\\ndef test_passed():    \\r\\n    \\r\\n    # Template-only check\\r\\n    print(\"-------------------------------------------------\")\\r\\n    print(\"Test #\" + str(0))\\r\\n    print(\"-------------------------------------------------\")\\r\\n    output, error = autograder.run_script(script_name(), [])\\r\\n    if len(error) == 0:\\r\\n        print(\"Be sure that you are not running just the template file.\")\\r\\n        return 0.2\\r\\n    else:\\r\\n        print(\"Ignore the errors for this run.\")\\r\\n        \\r\\n    # Run Data Sets\\r\\n    run_data = user_inputs()\\r\\n    \\r\\n    # Set the weights for the individual runs\\r\\n    relative_weights = []\\r\\n    for i in range(len(run_data)):         \\r\\n        relative_weights.append(1)\\r\\n    relative_weights = [1,19] #(override evenly weighted)\\r\\n    sum_of_relative_weights = sum(relative_weights)\\r\\n    run_weight = []\\r\\n    for weight in relative_weights:\\r\\n        run_weight.append(weight / sum_of_relative_weights)\\r\\n    \\r\\n    # Runs the Script for each data set\\r\\n    cum_score = 0\\r\\n    for run in range(len(run_data)):\\r\\n        print(\"-------------------------------------------------\")\\r\\n        print(\"Test #\" + str(run + 1))\\r\\n        print(\"-------------------------------------------------\")\\r\\n\\r\\n        inputs_for_this_run = run_data[run]\\r\\n\\r\\n        input_list = []\\r\\n        (correct, weights) = get_correct_output(inputs_for_this_run)\\r\\n        \\r\\n        output, error = autograder.run_script(script_name(), inputs_for_this_run)\\r\\n        \\r\\n        score = 0\\r\\n        # Deal with the case of errors occuring during run\\r\\n        if (run == 1): # Cost is a float\\r\\n            if len(error) > 0:\\r\\n                print(\"Error when handling a float cost\")\\r\\n                score = 0\\r\\n                \\r\\n        if (run == 2): # Cost is an integer\\r\\n            if len(error) > 0:\\r\\n                print(\"Error when handling an integer cost\")\\r\\n                score = 0\\r\\n\\r\\n        # Deal with case of no errors occurring during run\\r\\n        if len(error) == 0:\\r\\n            lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n            if len(lines) >= 1 and len(lines[0]) > 0:                    \\r\\n                output_table = ast.literal_eval(lines[0])\\r\\n            \\r\\n                score = score_correct_against_scored(correct, output_table, weights)\\r\\n\\r\\n            else:\\r\\n                score = 0\\r\\n                \\r\\n\\r\\n        print(\"This test score:\", round(score,1), \"% (weight =\", round(100*run_weight[run],1), \"%)\")\\r\\n        cum_score += score * run_weight[run]\\r\\n        print()\\r\\n        \\r\\n    return max([round(cum_score, 1), 0.1])\\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_2_sickness': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(temperature, body_aches, loss_of_smell, expected_output):\\r\\n    output, error = autograder.run_script(\"a4_2_sickness.py\", [temperature, body_aches, loss_of_smell])\\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) >= 4:\\r\\n        if lines[3] == expected_output:\\r\\n            print(\"Correct Output\\\\n\")\\r\\n            return True\\r\\n        else:\\r\\n            print(\"Incorrect Output.  Expected\", expected_output, \\'\\\\n\\')\\r\\n            return False\\r\\n    else:\\r\\n        print(\"No Output Found\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    num_tests_passed = 0\\r\\n    \\r\\n    testcase_library = [(round(random.uniform(98.0, 99.9), 1), \"yes\", \"no\", \"Low Risk\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"yes\", \"yes\", \"High Risk\"),\\r\\n                        (round(random.uniform(98.0, 99.9), 1), \"yes\", \"yes\", \"High Risk\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"no\", \"no\", \"High Risk\")]\\r\\n    \\r\\n    for i in range(len(testcase_library)):\\r\\n        print(\"-------------------\")\\r\\n        print(\"Test\", i+1, \"of\", len(testcase_library))\\r\\n        print(\"-------------------\")\\r\\n        if run_test(testcase_library[i][0], testcase_library[i][1], testcase_library[i][2], testcase_library[i][3]):\\r\\n            num_tests_passed += 1\\r\\n    \\r\\n    return round(100 / len(testcase_library) * num_tests_passed, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_2_pt': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(temperature, lightning, winds, expected_output):\\r\\n    output, error = autograder.run_script(\"a4_2_pt.py\", [temperature, lightning, winds])\\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) >= 4:\\r\\n        if lines[3] == expected_output:\\r\\n            print(\"Correct Output\\\\n\")\\r\\n            return True\\r\\n        else:\\r\\n            print(\"Incorrect Output.  Expected\", expected_output, \\'\\\\n\\')\\r\\n            return False\\r\\n    else:\\r\\n        print(\"No Output Found\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    num_tests_passed = 0\\r\\n    \\r\\n    testcase_library = [(round(random.uniform(72.0, 90), 1), \"no\", \"no\", \"PT is a Go\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"yes\", \"yes\", \"PT Cancelled\"),\\r\\n                        (round(random.uniform(72.0, 90), 1), \"yes\", \"no\", \"PT Cancelled\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"no\", \"no\", \"PT Cancelled\")]\\r\\n    \\r\\n    for i in range(len(testcase_library)):\\r\\n        print(\"-------------------\")\\r\\n        print(\"Test\", i+1, \"of\", len(testcase_library))\\r\\n        print(\"-------------------\")\\r\\n        if run_test(testcase_library[i][0], testcase_library[i][1], testcase_library[i][2], testcase_library[i][3]):\\r\\n            num_tests_passed += 1\\r\\n    \\r\\n    return round(100 / len(testcase_library) * num_tests_passed, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_2_dog': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(temperature, raining, daytime, expected_output):\\r\\n    output, error = autograder.run_script(\"a4_2_dog.py\", [temperature, raining, daytime])\\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) >= 4:\\r\\n        if lines[3] == expected_output:\\r\\n            print(\"Correct Output\\\\n\")\\r\\n            return True\\r\\n        else:\\r\\n            print(\"Incorrect Output.  Expected\", expected_output, \\'\\\\n\\')\\r\\n            return False\\r\\n    else:\\r\\n        print(\"No Output Found\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    num_tests_passed = 0\\r\\n    \\r\\n    testcase_library = [(round(random.uniform(83.0, 84.9), 1), \"no\", \"yes\", \"Dog Outside\"),\\r\\n                        (round(random.uniform(83.0, 84.9), 1), \"yes\", \"yes\", \"Dog Inside\"),\\r\\n                        (round(random.uniform(83.0, 84.9), 1), \"no\", \"no\", \"Dog Inside\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"no\", \"yes\", \"Dog Inside\")]\\r\\n    \\r\\n    for i in range(len(testcase_library)):\\r\\n        print(\"-------------------\")\\r\\n        print(\"Test\", i+1, \"of\", len(testcase_library))\\r\\n        print(\"-------------------\")\\r\\n        if run_test(testcase_library[i][0], testcase_library[i][1], testcase_library[i][2], testcase_library[i][3]):\\r\\n            num_tests_passed += 1\\r\\n    \\r\\n    return round(100 / len(testcase_library) * num_tests_passed, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_1_lift': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport a4_1_lift\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    \\r\\n    if \"calculate_lift\" in dir(a4_1_lift):\\r\\n        print(\"Function Defined\")\\r\\n        score += 20\\r\\n        \\r\\n        lift_coefficient = round(random.uniform(3, 5), 1)\\r\\n        density = round(random.uniform(2, 3), 1)\\r\\n        velocity = round(random.uniform(50, 200), 1)\\r\\n        area = round(random.uniform(400, 1000), 1)\\r\\n        lift = lift_coefficient * area * 0.5 * density * velocity ** 2.0\\r\\n        \\r\\n        if autograder.equals(lift, a4_1_lift.calculate_lift(lift_coefficient, density, velocity, area)):\\r\\n            print(\"Function Returned the Correct Value\")\\r\\n            score += 80\\r\\n        else:\\r\\n            print(\"calculate_lift(%1.1f, %1.1f, %1.1f, %1.1f) return %f instead of %f\" %\\r\\n                  (lift_coefficient, density, velocity, area, a4_1_lift.calculate_lift(lift_coefficient, density, velocity, area), lift))\\r\\n        \\r\\n    else:\\r\\n        print(\"Function Not Defined\")\\r\\n    \\r\\n    return score\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_1_buoyancy': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport a4_1_buoyancy\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    \\r\\n    if \"calculate_buoyancy\" in dir(a4_1_buoyancy):\\r\\n        print(\"Function Defined\")\\r\\n        score += 20\\r\\n        \\r\\n        volume = round(random.uniform(3, 5), 1)\\r\\n        density = round(random.uniform(2, 3), 1)\\r\\n        gravity = round(random.uniform(50, 200), 1)\\r\\n        buoyancy = volume * density * gravity\\r\\n        \\r\\n        if autograder.equals(buoyancy, a4_1_buoyancy.calculate_buoyancy(volume, density, gravity)):\\r\\n            print(\"Function Returned the Correct Value\")\\r\\n            score += 80\\r\\n        else:\\r\\n            print(\"calculate_buoyancy(%1.1f, %1.1f, %1.1f) returned %f instead of %f\" %\\r\\n                  (volume, density, gravity, a4_1_buoyancy.calculate_buoyancy(volume, density, gravity), buoyancy))\\r\\n        \\r\\n    else:\\r\\n        print(\"Function Not Defined\")\\r\\n    \\r\\n    return score\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a4_1_area': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport a4_1_area\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    \\r\\n    if \"calculate_area\" in dir(a4_1_area):\\r\\n        print(\"Function Defined\")\\r\\n        score += 20\\r\\n        \\r\\n        Side_A = round(random.uniform(3, 5), 1)\\r\\n        Side_B = round(random.uniform(2, 3), 1)\\r\\n        Height = round(random.uniform(50, 200), 1)\\r\\n        area = ((Side_A + Side_B) / 2) * Height\\r\\n        \\r\\n        if autograder.equals(area, a4_1_area.calculate_area(Side_A,Side_B,Height)):\\r\\n            print(\"Function Returned the Correct Value\")\\r\\n            score += 80\\r\\n        else:\\r\\n            print(\"calculate_area(%1.1f, %1.1f, %1.1f) return %f instead of %f\" %\\r\\n                  (Side_A, Side_B, Height, a4_1_area.calculate_area(Side_A,Side_B,Height), area))\\r\\n        \\r\\n    else:\\r\\n        print(\"Function Not Defined\")\\r\\n    \\r\\n    return score\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a3_7_minpower': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(power_generation_type):\\r\\n    file = open(\"powerplants.csv\", \\'r\\')\\r\\n    contents = file.read()\\r\\n    lines_in_file = contents.split(\\'\\\\n\\')\\r\\n    result = []\\r\\n\\r\\n    table_of_power_plants = []\\r\\n\\r\\n    for current_line in lines_in_file:\\r\\n        columns = current_line.split(\\',\\')\\r\\n        power_mw = float(columns[2])\\r\\n        power_name = columns[3]\\r\\n        power_type = columns[4]\\r\\n        \\r\\n        if power_type == power_generation_type:\\r\\n            table_of_power_plants.append([power_mw, power_name])\\r\\n\\r\\n    min_mw = min(table_of_power_plants)\\r\\n\\r\\n    result.append(str(min_mw[0]))\\r\\n\\r\\n    for row in table_of_power_plants:\\r\\n        if row[0] <= min_mw[0] + 1:\\r\\n            result.append(row[1])\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 3\\r\\n    num_min_correct = 0\\r\\n    num_min_names = 0\\r\\n    \\r\\n    types_to_test = [\\'Other\\', \\'SteamTurbine\\', \\'GasTurbine\\', \\'CombinedCycle\\', \\'HydraulicTurbine\\']\\r\\n    \\r\\n    for i in range(NUM_TESTS):\\r\\n        power_type = types_to_test[random.randint(0, len(types_to_test)-1)]\\r\\n        types_to_test.remove(power_type)\\r\\n        \\r\\n        print(\"-------------------------\")\\r\\n        print(\"Test\", i+1, \"of\", NUM_TESTS, \":\", power_type)\\r\\n        print(\"-------------------------\")\\r\\n        \\r\\n        output, error = autograder.run_script(\"a3_7_minpower.py\", [power_type])\\r\\n        expected_output = solution(power_type)\\r\\n        student_output = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n        # Determines if the stat is correct\\r\\n        print(\"CHECKING MIN VALUE:\")\\r\\n        if autograder.equals(student_output[0], expected_output[0]):\\r\\n            print(\"CORRECT\\\\n\")\\r\\n            num_min_correct += 1\\r\\n        else:\\r\\n            print(\"INCORRECT\\\\n\")\\r\\n\\r\\n        # Determines if the names are correct\\r\\n        print(\"CHECKING PLANT NAMES:\")\\r\\n        num_matches = 0\\r\\n        \\r\\n        for item in expected_output[1:]:\\r\\n            print(\"Looking for\", item, \". . . \", end=\"\")\\r\\n            if item in student_output[1:]:\\r\\n                print(\"FOUND\")\\r\\n                num_matches += 1\\r\\n            else:\\r\\n                print(\"NOT FOUND\")            \\r\\n        \\r\\n        if num_matches == len(expected_output[1:]) and len(student_output[1:]) == len(expected_output[1:]):\\r\\n            print(\"CORRECT\\\\n\")\\r\\n            num_min_names += 1\\r\\n        elif num_matches == len(expected_output[1:]) and len(student_output[1:]) >= len(expected_output[1:]):\\r\\n            print(\"INCORRECT.  Your program is printing more power plant names than are expected.\\\\n\") \\r\\n        else:\\r\\n            print(\"INCORRECT.  Missing\", str(len(expected_output[1:]) - num_matches), \"plant names\")\\r\\n            \\r\\n    return round(60 * (num_min_correct / NUM_TESTS) + 40 * (num_min_names / NUM_TESTS), 1)\\r\\n    \\r\\n\\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_7_min_lego': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(set_theme):\\r\\n    file = open(\"legos.csv\", \\'r\\')\\r\\n    contents = file.read()\\r\\n    lines_in_file = contents.split(\\'\\\\n\\')\\r\\n    result = []\\r\\n\\r\\n    table_of_lego_sets = []\\r\\n\\r\\n    for current_line in lines_in_file:\\r\\n        columns = current_line.split(\\',\\')\\r\\n        set_part_count = float(columns[4])\\r\\n        set_name = columns[1]\\r\\n        curr_set_theme = columns[3]\\r\\n        \\r\\n        if curr_set_theme == set_theme:\\r\\n            table_of_lego_sets.append([set_part_count, set_name])\\r\\n\\r\\n    min_set_count = min(table_of_lego_sets)\\r\\n\\r\\n    result.append(str(min_set_count[0]))\\r\\n\\r\\n    for row in table_of_lego_sets:\\r\\n        if row[0] <= min_set_count[0] + 14:\\r\\n            result.append(row[1])\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 3\\r\\n    num_max_correct = 0\\r\\n    num_max_names = 0\\r\\n    \\r\\n    types_to_test = [\"Model\", \"Technic\", \"City\", \"Town\", \"Vehicle\", \"Space\", \"Star Wars\", \"Seasonal\", \"Educational\", \"Bionicle\"]\\r\\n    \\r\\n    for i in range(NUM_TESTS):\\r\\n        lego_theme = types_to_test[random.randint(0, len(types_to_test)-1)]\\r\\n        types_to_test.remove(lego_theme)\\r\\n        \\r\\n        print(\"-------------------------\")\\r\\n        print(\"Test\", i+1, \"of\", NUM_TESTS, \":\", lego_theme)\\r\\n        print(\"-------------------------\")\\r\\n        \\r\\n        output, error = autograder.run_script(\"a3_7_min_lego.py\", [lego_theme])\\r\\n        expected_output = solution(lego_theme)\\r\\n        student_output = output.strip().split(\\'\\\\n\\')\\r\\n                \\r\\n        # Determines if the stat is correct\\r\\n        print(\"CHECKING MIN VALUE:\")\\r\\n        if autograder.equals(student_output[0], expected_output[0]):\\r\\n            print(\"CORRECT\\\\n\")\\r\\n            num_max_correct += 1\\r\\n        else:\\r\\n            print(\"INCORRECT\\\\n\")\\r\\n        \\r\\n        # Determines if the names are correct\\r\\n        print(\"CHECKING LEGO SET NAMES:\")\\r\\n        num_matches = 0\\r\\n        \\r\\n        for item in expected_output[1:]:\\r\\n            print(\"Looking for\", item, \". . . \", end=\"\")\\r\\n            if item in student_output[1:]:\\r\\n                print(\"FOUND\")\\r\\n                num_matches += 1\\r\\n            else:\\r\\n                print(\"NOT FOUND\")            \\r\\n        \\r\\n        if num_matches == len(expected_output[1:]) and len(student_output[1:]) == len(expected_output[1:]):\\r\\n            print(\"CORRECT\\\\n\")\\r\\n            num_max_names += 1\\r\\n        elif num_matches == len(expected_output[1:]) and len(student_output[1:]) >= len(expected_output[1:]):\\r\\n            print(\"INCORRECT.  Your program is printing more Lego set names than are expected.\\\\n\") \\r\\n        else:\\r\\n            print(\"INCORRECT.  Missing\", str(len(expected_output[1:]) - num_matches), \"Lego set names\")\\r\\n            \\r\\n            \\r\\n    return round(60 * (num_max_correct / NUM_TESTS) + 40 * (num_max_names / NUM_TESTS), 1)\\r\\n    \\r\\n\\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_7_maxpower': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(power_generation_type):\\r\\n    file = open(\"powerplants.csv\", \\'r\\')\\r\\n    contents = file.read()\\r\\n    lines_in_file = contents.split(\\'\\\\n\\')\\r\\n    result = []\\r\\n\\r\\n    table_of_power_plants = []\\r\\n\\r\\n    for current_line in lines_in_file:\\r\\n        columns = current_line.split(\\',\\')\\r\\n        power_mw = float(columns[2])\\r\\n        power_name = columns[3]\\r\\n        power_type = columns[4]\\r\\n        \\r\\n        if power_type == power_generation_type:\\r\\n            table_of_power_plants.append([power_mw, power_name])\\r\\n\\r\\n    max_mw = max(table_of_power_plants)\\r\\n\\r\\n    result.append(str(max_mw[0]))\\r\\n\\r\\n    for row in table_of_power_plants:\\r\\n        if row[0] >= max_mw[0] - 15:\\r\\n            result.append(row[1])\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 3\\r\\n    num_max_correct = 0\\r\\n    num_max_names = 0\\r\\n    \\r\\n    types_to_test = [\\'Other\\', \\'SteamTurbine\\', \\'GasTurbine\\', \\'CombinedCycle\\', \\'HydraulicTurbine\\']\\r\\n    \\r\\n    for i in range(NUM_TESTS):\\r\\n        power_type = types_to_test[random.randint(0, len(types_to_test)-1)]\\r\\n        types_to_test.remove(power_type)\\r\\n        \\r\\n        print(\"-------------------------\")\\r\\n        print(\"Test\", i+1, \"of\", NUM_TESTS, \":\", power_type)\\r\\n        print(\"-------------------------\")\\r\\n        \\r\\n        output, error = autograder.run_script(\"a3_7_maxpower.py\", [power_type])\\r\\n        expected_output = solution(power_type)\\r\\n        student_output = output.strip().split(\\'\\\\n\\')\\r\\n                \\r\\n        # Determines if the stat is correct\\r\\n        print(\"CHECKING MAX VALUE:\")\\r\\n        if autograder.equals(student_output[0], expected_output[0]):\\r\\n            print(\"CORRECT\\\\n\")\\r\\n            num_max_correct += 1\\r\\n        else:\\r\\n            print(\"INCORRECT\\\\n\")\\r\\n        \\r\\n        # Determines if the names are correct\\r\\n        print(\"CHECKING PLANT NAMES:\")\\r\\n        num_matches = 0\\r\\n        \\r\\n        for item in expected_output[1:]:\\r\\n            print(\"Looking for\", item, \". . . \", end=\"\")\\r\\n            if item in student_output[1:]:\\r\\n                print(\"FOUND\")\\r\\n                num_matches += 1\\r\\n            else:\\r\\n                print(\"NOT FOUND\")            \\r\\n        \\r\\n        if num_matches == len(expected_output[1:]) and len(student_output[1:]) == len(expected_output[1:]):\\r\\n            print(\"CORRECT\\\\n\")\\r\\n            num_max_names += 1\\r\\n        elif num_matches == len(expected_output[1:]) and len(student_output[1:]) >= len(expected_output[1:]):\\r\\n            print(\"INCORRECT.  Your program is printing more power plant names than are expected.\\\\n\") \\r\\n        else:\\r\\n            print(\"INCORRECT.  Missing\", str(len(expected_output[1:]) - num_matches), \"plant names\")\\r\\n            \\r\\n    return round(60 * (num_max_correct / NUM_TESTS) + 40 * (num_max_names / NUM_TESTS), 1)\\r\\n    \\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_7_max': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(power_generation_type):\\r\\n    file = open(\"powerplants.csv\", \\'r\\')\\r\\n    contents = file.read()\\r\\n    lines_in_file = contents.split(\\'\\\\n\\')\\r\\n    result = []\\r\\n\\r\\n    table_of_power_plants = []\\r\\n\\r\\n    for current_line in lines_in_file:\\r\\n        columns = current_line.split(\\',\\')\\r\\n        power_mw = float(columns[2])\\r\\n        power_name = columns[3]\\r\\n        power_type = columns[4]\\r\\n        \\r\\n        if power_type == power_generation_type:\\r\\n            table_of_power_plants.append([power_mw, power_name])\\r\\n\\r\\n    max_mw = max(table_of_power_plants)\\r\\n\\r\\n    result.append(str(max_mw[0]))\\r\\n\\r\\n    for row in table_of_power_plants:\\r\\n        if row[0] >= max_mw[0] - 8:\\r\\n            result.append(row[1])\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 3\\r\\n    num_max_correct = 0\\r\\n    num_max_names = 0\\r\\n    \\r\\n    types_to_test = [\\'Other\\', \\'SteamTurbine\\', \\'GasTurbine\\', \\'CombinedCycle\\', \\'HydraulicTurbine\\']\\r\\n    \\r\\n    for i in range(NUM_TESTS):\\r\\n        power_type = types_to_test[random.randint(0, len(types_to_test)-1)]\\r\\n        types_to_test.remove(power_type)\\r\\n        \\r\\n        print(\"-------------------------\")\\r\\n        print(\"Test\", i+1, \"of\", NUM_TESTS, \":\", power_type)\\r\\n        print(\"-------------------------\")\\r\\n        \\r\\n        output, error = autograder.run_script(\"a3_7_max.py\", [power_type])\\r\\n        expected_output = solution(power_type)\\r\\n        student_output = output.strip().split(\\'\\\\n\\')\\r\\n                \\r\\n        # Determines if the stat is correct\\r\\n        print(\"CHECKING MAX VALUE:\")\\r\\n        if autograder.equals(student_output[0], expected_output[0]):\\r\\n            print(\"CORRECT\\\\n\")\\r\\n            num_max_correct += 1\\r\\n        else:\\r\\n            print(\"INCORRECT\\\\n\")\\r\\n        \\r\\n        # Determines if the names are correct\\r\\n        print(\"CHECKING PLANT NAMES:\")\\r\\n        num_matches = 0\\r\\n        \\r\\n        for item in expected_output[1:]:\\r\\n            print(\"Looking for\", item, \". . . \", end=\"\")\\r\\n            if item in student_output[1:]:\\r\\n                print(\"FOUND\")\\r\\n                num_matches += 1\\r\\n            else:\\r\\n                print(\"NOT FOUND\")            \\r\\n        \\r\\n        if num_matches == len(expected_output[1:]) and len(student_output[1:]) == len(expected_output[1:]):\\r\\n            print(\"CORRECT\\\\n\")\\r\\n            num_max_names += 1\\r\\n        elif num_matches == len(expected_output[1:]) and len(student_output[1:]) >= len(expected_output[1:]):\\r\\n            print(\"INCORRECT.  Your program is printing more power plant names than are expected.\\\\n\") \\r\\n        else:\\r\\n            print(\"INCORRECT.  Missing\", str(len(expected_output[1:]) - num_matches), \"plant names\")\\r\\n            \\r\\n            \\r\\n    return round(60 * (num_max_correct / NUM_TESTS) + 40 * (num_max_names / NUM_TESTS), 1)\\r\\n    \\r\\n\\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_7_max_lego': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(set_theme):\\r\\n    file = open(\"legos.csv\", \\'r\\')\\r\\n    contents = file.read()\\r\\n    lines_in_file = contents.split(\\'\\\\n\\')\\r\\n    result = []\\r\\n\\r\\n    table_of_lego_sets = []\\r\\n\\r\\n    for current_line in lines_in_file:\\r\\n        columns = current_line.split(\\',\\')\\r\\n        set_part_count = float(columns[4])\\r\\n        set_name = columns[1]\\r\\n        curr_set_theme = columns[3]\\r\\n        \\r\\n        if curr_set_theme == set_theme:\\r\\n            table_of_lego_sets.append([set_part_count, set_name])\\r\\n\\r\\n    max_set_count = max(table_of_lego_sets)\\r\\n\\r\\n    result.append(str(max_set_count[0]))\\r\\n\\r\\n    for row in table_of_lego_sets:\\r\\n        if row[0] >= max_set_count[0] - 150:\\r\\n            result.append(row[1])\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 3\\r\\n    num_max_correct = 0\\r\\n    num_max_names = 0\\r\\n    \\r\\n    types_to_test = [\"Model\", \"Technic\", \"City\", \"Town\", \"Vehicle\", \"Space\", \"Star Wars\", \"Seasonal\", \"Educational\", \"Bionicle\"]\\r\\n    \\r\\n    for i in range(NUM_TESTS):\\r\\n        lego_theme = types_to_test[random.randint(0, len(types_to_test)-1)]\\r\\n        types_to_test.remove(lego_theme)\\r\\n        \\r\\n        print(\"-------------------------\")\\r\\n        print(\"Test\", i+1, \"of\", NUM_TESTS, \":\", lego_theme)\\r\\n        print(\"-------------------------\")\\r\\n        \\r\\n        output, error = autograder.run_script(\"a3_7_max_lego.py\", [lego_theme])\\r\\n        expected_output = solution(lego_theme)\\r\\n        student_output = output.strip().split(\\'\\\\n\\')\\r\\n                \\r\\n        # Determines if the stat is correct\\r\\n        print(\"CHECKING MAX VALUE:\")\\r\\n        if autograder.equals(student_output[0], expected_output[0]):\\r\\n            print(\"CORRECT\\\\n\")\\r\\n            num_max_correct += 1\\r\\n        else:\\r\\n            print(\"INCORRECT\\\\n\")\\r\\n        \\r\\n        # Determines if the names are correct\\r\\n        print(\"CHECKING LEGO SET NAMES:\")\\r\\n        num_matches = 0\\r\\n        \\r\\n        for item in expected_output[1:]:\\r\\n            print(\"Looking for\", item, \". . . \", end=\"\")\\r\\n            if item in student_output[1:]:\\r\\n                print(\"FOUND\")\\r\\n                num_matches += 1\\r\\n            else:\\r\\n                print(\"NOT FOUND\")            \\r\\n        \\r\\n        if num_matches == len(expected_output[1:]) and len(student_output[1:]) == len(expected_output[1:]):\\r\\n            print(\"CORRECT\\\\n\")\\r\\n            num_max_names += 1\\r\\n        elif num_matches == len(expected_output[1:]) and len(student_output[1:]) >= len(expected_output[1:]):\\r\\n            print(\"INCORRECT.  Your program is printing more Lego set names than are expected.\\\\n\") \\r\\n        else:\\r\\n            print(\"INCORRECT.  Missing\", str(len(expected_output[1:]) - num_matches), \"Lego set names\")\\r\\n            \\r\\n            \\r\\n    return round(60 * (num_max_correct / NUM_TESTS) + 40 * (num_max_names / NUM_TESTS), 1)\\r\\n    \\r\\n\\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_6_tests': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef script_name():\\r\\n    return \"a3_6_tests.py\"\\r\\n\\r\\n# There should be two outputs:\\r\\n#    The average followed by a count.\\r\\n# The test cases should be constructed so that:\\r\\n#    The average is >= 30\\r\\n#    The count   is <= 20\\r\\n\\r\\n# AUTOGRADER RUBRIC for scoring one test:\\r\\n\\r\\n# Number of outputs (10 pt):\\r\\n# 10 pt Output consists of exactly two values\\r\\n#  5 pt Output consists of one value or more than two values\\r\\n#  0 pt Output consists of either zero\\r\\n\\r\\n# Output of average (45 pt):\\r\\n# 45 pt Exactly correct and is first value in list\\r\\n# 30 pt Within 0.1 and is first value in list\\r\\n# 30 pt Exactly correct but is not first value in list\\r\\n# 15 pt Within 0.1 but is not first value in list\\r\\n\\r\\n# Output of count (45 pt):\\r\\n# 45 pt Exactly correct and is first value in list\\r\\n# 30 pt Within 1 and is first value in list\\r\\n# 30 pt Exactly correct but is not first value in list\\r\\n# 15 pt Within 1 but is not first value in list\\r\\n\\r\\ndef base_name(name_of_script):\\r\\n    return (name_of_script.split(\\'.\\')[0]).split(\\'_\\')[2]\\r\\n\\r\\ndef solution(input_list):\\r\\n\\r\\n    # Input is a count followed by that many values\\r\\n    # Create a list of just the values\\r\\n    items_list = input_list[1:]\\r\\n    \\r\\n    # Determine the average of the values\\r\\n    average = sum(items_list) / len(items_list)\\r\\n    \\r\\n    # Count the number of items that meet the criteria\\r\\n    # This depends on the specific variant of the problem\\r\\n    base_script = base_name(script_name())\\r\\n    count = 0\\r\\n    for score in items_list:\\r\\n        if base_script == \"pushups\" and score > average:\\r\\n            count += 1\\r\\n        if base_script == \"sami\" and score > average:\\r\\n            count += 1\\r\\n        if base_script == \"tests\" and score < average:\\r\\n            count += 1\\r\\n    \\r\\n    # Output is average (rounded to 1 decimal place) and count \\r\\n    return [str(round(average,1)), str(count)]\\r\\n\\r\\ndef is_value(s):\\r\\n    try:\\r\\n        float(s)\\r\\n        return True\\r\\n    except ValueError:\\r\\n        return False\\r\\n    \\r\\n# Returns the position and distance of the closes user value from the solution value.\\r\\n# Returns found=False if list from user contains no numeric values\\r\\ndef matchup_numeric(value, from_user):\\r\\n    value = float(value)\\r\\n    found = False\\r\\n    position = -1\\r\\n    within = 1E10\\r\\n    for i in range(len(from_user)):\\r\\n        item = from_user[i]\\r\\n        if is_value(item):\\r\\n            found = True\\r\\n            user_value = float(item)\\r\\n            distance = abs(value - user_value)\\r\\n            if  distance < within:\\r\\n                within = distance\\r\\n                position = i \\r\\n                \\r\\n    return (found, position, within)\\r\\n\\r\\ndef decimal_places(float_string):\\r\\n    if is_value(float_string):\\r\\n        decimal_point_index = float_string.find(\\'.\\')\\r\\n        if decimal_point_index == -1:\\r\\n            return 0\\r\\n        else:\\r\\n            return len(float_string) - (decimal_point_index + 1)\\r\\n    else:\\r\\n        return -1\\r\\n    \\r\\ndef grade_item(name, correct_position, places, tolerance, from_soln, from_user):\\r\\n    score = 0\\r\\n    \\r\\n    value_from_soln = from_soln[correct_position]\\r\\n    \\r\\n    (found, position, within) = matchup_numeric(value_from_soln, from_user)\\r\\n    if not found:\\r\\n        print(name, \"not found.  Expected: \", value_from_soln)\\r\\n        score += 0\\r\\n    else:\\r\\n        place_penalty = 0\\r\\n        if   (position == correct_position) and (within <= tolerance[0]):\\r\\n            print(name, \"appears correct.\")\\r\\n            score += 45 - place_penalty\\r\\n        elif (position == correct_position) and (within <= tolerance[1]):\\r\\n            print(name, \"is close.  Expected: \", value_from_soln)\\r\\n            score += 30 - place_penalty\\r\\n        elif (position != correct_position) and (within <= tolerance[0]):\\r\\n            print(name, \"appears correct, but in wrong position.\")\\r\\n            score += 30 - place_penalty\\r\\n        elif  (position != correct_position) and (within <= tolerance[1]):\\r\\n            print(name, \"is close, but in wrong position.  Expected: \", value_from_soln)\\r\\n            score += 15 - place_penalty\\r\\n        else:\\r\\n            print(name, \"is not close and probably in wrong position.  Expected: \", value_from_soln)\\r\\n            score += 0\\r\\n    return score            \\r\\n\\r\\ndef run_1_test(script_being_tested, input_list):\\r\\n\\r\\n    (output, error) = autograder.run_script(script_being_tested, input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_output = solution(input_list)\\r\\n    \\r\\n    score = 0\\r\\n\\r\\n    # Number of outputs\\r\\n    if len(lines) == 2:\\r\\n        print(\"Number of output lines is correct.\")\\r\\n        score += 10\\r\\n    elif len(lines) == 1:\\r\\n        print(\"Number of output lines is not quite correct.\")\\r\\n        score += 5\\r\\n    else:\\r\\n        print(\"Number of output lines is not correct.\")\\r\\n        score += 0\\r\\n\\r\\n    score += grade_item(\"Average\", 0, 1, [0.1, 10], expected_output, lines)\\r\\n    score += grade_item(\"Count\", 1, 0, [0, 1], expected_output, lines)\\r\\n\\r\\n    print(\\'-----------------------------\\')\\r\\n\\r\\n    return score\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    script_being_tested = script_name()\\r\\n    score = 0\\r\\n    cum_weight = 0.0\\r\\n\\r\\n    # Corner Case #1 (5%) -- only a single score\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n    \\r\\n    random_people = 1\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    for i in range(random_people):\\r\\n        random_score = random.randint(30, 100)\\r\\n        input_list.append(random_score)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n\\r\\n    # Corner Case #2 (5%) -- multiple all scores that are all the same\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    random_people = random.randint(5, 10)\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    random_score = random.randint(30, 100)\\r\\n    for i in range(random_people):\\r\\n        input_list.append(random_score)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n\\r\\n    # Corner Case #3 (5%) -- scores exist that exactly match average\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    random_people = random.randint(7,15)\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    random_mean = random.randint(50, 70)\\r\\n    \\r\\n    for i in range(random_people % 3):\\r\\n        input_list.append(random_mean)\\r\\n        \\r\\n    for i in range(random_people // 3):\\r\\n        random_step = random.randint(3,20)\\r\\n        input_list.append(random_mean)\\r\\n        input_list.append(random_mean + random_step)\\r\\n        input_list.append(random_mean - random_step)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n    \\r\\n    #Corner Case # 4 makes sure students are rounding to one decimal place\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100\\r\\n    \\r\\n    input_list = [17,82,98,100,42,95,45,93,71,91,39,65,82,46,77,56,67,44]\\r\\n    rounding_score = run_1_test(script_being_tested, input_list)\\r\\n    score += weight * rounding_score\\r\\n    \\r\\n    # General Case (80%) -- 4 runs @ 20% each\\r\\n    runs = 2\\r\\n    weight = (100.0 - cum_weight)\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    \\r\\n    for run in range(runs):\\r\\n        random_people = random.randint(2, 20)\\r\\n        input_list = [random_people]\\r\\n            \\r\\n        for i in range(random_people):\\r\\n            random_score = random.randint(30, 100)\\r\\n            input_list.append(random_score)\\r\\n        \\r\\n        score += weight * run_1_test(script_being_tested, input_list)\\r\\n    score = min([score,rounding_score])\\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a3_6_sami': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef script_name():\\r\\n    return \"a3_6_sami.py\"\\r\\n\\r\\n# There should be two outputs:\\r\\n#    The average followed by a count.\\r\\n# The test cases should be constructed so that:\\r\\n#    The average is >= 30\\r\\n#    The count   is <= 20\\r\\n\\r\\n# AUTOGRADER RUBRIC for scoring one test:\\r\\n\\r\\n# Number of outputs (10 pt):\\r\\n# 10 pt Output consists of exactly two values\\r\\n#  5 pt Output consists of one value or more than two values\\r\\n#  0 pt Output consists of either zero\\r\\n\\r\\n# Output of average (45 pt):\\r\\n# 45 pt Exactly correct and is first value in list\\r\\n# 30 pt Within 0.1 and is first value in list\\r\\n# 30 pt Exactly correct but is not first value in list\\r\\n# 15 pt Within 0.1 but is not first value in list\\r\\n\\r\\n# Output of count (45 pt):\\r\\n# 45 pt Exactly correct and is first value in list\\r\\n# 30 pt Within 1 and is first value in list\\r\\n# 30 pt Exactly correct but is not first value in list\\r\\n# 15 pt Within 1 but is not first value in list\\r\\n\\r\\ndef base_name(name_of_script):\\r\\n    return (name_of_script.split(\\'.\\')[0]).split(\\'_\\')[2]\\r\\n\\r\\ndef solution(input_list):\\r\\n\\r\\n    # Input is a count followed by that many values\\r\\n    # Create a list of just the values\\r\\n    items_list = input_list[1:]\\r\\n    \\r\\n    # Determine the average of the values\\r\\n    average = sum(items_list) / len(items_list)\\r\\n    \\r\\n    # Count the number of items that meet the criteria\\r\\n    # This depends on the specific variant of the problem\\r\\n    base_script = base_name(script_name())\\r\\n    count = 0\\r\\n    for score in items_list:\\r\\n        if base_script == \"pushups\" and score > average:\\r\\n            count += 1\\r\\n        if base_script == \"sami\" and score > average:\\r\\n            count += 1\\r\\n        if base_script == \"tests\" and score < average:\\r\\n            count += 1\\r\\n    \\r\\n    # Output is average (rounded to 1 decimal place) and count \\r\\n    return [str(round(average,1)), str(count)]\\r\\n\\r\\ndef is_value(s):\\r\\n    try:\\r\\n        float(s)\\r\\n        return True\\r\\n    except ValueError:\\r\\n        return False\\r\\n    \\r\\n# Returns the position and distance of the closes user value from the solution value.\\r\\n# Returns found=False if list from user contains no numeric values\\r\\ndef matchup_numeric(value, from_user):\\r\\n    value = float(value)\\r\\n    found = False\\r\\n    position = -1\\r\\n    within = 1E10\\r\\n    for i in range(len(from_user)):\\r\\n        item = from_user[i]\\r\\n        if is_value(item):\\r\\n            found = True\\r\\n            user_value = float(item)\\r\\n            distance = abs(value - user_value)\\r\\n            if  distance < within:\\r\\n                within = distance\\r\\n                position = i \\r\\n                \\r\\n    return (found, position, within)\\r\\n\\r\\ndef decimal_places(float_string):\\r\\n    if is_value(float_string):\\r\\n        decimal_point_index = float_string.find(\\'.\\')\\r\\n        if decimal_point_index == -1:\\r\\n            return 0\\r\\n        else:\\r\\n            return len(float_string) - (decimal_point_index + 1)\\r\\n    else:\\r\\n        return -1\\r\\n    \\r\\ndef grade_item(name, correct_position, places, tolerance, from_soln, from_user):\\r\\n    score = 0\\r\\n    \\r\\n    value_from_soln = from_soln[correct_position]\\r\\n    \\r\\n    (found, position, within) = matchup_numeric(value_from_soln, from_user)\\r\\n    if not found:\\r\\n        print(name, \"not found.  Expected: \", value_from_soln)\\r\\n        score += 0\\r\\n    else:\\r\\n        place_penalty = 0\\r\\n        if   (position == correct_position) and (within <= tolerance[0]):\\r\\n            print(name, \"appears correct.\")\\r\\n            score += 45 - place_penalty\\r\\n        elif (position == correct_position) and (within <= tolerance[1]):\\r\\n            print(name, \"is close.  Expected: \", value_from_soln)\\r\\n            score += 30 - place_penalty\\r\\n        elif (position != correct_position) and (within <= tolerance[0]):\\r\\n            print(name, \"appears correct, but in wrong position.\")\\r\\n            score += 30 - place_penalty\\r\\n        elif  (position != correct_position) and (within <= tolerance[1]):\\r\\n            print(name, \"is close, but in wrong position.  Expected: \", value_from_soln)\\r\\n            score += 15 - place_penalty\\r\\n        else:\\r\\n            print(name, \"is not close and probably in wrong position.  Expected: \", value_from_soln)\\r\\n            score += 0\\r\\n    return score            \\r\\n\\r\\ndef run_1_test(script_being_tested, input_list):\\r\\n\\r\\n    (output, error) = autograder.run_script(script_being_tested, input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_output = solution(input_list)\\r\\n    \\r\\n    score = 0\\r\\n\\r\\n    # Number of outputs\\r\\n    if len(lines) == 2:\\r\\n        print(\"Number of output lines is correct.\")\\r\\n        score += 10\\r\\n    elif len(lines) == 1:\\r\\n        print(\"Number of output lines is not quite correct.\")\\r\\n        score += 5\\r\\n    else:\\r\\n        print(\"Number of output lines is not correct.\")\\r\\n        score += 0\\r\\n\\r\\n    score += grade_item(\"Average\", 0, 1, [0.1, 10], expected_output, lines)\\r\\n    score += grade_item(\"Count\", 1, 0, [0, 1], expected_output, lines)\\r\\n\\r\\n    print(\\'-----------------------------\\')\\r\\n\\r\\n    return score\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    script_being_tested = script_name()\\r\\n    score = 0\\r\\n    cum_weight = 0.0\\r\\n\\r\\n    # Corner Case #1 (5%) -- only a single score\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n    \\r\\n    random_people = 1\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    for i in range(random_people):\\r\\n        random_score = random.randint(30, 100)\\r\\n        input_list.append(random_score)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n\\r\\n    # Corner Case #2 (5%) -- multiple all scores that are all the same\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    random_people = random.randint(5, 10)\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    random_score = random.randint(30, 100)\\r\\n    for i in range(random_people):\\r\\n        input_list.append(random_score)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n\\r\\n    # Corner Case #3 (5%) -- scores exist that exactly match average\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    random_people = random.randint(7,15)\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    random_mean = random.randint(50, 70)\\r\\n    \\r\\n    for i in range(random_people % 3):\\r\\n        input_list.append(random_mean)\\r\\n        \\r\\n    for i in range(random_people // 3):\\r\\n        random_step = random.randint(3,20)\\r\\n        input_list.append(random_mean)\\r\\n        input_list.append(random_mean + random_step)\\r\\n        input_list.append(random_mean - random_step)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n    \\r\\n    #Corner Case # 4 makes sure students are rounding to one decimal place\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100\\r\\n    \\r\\n    input_list = [17,82,98,100,42,95,45,93,71,91,39,65,82,46,77,56,67,44]\\r\\n    rounding_score = run_1_test(script_being_tested, input_list)\\r\\n    score += weight * rounding_score\\r\\n    \\r\\n    # General Case (80%) -- 4 runs @ 20% each\\r\\n    runs = 2\\r\\n    weight = (100.0 - cum_weight)\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    \\r\\n    for run in range(runs):\\r\\n        random_people = random.randint(2, 20)\\r\\n        input_list = [random_people]\\r\\n            \\r\\n        for i in range(random_people):\\r\\n            random_score = random.randint(30, 100)\\r\\n            input_list.append(random_score)\\r\\n        \\r\\n        score += weight * run_1_test(script_being_tested, input_list)\\r\\n    score = min([score,rounding_score])\\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a3_6_pushups': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef script_name():\\r\\n    return \"a3_6_pushups.py\"\\r\\n\\r\\n# There should be two outputs:\\r\\n#    The average followed by a count.\\r\\n# The test cases should be constructed so that:\\r\\n#    The average is >= 30\\r\\n#    The count   is <= 20\\r\\n\\r\\n# AUTOGRADER RUBRIC for scoring one test:\\r\\n\\r\\n# Number of outputs (10 pt):\\r\\n# 10 pt Output consists of exactly two values\\r\\n#  5 pt Output consists of one value or more than two values\\r\\n#  0 pt Output consists of either zero\\r\\n\\r\\n# Output of average (45 pt):\\r\\n# 45 pt Exactly correct and is first value in list\\r\\n# 30 pt Within 0.1 and is first value in list\\r\\n# 30 pt Exactly correct but is not first value in list\\r\\n# 15 pt Within 0.1 but is not first value in list\\r\\n\\r\\n# Output of count (45 pt):\\r\\n# 45 pt Exactly correct and is first value in list\\r\\n# 30 pt Within 1 and is first value in list\\r\\n# 30 pt Exactly correct but is not first value in list\\r\\n# 15 pt Within 1 but is not first value in list\\r\\n\\r\\ndef base_name(name_of_script):\\r\\n    return (name_of_script.split(\\'.\\')[0]).split(\\'_\\')[2]\\r\\n\\r\\ndef solution(input_list):\\r\\n\\r\\n    # Input is a count followed by that many values\\r\\n    # Create a list of just the values\\r\\n    items_list = input_list[1:]\\r\\n    \\r\\n    # Determine the average of the values\\r\\n    average = sum(items_list) / len(items_list)\\r\\n    \\r\\n    # Count the number of items that meet the criteria\\r\\n    # This depends on the specific variant of the problem\\r\\n    base_script = base_name(script_name())\\r\\n    count = 0\\r\\n    for score in items_list:\\r\\n        if base_script == \"pushups\" and score > average:\\r\\n            count += 1\\r\\n        if base_script == \"sami\" and score > average:\\r\\n            count += 1\\r\\n        if base_script == \"tests\" and score < average:\\r\\n            count += 1\\r\\n    \\r\\n    # Output is average (rounded to 1 decimal place) and count \\r\\n    return [str(round(average,1)), str(count)]\\r\\n\\r\\ndef is_value(s):\\r\\n    try:\\r\\n        float(s)\\r\\n        return True\\r\\n    except ValueError:\\r\\n        return False\\r\\n    \\r\\n# Returns the position and distance of the closes user value from the solution value.\\r\\n# Returns found=False if list from user contains no numeric values\\r\\ndef matchup_numeric(value, from_user):\\r\\n    value = float(value)\\r\\n    found = False\\r\\n    position = -1\\r\\n    within = 1E10\\r\\n    for i in range(len(from_user)):\\r\\n        item = from_user[i]\\r\\n        if is_value(item):\\r\\n            found = True\\r\\n            user_value = float(item)\\r\\n            distance = abs(value - user_value)\\r\\n            if  distance < within:\\r\\n                within = distance\\r\\n                position = i \\r\\n                \\r\\n    return (found, position, within)\\r\\n\\r\\ndef decimal_places(float_string):\\r\\n    if is_value(float_string):\\r\\n        decimal_point_index = float_string.find(\\'.\\')\\r\\n        if decimal_point_index == -1:\\r\\n            return 0\\r\\n        else:\\r\\n            return len(float_string) - (decimal_point_index + 1)\\r\\n    else:\\r\\n        return -1\\r\\n    \\r\\ndef grade_item(name, correct_position, places, tolerance, from_soln, from_user):\\r\\n    score = 0\\r\\n    \\r\\n    value_from_soln = from_soln[correct_position]\\r\\n    \\r\\n    (found, position, within) = matchup_numeric(value_from_soln, from_user)\\r\\n    if not found:\\r\\n        print(name, \"not found.  Expected: \", value_from_soln)\\r\\n        score += 0\\r\\n    else:\\r\\n        place_penalty = 0\\r\\n        if   (position == correct_position) and (within <= tolerance[0]):\\r\\n            print(name, \"appears correct.\")\\r\\n            score += 45 - place_penalty\\r\\n        elif (position == correct_position) and (within <= tolerance[1]):\\r\\n            print(name, \"is close.  Expected: \", value_from_soln)\\r\\n            score += 30 - place_penalty\\r\\n        elif (position != correct_position) and (within <= tolerance[0]):\\r\\n            print(name, \"appears correct, but in wrong position.\")\\r\\n            score += 30 - place_penalty\\r\\n        elif  (position != correct_position) and (within <= tolerance[1]):\\r\\n            print(name, \"is close, but in wrong position.  Expected: \", value_from_soln)\\r\\n            score += 15 - place_penalty\\r\\n        else:\\r\\n            print(name, \"is not close and probably in wrong position.  Expected: \", value_from_soln)\\r\\n            score += 0\\r\\n    return score            \\r\\n\\r\\ndef run_1_test(script_being_tested, input_list):\\r\\n\\r\\n    (output, error) = autograder.run_script(script_being_tested, input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_output = solution(input_list)\\r\\n    \\r\\n    score = 0\\r\\n\\r\\n    # Number of outputs\\r\\n    if len(lines) == 2:\\r\\n        print(\"Number of output lines is correct.\")\\r\\n        score += 10\\r\\n    elif len(lines) == 1:\\r\\n        print(\"Number of output lines is not quite correct.\")\\r\\n        score += 5\\r\\n    else:\\r\\n        print(\"Number of output lines is not correct.\")\\r\\n        score += 0\\r\\n\\r\\n    score += grade_item(\"Average\", 0, 1, [0.1, 10], expected_output, lines)\\r\\n    score += grade_item(\"Count\", 1, 0, [0, 1], expected_output, lines)\\r\\n\\r\\n    print(\\'-----------------------------\\')\\r\\n\\r\\n    return score\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    script_being_tested = script_name()\\r\\n    score = 0\\r\\n    cum_weight = 0.0\\r\\n\\r\\n    # Corner Case #1 (5%) -- only a single score\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n    \\r\\n    random_people = 1\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    for i in range(random_people):\\r\\n        random_score = random.randint(30, 100)\\r\\n        input_list.append(random_score)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n\\r\\n    # Corner Case #2 (5%) -- multiple all scores that are all the same\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    random_people = random.randint(5, 10)\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    random_score = random.randint(30, 100)\\r\\n    for i in range(random_people):\\r\\n        input_list.append(random_score)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n\\r\\n    # Corner Case #3 (5%) -- scores exist that exactly match average\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    random_people = random.randint(7,15)\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    random_mean = random.randint(50, 70)\\r\\n    \\r\\n    for i in range(random_people % 3):\\r\\n        input_list.append(random_mean)\\r\\n        \\r\\n    for i in range(random_people // 3):\\r\\n        random_step = random.randint(3,20)\\r\\n        input_list.append(random_mean)\\r\\n        input_list.append(random_mean + random_step)\\r\\n        input_list.append(random_mean - random_step)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n    \\r\\n    #Corner Case # 4 makes sure students are rounding to one decimal place\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100\\r\\n    \\r\\n    input_list = [17,82,98,100,42,95,45,93,71,91,39,65,82,46,77,56,67,44]\\r\\n    rounding_score = run_1_test(script_being_tested, input_list)\\r\\n    score += weight * rounding_score\\r\\n    \\r\\n    # General Case (80%) -- 4 runs @ 20% each\\r\\n    runs = 2\\r\\n    weight = (100.0 - cum_weight)\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    \\r\\n    for run in range(runs):\\r\\n        random_people = random.randint(2, 20)\\r\\n        input_list = [random_people]\\r\\n            \\r\\n        for i in range(random_people):\\r\\n            random_score = random.randint(30, 100)\\r\\n            input_list.append(random_score)\\r\\n        \\r\\n        score += weight * run_1_test(script_being_tested, input_list)\\r\\n    score = min([score,rounding_score])\\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a3_6_missiletest': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef script_name():\\r\\n    return \"a3_6_missiletest.py\"\\r\\n\\r\\n# There should be two outputs:\\r\\n#    The average followed by a count.\\r\\n# The test cases should be constructed so that:\\r\\n#    The average is >= 30\\r\\n#    The count   is <= 20\\r\\n\\r\\n# AUTOGRADER RUBRIC for scoring one test:\\r\\n\\r\\n# Number of outputs (10 pt):\\r\\n# 10 pt Output consists of exactly two values\\r\\n#  5 pt Output consists of one value or more than two values\\r\\n#  0 pt Output consists of either zero\\r\\n\\r\\n# Output of average (45 pt):\\r\\n# 45 pt Exactly correct and is first value in list\\r\\n# 30 pt Within 0.1 and is first value in list\\r\\n# 30 pt Exactly correct but is not first value in list\\r\\n# 15 pt Within 0.1 but is not first value in list\\r\\n\\r\\n# Output of count (45 pt):\\r\\n# 45 pt Exactly correct and is first value in list\\r\\n# 30 pt Within 1 and is first value in list\\r\\n# 30 pt Exactly correct but is not first value in list\\r\\n# 15 pt Within 1 but is not first value in list\\r\\n\\r\\ndef base_name(name_of_script):\\r\\n    return (name_of_script.split(\\'.\\')[0]).split(\\'_\\')[2]\\r\\n\\r\\ndef solution(input_list):\\r\\n\\r\\n    # Input is a count followed by that many values\\r\\n    # Create a list of just the values\\r\\n    items_list = input_list[1:]\\r\\n    \\r\\n    # Determine the average of the values\\r\\n    average = sum(items_list) / len(items_list)\\r\\n    \\r\\n    # Count the number of items that meet the criteria\\r\\n    # This depends on the specific variant of the problem\\r\\n    base_script = base_name(script_name())\\r\\n    count = 0\\r\\n    for score in items_list:\\r\\n        if base_script == \"pushups\" and score > average:\\r\\n            count += 1\\r\\n        if base_script == \"sami\" and score > average:\\r\\n            count += 1\\r\\n        if base_script == \"tests\" and score < average:\\r\\n            count += 1\\r\\n        if base_script == \"flighttest\" and score < average:\\r\\n            count += 1\\r\\n        if base_script == \"missiletest\" and score > average:\\r\\n            count += 1\\r\\n    \\r\\n    # Output is average (rounded to 1 decimal place) and count \\r\\n    return [str(round(average,1)), str(count)]\\r\\n\\r\\ndef is_value(s):\\r\\n    try:\\r\\n        float(s)\\r\\n        return True\\r\\n    except ValueError:\\r\\n        return False\\r\\n    \\r\\n# Returns the position and distance of the closes user value from the solution value.\\r\\n# Returns found=False if list from user contains no numeric values\\r\\ndef matchup_numeric(value, from_user):\\r\\n    value = float(value)\\r\\n    found = False\\r\\n    position = -1\\r\\n    within = 1E10\\r\\n    for i in range(len(from_user)):\\r\\n        item = from_user[i]\\r\\n        if is_value(item):\\r\\n            found = True\\r\\n            user_value = float(item)\\r\\n            distance = abs(value - user_value)\\r\\n            if  distance < within:\\r\\n                within = distance\\r\\n                position = i \\r\\n                \\r\\n    return (found, position, within)\\r\\n\\r\\ndef decimal_places(float_string):\\r\\n    if is_value(float_string):\\r\\n        decimal_point_index = float_string.find(\\'.\\')\\r\\n        if decimal_point_index == -1:\\r\\n            return 0\\r\\n        else:\\r\\n            return len(float_string) - (decimal_point_index + 1)\\r\\n    else:\\r\\n        return -1\\r\\n    \\r\\ndef grade_item(name, correct_position, places, tolerance, from_soln, from_user):\\r\\n    score = 0\\r\\n    \\r\\n    value_from_soln = from_soln[correct_position]\\r\\n    \\r\\n    (found, position, within) = matchup_numeric(value_from_soln, from_user)\\r\\n    if not found:\\r\\n        print(name, \"not found.  Expected: \", value_from_soln)\\r\\n        score += 0\\r\\n    else:\\r\\n        place_penalty = 0\\r\\n        if   (position == correct_position) and (within <= tolerance[0]):\\r\\n            print(name, \"appears correct.\")\\r\\n            score += 45 - place_penalty\\r\\n        elif (position == correct_position) and (within <= tolerance[1]):\\r\\n            print(name, \"is close.  Expected: \", value_from_soln)\\r\\n            score += 30 - place_penalty\\r\\n        elif (position != correct_position) and (within <= tolerance[0]):\\r\\n            print(name, \"appears correct, but in wrong position.\")\\r\\n            score += 30 - place_penalty\\r\\n        elif  (position != correct_position) and (within <= tolerance[1]):\\r\\n            print(name, \"is close, but in wrong position.  Expected: \", value_from_soln)\\r\\n            score += 15 - place_penalty\\r\\n        else:\\r\\n            print(name, \"is not close and probably in wrong position.  Expected: \", value_from_soln)\\r\\n            score += 0\\r\\n    return score            \\r\\n\\r\\ndef run_1_test(script_being_tested, input_list):\\r\\n\\r\\n    (output, error) = autograder.run_script(script_being_tested, input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_output = solution(input_list)\\r\\n    \\r\\n    score = 0\\r\\n\\r\\n    # Number of outputs\\r\\n    if len(lines) == 2:\\r\\n        print(\"Number of output lines is correct.\")\\r\\n        score += 10\\r\\n    elif len(lines) == 1:\\r\\n        print(\"Number of output lines is not quite correct.\")\\r\\n        score += 5\\r\\n    else:\\r\\n        print(\"Number of output lines is not correct.\")\\r\\n        score += 0\\r\\n\\r\\n    score += grade_item(\"Average\", 0, 1, [0.1, 10], expected_output, lines)\\r\\n    score += grade_item(\"Count\", 1, 0, [0, 1], expected_output, lines)\\r\\n\\r\\n    print(\\'-----------------------------\\')\\r\\n\\r\\n    return score\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    script_being_tested = script_name()\\r\\n    score = 0\\r\\n    cum_weight = 0.0\\r\\n\\r\\n    # Corner Case #1 (5%) -- only a single score\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n    \\r\\n    random_people = 1\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    for i in range(random_people):\\r\\n        random_score = random.randint(30, 100)\\r\\n        input_list.append(random_score)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n\\r\\n    # Corner Case #2 (5%) -- multiple all scores that are all the same\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    random_people = random.randint(5, 10)\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    random_score = random.randint(30, 100)\\r\\n    for i in range(random_people):\\r\\n        input_list.append(random_score)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n\\r\\n    # Corner Case #3 (5%) -- scores exist that exactly match average\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    random_people = random.randint(7,15)\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    random_mean = random.randint(50, 70)\\r\\n    \\r\\n    for i in range(random_people % 3):\\r\\n        input_list.append(random_mean)\\r\\n        \\r\\n    for i in range(random_people // 3):\\r\\n        random_step = random.randint(3,20)\\r\\n        input_list.append(random_mean)\\r\\n        input_list.append(random_mean + random_step)\\r\\n        input_list.append(random_mean - random_step)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n    \\r\\n    #Corner Case # 4 makes sure students are rounding to one decimal place\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100\\r\\n    \\r\\n    input_list = [17,82,98,100,42,95,45,93,71,91,39,65,82,46,77,56,67,44]\\r\\n    rounding_score = run_1_test(script_being_tested, input_list)\\r\\n    score += weight * rounding_score\\r\\n    \\r\\n    # General Case (80%) -- 4 runs @ 20% each\\r\\n    runs = 2\\r\\n    weight = (100.0 - cum_weight)\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    \\r\\n    for run in range(runs):\\r\\n        random_people = random.randint(2, 20)\\r\\n        input_list = [random_people]\\r\\n            \\r\\n        for i in range(random_people):\\r\\n            random_score = random.randint(30, 100)\\r\\n            input_list.append(random_score)\\r\\n        \\r\\n        score += weight * run_1_test(script_being_tested, input_list)\\r\\n    score = min([score,rounding_score])\\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a3_6_flighttest': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef script_name():\\r\\n    return \"a3_6_flighttest.py\"\\r\\n\\r\\n# There should be two outputs:\\r\\n#    The average followed by a count.\\r\\n# The test cases should be constructed so that:\\r\\n#    The average is >= 30\\r\\n#    The count   is <= 20\\r\\n\\r\\n# AUTOGRADER RUBRIC for scoring one test:\\r\\n\\r\\n# Number of outputs (10 pt):\\r\\n# 10 pt Output consists of exactly two values\\r\\n#  5 pt Output consists of one value or more than two values\\r\\n#  0 pt Output consists of either zero\\r\\n\\r\\n# Output of average (45 pt):\\r\\n# 45 pt Exactly correct and is first value in list\\r\\n# 30 pt Within 0.1 and is first value in list\\r\\n# 30 pt Exactly correct but is not first value in list\\r\\n# 15 pt Within 0.1 but is not first value in list\\r\\n\\r\\n# Output of count (45 pt):\\r\\n# 45 pt Exactly correct and is first value in list\\r\\n# 30 pt Within 1 and is first value in list\\r\\n# 30 pt Exactly correct but is not first value in list\\r\\n# 15 pt Within 1 but is not first value in list\\r\\n\\r\\ndef base_name(name_of_script):\\r\\n    return (name_of_script.split(\\'.\\')[0]).split(\\'_\\')[2]\\r\\n\\r\\ndef solution(input_list):\\r\\n\\r\\n    # Input is a count followed by that many values\\r\\n    # Create a list of just the values\\r\\n    items_list = input_list[1:]\\r\\n    \\r\\n    # Determine the average of the values\\r\\n    average = sum(items_list) / len(items_list)\\r\\n    \\r\\n    # Count the number of items that meet the criteria\\r\\n    # This depends on the specific variant of the problem\\r\\n    base_script = base_name(script_name())\\r\\n    count = 0\\r\\n    for score in items_list:\\r\\n        if base_script == \"pushups\" and score > average:\\r\\n            count += 1\\r\\n        if base_script == \"sami\" and score > average:\\r\\n            count += 1\\r\\n        if base_script == \"tests\" and score < average:\\r\\n            count += 1\\r\\n        if base_script == \"flighttest\" and score < average:\\r\\n            count += 1\\r\\n        \\r\\n    \\r\\n    # Output is average (rounded to 1 decimal place) and count \\r\\n    return [str(round(average,1)), str(count)]\\r\\n\\r\\ndef is_value(s):\\r\\n    try:\\r\\n        float(s)\\r\\n        return True\\r\\n    except ValueError:\\r\\n        return False\\r\\n    \\r\\n# Returns the position and distance of the closes user value from the solution value.\\r\\n# Returns found=False if list from user contains no numeric values\\r\\ndef matchup_numeric(value, from_user):\\r\\n    value = float(value)\\r\\n    found = False\\r\\n    position = -1\\r\\n    within = 1E10\\r\\n    for i in range(len(from_user)):\\r\\n        item = from_user[i]\\r\\n        if is_value(item):\\r\\n            found = True\\r\\n            user_value = float(item)\\r\\n            distance = abs(value - user_value)\\r\\n            if  distance < within:\\r\\n                within = distance\\r\\n                position = i \\r\\n                \\r\\n    return (found, position, within)\\r\\n\\r\\ndef decimal_places(float_string):\\r\\n    if is_value(float_string):\\r\\n        decimal_point_index = float_string.find(\\'.\\')\\r\\n        if decimal_point_index == -1:\\r\\n            return 0\\r\\n        else:\\r\\n            return len(float_string) - (decimal_point_index + 1)\\r\\n    else:\\r\\n        return -1\\r\\n    \\r\\ndef grade_item(name, correct_position, places, tolerance, from_soln, from_user):\\r\\n    score = 0\\r\\n    \\r\\n    value_from_soln = from_soln[correct_position]\\r\\n    \\r\\n    (found, position, within) = matchup_numeric(value_from_soln, from_user)\\r\\n    if not found:\\r\\n        print(name, \"not found.  Expected: \", value_from_soln)\\r\\n        score += 0\\r\\n    else:\\r\\n        place_penalty = 0\\r\\n        if   (position == correct_position) and (within <= tolerance[0]):\\r\\n            print(name, \"appears correct.\")\\r\\n            score += 45 - place_penalty\\r\\n        elif (position == correct_position) and (within <= tolerance[1]):\\r\\n            print(name, \"is close.  Expected: \", value_from_soln)\\r\\n            score += 30 - place_penalty\\r\\n        elif (position != correct_position) and (within <= tolerance[0]):\\r\\n            print(name, \"appears correct, but in wrong position.\")\\r\\n            score += 30 - place_penalty\\r\\n        elif  (position != correct_position) and (within <= tolerance[1]):\\r\\n            print(name, \"is close, but in wrong position.  Expected: \", value_from_soln)\\r\\n            score += 15 - place_penalty\\r\\n        else:\\r\\n            print(name, \"is not close and probably in wrong position.  Expected: \", value_from_soln)\\r\\n            score += 0\\r\\n    return score            \\r\\n\\r\\ndef run_1_test(script_being_tested, input_list):\\r\\n\\r\\n    (output, error) = autograder.run_script(script_being_tested, input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_output = solution(input_list)\\r\\n    \\r\\n    score = 0\\r\\n\\r\\n    # Number of outputs\\r\\n    if len(lines) == 2:\\r\\n        print(\"Number of output lines is correct.\")\\r\\n        score += 10\\r\\n    elif len(lines) == 1:\\r\\n        print(\"Number of output lines is not quite correct.\")\\r\\n        score += 5\\r\\n    else:\\r\\n        print(\"Number of output lines is not correct.\")\\r\\n        score += 0\\r\\n\\r\\n    score += grade_item(\"Average\", 0, 1, [0.1, 10], expected_output, lines)\\r\\n    score += grade_item(\"Count\", 1, 0, [0, 1], expected_output, lines)\\r\\n\\r\\n    print(\\'-----------------------------\\')\\r\\n\\r\\n    return score\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    script_being_tested = script_name()\\r\\n    score = 0\\r\\n    cum_weight = 0.0\\r\\n\\r\\n    # Corner Case #1 (5%) -- only a single score\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n    \\r\\n    random_people = 1\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    for i in range(random_people):\\r\\n        random_score = random.randint(30, 100)\\r\\n        input_list.append(random_score)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n\\r\\n    # Corner Case #2 (5%) -- multiple all scores that are all the same\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    random_people = random.randint(5, 10)\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    random_score = random.randint(30, 100)\\r\\n    for i in range(random_people):\\r\\n        input_list.append(random_score)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n\\r\\n    # Corner Case #3 (5%) -- scores exist that exactly match average\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    random_people = random.randint(7,15)\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    random_mean = random.randint(50, 70)\\r\\n    \\r\\n    for i in range(random_people % 3):\\r\\n        input_list.append(random_mean)\\r\\n        \\r\\n    for i in range(random_people // 3):\\r\\n        random_step = random.randint(3,20)\\r\\n        input_list.append(random_mean)\\r\\n        input_list.append(random_mean + random_step)\\r\\n        input_list.append(random_mean - random_step)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n    \\r\\n    #Corner Case # 4 makes sure students are rounding to one decimal place\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100\\r\\n    \\r\\n    input_list = [17,82,98,100,42,95,45,93,71,91,39,65,82,46,77,56,67,44]\\r\\n    rounding_score = run_1_test(script_being_tested, input_list)\\r\\n    score += weight * rounding_score\\r\\n    \\r\\n    # General Case (80%) -- 4 runs @ 20% each\\r\\n    runs = 2\\r\\n    weight = (100.0 - cum_weight)\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    \\r\\n    for run in range(runs):\\r\\n        random_people = random.randint(2, 20)\\r\\n        input_list = [random_people]\\r\\n            \\r\\n        for i in range(random_people):\\r\\n            random_score = random.randint(30, 100)\\r\\n            input_list.append(random_score)\\r\\n        \\r\\n        score += weight * run_1_test(script_being_tested, input_list)\\r\\n    score = min([score,rounding_score])\\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a3_5_star_map': 'import random\\nfrom cs110 import autograder\\n\\nsimple_map = [[\\'M\\', \\'C\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'M\\', \\'P\\'],\\n              [\\'S\\', \\'M\\', \\'_\\', \\'_\\', \\'P\\', \\'M\\', \\'St\\', \\'St\\'],\\n              [\\'C\\', \\'_\\', \\'_\\', \\'P\\', \\'M\\', \\'M\\', \\'S\\', \\'M\\'],\\n              [\\'C\\', \\'C\\', \\'_\\', \\'C\\', \\'_\\', \\'S\\', \\'_\\', \\'P\\'],\\n              [\\'M\\', \\'St\\', \\'_\\', \\'St\\', \\'_\\', \\'_\\', \\'P\\', \\'S\\'],\\n              [\\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\'],\\n              [\\'_\\', \\'M\\', \\'_\\', \\'_\\', \\'M\\', \\'_\\', \\'_\\', \\'S\\'],\\n              [\\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'St\\', \\'St\\', \\'P\\', \\'P\\']]\\n\\n\\ndef check_location(row, col):\\n    print(\"-----------------------------\")\\n    print(\"Checking row:{} col:{}\".format(row+1, col+1))\\n    print(\"-----------------------------\")\\n\\n    output, error = autograder.run_script(\"a3_5_star_map.py\", [row+1, col+1])\\n\\n    if simple_map[row][col] == output.strip():\\n        print(\"Correct\\\\n\")\\n        return True\\n    else:\\n        print(\"Incorrect.  Expected:\", simple_map[row][col], \"\\\\n\")\\n        return False\\n\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    score = 0\\n\\n    if (check_location(0,\\n                       1)):\\n        score += 20\\n\\n    if (check_location(1,\\n                       random.randint(0, len(simple_map[0])-1))):\\n        score += 20\\n\\n    if (check_location(7,\\n                       random.randint(0, len(simple_map[0])-1))):\\n        score += 20\\n\\n    if (check_location(random.randint(0, len(simple_map)-1),\\n                       random.randint(0, len(simple_map[0])-1))):\\n        score += 20\\n\\n    if (check_location(random.randint(0, len(simple_map)-1),\\n                       random.randint(0, len(simple_map[0])-1))):\\n        score += 20\\n\\n    return score\\n\\n\\n# ---------------------------------------------------------------------\\n# Optional\\n# Runs your code in an IDE (for testing purposes)\\n# ---------------------------------------------------------------------\\nif __name__ == \\'__main__\\':\\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_5_map': 'import random\\nfrom cs110 import autograder\\n\\n## EDITED 15 MAR 2022 by Capt Ben McGraw\\n\\nsimple_map = [[\\'_\\', \\'T\\', \\'_\\', \\'_\\', \\'_\\', \\'R\\', \\'_\\', \\'_\\'],\\n              [\\'_\\', \\'_\\', \\'T\\', \\'S\\', \\'B\\', \\'R\\', \\'_\\', \\'_\\'],\\n              [\\'W\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'R\\', \\'_\\'],\\n              [\\'W\\', \\'W\\', \\'S\\', \\'_\\', \\'_\\', \\'B\\', \\'_\\', \\'_\\'],\\n              [\\'W\\', \\'_\\', \\'_\\', \\'S\\', \\'_\\', \\'_\\', \\'B\\', \\'R\\'],\\n              [\\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'T\\', \\'_\\', \\'_\\'],\\n              [\\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'T\\', \\'_\\'],\\n              [\\'R\\', \\'R\\', \\'R\\', \\'R\\', \\'R\\', \\'_\\', \\'_\\', \\'_\\']]\\n\\n\\ndef check_location(row, col):\\n    print(\"-----------------------------\")\\n    print(\"Checking row:{} col:{}\".format(row, col))\\n    print(\"-----------------------------\")\\n\\n    output, error = autograder.run_script(\"a3_5_map.py\", [row, col])\\n\\n    if simple_map[row][col] == output.strip():\\n        print(\"Correct\\\\n\")\\n        return True\\n    else:\\n        print(\"Incorrect.  Expected:\", simple_map[row][col], \"\\\\n\")\\n        return False\\n\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    score = 0\\n\\n    if (check_location(0,\\n                       1)):\\n        score += 20\\n\\n    if (check_location(1,\\n                       random.randint(0, len(simple_map[0])-1))):\\n        score += 20\\n\\n    if (check_location(7,\\n                       random.randint(0, len(simple_map[0])-1))):\\n        score += 20\\n\\n    if (check_location(random.randint(0, len(simple_map)-1),\\n                       random.randint(0, len(simple_map[0])-1))):\\n        score += 20\\n\\n    if (check_location(random.randint(0, len(simple_map)-1),\\n                       random.randint(0, len(simple_map[0])-1))):\\n        score += 20\\n\\n    return score\\n# ---------------------------------------------------------------------\\n# Optional\\n# Runs your code in an IDE (for testing purposes)\\n# ---------------------------------------------------------------------\\nif __name__ == \\'__main__\\':\\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_5_chess': 'import random\\nfrom cs110 import autograder\\n\\n## EDITED 15 MAR 2022 by Capt Ben McGraw\\n\\nchess_board = [[\\'R\\', \\'N\\', \\'_\\', \\'K\\', \\'_\\', \\'B\\', \\'N\\', \\'R\\'],\\n               [\\'p\\', \\'p\\', \\'p\\', \\'_\\', \\'p\\', \\'p\\', \\'p\\', \\'p\\'],\\n               [\\'_\\', \\'_\\', \\'Q\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\'],\\n               [\\'_\\', \\'_\\', \\'_\\', \\'p\\', \\'_\\', \\'B\\', \\'_\\', \\'_\\'],\\n               [\\'_\\', \\'_\\', \\'_\\', \\'p\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\'],\\n               [\\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'p\\', \\'_\\', \\'_\\', \\'_\\'],\\n               [\\'p\\', \\'p\\', \\'p\\', \\'_\\', \\'_\\', \\'p\\', \\'p\\', \\'p\\'],\\n               [\\'R\\', \\'N\\', \\'B\\', \\'K\\', \\'Q\\', \\'B\\', \\'N\\', \\'R\\']]\\n\\n\\ndef check_location(row, col):\\n    print(\"-----------------------------\")\\n    print(\"Checking row:{} col:{}\".format(row, col))\\n    print(\"-----------------------------\")\\n\\n    output, error = autograder.run_script(\"a3_5_chess.py\", [row, col])\\n\\n    if chess_board[row][col] == output.strip():\\n        print(\"Correct\\\\n\")\\n        return True\\n    else:\\n        print(\"Incorrect.  Expected:\", chess_board[row][col], \"\\\\n\")\\n        return False\\n\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    score = 0\\n\\n    if (check_location(0,\\n                       2)):\\n        score += 20\\n\\n    if (check_location(1,\\n                       random.randint(0, len(chess_board[0])-1))):\\n        score += 20\\n\\n    if (check_location(7,\\n                       random.randint(0, len(chess_board[0])-1))):\\n        score += 20\\n\\n    if (check_location(random.randint(0, len(chess_board)-1),\\n                       random.randint(0, len(chess_board[0])-1))):\\n        score += 20\\n\\n    if (check_location(random.randint(0, len(chess_board)-1),\\n                       random.randint(0, len(chess_board[0])-1))):\\n        score += 20\\n\\n    return score\\n\\n# ---------------------------------------------------------------------\\n# Optional\\n# Runs your code in an IDE (for testing purposes)\\n# ---------------------------------------------------------------------\\nif __name__ == \\'__main__\\':\\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_5_carnival': 'import random\\nfrom cs110 import autograder\\n\\n## EDITED 15 MAR 2022 by Capt Ben McGraw\\n\\nsimple_map = [[\\'O\\', \\'_\\', \\'_\\', \\'P\\', \\'_\\', \\'R\\', \\'_\\', \\'G\\'],\\n              [\\'R\\', \\'O\\', \\'_\\', \\'_\\', \\'_\\', \\'P\\', \\'_\\', \\'_\\'],\\n              [\\'_\\', \\'_\\', \\'O\\', \\'_\\', \\'_\\', \\'O\\', \\'P\\', \\'_\\'],\\n              [\\'R\\', \\'_\\', \\'G\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'P\\'],\\n              [\\'B\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'P\\'],\\n              [\\'G\\', \\'R\\', \\'P\\', \\'O\\', \\'O\\', \\'_\\', \\'_\\', \\'G\\'],\\n              [\\'P\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'G\\', \\'B\\', \\'_\\'],\\n              [\\'B\\', \\'R\\', \\'G\\', \\'B\\', \\'_\\', \\'G\\', \\'B\\', \\'G\\']]\\n\\n\\ndef check_location(row, col):\\n    print(\"-----------------------------\")\\n    print(\"Checking row:{} col:{}\".format(row, col))\\n    print(\"-----------------------------\")\\n\\n    output, error = autograder.run_script(\"a3_5_carnival.py\", [row, col])\\n\\n    if simple_map[row][col] == output.strip():\\n        print(\"Correct\\\\n\")\\n        return True\\n    else:\\n        print(\"Incorrect.  Expected:\", simple_map[row][col], \"\\\\n\")\\n        return False\\n\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    score = 0\\n\\n    if (check_location(0,\\n                       3)):\\n        score += 20\\n\\n    if (check_location(1,\\n                       random.randint(0, len(simple_map[0])-1))):\\n        score += 20\\n\\n    if (check_location(7,\\n                       random.randint(0, len(simple_map[0])-1))):\\n        score += 20\\n\\n    if (check_location(random.randint(0, len(simple_map)-1),\\n                       random.randint(0, len(simple_map[0])-1))):\\n        score += 20\\n\\n    if (check_location(random.randint(0, len(simple_map)-1),\\n                       random.randint(0, len(simple_map[0])-1))):\\n        score += 20\\n\\n    return score\\n\\n# ---------------------------------------------------------------------\\n# Optional\\n# Runs your code in an IDE (for testing purposes)\\n# ---------------------------------------------------------------------\\nif __name__ == \\'__main__\\':\\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_5_battleship': 'import random\\nfrom cs110 import autograder\\n\\n## EDITED 15 MAR 2022 by Capt Ben McGraw\\n\\nbattleship_board = [[\\'_\\', \\'_\\', \\'C\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\'],\\n                    [\\'_\\', \\'_\\', \\'C\\', \\'S\\', \\'S\\', \\'S\\', \\'_\\', \\'_\\'],\\n                    [\\'D\\', \\'D\\', \\'C\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\'],\\n                    [\\'_\\', \\'_\\', \\'C\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\'],\\n                    [\\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'R\\', \\'R\\', \\'R\\'],\\n                    [\\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\'],\\n                    [\\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\'],\\n                    [\\'_\\', \\'B\\', \\'B\\', \\'B\\', \\'B\\', \\'_\\', \\'_\\', \\'_\\']]\\n\\n\\ndef check_location(row, col):\\n    print(\"-----------------------------\")\\n    print(\"Checking row:{} col:{}\".format(row, col))\\n    print(\"-----------------------------\")\\n\\n    output, error = autograder.run_script(\"a3_5_battleship.py\", [row, col])\\n\\n    if battleship_board[row][col] == output.strip():\\n        print(\"Correct\\\\n\")\\n        return True\\n    else:\\n        print(\"Incorrect.  Expected:\", battleship_board[row][col], \"\\\\n\")\\n        return False\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    score = 0\\n    if check_location(0, 2):\\n        score += 20\\n    if check_location(1, random.randint(0, len(battleship_board[0])-1)):\\n        score += 20\\n    if check_location(7, random.randint(0, len(battleship_board[0])-1)):\\n        score += 20\\n    if check_location(random.randint(0, len(battleship_board)-1),\\n                      random.randint(0, len(battleship_board[0])-1)):\\n        score += 20\\n    if check_location(random.randint(0, len(battleship_board)-1),\\n                      random.randint(0, len(battleship_board[0])-1)):\\n        score += 20\\n    return score\\n\\n\\n# ---------------------------------------------------------------------\\n# Optional\\n# Runs your code in an IDE (for testing purposes)\\n# ---------------------------------------------------------------------\\nif __name__ == \\'__main__\\':\\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_4_weights': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nSTUDENT_FILE = \"a3_4_weights.py\"\\r\\nANSWER = 5416\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    output, error = autograder.run_script(STUDENT_FILE, [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    score = 0\\r\\n    \\r\\n    if len(lines) >= 1:           \\r\\n        if autograder.equals(lines[0], ANSWER):\\r\\n            print(\"CORRECT: Range Looks Good!\")\\r\\n            score += 100\\r\\n        else:\\r\\n            print(\"Incorrect range.  Remember that the range is the difference between the max and the min\")\\r\\n            \\r\\n    else:\\r\\n        print(\"More lines expected in your answer.  Make sure you are printing out the range.\")\\r\\n    \\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a3_4_run': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nSTUDENT_FILE = \"a3_4_run.py\"\\r\\nANSWER = 4491\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    output, error = autograder.run_script(STUDENT_FILE, [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    score = 0\\r\\n    \\r\\n    if len(lines) >= 1:           \\r\\n        if autograder.equals(lines[0], ANSWER):\\r\\n            print(\"CORRECT: Range Looks Good!\")\\r\\n            score += 100\\r\\n        else:\\r\\n            print(\"Incorrect range.  Remember that the range is the difference between the max and the min\")\\r\\n            \\r\\n    else:\\r\\n        print(\"More lines expected in your answer.  Make sure you are printing out the range.\")\\r\\n    \\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a3_4_ptscores': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nSTUDENT_FILE = \"a3_4_ptscores.py\"\\r\\nANSWER = 6068\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    output, error = autograder.run_script(STUDENT_FILE, [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    score = 0\\r\\n    \\r\\n    if len(lines) >= 1:           \\r\\n        if autograder.equals(lines[0], ANSWER):\\r\\n            print(\"CORRECT: Range Looks Good!\")\\r\\n            score += 100\\r\\n        else:\\r\\n            print(\"Incorrect range.  Remember that the range is the difference between the max and the min\")\\r\\n            \\r\\n    else:\\r\\n        print(\"More lines expected in your answer.  Make sure you are printing out the range.\")\\r\\n    \\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a3_4_ages': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nSTUDENT_FILE = \"a3_4_ages.py\"\\r\\nANSWER = 9840\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    output, error = autograder.run_script(STUDENT_FILE, [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    score = 0\\r\\n    \\r\\n    if len(lines) >= 1:           \\r\\n        if autograder.equals(lines[0], ANSWER):\\r\\n            print(\"CORRECT: Range Looks Good!\")\\r\\n            score += 100\\r\\n        else:\\r\\n            print(\"Incorrect range.  Remember that the range is the difference between the max and the min\")\\r\\n            \\r\\n    else:\\r\\n        print(\"More lines expected in your answer.  Make sure you are printing out the range.\")\\r\\n    \\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a3_3_ships': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nlist_of_ship_classes = [\\'Ford\\', \\'Ticonderoga\\', \\'Arleigh Burke\\', \\'Virginia\\', \\'Zumwalt\\', \\'Hamilton\\', \\'Legend\\']\\r\\n\\r\\ndef solution():\\r\\n    result = []\\r\\n    \\r\\n    for item in list_of_ship_classes:\\r\\n        result.append(item)\\r\\n    \\r\\n    return result\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    output, error = autograder.run_script(\"a3_3_ships.py\", [])\\r\\n    expected_output = solution()\\r\\n    num_matches = autograder.compare_strings(output.strip().split(\\'\\\\n\\'), expected_output)\\r\\n    \\r\\n    return round(100 / len(expected_output) * num_matches, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_3_pizza': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nlist_of_pizza_toppings = [\\'Pepporoni\\', \\'Sausage\\', \\'Onion\\', \\'Mushroom\\', \\'Peppers\\', \\'Chicken\\', \\'Hamburger\\']\\r\\n\\r\\ndef solution():\\r\\n    result = []\\r\\n    \\r\\n    for item in list_of_pizza_toppings:\\r\\n        result.append(item)\\r\\n    \\r\\n    return result\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    output, error = autograder.run_script(\"a3_3_pizza.py\", [])\\r\\n    expected_output = solution()\\r\\n    num_matches = autograder.compare_strings(output.strip().split(\\'\\\\n\\'), expected_output)\\r\\n    \\r\\n    return round(100 / len(expected_output) * num_matches, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_3_aircraft': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nlist_of_aircraft_classes = [\\'Attack\\',\\'Cargo\\',\\'Drone\\', \\'Fighter\\', \\'Unmanned\\',\\'Trainer\\',\\'Tanker\\']\\r\\n\\r\\ndef solution():\\r\\n    result = []\\r\\n    \\r\\n    for item in list_of_aircraft_classes:\\r\\n        result.append(item)\\r\\n    \\r\\n    return result\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    output, error = autograder.run_script(\"a3_3_aircraft.py\", [])\\r\\n    expected_output = solution()\\r\\n    num_matches = autograder.compare_strings(output.strip().split(\\'\\\\n\\'), expected_output)\\r\\n    \\r\\n    return round(100 / len(expected_output) * num_matches, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_2_jets': 'from cs110 import autograder\\nimport random, math\\n\\nlist_of_jets = [\\'F-16\\', \\'F-15\\', \\'F-22\\', \\'F-35\\', \\'B-1\\', \\'B-2\\']\\n\\n\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n\\n    index_list = [1, random.randint(2, len(list_of_jets)-2), len(list_of_jets)]\\n    score = 0\\n\\n    new_jets = [\"B-52\",\"KC-10\",\"KC-135\",\"A-10\",\"AC-130\",\"C-130\",\"CV-22\"]\\n\\n    random_ac1 = new_jets[random.randint(0, len(new_jets)-1)]\\n    new_jets.remove(random_ac1)\\n    random_ac2 = new_jets[random.randint(0, len(new_jets)-1)]\\n\\n    list_of_jets.append(random_ac1)\\n    list_of_jets.append(random_ac2)\\n\\n    output, error = autograder.run_script(\"a3_2_jets.py\", [random_ac1, random_ac2])\\n    output = output.strip().replace(\"[\", \"\")\\n    output = output.strip().replace(\"]\", \"\")\\n    output = output.strip().replace(\"\\'\", \"\")\\n    lines = output.split(\\',\\')\\n\\n    if lines[len(lines)-2].strip() == list_of_jets[len(list_of_jets)-2]:\\n        print(\"Second to Last Element in List is Correct!\")\\n        score += 50\\n    else:\\n        print(\"Incorrect Second to Last Element in List.  Expected:\", random_ac1, \"instead of\", lines[len(lines)-2].strip())\\n\\n    if lines[len(lines)-1].strip() == list_of_jets[len(list_of_jets)-1]:\\n        print(\"Last Element in List is Correct!\")\\n        score += 50\\n    else:\\n        print(\"Incorrect Last Element in List.  Expected:\", random_ac2, \"instead of\", lines[len(lines)-1].strip())\\n\\n    return score\\n\\n# ---------------------------------------------------------------------\\n# Optional\\n# Runs your code in an IDE (for testing purposes)\\n# ---------------------------------------------------------------------\\nif __name__ == \\'__main__\\':\\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a3_2_grammys': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ngrammy_list = [\\'Pop\\', \\'Global\\', \\'Rock\\', \\'Rap\\', \\'Jazz\\', \\'R&B\\', \\'Comedy\\']\\r\\n\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    index_list = [1, random.randint(2, len(grammy_list)-2), len(grammy_list)]\\r\\n    score = 0\\r\\n\\r\\n    new_categories = [\"Dance\", \"Country\", \"Classical\", \"Gospel\", \"Alternative\", \"Soundtrack\", \"Instrumental\", \"Latin\", \"Reggae\"]\\r\\n    \\r\\n    random_ac1 = new_categories[random.randint(0, len(new_categories)-1)]\\r\\n    new_categories.remove(random_ac1)\\r\\n    random_ac2 = new_categories[random.randint(0, len(new_categories)-1)]\\r\\n    \\r\\n    grammy_list.append(random_ac1)\\r\\n    grammy_list.append(random_ac2)\\r\\n\\r\\n    output, error = autograder.run_script(\"a3_2_grammys.py\", [random_ac1, random_ac2])\\r\\n    output = output.strip().replace(\"[\", \"\")\\r\\n    output = output.strip().replace(\"]\", \"\")\\r\\n    output = output.strip().replace(\"\\'\", \"\")\\r\\n    lines = output.split(\\',\\')\\r\\n    \\r\\n    if lines[len(lines)-2].strip() == grammy_list[len(grammy_list)-2]:\\r\\n        print(\"Second to Last Element in List is Correct!\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Incorrect Second to Last Element in List.  Expected:\", random_ac1, \"instead of\", lines[len(lines)-2].strip())\\r\\n    \\r\\n    if lines[len(lines)-1].strip() == grammy_list[len(grammy_list)-1]:\\r\\n        print(\"Last Element in List is Correct!\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Incorrect Last Element in List.  Expected:\", random_ac2, \"instead of\", lines[len(lines)-1].strip())\\r\\n    \\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_2_departments': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndepartment_list = [\\'Science\\',\\'Engineering\\',\\'Humanities\\',\\'Social Science\\']\\r\\n\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    index_list = [1, random.randint(2, len(department_list)-2), len(department_list)]\\r\\n    score = 0\\r\\n\\r\\n    new_departments = [\\'Education\\', \\'E-Sports\\', \\'8-Bit Gaming\\', \\'Midi Music\\', \\'General Studies\\', \"Deep Space\", \"Department of Motor Vehicles\"]\\r\\n    \\r\\n    random_ac1 = new_departments[random.randint(0, len(new_departments)-1)]\\r\\n    new_departments.remove(random_ac1)\\r\\n    random_ac2 = new_departments[random.randint(0, len(new_departments)-1)]\\r\\n    \\r\\n    department_list.append(random_ac1)\\r\\n    department_list.append(random_ac2)\\r\\n\\r\\n    output, error = autograder.run_script(\"a3_2_departments.py\", [random_ac1, random_ac2])\\r\\n    output = output.strip().replace(\"[\", \"\")\\r\\n    output = output.strip().replace(\"]\", \"\")\\r\\n    output = output.strip().replace(\"\\'\", \"\")\\r\\n    lines = output.split(\\',\\')\\r\\n    \\r\\n    if lines[len(lines)-2].strip() == department_list[len(department_list)-2]:\\r\\n        print(\"Second to Last Element in List is Correct!\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Incorrect Second to Last Element in List.  Expected:\", random_ac1, \"instead of\", lines[len(lines)-2].strip())\\r\\n    \\r\\n    if lines[len(lines)-1].strip() == department_list[len(department_list)-1]:\\r\\n        print(\"Last Element in List is Correct!\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Incorrect Last Element in List.  Expected:\", random_ac2, \"instead of\", lines[len(lines)-1].strip())\\r\\n    \\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_2_cities': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nlist_of_cities = [\\'Tokyo\\', \\'Delhi\\', \\'Shanghai\\', \\'Cairo\\', \\'Mumbai\\', \\'Bejing\\', \\'Dhaka\\']\\r\\n\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    index_list = [1, random.randint(2, len(list_of_cities)-2), len(list_of_cities)]\\r\\n    score = 0\\r\\n\\r\\n    new_cities = [\"Osaka\", \"Karachi\", \"Istanbul\", \"Kolkata\", \"Manila\", \"Lagos\", \"Moscow\", \"Lahore\", \"Paris\"]\\r\\n    \\r\\n    random_ac1 = new_cities[random.randint(0, len(new_cities)-1)]\\r\\n    new_cities.remove(random_ac1)\\r\\n    random_ac2 = new_cities[random.randint(0, len(new_cities)-1)]\\r\\n    \\r\\n    list_of_cities.append(random_ac1)\\r\\n    list_of_cities.append(random_ac2)\\r\\n\\r\\n    output, error = autograder.run_script(\"a3_2_cities.py\", [random_ac1, random_ac2])\\r\\n    output = output.strip().replace(\"[\", \"\")\\r\\n    output = output.strip().replace(\"]\", \"\")\\r\\n    output = output.strip().replace(\"\\'\", \"\")\\r\\n    lines = output.split(\\',\\')\\r\\n    \\r\\n    if lines[len(lines)-2].strip() == list_of_cities[len(list_of_cities)-2]:\\r\\n        print(\"Second to Last Element in List is Correct!\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Incorrect Second to Last Element in List.  Expected:\", random_ac1, \"instead of\", lines[len(lines)-2].strip())\\r\\n    \\r\\n    if lines[len(lines)-1].strip() == list_of_cities[len(list_of_cities)-1]:\\r\\n        print(\"Last Element in List is Correct!\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Incorrect Last Element in List.  Expected:\", random_ac2, \"instead of\", lines[len(lines)-1].strip())\\r\\n    \\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_2_cars': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nlist_of_cars = [\\'Viper\\', \\'Highlander\\', \\'Audi A8\\', \\'Tundra\\', \\'Porsche\\', \\'Mazada\\', \\'Fiesta\\']\\r\\n\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    index_list = [1, random.randint(2, len(list_of_cars)-2), len(list_of_cars)]\\r\\n    score = 0\\r\\n\\r\\n    new_cars = [\"Ford\", \"Maserati\", \"BMW\", \"Cheetah\", \"Scion\", \"Lambo\", \"Pilot\", \"Civic\", \"Corolla\"]\\r\\n    \\r\\n    random_ac1 = new_cars[random.randint(0, len(new_cars)-1)]\\r\\n    new_cars.remove(random_ac1)\\r\\n    random_ac2 = new_cars[random.randint(0, len(new_cars)-1)]\\r\\n    \\r\\n    list_of_cars.append(random_ac1)\\r\\n    list_of_cars.append(random_ac2)\\r\\n\\r\\n    output, error = autograder.run_script(\"a3_2_cars.py\", [random_ac1, random_ac2])\\r\\n    output = output.strip().replace(\"[\", \"\")\\r\\n    output = output.strip().replace(\"]\", \"\")\\r\\n    output = output.strip().replace(\"\\'\", \"\")\\r\\n    lines = output.split(\\',\\')\\r\\n    \\r\\n    if lines[len(lines)-2].strip() == list_of_cars[len(list_of_cars)-2]:\\r\\n        print(\"Second to Last Element in List is Correct!\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Incorrect Second to Last Element in List.  Expected:\", random_ac1, \"instead of\", lines[len(lines)-2].strip())\\r\\n    \\r\\n    if lines[len(lines)-1].strip() == list_of_cars[len(list_of_cars)-1]:\\r\\n        print(\"Last Element in List is Correct!\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Incorrect Last Element in List.  Expected:\", random_ac2, \"instead of\", lines[len(lines)-1].strip())\\r\\n    \\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_1_medals': 'from cs110 import autograder\\nimport random, math\\n\\nsoln_list = [\\n                    \\'Congressional Medal of Honor\\', \\'Air Force Cross\\',\\t\\'Air Force Distinguished Service Medal\\',\\n                    \"Airman\\'s Medal\",\\t\"Aerial Achievement Medal\",\\t\"Air Force Commendation Medal\",\\n                    \"Air Force Achievement Medal\", \\'Air Force Combat Action Medal\\',\\t\\'Combat Readiness Medal\\',\\n                    \\'Air and Space Campaign Medal\\',\\t\\'Nuclear Deterrence Operations Service Medal\\',\\n                    \\'Remote Combat Effects Campaign Medal\\'\\n            ] \\n             \\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    \\n    index_list = [1, random.randint(2, len(soln_list)-2), len(soln_list)]\\n    tests_passed = 0\\n\\n    for i in range(len(index_list)):\\n        print(\"----------------------------------------------------------\")\\n        print(\"Testing item #\" + str(index_list[i]) + \": \")\\n        print(\"----------------------------------------------------------\")\\n               \\n        # Runs the Script\\n        output, error_message = autograder.run_script(\"a3_1_medals.py\", [index_list[i]])\\n\\n        # Test Goes Here\\n        lines = output.split(\"\\\\n\")\\n        \\n        if lines[0] == soln_list[index_list[i]-1]:\\n            print(\"Looks Good!\")\\n            tests_passed += 1\\n        elif error_message == \\'\\' and lines[0] != soln_list[index_list[i]-1]:\\n            print(\"Unexpected Output (Expected \" + str(soln_list[index_list[i]-1]) + \")\")\\n    \\n        print()\\n    \\n    return (100 / len(index_list)) * tests_passed\\n\\n\\n# ---------------------------------------------------------------------\\n# Optional\\n# Runs your code in an IDE (for testing purposes)\\n# ---------------------------------------------------------------------\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_1_countries': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nsoln_list = [\\'United States\\', \\'United Kingdom\\', \\'Australia\\', \\'South Korea\\', \\'Czech Republic\\', \\'Romania\\', \\'El Salvador\\', \\'Estonia\\', \\r\\n             \\'Bulgaria\\', \\'Moldova\\', \\'Albania\\', \\'Ukraine\\', \\'Denmark\\', \\'Tonga\\', \\'Azerbaijan\\', \\'Singapore\\', \\'Bosnia\\', \\'Macedonia\\',\\r\\n             \\'Latvia\\', \\'Poland\\', \\'Kazakhstan\\']\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    index_list = [1, random.randint(2, len(soln_list)-2), len(soln_list)]\\r\\n    tests_passed = 0\\r\\n\\r\\n    for i in range(len(index_list)):\\r\\n        print(\"----------------------------------------------------------\")\\r\\n        print(\"Testing item #\" + str(index_list[i]) + \": \")\\r\\n        print(\"----------------------------------------------------------\")\\r\\n               \\r\\n        # Runs the Script\\r\\n        output, error_message = autograder.run_script(\"a3_1_countries.py\", [index_list[i]])\\r\\n\\r\\n        # Test Goes Here\\r\\n        lines = output.split(\"\\\\n\")\\r\\n        \\r\\n        if lines[0] == soln_list[index_list[i]-1]:\\r\\n            print(\"Looks Good!\")\\r\\n            tests_passed += 1\\r\\n        elif error_message == \\'\\' and lines[0] != soln_list[index_list[i]-1]:\\r\\n            print(\"Unexpected Output (Expected \" + str(soln_list[index_list[i]-1]) + \")\")\\r\\n    \\r\\n        print()\\r\\n    \\r\\n    return (100 / len(index_list)) * tests_passed\\r\\n\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_1_commands': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nlist_of_usaf_commands = [\\'ACC\\',\\'AETC\\',\\'AFGSC\\',\\'AFMC\\',\\r\\n                         \\'AFRC\\',\\'AFSOC\\',\\'AMC\\',\\'PACAF\\',\\r\\n                         \\'USAFE\\']\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    index_list = [1, random.randint(2, len(list_of_usaf_commands)-2), len(list_of_usaf_commands)]\\r\\n    tests_passed = 0\\r\\n\\r\\n    for i in range(len(index_list)):\\r\\n        print(\"----------------------------------------------------------\")\\r\\n        print(\"Testing item #\" + str(index_list[i]) + \": \")\\r\\n        print(\"----------------------------------------------------------\")\\r\\n               \\r\\n        # Runs the Script\\r\\n        output, error_message = autograder.run_script(\"a3_1_commands.py\", [index_list[i]])\\r\\n\\r\\n        # Test Goes Here\\r\\n        lines = output.split(\"\\\\n\")\\r\\n        \\r\\n        if lines[0] == list_of_usaf_commands[index_list[i]-1]:\\r\\n            print(\"Looks Good!\")\\r\\n            tests_passed += 1\\r\\n        elif error_message == \\'\\' and lines[0] != list_of_usaf_commands[index_list[i]-1]:\\r\\n            print(\"Unexpected Output (Expected \" + str(list_of_usaf_commands[index_list[i]-1]) + \")\")\\r\\n    \\r\\n        print()\\r\\n    \\r\\n    return (100 / len(index_list)) * tests_passed\\r\\n\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a3_1_afbs': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nsoln_list = [\\'Travis\\', \\'Eglin\\', \\'Offutt\\', \\'Minot\\', \\'Luke\\', \\'Malmstrom\\', \\'Ellsworth\\', \\'Patrick\\', \\'Moody\\', \\'Barksdale\\',\\r\\n             \\'Maxwell\\', \\'Mountain Home\\', \\'Keesler\\', \\'Lackland\\', \\'Kelly\\', \\'Andrews\\', \\'Tinker\\', \\'Peterson\\', \\'Buckley\\',\\r\\n             \\'Hill\\', \\'Dyess\\', \\'Wright-Patterson\\', \\'Nellis\\']\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    index_list = [1, random.randint(2, len(soln_list)-2), len(soln_list)]\\r\\n    tests_passed = 0\\r\\n\\r\\n    for i in range(len(index_list)):\\r\\n        print(\"----------------------------------------------------------\")\\r\\n        print(\"Testing item #\" + str(index_list[i]) + \": \")\\r\\n        print(\"----------------------------------------------------------\")\\r\\n               \\r\\n        # Runs the Script\\r\\n        output, error_message = autograder.run_script(\"a3_1_afbs.py\", [index_list[i]])\\r\\n\\r\\n        # Test Goes Here\\r\\n        lines = output.split(\"\\\\n\")\\r\\n        \\r\\n        if lines[0] == soln_list[index_list[i]-1]:\\r\\n            print(\"Looks Good!\")\\r\\n            tests_passed += 1\\r\\n        elif error_message == \\'\\' and lines[0] != soln_list[index_list[i]-1]:\\r\\n            print(\"Unexpected Output (Expected \" + str(soln_list[index_list[i]-1]) + \")\")\\r\\n    \\r\\n        print()\\r\\n    \\r\\n    return (100 / len(index_list)) * tests_passed\\r\\n\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_7_lowest_spec_attack': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(pokemon_type):\\r\\n    file = open(\"pokemon.csv\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    lines = file_contents.split(\\'\\\\n\\')\\r\\n\\r\\n    lowest_value = 999\\r\\n    lowest_name = \"UNKNOWN\"\\r\\n\\r\\n    for line in lines:\\r\\n        columns = line.split(\\',\\')\\r\\n        p_name  = columns[1]\\r\\n        p_type  = columns[2]\\r\\n        p_value = float(columns[6])\\r\\n        \\r\\n        if p_type == pokemon_type:\\r\\n            if p_value < lowest_value:\\r\\n                lowest_value = p_value\\r\\n                lowest_name = p_name\\r\\n\\r\\n    return (lowest_value, lowest_name)\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    list_of_types = [\"Poison\", \"Grass\", \"Electric\", \"Fire\"]\\r\\n    random_type = list_of_types[random.randint(0, len(list_of_types)-1)]\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_7_lowest_spec_attack.py\", [random_type])\\r\\n    expected_output = solution(random_type)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Lowest Value Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Lowest Value Incorrect.  Expected:\", expected_output[0])\\r\\n    \\r\\n    if len(lines) > 1 and lines[1] == expected_output[1]:\\r\\n        print(\"Name is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Name is Incorrect.  Expected:\", expected_output[1])\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_7_lowest_defense': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(pokemon_type):\\r\\n    file = open(\"pokemon.csv\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    lines = file_contents.split(\\'\\\\n\\')\\r\\n\\r\\n    lowest_value = 999\\r\\n    lowest_name = \"UNKNOWN\"\\r\\n\\r\\n    for line in lines:\\r\\n        columns = line.split(\\',\\')\\r\\n        p_name  = columns[1]\\r\\n        p_type  = columns[2]\\r\\n        p_value = float(columns[5])\\r\\n        \\r\\n        if p_type == pokemon_type:\\r\\n            if p_value < lowest_value:\\r\\n                lowest_value = p_value\\r\\n                lowest_name = p_name\\r\\n\\r\\n    return (lowest_value, lowest_name)\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    list_of_types = [\"Poison\", \"Grass\", \"Electric\", \"Fire\"]\\r\\n    random_type = list_of_types[random.randint(0, len(list_of_types)-1)]\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_7_lowest_defense.py\", [random_type])\\r\\n    expected_output = solution(random_type)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Lowest Value Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Lowest Value Incorrect.  Expected:\", expected_output[0])\\r\\n    \\r\\n    if len(lines) > 1 and lines[1] == expected_output[1]:\\r\\n        print(\"Name is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Name is Incorrect.  Expected:\", expected_output[1])\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_7_highest_hp': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(pokemon_type):\\r\\n    file = open(\"pokemon.csv\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    lines = file_contents.split(\\'\\\\n\\')\\r\\n\\r\\n    highest_value = -999\\r\\n    highest_name = \"UNKNOWN\"\\r\\n\\r\\n    for line in lines:\\r\\n        columns = line.split(\\',\\')\\r\\n        p_name  = columns[1]\\r\\n        p_type  = columns[2]\\r\\n        p_value = float(columns[3])\\r\\n        \\r\\n        if p_type == pokemon_type:\\r\\n            if p_value > highest_value:\\r\\n                highest_value = p_value\\r\\n                highest_name = p_name\\r\\n\\r\\n    return (highest_value, highest_name)\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    list_of_types = [\"Poison\", \"Grass\", \"Electric\", \"Fire\"]\\r\\n    random_type = list_of_types[random.randint(0, len(list_of_types)-1)]\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_7_highest_hp.py\", [random_type])\\r\\n    expected_output = solution(random_type)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Highest Value Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Highest Value Incorrect.  Expected:\", expected_output[0])\\r\\n    \\r\\n    if len(lines) > 1 and lines[1] == expected_output[1]:\\r\\n        print(\"Name is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Name is Incorrect.  Expected:\", expected_output[1])\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_7_fastest': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(pokemon_type):\\r\\n    file = open(\"pokemon.csv\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    lines = file_contents.split(\\'\\\\n\\')\\r\\n\\r\\n    fastest_value = 0\\r\\n    fastest_name = \"UNKNOWN\"\\r\\n\\r\\n    for line in lines:\\r\\n        columns = line.split(\\',\\')\\r\\n        p_name  = columns[1]\\r\\n        p_type  = columns[2]\\r\\n        p_value = float(columns[8])\\r\\n        \\r\\n        if p_type == pokemon_type:\\r\\n            if p_value > fastest_value:\\r\\n                fastest_value = p_value\\r\\n                fastest_name = p_name\\r\\n\\r\\n    return (fastest_value, fastest_name)\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    list_of_types = [\"Poison\", \"Grass\", \"Electric\", \"Fire\"]\\r\\n    random_type = list_of_types[random.randint(0, len(list_of_types)-1)]\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_7_fastest.py\", [random_type])\\r\\n    expected_output = solution(random_type)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Fastest Value Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Fastest Value Incorrect.  Expected:\", expected_output[0])\\r\\n    \\r\\n    if len(lines) > 1 and lines[1] == expected_output[1]:\\r\\n        print(\"Name is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Name is Incorrect.  Expected:\", expected_output[1])\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_7_attack': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(pokemon_type):\\r\\n    file = open(\"pokemon.csv\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    lines = file_contents.split(\\'\\\\n\\')\\r\\n\\r\\n    highest_value = -999\\r\\n    highest_name = \"UNKNOWN\"\\r\\n\\r\\n    for line in lines:\\r\\n        columns = line.split(\\',\\')\\r\\n        p_name  = columns[1]\\r\\n        p_type  = columns[2]\\r\\n        p_value = float(columns[4])\\r\\n        \\r\\n        if p_type == pokemon_type:\\r\\n            if p_value > highest_value:\\r\\n                highest_value = p_value\\r\\n                highest_name = p_name\\r\\n\\r\\n    return (highest_value, highest_name)\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    list_of_types = [\"Poison\", \"Grass\", \"Electric\", \"Fire\"]\\r\\n    random_type = list_of_types[random.randint(0, len(list_of_types)-1)]\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_7_attack.py\", [random_type])\\r\\n    expected_output = solution(random_type)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Highest Value Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Highest Value Incorrect.  Expected:\", expected_output[0])\\r\\n    \\r\\n    if len(lines) > 1 and lines[1] == expected_output[1]:\\r\\n        print(\"Name is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Name is Incorrect.  Expected:\", expected_output[1])\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_6_virus': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(num_violating, num_people):    \\r\\n    inputs = [num_people]\\r\\n    \\r\\n    for i in range(num_people):\\r\\n        if i < num_violating:\\r\\n            if (i + 1 == num_violating):\\r\\n                inputs.append(6)\\r\\n            else:\\r\\n                inputs.append(round(random.uniform(0, 6), 1))\\r\\n        else:\\r\\n            inputs.append(round(random.uniform(7, 20), 1))\\r\\n\\r\\n    # Generates Expected Answer\\r\\n    if num_violating == 0:\\r\\n        answer = \"All Clear\"\\r\\n    elif num_violating <= 2:\\r\\n        answer = \"Warning\"\\r\\n    else:\\r\\n        answer = \"Find Another Place\"\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"a2_6_virus.py\", inputs)\\r\\n    \\r\\n    print(\"Testing when\", num_violating, \"out of\", num_people, \"are violating . . . \")\\r\\n    print(\"  Inputs:\", inputs)\\r\\n    print(\"  Result: \", end=\\'\\')\\r\\n    \\r\\n    if answer.strip() == output.strip():\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected: \\'\" + answer + \"\\' instead of \\'\" + output + \"\\'\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_passed = 0\\r\\n    \\r\\n    if (run_test(0, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(1, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(2, random.randint(2, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(3, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n        \\r\\n    return (100 / 4) * num_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_6_traffic_lights': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(num_over, traffic):    \\r\\n    inputs = [traffic]\\r\\n    \\r\\n    for i in range(traffic):\\r\\n        if i < num_over:\\r\\n            if (i + 1 == num_over):\\r\\n                inputs.append(15)\\r\\n            else:\\r\\n                inputs.append(round(random.uniform(15, 30), 1))\\r\\n        else:\\r\\n            inputs.append(round(random.uniform(1, 15), 1))\\r\\n\\r\\n    # Generates Expected Answer\\r\\n    if num_over == 0:\\r\\n        answer = \"Regular Schedule\"\\r\\n    elif num_over <= 2:\\r\\n        answer = \"Prepare Activation\"\\r\\n    else:\\r\\n        answer = \"Activate New Schedule\"\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"a2_6_traffic_lights.py\", inputs)\\r\\n    \\r\\n    print(\"Testing when\", num_over, \"out of\", traffic, \"\\\\\"time periods\\\\\" are experiencing heavy traffic . . . \")\\r\\n    print(\"  Inputs:\", inputs)\\r\\n    print(\"  Result: \", end=\\'\\')\\r\\n    \\r\\n    if answer.strip() == output.strip():\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected: \\'\" + answer + \"\\' instead of \\'\" + output + \"\\'\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_passed = 0\\r\\n    \\r\\n    if (run_test(0, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(1, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(2, random.randint(2, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(3, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n        \\r\\n    return (100 / 4) * num_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_6_network_traffic': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(num_over, traffic):    \\r\\n    inputs = [traffic]\\r\\n    \\r\\n    for i in range(traffic):\\r\\n        if i < num_over:\\r\\n            if (i + 1 == num_over):\\r\\n                inputs.append(512.1)\\r\\n            else:\\r\\n                inputs.append(round(random.uniform(512, 1024), 1))\\r\\n        else:\\r\\n            inputs.append(round(random.uniform(256, 512), 1))\\r\\n\\r\\n    # Generates Expected Answer\\r\\n    if num_over == 0:\\r\\n        answer = \"Ops Normal\"\\r\\n    elif num_over <= 2:\\r\\n        answer = \"Initialize NLB\"\\r\\n    else:\\r\\n        answer = \"Activate NLB\"\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"a2_6_network_traffic.py\", inputs)\\r\\n    \\r\\n    print(\"Testing when\", num_over, \"out of\", traffic, \"\\\\\"snaphots\\\\\" have high volume of network traffic . . . \")\\r\\n    print(\"  Inputs:\", inputs)\\r\\n    print(\"  Result: \", end=\\'\\')\\r\\n    \\r\\n    if answer.strip() == output.strip():\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected: \\'\" + answer + \"\\' instead of \\'\" + output + \"\\'\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_passed = 0\\r\\n    \\r\\n    if (run_test(0, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(1, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(2, random.randint(2, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(3, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n        \\r\\n    return (100 / 4) * num_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_6_grades': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(num_failures, num_papers):    \\r\\n    inputs = [num_papers]\\r\\n    \\r\\n    for i in range(num_papers):\\r\\n        if i < num_failures:\\r\\n            inputs.append(round(random.uniform(0, 70), 1))\\r\\n        else:\\r\\n            if (i == num_failures):\\r\\n                inputs.append(70)\\r\\n            else:\\r\\n                inputs.append(round(random.uniform(70, 100), 1))\\r\\n\\r\\n    # Generates Expected Answer\\r\\n    if num_failures == 0:\\r\\n        answer = \"Excellent\"\\r\\n    elif num_failures >= 1 and num_failures <= 2:\\r\\n        answer = \"Satisfactory\"\\r\\n    else:\\r\\n        answer = \"Unsatisfactory\"\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"a2_6_grades.py\", inputs)\\r\\n    \\r\\n    print(\"Testing when\", num_failures, \"out of\", num_papers, \"failed . . . \")\\r\\n    print(\"  Inputs:\", inputs)\\r\\n    print(\"  Result: \", end=\\'\\')\\r\\n    \\r\\n    if answer.strip() == output.strip():\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected: \\'\" + answer + \"\\' instead of \\'\" + output + \"\\'\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_passed = 0\\r\\n    \\r\\n    if (run_test(0, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(1, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(2, random.randint(2, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(3, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n        \\r\\n    return (100 / 4) * num_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_6_gameday': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(num_close, num_strikes):    \\r\\n    inputs = [num_strikes]\\r\\n    \\r\\n    for i in range(num_strikes):\\r\\n        if i < num_close:\\r\\n            if (i + 1 == num_close):\\r\\n                inputs.append(15)\\r\\n            else:\\r\\n                inputs.append(round(random.uniform(0, 15), 1))\\r\\n        else:\\r\\n            inputs.append(round(random.uniform(15, 50), 1))\\r\\n\\r\\n    # Generates Expected Answer\\r\\n    if num_close == 0:\\r\\n        answer = \"All Clear\"\\r\\n    elif num_close <= 3:\\r\\n        answer = \"Weather Warning\"\\r\\n    else:\\r\\n        answer = \"Game Delay\"\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"a2_6_gameday.py\", inputs)\\r\\n    \\r\\n    print(\"Testing when\", num_close, \"out of\", num_strikes, \"\\\\\"strikes\\\\\" are are close . . . \")\\r\\n    print(\"  Inputs:\", inputs)\\r\\n    print(\"  Result: \", end=\\'\\')\\r\\n    \\r\\n    if answer.strip() == output.strip():\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected: \\'\" + answer + \"\\' instead of \\'\" + output + \"\\'\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_passed = 0\\r\\n    \\r\\n    if (run_test(0, random.randint(2, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(1, random.randint(2, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(2, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(4, random.randint(4, 5))):\\r\\n        num_passed += 1\\r\\n        \\r\\n    return (100 / 4) * num_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_6_combat': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(num_close, num_planes):    \\r\\n    inputs = [num_planes]\\r\\n    \\r\\n    for i in range(num_planes):\\r\\n        if i < num_close:\\r\\n            if (i + 1 == num_close):\\r\\n                inputs.append(20)\\r\\n            else:\\r\\n                inputs.append(round(random.uniform(0, 20), 1))\\r\\n        else:\\r\\n            inputs.append(round(random.uniform(20, 50), 1))\\r\\n\\r\\n    # Generates Expected Answer\\r\\n    if num_close == 0:\\r\\n        answer = \"All Clear\"\\r\\n    elif num_close <= 2:\\r\\n        answer = \"Warning\"\\r\\n    else:\\r\\n        answer = \"Evasive Action\"\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"a2_6_combat.py\", inputs)\\r\\n    \\r\\n    print(\"Testing when\", num_close, \"out of\", num_planes, \"are close . . . \")\\r\\n    print(\"  Inputs:\", inputs)\\r\\n    print(\"  Result: \", end=\\'\\')\\r\\n    \\r\\n    if answer.strip() == output.strip():\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected: \\'\" + answer + \"\\' instead of \\'\" + output + \"\\'\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_passed = 0\\r\\n    \\r\\n    if (run_test(0, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(1, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(2, random.randint(2, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(3, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n        \\r\\n    return (100 / 4) * num_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_4_slash': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\nvariant = \"slash\"\\r\\nverbose = False\\r\\n\\r\\nvariants = {\\r\\n            \"validate\": {\"delimiter\": \\'.\\'}, \\r\\n            \"comma\"   : {\"delimiter\": \\',\\'},\\r\\n            \"pipe\"    : {\"delimiter\": \\'|\\'}, #\\r\\n            \"amp\"     : {\"delimiter\": \\'&\\'}, #\\r\\n            \"caret\"   : {\"delimiter\": \\'^\\'}, #\\r\\n            \"dollar\"  : {\"delimiter\": \\'$\\'}, #\\r\\n            \"hash\"    : {\"delimiter\": \\'#\\'}, #\\r\\n            \"ques\"    : {\"delimiter\": \\'?\\'}, #\\r\\n            \"semic\"   : {\"delimiter\": \\';\\'}, #\\r\\n            \"slash\"   : {\"delimiter\": \\'/\\'}, #\\r\\n            \"star\"    : {\"delimiter\": \\'*\\'}, #\\r\\n            \"colon\"   : {\"delimiter\": \\':\\'}, #\\r\\n            \"hyphen\"  : {\"delimiter\": \\'-\\'}, #\\r\\n            \"score\"   : {\"delimiter\": \\'_\\'}, #\\r\\n           }\\r\\n\\r\\ndelimiter_proper = variants[variant][\"delimiter\"]\\r\\n\\r\\ndef generate_test_string(delimiter):\\r\\n    \\r\\n    random_lists = [\\r\\n                    [\"booker12\",\"9012\",\"12se74\",\"rb9012\",\"Rachel\",\"Booker\",\"Sales\",\"Coventry\"],\\r\\n                    [\"grey07\",\"2070\",\"04ap67\",\"lg2070\",\"Laura\",\"Grey\",\"Depot\",\"London\"],\\r\\n                    [\"johnson81\",\"4081\",\"30no86\",\"cj4081\",\"Craig\",\"Johnson\",\"Shipping\",\"Westminster\"],\\r\\n                    [\"jenkins46\",\"9346\",\"14ju73\",\"mj9346\",\"Mary\",\"Jenkins\",\"Engineering\",\"Liverpool\"],\\r\\n                    [\"smith79\",\"5079\",\"09ja61\",\"js5079\",\"Jamie\",\"Smith\",\"Testing\",\"Manchester\"]\\r\\n                   ]\\r\\n    \\r\\n    random_list = random_lists[random.randrange(len(random_lists))]\\r\\n    random_column = random.randrange(len(random_list))\\r\\n    test_string = \"\"\\r\\n    for field in random_list:\\r\\n        if test_string != \"\":\\r\\n            test_string += delimiter\\r\\n        test_string += field\\r\\n    return test_string, random_column\\r\\n\\r\\ndef solution(delimiter, string, column_num):\\r\\n    \\r\\n    #print(\"SOLUTION:\", string, delimiter, column_num, sep=\"\\\\n\")\\r\\n    columns = string.split(delimiter)\\r\\n    output = str(len(columns)) + \\'\\\\n\\'\\r\\n    output += columns[column_num] + \\'\\\\n\\'\\r\\n        \\r\\n    return output\\r\\n\\r\\ndef print_test_results(test_score, actual_output, expected_output):\\r\\n\\r\\n    if verbose:\\r\\n        \\r\\n        if test_score == 100:\\r\\n            print(\"CORRECT: %.1f%%\" % (test_score))\\r\\n        else:\\r\\n            print(\"INCORRECT: %.1f%%\" % (test_score))\\r\\n            print(\"Expected:\")\\r\\n            print(expected_output)\\r\\n\\r\\n    else:\\r\\n\\r\\n        if test_score == 100:\\r\\n            print(\"CORRECT\")\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n            print(\"Expected:\")\\r\\n            print(expected_output)\\r\\n\\r\\ndef run1test(delimiter):\\r\\n\\r\\n    # Rubric\\r\\n    # 1 Runs without errors\\r\\n    # 1 Prints out the correct item count (regardless of order)\\r\\n    # 1 Prints out the correct item value (regardless of order)\\r\\n    # 1 Prints out the items in the correct order (0.5 for each)\\r\\n\\r\\n    test_score = 0\\r\\n    test_max = 4\\r\\n    \\r\\n    test_string, random_column = generate_test_string(delimiter)\\r\\n    output, error = autograder.run_script(\"a2_4_%s.py\" % (variant), [ test_string, random_column ])\\r\\n    expected_output = solution(delimiter, test_string, random_column)\\r\\n\\r\\n    if error == \"\":\\r\\n        test_score += 1\\r\\n    \\r\\n    returned_lines = output.strip().split(\\'\\\\n\\')\\r\\n    returned_count = None\\r\\n    returned_item = None\\r\\n    if len(returned_lines) > 0:\\r\\n        returned_count = returned_lines[0]\\r\\n    if len(returned_lines) > 1:\\r\\n        returned_item = returned_lines[1]\\r\\n    \\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    expected_count = expected_lines[0]\\r\\n    expected_item = expected_lines[1]\\r\\n\\r\\n    if returned_count in expected_lines:\\r\\n        test_score += 1\\r\\n    if returned_count == expected_count:\\r\\n        test_score += 0.5\\r\\n    \\r\\n    if returned_item in expected_lines:\\r\\n        test_score += 1\\r\\n    if returned_item == expected_item:\\r\\n        test_score += 0.5\\r\\n\\r\\n    test_score = round(100 * (test_score / test_max), 1)\\r\\n    print_test_results(test_score, output, expected_output)\\r\\n    \\r\\n    return test_score\\r\\n\\r\\ndef initial_test():\\r\\n    global delimiter_used\\r\\n    \\r\\n    test_max = 12\\r\\n\\r\\n    test_score = 1 # For testing against the server\\r\\n\\r\\n    sensor_string = \"sensor.validate.,comma,|pipe|#hash#$dollar$^caret^:colon:;semic;*star*&amp&?ques?-hyphen-/slash/_score_end\"\\r\\n    delimiter_column = 1\\r\\n\\r\\n    detection_failed = False\\r\\n    output, error   = autograder.run_script(\"a2_4_%s.py\" % (variant), [ sensor_string, delimiter_column ])\\r\\n    \\r\\n    if error == \"\":\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Running without error.\")\\r\\n    expected_output = solution(delimiter_proper, sensor_string, delimiter_column)\\r\\n\\r\\n    returned_lines = output.strip().split(\\'\\\\n\\')\\r\\n    returned_count = None\\r\\n    returned_item = None\\r\\n    if len(returned_lines) > 0:\\r\\n        returned_count = returned_lines[0]\\r\\n    if len(returned_lines) > 1:\\r\\n        returned_item = returned_lines[1]\\r\\n\\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    #expected_count = expected_lines[0]\\r\\n    #expected_item = expected_lines[1]\\r\\n\\r\\n    if len(returned_lines) >= 1 and returned_lines[0] != \\'\\':\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 At least one line of output.\")\\r\\n    if len(returned_lines) == 2:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Exactly two lines of output.\")\\r\\n        \\r\\n    if returned_count in expected_lines:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Count contained in output somewhere.\")\\r\\n    if returned_item in expected_lines:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Requested item contained in output somewhere.\")\\r\\n\\r\\n    detection_failed = len(returned_lines) < 2\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"Delimiter Detection:\")\\r\\n        if detection_failed:\\r\\n            print(\"Failed:\", returned_lines)\\r\\n        else:\\r\\n            print(\"Detected delimiter: \", returned_lines[1])\\r\\n            print(\"Sensor fields: \", returned_lines[0])\\r\\n    \\r\\n    if variant in returned_lines:\\r\\n        test_score += 3\\r\\n        if verbose: print(\"+3 Detected delimiter is correct.\")\\r\\n\\r\\n    delimiter_used = None\\r\\n    if (not detection_failed) and (returned_lines[1] in variants):\\r\\n        delimiter_used = variants[returned_lines[1]][\"delimiter\"]\\r\\n\\r\\n    if delimiter_used == delimiter_proper:\\r\\n        test_score += 3\\r\\n        if verbose: print(\"+3 Detected delimiter is proper.\")\\r\\n\\r\\n    if delimiter_used == None:\\r\\n        delimiter_used = delimiter_proper\\r\\n        \\r\\n    test_score = round(100 * (test_score / test_max), 1)\\r\\n    print_test_results(test_score, output, expected_output)\\r\\n\\r\\n    return test_score\\r\\n    \\r\\ndef test_passed():\\r\\n\\r\\n    test_weights = [20, 12,4,4]\\r\\n    test_total = sum(test_weights) - test_weights[0]\\r\\n    if test_total != test_weights[0]:\\r\\n        print(\"Individual tests do not add to total value.\\\\n\")\\r\\n        \\r\\n    score = 0\\r\\n    test_num = 0\\r\\n    #------------------------------------------------\\r\\n    # Test #1: Sense delimiter used\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(test_weights[test_num]/test_total)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n        \\r\\n    test_score = initial_test()\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n    \\r\\n    #------------------------------------------------\\r\\n    # Test #2: Using detected delimiter\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(4/20)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    \\r\\n    test_score = run1test(delimiter_used)\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n\\r\\n    #------------------------------------------------\\r\\n    # Test #3: Use correct delimiter\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(4/20)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n        \\r\\n    test_score = run1test(delimiter_proper)\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n\\r\\n    #------------------------------------------------\\r\\n    # End of Test\\r\\n    #------------------------------------------------\\r\\n    \\r\\n    print(\"\\\\nOVERALL SCORE:\")\\r\\n    return round(score,1)\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':   \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------',\n",
       "  'a2_4_semic': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\nvariant = \"semic\"\\r\\nverbose = False\\r\\n\\r\\nvariants = {\\r\\n            \"validate\": {\"delimiter\": \\'.\\'}, \\r\\n            \"comma\"   : {\"delimiter\": \\',\\'},\\r\\n            \"pipe\"    : {\"delimiter\": \\'|\\'}, #\\r\\n            \"amp\"     : {\"delimiter\": \\'&\\'}, #\\r\\n            \"caret\"   : {\"delimiter\": \\'^\\'}, #\\r\\n            \"dollar\"  : {\"delimiter\": \\'$\\'}, #\\r\\n            \"hash\"    : {\"delimiter\": \\'#\\'}, #\\r\\n            \"ques\"    : {\"delimiter\": \\'?\\'}, #\\r\\n            \"semic\"   : {\"delimiter\": \\';\\'}, #\\r\\n            \"slash\"   : {\"delimiter\": \\'/\\'}, #\\r\\n            \"star\"    : {\"delimiter\": \\'*\\'}, #\\r\\n            \"colon\"   : {\"delimiter\": \\':\\'}, #\\r\\n            \"hyphen\"  : {\"delimiter\": \\'-\\'}, #\\r\\n            \"score\"   : {\"delimiter\": \\'_\\'}, #\\r\\n           }\\r\\n\\r\\ndelimiter_proper = variants[variant][\"delimiter\"]\\r\\n\\r\\ndef generate_test_string(delimiter):\\r\\n    \\r\\n    random_lists = [\\r\\n                    [\"booker12\",\"9012\",\"12se74\",\"rb9012\",\"Rachel\",\"Booker\",\"Sales\",\"Coventry\"],\\r\\n                    [\"grey07\",\"2070\",\"04ap67\",\"lg2070\",\"Laura\",\"Grey\",\"Depot\",\"London\"],\\r\\n                    [\"johnson81\",\"4081\",\"30no86\",\"cj4081\",\"Craig\",\"Johnson\",\"Shipping\",\"Westminster\"],\\r\\n                    [\"jenkins46\",\"9346\",\"14ju73\",\"mj9346\",\"Mary\",\"Jenkins\",\"Engineering\",\"Liverpool\"],\\r\\n                    [\"smith79\",\"5079\",\"09ja61\",\"js5079\",\"Jamie\",\"Smith\",\"Testing\",\"Manchester\"]\\r\\n                   ]\\r\\n    \\r\\n    random_list = random_lists[random.randrange(len(random_lists))]\\r\\n    random_column = random.randrange(len(random_list))\\r\\n    test_string = \"\"\\r\\n    for field in random_list:\\r\\n        if test_string != \"\":\\r\\n            test_string += delimiter\\r\\n        test_string += field\\r\\n    return test_string, random_column\\r\\n\\r\\ndef solution(delimiter, string, column_num):\\r\\n    \\r\\n    #print(\"SOLUTION:\", string, delimiter, column_num, sep=\"\\\\n\")\\r\\n    columns = string.split(delimiter)\\r\\n    output = str(len(columns)) + \\'\\\\n\\'\\r\\n    output += columns[column_num] + \\'\\\\n\\'\\r\\n        \\r\\n    return output\\r\\n\\r\\ndef print_test_results(test_score, actual_output, expected_output):\\r\\n\\r\\n    if verbose:\\r\\n        \\r\\n        if test_score == 100:\\r\\n            print(\"CORRECT: %.1f%%\" % (test_score))\\r\\n        else:\\r\\n            print(\"INCORRECT: %.1f%%\" % (test_score))\\r\\n            print(\"Expected:\")\\r\\n            print(expected_output)\\r\\n\\r\\n    else:\\r\\n\\r\\n        if test_score == 100:\\r\\n            print(\"CORRECT\")\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n            print(\"Expected:\")\\r\\n            print(expected_output)\\r\\n\\r\\ndef run1test(delimiter):\\r\\n\\r\\n    # Rubric\\r\\n    # 1 Runs without errors\\r\\n    # 1 Prints out the correct item count (regardless of order)\\r\\n    # 1 Prints out the correct item value (regardless of order)\\r\\n    # 1 Prints out the items in the correct order (0.5 for each)\\r\\n\\r\\n    test_score = 0\\r\\n    test_max = 4\\r\\n    \\r\\n    test_string, random_column = generate_test_string(delimiter)\\r\\n    output, error = autograder.run_script(\"a2_4_%s.py\" % (variant), [ test_string, random_column ])\\r\\n    expected_output = solution(delimiter, test_string, random_column)\\r\\n\\r\\n    if error == \"\":\\r\\n        test_score += 1\\r\\n    \\r\\n    returned_lines = output.strip().split(\\'\\\\n\\')\\r\\n    returned_count = None\\r\\n    returned_item = None\\r\\n    if len(returned_lines) > 0:\\r\\n        returned_count = returned_lines[0]\\r\\n    if len(returned_lines) > 1:\\r\\n        returned_item = returned_lines[1]\\r\\n    \\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    expected_count = expected_lines[0]\\r\\n    expected_item = expected_lines[1]\\r\\n\\r\\n    if returned_count in expected_lines:\\r\\n        test_score += 1\\r\\n    if returned_count == expected_count:\\r\\n        test_score += 0.5\\r\\n    \\r\\n    if returned_item in expected_lines:\\r\\n        test_score += 1\\r\\n    if returned_item == expected_item:\\r\\n        test_score += 0.5\\r\\n\\r\\n    test_score = round(100 * (test_score / test_max), 1)\\r\\n    print_test_results(test_score, output, expected_output)\\r\\n    \\r\\n    return test_score\\r\\n\\r\\ndef initial_test():\\r\\n    global delimiter_used\\r\\n    \\r\\n    test_max = 12\\r\\n\\r\\n    test_score = 1 # For testing against the server\\r\\n\\r\\n    sensor_string = \"sensor.validate.,comma,|pipe|#hash#$dollar$^caret^:colon:;semic;*star*&amp&?ques?-hyphen-/slash/_score_end\"\\r\\n    delimiter_column = 1\\r\\n\\r\\n    detection_failed = False\\r\\n    output, error   = autograder.run_script(\"a2_4_%s.py\" % (variant), [ sensor_string, delimiter_column ])\\r\\n    \\r\\n    if error == \"\":\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Running without error.\")\\r\\n    expected_output = solution(delimiter_proper, sensor_string, delimiter_column)\\r\\n\\r\\n    returned_lines = output.strip().split(\\'\\\\n\\')\\r\\n    returned_count = None\\r\\n    returned_item = None\\r\\n    if len(returned_lines) > 0:\\r\\n        returned_count = returned_lines[0]\\r\\n    if len(returned_lines) > 1:\\r\\n        returned_item = returned_lines[1]\\r\\n\\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    #expected_count = expected_lines[0]\\r\\n    #expected_item = expected_lines[1]\\r\\n\\r\\n    if len(returned_lines) >= 1 and returned_lines[0] != \\'\\':\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 At least one line of output.\")\\r\\n    if len(returned_lines) == 2:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Exactly two lines of output.\")\\r\\n        \\r\\n    if returned_count in expected_lines:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Count contained in output somewhere.\")\\r\\n    if returned_item in expected_lines:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Requested item contained in output somewhere.\")\\r\\n\\r\\n    detection_failed = len(returned_lines) < 2\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"Delimiter Detection:\")\\r\\n        if detection_failed:\\r\\n            print(\"Failed:\", returned_lines)\\r\\n        else:\\r\\n            print(\"Detected delimiter: \", returned_lines[1])\\r\\n            print(\"Sensor fields: \", returned_lines[0])\\r\\n    \\r\\n    if variant in returned_lines:\\r\\n        test_score += 3\\r\\n        if verbose: print(\"+3 Detected delimiter is correct.\")\\r\\n\\r\\n    delimiter_used = None\\r\\n    if (not detection_failed) and (returned_lines[1] in variants):\\r\\n        delimiter_used = variants[returned_lines[1]][\"delimiter\"]\\r\\n\\r\\n    if delimiter_used == delimiter_proper:\\r\\n        test_score += 3\\r\\n        if verbose: print(\"+3 Detected delimiter is proper.\")\\r\\n\\r\\n    if delimiter_used == None:\\r\\n        delimiter_used = delimiter_proper\\r\\n        \\r\\n    test_score = round(100 * (test_score / test_max), 1)\\r\\n    print_test_results(test_score, output, expected_output)\\r\\n\\r\\n    return test_score\\r\\n    \\r\\ndef test_passed():\\r\\n\\r\\n    test_weights = [20, 12,4,4]\\r\\n    test_total = sum(test_weights) - test_weights[0]\\r\\n    if test_total != test_weights[0]:\\r\\n        print(\"Individual tests do not add to total value.\\\\n\")\\r\\n        \\r\\n    score = 0\\r\\n    test_num = 0\\r\\n    #------------------------------------------------\\r\\n    # Test #1: Sense delimiter used\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(test_weights[test_num]/test_total)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n        \\r\\n    test_score = initial_test()\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n    \\r\\n    #------------------------------------------------\\r\\n    # Test #2: Using detected delimiter\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(4/20)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    \\r\\n    test_score = run1test(delimiter_used)\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n\\r\\n    #------------------------------------------------\\r\\n    # Test #3: Use correct delimiter\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(4/20)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n        \\r\\n    test_score = run1test(delimiter_proper)\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n\\r\\n    #------------------------------------------------\\r\\n    # End of Test\\r\\n    #------------------------------------------------\\r\\n    \\r\\n    print(\"\\\\nOVERALL SCORE:\")\\r\\n    return round(score,1)\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':   \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_4_dash': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(string, column_num):\\r\\n    \\r\\n    columns = string.split(\\'-\\')\\r\\n    return columns[column_num]\\r\\n    \\r\\n\\r\\ndef test_passed():\\r\\n\\r\\n    score = 0\\r\\n\\r\\n    # Generates the Test Set\\r\\n    random_strings = [\"booker12-9012-12se74-rb9012-Rachel-Booker-Sales-Manchester\",\\r\\n                      \"grey07-2070-04ap67-lg2070-Laura-Grey-Depot-London\",\\r\\n                      \"johnson81-4081-30no86-cj4081-Craig-Johnson-Depot-London\",\\r\\n                      \"jenkins46-9346-14ju73-mj9346-Mary-Jenkins-Engineering-Manchester\",\\r\\n                      \"smith79-5079-09ja61-js5079-Jamie-Smith-Engineering-Manchester\"]\\r\\n    \\r\\n    random_column   = random.randint(0, 6)\\r\\n    random_string   = random_strings[random.randint(0, len(random_strings)-1)]\\r\\n    output, error   = autograder.run_script(\"a2_4_dash.py\", [ random_string, random_column ])\\r\\n    expected_output = solution(random_string, random_column)\\r\\n    \\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\", expected_output)\\r\\n        return 0.0\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_4_comma': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(string, column_num):\\r\\n    \\r\\n    columns = string.split(\\',\\')\\r\\n    return columns[column_num]\\r\\n    \\r\\n\\r\\ndef test_passed():\\r\\n\\r\\n    score = 0\\r\\n\\r\\n    # Generates the Test Set\\r\\n    random_strings = [\"booker12,9012,12se74,rb9012,Rachel,Booker,Sales,Manchester\",\\r\\n                      \"grey07,2070,04ap67,lg2070,Laura,Grey,Depot,London\",\\r\\n                      \"johnson81,4081,30no86,cj4081,Craig,Johnson,Depot,London\",\\r\\n                      \"jenkins46,9346,14ju73,mj9346,Mary,Jenkins,Engineering,Manchester\",\\r\\n                      \"smith79,5079,09ja61,js5079,Jamie,Smith,Engineering,Manchester\"]\\r\\n    \\r\\n    random_column   = random.randint(0, 6)\\r\\n    random_string   = random_strings[random.randint(0, len(random_strings)-1)]\\r\\n    output, error   = autograder.run_script(\"a2_4_comma.py\", [ random_string, random_column ])\\r\\n    expected_output = solution(random_string, random_column)\\r\\n    \\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\", expected_output)\\r\\n        return 0.0\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_4_colon': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\nvariant = \"colon\"\\r\\nverbose = False\\r\\n\\r\\nvariants = {\\r\\n            \"validate\": {\"delimiter\": \\'.\\'}, \\r\\n            \"comma\"   : {\"delimiter\": \\',\\'},\\r\\n            \"pipe\"    : {\"delimiter\": \\'|\\'}, #\\r\\n            \"amp\"     : {\"delimiter\": \\'&\\'}, #\\r\\n            \"caret\"   : {\"delimiter\": \\'^\\'}, #\\r\\n            \"dollar\"  : {\"delimiter\": \\'$\\'}, #\\r\\n            \"hash\"    : {\"delimiter\": \\'#\\'}, #\\r\\n            \"ques\"    : {\"delimiter\": \\'?\\'}, #\\r\\n            \"semic\"   : {\"delimiter\": \\';\\'}, #\\r\\n            \"slash\"   : {\"delimiter\": \\'/\\'}, #\\r\\n            \"star\"    : {\"delimiter\": \\'*\\'}, #\\r\\n            \"colon\"   : {\"delimiter\": \\':\\'}, #\\r\\n            \"hyphen\"  : {\"delimiter\": \\'-\\'}, #\\r\\n            \"score\"   : {\"delimiter\": \\'_\\'}, #\\r\\n           }\\r\\n\\r\\ndelimiter_proper = variants[variant][\"delimiter\"]\\r\\n\\r\\ndef generate_test_string(delimiter):\\r\\n    \\r\\n    random_lists = [\\r\\n                    [\"booker12\",\"9012\",\"12se74\",\"rb9012\",\"Rachel\",\"Booker\",\"Sales\",\"Coventry\"],\\r\\n                    [\"grey07\",\"2070\",\"04ap67\",\"lg2070\",\"Laura\",\"Grey\",\"Depot\",\"London\"],\\r\\n                    [\"johnson81\",\"4081\",\"30no86\",\"cj4081\",\"Craig\",\"Johnson\",\"Shipping\",\"Westminster\"],\\r\\n                    [\"jenkins46\",\"9346\",\"14ju73\",\"mj9346\",\"Mary\",\"Jenkins\",\"Engineering\",\"Liverpool\"],\\r\\n                    [\"smith79\",\"5079\",\"09ja61\",\"js5079\",\"Jamie\",\"Smith\",\"Testing\",\"Manchester\"]\\r\\n                   ]\\r\\n    \\r\\n    random_list = random_lists[random.randrange(len(random_lists))]\\r\\n    random_column = random.randrange(len(random_list))\\r\\n    test_string = \"\"\\r\\n    for field in random_list:\\r\\n        if test_string != \"\":\\r\\n            test_string += delimiter\\r\\n        test_string += field\\r\\n    return test_string, random_column\\r\\n\\r\\ndef solution(delimiter, string, column_num):\\r\\n    \\r\\n    #print(\"SOLUTION:\", string, delimiter, column_num, sep=\"\\\\n\")\\r\\n    columns = string.split(delimiter)\\r\\n    output = str(len(columns)) + \\'\\\\n\\'\\r\\n    output += columns[column_num] + \\'\\\\n\\'\\r\\n        \\r\\n    return output\\r\\n\\r\\ndef print_test_results(test_score, actual_output, expected_output):\\r\\n\\r\\n    if verbose:\\r\\n        \\r\\n        if test_score == 100:\\r\\n            print(\"CORRECT: %.1f%%\" % (test_score))\\r\\n        else:\\r\\n            print(\"INCORRECT: %.1f%%\" % (test_score))\\r\\n            print(\"Expected:\")\\r\\n            print(expected_output)\\r\\n\\r\\n    else:\\r\\n\\r\\n        if test_score == 100:\\r\\n            print(\"CORRECT\")\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n            print(\"Expected:\")\\r\\n            print(expected_output)\\r\\n\\r\\ndef run1test(delimiter):\\r\\n\\r\\n    # Rubric\\r\\n    # 1 Runs without errors\\r\\n    # 1 Prints out the correct item count (regardless of order)\\r\\n    # 1 Prints out the correct item value (regardless of order)\\r\\n    # 1 Prints out the items in the correct order (0.5 for each)\\r\\n\\r\\n    test_score = 0\\r\\n    test_max = 4\\r\\n    \\r\\n    test_string, random_column = generate_test_string(delimiter)\\r\\n    output, error = autograder.run_script(\"a2_4_%s.py\" % (variant), [ test_string, random_column ])\\r\\n    expected_output = solution(delimiter, test_string, random_column)\\r\\n\\r\\n    if error == \"\":\\r\\n        test_score += 1\\r\\n    \\r\\n    returned_lines = output.strip().split(\\'\\\\n\\')\\r\\n    returned_count = None\\r\\n    returned_item = None\\r\\n    if len(returned_lines) > 0:\\r\\n        returned_count = returned_lines[0]\\r\\n    if len(returned_lines) > 1:\\r\\n        returned_item = returned_lines[1]\\r\\n    \\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    expected_count = expected_lines[0]\\r\\n    expected_item = expected_lines[1]\\r\\n\\r\\n    if returned_count in expected_lines:\\r\\n        test_score += 1\\r\\n    if returned_count == expected_count:\\r\\n        test_score += 0.5\\r\\n    \\r\\n    if returned_item in expected_lines:\\r\\n        test_score += 1\\r\\n    if returned_item == expected_item:\\r\\n        test_score += 0.5\\r\\n\\r\\n    test_score = round(100 * (test_score / test_max), 1)\\r\\n    print_test_results(test_score, output, expected_output)\\r\\n    \\r\\n    return test_score\\r\\n\\r\\ndef initial_test():\\r\\n    global delimiter_used\\r\\n    \\r\\n    test_max = 12\\r\\n\\r\\n    test_score = 1 # For testing against the server\\r\\n\\r\\n    sensor_string = \"sensor.validate.,comma,|pipe|#hash#$dollar$^caret^:colon:;semic;*star*&amp&?ques?-hyphen-/slash/_score_end\"\\r\\n    delimiter_column = 1\\r\\n\\r\\n    detection_failed = False\\r\\n    output, error   = autograder.run_script(\"a2_4_%s.py\" % (variant), [ sensor_string, delimiter_column ])\\r\\n    \\r\\n    if error == \"\":\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Running without error.\")\\r\\n    expected_output = solution(delimiter_proper, sensor_string, delimiter_column)\\r\\n\\r\\n    returned_lines = output.strip().split(\\'\\\\n\\')\\r\\n    returned_count = None\\r\\n    returned_item = None\\r\\n    if len(returned_lines) > 0:\\r\\n        returned_count = returned_lines[0]\\r\\n    if len(returned_lines) > 1:\\r\\n        returned_item = returned_lines[1]\\r\\n\\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    #expected_count = expected_lines[0]\\r\\n    #expected_item = expected_lines[1]\\r\\n\\r\\n    if len(returned_lines) >= 1 and returned_lines[0] != \\'\\':\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 At least one line of output.\")\\r\\n    if len(returned_lines) == 2:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Exactly two lines of output.\")\\r\\n        \\r\\n    if returned_count in expected_lines:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Count contained in output somewhere.\")\\r\\n    if returned_item in expected_lines:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Requested item contained in output somewhere.\")\\r\\n\\r\\n    detection_failed = len(returned_lines) < 2\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"Delimiter Detection:\")\\r\\n        if detection_failed:\\r\\n            print(\"Failed:\", returned_lines)\\r\\n        else:\\r\\n            print(\"Detected delimiter: \", returned_lines[1])\\r\\n            print(\"Sensor fields: \", returned_lines[0])\\r\\n    \\r\\n    if variant in returned_lines:\\r\\n        test_score += 3\\r\\n        if verbose: print(\"+3 Detected delimiter is correct.\")\\r\\n\\r\\n    delimiter_used = None\\r\\n    if (not detection_failed) and (returned_lines[1] in variants):\\r\\n        delimiter_used = variants[returned_lines[1]][\"delimiter\"]\\r\\n\\r\\n    if delimiter_used == delimiter_proper:\\r\\n        test_score += 3\\r\\n        if verbose: print(\"+3 Detected delimiter is proper.\")\\r\\n\\r\\n    if delimiter_used == None:\\r\\n        delimiter_used = delimiter_proper\\r\\n        \\r\\n    test_score = round(100 * (test_score / test_max), 1)\\r\\n    print_test_results(test_score, output, expected_output)\\r\\n\\r\\n    return test_score\\r\\n    \\r\\ndef test_passed():\\r\\n\\r\\n    test_weights = [20, 12,4,4]\\r\\n    test_total = sum(test_weights) - test_weights[0]\\r\\n    if test_total != test_weights[0]:\\r\\n        print(\"Individual tests do not add to total value.\\\\n\")\\r\\n        \\r\\n    score = 0\\r\\n    test_num = 0\\r\\n    #------------------------------------------------\\r\\n    # Test #1: Sense delimiter used\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(test_weights[test_num]/test_total)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n        \\r\\n    test_score = initial_test()\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n    \\r\\n    #------------------------------------------------\\r\\n    # Test #2: Using detected delimiter\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(4/20)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    \\r\\n    test_score = run1test(delimiter_used)\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n\\r\\n    #------------------------------------------------\\r\\n    # Test #3: Use correct delimiter\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(4/20)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n        \\r\\n    test_score = run1test(delimiter_proper)\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n\\r\\n    #------------------------------------------------\\r\\n    # End of Test\\r\\n    #------------------------------------------------\\r\\n    \\r\\n    print(\"\\\\nOVERALL SCORE:\")\\r\\n    return round(score,1)\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':   \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_3_twenty_one': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(starting_num):\\r\\n    result = \\'\\'\\r\\n    i = starting_num\\r\\n    \\r\\n    while i >= 0:\\r\\n    \\r\\n        result += str(i) + \"\\\\n\"\\r\\n        \\r\\n        i = i - 21\\r\\n    return result\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    random_number = 126 + 21 * random.randint(1, 15)\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_3_twenty_one.py\", [random_number])\\r\\n    expected_string = solution(random_number)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_string.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    #Exactly correct\\r\\n    if output.strip() == expected_string.strip():\\r\\n        print(\"CORRECT\")\\r\\n        score += 100\\r\\n    #Mostly correct but added an extra value or included one less value: -2 points\\r\\n    elif output.strip().split(\\'\\\\n\\') == expected_lines[:-1] or \\\\\\r\\n         output.strip().split(\\'\\\\n\\')[:-1] == expected_lines:\\r\\n        print(\"INCORRECT.  Expected:\\\\n\"+expected_string)\\r\\n        score+=90\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\\\\n\"+expected_string)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_3_seventeen': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(starting_num):\\r\\n    result = \\'\\'\\r\\n    i = starting_num\\r\\n    \\r\\n    while i >= 0:\\r\\n    \\r\\n        result += str(i) + \"\\\\n\"\\r\\n        \\r\\n        i = i - 17\\r\\n    return result\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    random_number = 102 + 17 * random.randint(1, 20)\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_3_seventeen.py\", [random_number])\\r\\n    expected_string = solution(random_number)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_string.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    #Exactly correct\\r\\n    if output.strip() == expected_string.strip():\\r\\n        print(\"CORRECT\")\\r\\n        score += 100\\r\\n    #Mostly correct but added an extra value or included one less value: -2 points\\r\\n    elif output.strip().split(\\'\\\\n\\') == expected_lines[:-1] or \\\\\\r\\n         output.strip().split(\\'\\\\n\\')[:-1] == expected_lines:\\r\\n        print(\"INCORRECT.  Expected:\\\\n\"+expected_string)\\r\\n        score+=90\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\\\\n\"+expected_string)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_3_fourty_two': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(starting_num):\\r\\n    result = \\'\\'\\r\\n    i = starting_num\\r\\n    \\r\\n    while i >= 0:\\r\\n    \\r\\n        result += str(i) + \"\\\\n\"\\r\\n        \\r\\n        i = i - 42\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    random_number = 85 + 42 * random.randint(1, 20)\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_3_fourty_two.py\", [random_number])\\r\\n    expected_string = solution(random_number)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_string.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    if output.strip() == expected_string.strip():\\r\\n        print(\"CORRECT\")\\r\\n        score += 100\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\")\\r\\n        print(expected_string)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_3_countdown': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(starting_num):\\r\\n    result = \\'\\'\\r\\n    i = starting_num\\r\\n    \\r\\n    while i >= 0:\\r\\n    \\r\\n        result += str(i) + \"\\\\n\"\\r\\n        \\r\\n        i = i - 13\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    random_number = 85 + 13 * random.randint(1, 20)\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_3_countdown.py\", [random_number])\\r\\n    expected_string = solution(random_number)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_string.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    if output.strip() == expected_string.strip():\\r\\n        print(\"CORRECT\")\\r\\n        score += 100\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\")\\r\\n        print(expected_string)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_3_19': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(starting_num):\\r\\n    result = \\'\\'\\r\\n    i = starting_num\\r\\n    \\r\\n    while i >= 0:\\r\\n    \\r\\n        result += str(i) + \"\\\\n\"\\r\\n        \\r\\n        i = i - 19\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    random_number = 85 + 19 * random.randint(1, 20)\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_3_19.py\", [random_number])\\r\\n    expected_string = solution(random_number)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_string.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    if output.strip() == expected_string.strip():\\r\\n        print(\"CORRECT\")\\r\\n        score += 100\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\")\\r\\n        print(expected_string)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n',\n",
       "  'a2_2_unladen': 'from cs110 import autograder\\r\\nimport a2_2_unladen\\r\\n\\r\\ndef solution(S, A):\\r\\n    return 3 * S * A\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    \\r\\n    if \\'speed_of_unladen_swallow\\' in dir(a2_2_unladen):\\r\\n        print(\"Function Defined\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function Not Defined\")\\r\\n    \\r\\n    if \\'speed_of_unladen_swallow\\' in dir(a2_2_unladen) and \\\\\\r\\n        abs(a2_2_unladen.speed_of_unladen_swallow(15, 0.22) - solution(15, 0.22)) < 0.001:\\r\\n        print(\"Function Returns Correct Value\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function Does NOT Return the Correct Value\")\\r\\n\\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_2_stride': 'from cs110 import autograder\\r\\nimport a2_2_stride\\r\\n\\r\\ndef solution(S, SPM):\\r\\n    return S * SPM * .011\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    \\r\\n    if \\'person_speed\\' in dir(a2_2_stride):\\r\\n        print(\"Function Defined\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function Not Defined\")\\r\\n    \\r\\n    if \\'person_speed\\' in dir(a2_2_stride) and a2_2_stride.person_speed(32, 60) == solution(32, 60):\\r\\n        print(\"Function Returns Correct Value\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function Does NOT Return the Correct Value\")\\r\\n\\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_2_speed': 'from cs110 import autograder\\r\\nimport a2_2_speed\\r\\n\\r\\ndef solution(RPM, Cir):\\r\\n    return RPM * Cir / 12\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    \\r\\n    if \\'speed_fpm\\' in dir(a2_2_speed):\\r\\n        print(\"Function Defined\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function Not Defined\")\\r\\n    \\r\\n    if \\'speed_fpm\\' in dir(a2_2_speed) and a2_2_speed.speed_fpm(10, 6.6) == solution(10, 6.6):\\r\\n        print(\"Function Returns Correct Value\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function Does NOT Return the Correct Value\")\\r\\n\\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_2_hp': 'from cs110 import autograder\\r\\nimport a2_2_hp\\r\\n\\r\\ndef solution(RPM, Torque):\\r\\n    return RPM*Torque/5252\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    \\r\\n    if \\'horsepower\\' in dir(a2_2_hp):\\r\\n        print(\"Function Defined\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function Not Defined\")\\r\\n    \\r\\n    if \\'horsepower\\' in dir(a2_2_hp) and a2_2_hp.horsepower(4000, 600) == solution(4000, 600):\\r\\n        print(\"Function Returns Correct Value\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function Does NOT Return the Correct Value\")\\r\\n\\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_2_bmi': 'from cs110 import autograder\\r\\nimport a2_2_bmi\\r\\n\\r\\ndef solution(H, W):\\r\\n    return W/(H**2) * 703\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    \\r\\n    if \\'body_mass_index\\' in dir(a2_2_bmi):\\r\\n        print(\"Function Defined\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function Not Defined\")\\r\\n    \\r\\n    if \\'body_mass_index\\' in dir(a2_2_bmi) and a2_2_bmi.body_mass_index(15, 0.22) == solution(15, 0.22):\\r\\n        print(\"Function Returns Correct Value\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function Does NOT Return the Correct Value\")\\r\\n\\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_1_surface': 'from cs110 import autograder\\nfrom a2_1_surface import *  \\n\\ndef calculate_surface(radius, Pi):\\n    return 4*Pi*radius**2\\n\\n\\ndef test_passed():\\n    solution = calculate_surface(5,  3.141592653589793 )\\n    \\n    print(\"Feedback:\")\\n        \\n    if \\'result\\' in globals() and abs(result - solution) < 0.1:\\n        print(\"PASSED\")\\n        return 100\\n    elif \\'result\\' not in globals():\\n        print(\"FAILED.  Could not find variable \\'result\\'\")\\n    elif result != solution:\\n        print(\"FAILED.  Variable \\'result\\' has the wrong value \" + str(result))\\n    else:\\n        print(\"FAILED.  Something unexpected happened.\")\\n    \\n    return 0\\n\\n        \\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n    \\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_1_future_value': 'from cs110 import autograder\\nfrom a2_1_future_value import *  \\n\\ndef calculate_future_value(present_value, years):\\n    return present_value * (1 + 0.05/12) ** (years * 12)\\n\\n\\ndef test_passed():\\n    solution = calculate_future_value(50000, 25)\\n    \\n    print(\"Feedback:\")\\n        \\n    if \\'result\\' in globals() and abs(result - solution) < 0.1:\\n        print(\"PASSED\")\\n        return 100\\n    elif \\'result\\' not in globals():\\n        print(\"FAILED.  Could not find variable \\'result\\'\")\\n    elif result != solution:\\n        print(\"FAILED.  Variable \\'result\\' has the wrong value \" + str(result))\\n    else:\\n        print(\"FAILED.  Something unexpected happened.\")\\n    \\n    return 0\\n\\n        \\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    test_case_result = test_passed()\\n    print(\"Unit Test Returned:\", test_case_result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_1_equation': 'from cs110 import autograder\\r\\nfrom a2_1_equation import *  \\r\\n\\r\\ndef calculate_equation(value, C):\\r\\n    return value * (1.0 / 1 - (value**2)/(C*2))\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n    solution = calculate_equation(35500, 29900)\\r\\n    solution_prev = 35500 * (1.0 / (1 - (35500**2)/(29900**2))**0.5)\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n        \\r\\n    if \\'result\\' in globals() and (abs(result - solution) < 0.1 or abs(result - solution_prev) < 0.1):\\r\\n        print(\"PASSED\")\\r\\n        return 100\\r\\n    elif \\'result\\' not in globals():\\r\\n        print(\"FAILED.  Could not find variable \\'result\\'\")\\r\\n    elif result != solution:\\r\\n        print(\"FAILED.  Variable \\'result\\' has the wrong value \" + str(result))\\r\\n    else:\\r\\n        print(\"FAILED.  Something unexpected happened.\")\\r\\n    \\r\\n    return 0\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    test_case_result = test_passed()\\r\\n    print(\"Unit Test Returned:\", test_case_result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_1_calculate': 'from cs110 import autograder\\nfrom a2_1_calculate import *  \\n\\ndef calculate_equation(value):\\n    C =  6.4*2**10\\n    return value * (1.0 / (1 - (value**2)/(C**2))**0.5)\\n\\n\\ndef test_passed():\\n    solution = calculate_equation(278)\\n    \\n    print(\"Feedback:\")\\n        \\n    if \\'result\\' in globals() and abs(result - solution) < 0.1:\\n        print(\"PASSED\")\\n        return 100\\n    elif \\'result\\' not in globals():\\n        print(\"FAILED.  Could not find variable \\'result\\'\")\\n    elif result != solution:\\n        print(\"FAILED.  Variable \\'result\\' has the wrong value \" + str(result))\\n        return 50\\n    else:\\n        print(\"FAILED.  Something unexpected happened.\")\\n    \\n    return 0\\n\\n        \\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    ans = test_passed()\\n    print(\"Unit Test Returned:\", ans)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_1_calculate_volume': 'from cs110 import autograder\\nfrom a2_1_calculate_volume import *  \\n\\ndef calculate_volume(radius, pi):\\n    return pi * 4/3 * radius **3\\n\\n\\ndef test_passed():\\n    solution = calculate_volume(15, 3.1415)\\n    \\n    print(\"Feedback:\")\\n        \\n    if \\'result\\' in globals() and abs(result - solution) < 0.1:\\n        print(\"PASSED\")\\n        return 100\\n    elif \\'result\\' not in globals():\\n        print(\"FAILED.  Could not find variable \\'result\\'\")\\n    elif result != solution:\\n        print(\"FAILED.  Variable \\'result\\' has the wrong value \" + str(result))\\n    else:\\n        print(\"FAILED.  Something unexpected happened.\")\\n    \\n    return 0\\n\\n        \\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    test_case_result = test_passed()\\n    print(\"Unit Test Returned:\", test_case_result)',\n",
       "  'a1_7_pilot_quals': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n\\r\\ndef solution(hours):\\r\\n    result = \"\"\\r\\n\\r\\n    if hours < 600:\\r\\n        result += \"Co-Pilot\\\\n\"\\r\\n\\r\\n    if hours >= 600:\\r\\n        result += \"Upgrade Pilot\\\\n\"\\r\\n\\r\\n    if hours >= 800:\\r\\n        result += \"Aircraft Commander\\\\n\"\\r\\n        \\r\\n    if hours >= 1000:\\r\\n        result += \"Formation Lead\\\\n\"\\r\\n\\r\\n    if hours >=1250:\\r\\n        result += \"Instructor Pilot\\\\n\"\\r\\n\\r\\n    if hours >= 1500:\\r\\n        result += \"Evaluator Pilot\\\\n\"\\r\\n\\r\\n    \\r\\n    return result.strip().split(\\'\\\\n\\')\\r\\n\\r\\n\\r\\ndef run_test(hours):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"------------------------------\")\\r\\n    print(\"Test\", num_tests_run, \"-\", hours, \"hours\")\\r\\n    print(\"------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_7_pilot_quals.py\", [hours], True)\\r\\n    lines = output.strip().split(\"\\\\n\")\\r\\n    expected_answer = solution(hours)\\r\\n    \\r\\n    count = 0\\r\\n    \\r\\n    for answer in expected_answer:\\r\\n        if answer in lines:\\r\\n            print(\"Expecting\", answer, \" . . . FOUND!\")\\r\\n            count += 1\\r\\n        else:\\r\\n            print(\"Expecting\", answer, \" . . . MISSING!\")\\r\\n            \\r\\n    if count == len(expected_answer) and len(expected_answer) == len(lines):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    elif len(expected_answer) < len(lines):\\r\\n        print(\"Problems Detected - Your output has more lines than expected.\\\\n\")\\r\\n    else:\\r\\n        print(\"Problems Detected - Your output is missing one or more expected outputs.\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(0, 600), 1))\\r\\n    run_test(600)\\r\\n    run_test(round(random.uniform(600, 799), 1))\\r\\n    run_test(800)\\r\\n    run_test(round(random.uniform(800, 999), 1))\\r\\n    run_test(1000)\\r\\n    run_test(round(random.uniform(1000, 1249), 1))\\r\\n    run_test(1250)\\r\\n    run_test(round(random.uniform(1250, 1499), 1))\\r\\n    run_test(1500)\\r\\n    run_test(2750)\\r\\n    \\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\nif __name__ == \\'__main__\\':\\r\\n    class Console:\\r\\n        def write(self, txt):\\r\\n            print(txt, end=\\'\\')\\r\\n    \\r\\n    test_passed()\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a1_7_payload': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n\\r\\ndef solution(payload_weight):\\r\\n    result = \"\"\\r\\n    \\r\\n    if payload_weight <= 6000:\\r\\n        result += \"V-22 Osprey\\\\n\"\\r\\n\\r\\n    if payload_weight <= 42000:\\r\\n        result += \"C-130 Hercules\\\\n\"\\r\\n        \\r\\n    if payload_weight <= 169000:\\r\\n        result += \"KC-10 Extender\\\\n\"\\r\\n\\r\\n    if payload_weight <= 170900:\\r\\n        result += \"C-17 Globemaster\\\\n\"\\r\\n\\r\\n    if payload_weight <= 285000:\\r\\n        result += \"C-5 Galaxy\\\\n\"\\r\\n\\r\\n    if payload_weight > 285000:\\r\\n        result += \"Too Heavy for Airlift\\\\n\"\\r\\n    \\r\\n    return result.strip().split(\\'\\\\n\\')\\r\\n\\r\\n\\r\\ndef run_test(payload_weight):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"------------------------------\")\\r\\n    print(\"Test\", num_tests_run, \"-\", payload_weight, \"lbs\")\\r\\n    print(\"------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_7_payload.py\", [payload_weight], True)\\r\\n    lines = output.strip().split(\"\\\\n\")\\r\\n    expected_answer = solution(payload_weight)\\r\\n    \\r\\n    count = 0\\r\\n    \\r\\n    for answer in expected_answer:\\r\\n        if answer in lines:\\r\\n            print(\"Expecting\", answer, \" . . . FOUND!\")\\r\\n            count += 1\\r\\n        else:\\r\\n            print(\"Expecting\", answer, \" . . . MISSING!\")\\r\\n            \\r\\n    if count == len(expected_answer) and len(expected_answer) == len(lines):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    elif len(expected_answer) < len(lines):\\r\\n        print(\"Problems Detected - Your output has more lines than expected.\\\\n\")\\r\\n    else:\\r\\n        print(\"Problems Detected - Your output is missing one or more expected outputs.\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(0, 5999), 1))\\r\\n    run_test(6000)\\r\\n    run_test(round(random.uniform(6001, 41999), 1))\\r\\n    run_test(42000)\\r\\n    run_test(round(random.uniform(42001, 168999), 1))\\r\\n    run_test(169000)\\r\\n    run_test(round(random.uniform(169001, 170899), 1))\\r\\n    run_test(170900)\\r\\n    run_test(round(random.uniform(170901, 284999), 1))\\r\\n    run_test(285000)\\r\\n    run_test(300000)\\r\\n    \\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\nif __name__ == \\'__main__\\':\\r\\n    class Console:\\r\\n        def write(self, txt):\\r\\n            print(txt, end=\\'\\')\\r\\n    \\r\\n    test_passed()',\n",
       "  'a1_7_missilethreat': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n\\r\\ndef solution(target_range):\\r\\n    result = \"\"\\r\\n    \\r\\n    if target_range <= 500:\\r\\n        result += \"Hwasong-6\\\\n\"\\r\\n\\r\\n    if target_range <= 1200:\\r\\n        result += \"KN-11\\\\n\"\\r\\n        \\r\\n    if target_range <= 4000:\\r\\n        result += \"Musudan BM-25\\\\n\"\\r\\n\\r\\n    if target_range <= 8000:\\r\\n        result += \"Hwasong-14\\\\n\"\\r\\n\\r\\n    if target_range <= 12000:\\r\\n        result += \"Taepodong-2\\\\n\"\\r\\n\\r\\n    if target_range > 12000:\\r\\n        result += \"Not in range\\\\n\"\\r\\n    \\r\\n    return result.strip().split(\\'\\\\n\\')\\r\\n\\r\\n\\r\\ndef run_test(target_range):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"------------------------------\")\\r\\n    print(\"Test\", num_tests_run, \"-\", target_range, \"kilometers\")\\r\\n    print(\"------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_7_missilethreat.py\", [target_range], True)\\r\\n    lines = output.strip().split(\"\\\\n\")\\r\\n    expected_answer = solution(target_range)\\r\\n    \\r\\n    count = 0\\r\\n    \\r\\n    for answer in expected_answer:\\r\\n        if answer in lines:\\r\\n            print(\"Expecting\", answer, \" . . . FOUND!\")\\r\\n            count += 1\\r\\n        else:\\r\\n            print(\"Expecting\", answer, \" . . . MISSING!\")\\r\\n            \\r\\n    if count == len(expected_answer) and len(expected_answer) == len(lines):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    elif len(expected_answer) < len(lines):\\r\\n        print(\"Problems Detected - Your output has more lines than expected.\\\\n\")\\r\\n    else:\\r\\n        print(\"Problems Detected - Your output is missing one or more expected outputs.\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(0, 499), 1))\\r\\n    run_test(500)\\r\\n    run_test(round(random.uniform(501, 1199), 1))\\r\\n    run_test(1200)\\r\\n    run_test(round(random.uniform(1201, 3999), 1))\\r\\n    run_test(4000)\\r\\n    run_test(round(random.uniform(4001, 7999), 1))\\r\\n    run_test(8000)\\r\\n    run_test(round(random.uniform(8001, 11999), 1))\\r\\n    run_test(12000)\\r\\n    run_test(12001)\\r\\n    \\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\nif __name__ == \\'__main__\\':\\r\\n    class Console:\\r\\n        def write(self, txt):\\r\\n            print(txt, end=\\'\\')\\r\\n    \\r\\n    test_passed()',\n",
       "  'a1_7_evacuation': 'from cs110 import autograder\\nimport random, math\\n\\nnum_tests_passed = 0\\nnum_tests_run = 0\\n\\n\\ndef solution(target_range):\\n    result = \"\"\\n    \\n    if target_range <= 850:\\n        result += \"Pipe Bomb\\\\n\"\\n\\n    if target_range <= 1850:\\n        result += \"Suitcase Bomb\\\\n\"\\n        \\n    if target_range <= 2000:\\n        result += \"Sedan\\\\n\"\\n\\n    if target_range <= 2750:\\n        result += \"Cargo Van\\\\n\"\\n\\n    if target_range <= 7000:\\n        result += \"Semi-Trailer\\\\n\"\\n\\n    if target_range > 7000:\\n        result += \"Not in range\\\\n\"\\n    \\n    return result.strip().split(\\'\\\\n\\')\\n\\n\\ndef run_test(target_range):\\n    global num_tests_run, num_tests_passed\\n        \\n    num_tests_run += 1\\n    \\n    print(\"------------------------------\")\\n    print(\"Test\", num_tests_run, \"-\", target_range, \"feet\")\\n    print(\"------------------------------\")\\n    \\n    output, error_message = autograder.run_script(\"a1_7_evacuation.py\", [target_range], True)\\n    lines = output.strip().split(\"\\\\n\")\\n    expected_answer = solution(target_range)\\n    \\n    count = 0\\n    \\n    for answer in expected_answer:\\n        if answer in lines:\\n            print(\"Expecting\", answer, \" . . . FOUND!\")\\n            count += 1\\n        else:\\n            print(\"Expecting\", answer, \" . . . MISSING!\")\\n            \\n    if count == len(expected_answer) and len(expected_answer) == len(lines):\\n        print(\"SUCCESS!\\\\n\")\\n        num_tests_passed += 1\\n    elif len(expected_answer) < len(lines):\\n        print(\"Problems Detected - Your output has more lines than expected.\\\\n\")\\n    else:\\n        print(\"Problems Detected - Your output is missing one or more expected outputs.\\\\n\")\\n\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    run_test(round(random.uniform(0, 899), 1))\\n    run_test(850)\\n    run_test(round(random.uniform(851, 1849), 1))\\n    run_test(1850)\\n    run_test(round(random.uniform(1851, 1999), 1))\\n    run_test(2000)\\n    run_test(round(random.uniform(2001, 2749), 1))\\n    run_test(2750)\\n    run_test(round(random.uniform(2751, 7999), 1))\\n    run_test(7000)\\n    run_test(7001)\\n    \\n    \\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\n\\n        \\n# Testbench (to run on outside of zyBooks)\\nif __name__ == \\'__main__\\':\\n    class Console:\\n        def write(self, txt):\\n            print(txt, end=\\'\\')\\n    \\n    test_passed()\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_7_digitalstorage': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n\\r\\ndef solution(num_images):\\r\\n    result = \"\"\\r\\n    \\r\\n    if num_images <= 116:\\r\\n        result += \"CD\\\\n\"\\r\\n\\r\\n    if num_images <= 780:\\r\\n        result += \"DVD\\\\n\"\\r\\n        \\r\\n    if num_images <= 2660:\\r\\n        result += \"USB Small\\\\n\"\\r\\n\\r\\n    if num_images <= 10600:\\r\\n        result += \"USB Large\\\\n\"\\r\\n\\r\\n    if num_images <= 42600:\\r\\n        result += \"Portable HDD\\\\n\"\\r\\n\\r\\n    if num_images > 42600:\\r\\n        result += \"Consider Cloud Storage\\\\n\"\\r\\n    \\r\\n    return result.strip().split(\\'\\\\n\\')\\r\\n\\r\\n\\r\\ndef run_test(num_images):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"------------------------------\")\\r\\n    print(\"Test\", num_tests_run, \"-\", num_images, \"images\")\\r\\n    print(\"------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_7_digitalstorage.py\", [num_images], True)\\r\\n    lines = output.strip().split(\"\\\\n\")\\r\\n    expected_answer = solution(num_images)\\r\\n    \\r\\n    count = 0\\r\\n    \\r\\n    for answer in expected_answer:\\r\\n        if answer in lines:\\r\\n            print(\"Expecting\", answer, \" . . . FOUND!\")\\r\\n            count += 1\\r\\n        else:\\r\\n            print(\"Expecting\", answer, \" . . . MISSING!\")\\r\\n            \\r\\n    if count == len(expected_answer) and len(expected_answer) == len(lines):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    elif len(expected_answer) < len(lines):\\r\\n        print(\"Problems Detected - Your output has more lines than expected.\\\\n\")\\r\\n    else:\\r\\n        print(\"Problems Detected - Your output is missing one or more expected outputs.\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(int(random.uniform(0, 115)))\\r\\n    run_test(116)\\r\\n    run_test(int(random.uniform(117, 779)))\\r\\n    run_test(780)\\r\\n    run_test(int(random.uniform(781, 2659)))\\r\\n    run_test(2660)\\r\\n    run_test(int(random.uniform(2661, 10599)))\\r\\n    run_test(10600)\\r\\n    run_test(int(random.uniform(10601, 42599)))\\r\\n    run_test(42600)\\r\\n    run_test(45000)\\r\\n    \\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\nif __name__ == \\'__main__\\':\\r\\n    class Console:\\r\\n        def write(self, txt):\\r\\n            print(txt, end=\\'\\')\\r\\n    \\r\\n    test_passed()\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a1_7_broadband': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n\\r\\ndef solution(speed):\\r\\n    result = \"\"\\r\\n    \\r\\n    if speed >= 1000:\\r\\n        result += \"Social Media\\\\n\"\\r\\n\\r\\n    if speed >= 4000:\\r\\n        result += \"Gaming\\\\n\"\\r\\n        \\r\\n    if speed >= 6000:\\r\\n        result += \"Video Conferencing\\\\n\"\\r\\n\\r\\n    if speed >= 10000:\\r\\n        result += \"File Downloads\\\\n\"\\r\\n\\r\\n    if speed >= 25000:\\r\\n        result += \"HD 4K Video\\\\n\"\\r\\n\\r\\n    if speed < 1000:\\r\\n        result += \"Upgrade to Broadband\\\\n\"\\r\\n    \\r\\n    return result.strip().split(\\'\\\\n\\')\\r\\n\\r\\n\\r\\ndef run_test(speed):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"------------------------------\")\\r\\n    print(\"Test\", num_tests_run, \"-\", speed, \"Kbps\")\\r\\n    print(\"------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_7_broadband.py\", [speed], True)\\r\\n    lines = output.strip().split(\"\\\\n\")\\r\\n    expected_answer = solution(speed)\\r\\n    \\r\\n    count = 0\\r\\n    \\r\\n    for answer in expected_answer:\\r\\n        if answer in lines:\\r\\n            print(\"Expecting\", answer, \" . . . FOUND!\")\\r\\n            count += 1\\r\\n        else:\\r\\n            print(\"Expecting\", answer, \" . . . MISSING!\")\\r\\n            \\r\\n    if count == len(expected_answer) and len(expected_answer) == len(lines):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    elif len(expected_answer) < len(lines):\\r\\n        print(\"Problems Detected - Your output has more lines than expected.\\\\n\")\\r\\n    else:\\r\\n        print(\"Problems Detected - Your output is missing one or more expected outputs.\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(0, 999), 1))\\r\\n    run_test(1000)\\r\\n    run_test(round(random.uniform(1001, 4999), 1))\\r\\n    run_test(4000)\\r\\n    run_test(round(random.uniform(4001, 5999), 1))\\r\\n    run_test(6000)\\r\\n    run_test(round(random.uniform(6001, 9999), 1))\\r\\n    run_test(10000)\\r\\n    run_test(round(random.uniform(10001, 24999), 1))\\r\\n    run_test(25000)\\r\\n    run_test(30000)\\r\\n    \\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\nif __name__ == \\'__main__\\':\\r\\n    class Console:\\r\\n        def write(self, txt):\\r\\n            print(txt, end=\\'\\')\\r\\n    \\r\\n    test_passed()\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a1_6_woodshop': 'from cs110 import autograder\\nimport random, math\\n\\nnum_tests_passed = 0\\nnum_tests_run = 0\\n\\ndef run_test(total_bf, budget):\\n    global num_tests_run, num_tests_passed\\n        \\n    num_tests_run += 1\\n    \\n    print(\"----------------------------------\")\\n    print(\"Test #\" + str(num_tests_run))\\n    print(\"----------------------------------\")\\n    \\n    total_boards = math.ceil(total_bf/5.33)\\n    total_cost = 45.25*total_boards\\n    \\n    \\n    if total_cost > budget:\\n        expected_output = \"Over Budget\"\\n    else:\\n        expected_output = \"Within Budget\"\\n    \\n    output, error_message = autograder.run_script(\"a1_6_woodshop.py\", [total_bf, budget])\\n    \\n    lines = output.split(\"\\\\n\")\\n    \\n    # Length of Materials\\n    if len(lines) >= 1 and autograder.equals(lines[0], total_boards):\\n        print(\"Number of Boards Looks Good!\")\\n        num_tests_passed += 0.33\\n    else:\\n        print(\"Incorrect Amount. Expected:\", total_boards)\\n\\n    # Cost of Materials\\n    if len(lines) >= 2 and autograder.equals(lines[1], total_cost):\\n        print(\"Cost of Materials Looks Good!\")\\n        num_tests_passed += 0.33\\n    else:\\n        print(\"Incorrect Cost. Expected:\", total_cost)\\n        \\n    # Cost Analysis\\n    if len(lines) >= 3 and lines[2].strip() == expected_output:\\n        print(\"Correct Budget Analysis\\\\n\")\\n        num_tests_passed += 0.34\\n    else:\\n        print(\"Incorrect Budget Analysis. Expected:\", expected_output, \"\\\\n\")\\n\\n    return round((num_tests_passed / num_tests_run) * 100.0, 1)\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    for x in range(4):\\n        run_test(round(random.uniform(10, 50), 1), random.randint(100, 500))\\n    run_test(round(random.uniform(10, 100), 1), 0)\\n    \\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\n\\n        \\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_6_scuba': 'from cs110 import autograder\\nimport random, math\\n\\nnum_tests_passed = 0\\nnum_tests_run = 0\\n\\ndef run_test(target_minutes, budget):\\n    global num_tests_run, num_tests_passed\\n        \\n    num_tests_run += 1\\n    \\n    print(\"----------------------------------\")\\n    print(\"Test #\" + str(num_tests_run))\\n    print(\"----------------------------------\")\\n    \\n    \\n    total_liters = target_minutes*14.5\\n    total_cost = total_liters*.02\\n        \\n    if total_cost > budget:\\n        expected_output = \"Over Budget\"\\n    else:\\n        expected_output = \"Within Budget\"\\n    \\n    output, error_message = autograder.run_script(\"a1_6_scuba.py\", [target_minutes, budget])\\n    \\n    lines = output.split(\"\\\\n\")\\n    \\n    # Length of Materials\\n    if len(lines) >= 1 and autograder.equals(lines[0], total_liters):\\n        print(\"Amount of Air Looks Good!\")\\n        num_tests_passed += 0.33\\n    else:\\n        print(\"Incorrect Amount. Expected:\", total_liters)\\n\\n    # Cost of Materials\\n    if len(lines) >= 2 and autograder.equals(lines[1], total_cost):\\n        print(\"Cost of Air Looks Good!\")\\n        num_tests_passed += 0.33\\n    else:\\n        print(\"Incorrect Cost. Expected:\", total_cost)\\n        \\n    # Cost Analysis\\n    if len(lines) >= 3 and lines[2].strip() == expected_output:\\n        print(\"Correct Budget Analysis\\\\n\")\\n        num_tests_passed += 0.34\\n    else:\\n        print(\"Incorrect Budget Analysis. Expected:\", expected_output, \"\\\\n\")\\n\\n    return round((num_tests_passed / num_tests_run) * 100.0, 1)\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    for x in range(4):\\n        run_test(round(random.uniform(10,100), 1), random.randint(10, 50))\\n    run_test(round(random.uniform(10,100), 1), 0)\\n    \\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\n\\n        \\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_6_runway': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(runway_length, budget):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Test #\" + str(num_tests_run))\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    tons_of_concrete = 2.5 * runway_length\\r\\n    cost_of_materials = 75.50 * tons_of_concrete\\r\\n    if cost_of_materials > budget:\\r\\n        expected_output = \"Over Budget\"\\r\\n    else:\\r\\n        expected_output = \"Within Budget\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_6_runway.py\", [runway_length, budget])\\r\\n    \\r\\n    lines = output.split(\"\\\\n\")\\r\\n    \\r\\n    # Length of Materials\\r\\n    if len(lines) >= 1 and autograder.equals(lines[0], tons_of_concrete):\\r\\n        print(\"Amount of Concrete Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Amount. Expected:\", tons_of_concrete)\\r\\n\\r\\n    # Cost of Materials\\r\\n    if len(lines) >= 2 and autograder.equals(lines[1], cost_of_materials):\\r\\n        print(\"Cost of Materials Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Cost. Expected:\", cost_of_materials)\\r\\n        \\r\\n    # Cost Analysis\\r\\n    if len(lines) >= 3 and lines[2].strip() == expected_output:\\r\\n        print(\"Correct Budget Analysis\\\\n\")\\r\\n        num_tests_passed += 0.34\\r\\n    else:\\r\\n        print(\"Incorrect Budget Analysis. Expected:\", expected_output, \"\\\\n\")\\r\\n\\r\\n    return round((num_tests_passed / num_tests_run) * 100.0, 1)\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(500, 3000), 1), random.randint(100000, 500000))\\r\\n    run_test(round(random.uniform(500, 3000), 1), 0)\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'a1_6_printer': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(volume, budget):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Test #\" + str(num_tests_run))\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    length_of_materials = 0.312 * volume\\r\\n    cost_of_materials = 0.063 * length_of_materials\\r\\n    if cost_of_materials > budget:\\r\\n        expected_output = \"Over Budget\"\\r\\n    else:\\r\\n        expected_output = \"Within Budget\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_6_printer.py\", [volume, budget])\\r\\n    \\r\\n    lines = output.split(\"\\\\n\")\\r\\n    \\r\\n    # Length of Materials\\r\\n    if len(lines) >= 1 and autograder.equals(lines[0], length_of_materials):\\r\\n        print(\"Length of Materials Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Length. Expected:\", length_of_materials)\\r\\n\\r\\n    # Cost of Materials\\r\\n    if len(lines) >= 2 and autograder.equals(lines[1], cost_of_materials):\\r\\n        print(\"Cost of Materials Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Cost. Expected:\", cost_of_materials)\\r\\n        \\r\\n    # Cost Analysis\\r\\n    if len(lines) >= 3 and lines[2].strip() == expected_output:\\r\\n        print(\"Correct Budget Analysis\\\\n\")\\r\\n        num_tests_passed += 0.34\\r\\n    else:\\r\\n        print(\"Incorrect Budget Analysis. Expected:\", expected_output, \"\\\\n\")\\r\\n\\r\\n    return round((num_tests_passed / num_tests_run) * 100.0, 1)\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(0, 100), 1), random.randint(10, 50))\\r\\n    run_test(round(random.uniform(0, 100), 1), 0)\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a1_6_fueldepot': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(target_distance, budget):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Test #\" + str(num_tests_run))\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    fuel_required = target_distance / 12.5\\r\\n    cost_of_materials = 3.73 * fuel_required\\r\\n    \\r\\n    if cost_of_materials > budget:\\r\\n        expected_output = \"Over Budget\"\\r\\n    else:\\r\\n        expected_output = \"Within Budget\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_6_fueldepot.py\", [target_distance, budget])\\r\\n    \\r\\n    lines = output.split(\"\\\\n\")\\r\\n    \\r\\n    # Length of Materials\\r\\n    if len(lines) >= 1 and autograder.equals(lines[0], fuel_required):\\r\\n        print(\"Amount of Fuel Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Amount. Expected:\", fuel_required)\\r\\n\\r\\n    # Cost of Materials\\r\\n    if len(lines) >= 2 and autograder.equals(lines[1], cost_of_materials):\\r\\n        print(\"Cost of Materials Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Cost. Expected:\", cost_of_materials)\\r\\n        \\r\\n    # Cost Analysis\\r\\n    if len(lines) >= 3 and lines[2].strip() == expected_output:\\r\\n        print(\"Correct Budget Analysis\\\\n\")\\r\\n        num_tests_passed += 0.34\\r\\n    else:\\r\\n        print(\"Incorrect Budget Analysis. Expected:\", expected_output, \"\\\\n\")\\r\\n\\r\\n    return round((num_tests_passed / num_tests_run) * 100.0, 1)\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(500, 3000), 1), random.randint(100000, 500000))\\r\\n    run_test(round(random.uniform(500, 3000), 1), 0)\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_4_speed': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(speed):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Testing speed =\", speed, \"MPH\")\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    if speed > 767.269:\\r\\n        solution = \"Faster than Mach 1\"\\r\\n    elif speed == 767.269:\\r\\n        solution = \"Mach 1\"\\r\\n    else:\\r\\n        solution = \"Slower than Mach 1\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_4_speed.py\", [speed])\\r\\n    \\r\\n    if output.strip() == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(768.0, 1000.0), 1))\\r\\n    run_test(767.269)\\r\\n    run_test(round(random.uniform(0.0, 767.0), 1))\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_4_satellite': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(speed):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Testing speed =\", speed, \"km/s\")\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    if speed > 7.8:\\r\\n        solution = \"Lost to Space\"\\r\\n    elif speed == 7.8:\\r\\n        solution = \"In Orbit\"\\r\\n    else:\\r\\n        solution = \"Crashed to Earth\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_4_satellite.py\", [speed])\\r\\n    \\r\\n    if output.strip() == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(7.8, 20), 1))\\r\\n    run_test(7.8)\\r\\n    run_test(round(random.uniform(0.0, 7.7), 1))\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'a1_4_goldilocks': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(temp):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Testing temperature =\", temp, \"degrees\")\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    if temp > 105:\\r\\n        solution = \"Too Hot\"\\r\\n    elif temp == 105:\\r\\n        solution = \"Just Right\"\\r\\n    else:\\r\\n        solution = \"Too Cold\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_4_goldilocks.py\", [temp])\\r\\n    \\r\\n    if output.strip() == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(106, 130), 1))\\r\\n    run_test(105)\\r\\n    run_test(round(random.uniform(80, 104), 1))\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'a1_4_cards': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(num_cards):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Testing number of cards =\", num_cards, \"cards\")\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    if num_cards > 52:\\r\\n        solution = \"Too many cards\"\\r\\n    elif num_cards == 52:\\r\\n        solution = \"Full deck\"\\r\\n    else:\\r\\n        solution = \"Not enough cards\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_4_cards.py\", [num_cards])\\r\\n    \\r\\n    if output.strip() == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(53, 60)))\\r\\n    run_test(52)\\r\\n    run_test(round(random.uniform(0, 51)))\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_4_arrow': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(height):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Testing height =\", height, \"feet\")\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    if height > 6.2:\\r\\n        solution = \"Arrow too high\"\\r\\n    elif height == 6.2:\\r\\n        solution = \"Direct hit\"\\r\\n    else:\\r\\n        solution = \"Arrow too low\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_4_arrow.py\", [height])\\r\\n    \\r\\n    if output.strip() == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(6.2, 20), 1))\\r\\n    run_test(6.2)\\r\\n    run_test(round(random.uniform(0.0, 6.1), 1))\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_3_spheres': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nfrom a1_3_spheres import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    answer = math.pi * (4/3) * (radius**3)*total\\r\\n    file = open(\"a1_3_spheres.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    print(\"Checking to see if variable \\'volume\\' exists . . . \", end=\\'\\')\\r\\n    if \\'volume\\' in globals():\\r\\n        print(\"FOUND!\")\\r\\n        score += 10\\r\\n        \\r\\n        print(\"Checking mathematical formula . . . \", end=\\'\\')\\r\\n        if \\'*\\' in file_contents and \\'math.pi\\' in file_contents and (\\'**\\' in file_contents or \\'math.pow\\' in file_contents or \\'pow\\' in file_contents):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 60\\r\\n        else:\\r\\n            print(\"NOT FOUND. Make sure you are using the formula.\")\\r\\n        \\r\\n        print(\"Checking the value of \\'volume\\' . . . \", end=\\'\\')\\r\\n        if \\'volume\\' in globals() and autograder.equals(volume, answer):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 30\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n    else:\\r\\n        print(\"NOT FOUND. Make sure you name your variable according to the prompt.\")\\r\\n      \\r\\n    return score\\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_3_radius': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nfrom a1_3_radius import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    answer = math.pi * (radius**2) * height * total\\r\\n    file = open(\"a1_3_radius.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    print(\"Checking to see areif variable \\'volume\\' exists . . . \", end=\\'\\')\\r\\n    if \\'volume\\' in globals():\\r\\n        print(\"FOUND!\")\\r\\n        score += 10\\r\\n        \\r\\n        print(\"Checking mathematical formula . . . \", end=\\'\\')\\r\\n        if \\'*\\' in file_contents and \\'math.pi\\' in file_contents and (\\'**\\' in file_contents or \\'math.pow\\' in file_contents or \\'pow\\' in file_contents):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 60\\r\\n        else:\\r\\n            print(\"NOT FOUND. Make sure you are using the formula.\")\\r\\n        \\r\\n        print(\"Checking the value of \\'volume\\' . . . \", end=\\'\\')\\r\\n        if \\'volume\\' in globals() and autograder.equals(volume, answer):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 30\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n    else:\\r\\n        print(\"NOT FOUND. Make sure you name your variable according to the prompt.\")\\r\\n      \\r\\n    return score\\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a1_3_interest': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nfrom a1_3_interest import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    answer = principal_amount * math.e**(interest_rate * time)\\r\\n    file = open(\"a1_3_interest.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    print(\"Checking to see if variable \\'amount\\' exists . . . \", end=\\'\\')\\r\\n    if \\'amount\\' in globals():\\r\\n        print(\"FOUND!\")\\r\\n        score += 10\\r\\n        \\r\\n        print(\"Checking mathematical formula . . . \", end=\\'\\')\\r\\n        if \\'*\\' in file_contents and \\'math.e\\' in file_contents and (\\'**\\' in file_contents or \\'math.pow\\' in file_contents or \\'pow\\' in file_contents):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 60\\r\\n        else:\\r\\n            print(\"NOT FOUND. Make sure you are using the formula.\")\\r\\n        \\r\\n        print(\"Checking the value of \\'amount\\' . . . \", end=\\'\\')\\r\\n        if \\'amount\\' in globals() and autograder.equals(amount, answer):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 30\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n    else:\\r\\n        print(\"NOT FOUND. Make sure you name your variable according to the prompt.\")\\r\\n      \\r\\n    return score\\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_3_cones': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nfrom a1_3_cones import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    answer = math.pi * (radius**2) * (height/3) * total\\r\\n    file = open(\"a1_3_cones.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    print(\"Checking to see if variable \\'volume\\' exists . . . \", end=\\'\\')\\r\\n    if \\'volume\\' in globals():\\r\\n        print(\"FOUND!\")\\r\\n        score += 10\\r\\n        \\r\\n        print(\"Checking mathematical formula . . . \", end=\\'\\')\\r\\n        if \\'*\\' in file_contents and \\'math.pi\\' in file_contents and (\\'**\\' in file_contents or \\'math.pow\\' in file_contents or \\'pow\\' in file_contents):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 60\\r\\n        else:\\r\\n            print(\"NOT FOUND. Make sure you are using the formula.\")\\r\\n        \\r\\n        print(\"Checking the value of \\'volume\\' . . . \", end=\\'\\')\\r\\n        if \\'volume\\' in globals() and autograder.equals(volume, answer):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 30\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n    else:\\r\\n        print(\"NOT FOUND. Make sure you name your variable according to the prompt.\")\\r\\n      \\r\\n    return score\\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_3_circles': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nfrom a1_3_circles import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    answer = math.pi * (radius**2)*total\\r\\n    file = open(\"a1_3_circles.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    print(\"Checking to see if variable \\'area\\' exists . . . \", end=\\'\\')\\r\\n    if \\'area\\' in globals():\\r\\n        print(\"FOUND!\")\\r\\n        score += 10\\r\\n        \\r\\n        print(\"Checking mathematical formula . . . \", end=\\'\\')\\r\\n        if \\'*\\' in file_contents and \\'math.pi\\' in file_contents and (\\'**\\' in file_contents or \\'math.pow\\' in file_contents or \\'pow\\' in file_contents):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 60\\r\\n        else:\\r\\n            print(\"NOT FOUND. Make sure you are using the formula.\")\\r\\n        \\r\\n        print(\"Checking the value of \\'area\\' . . . \", end=\\'\\')\\r\\n        if \\'area\\' in globals() and autograder.equals(area, answer):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 30\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n    else:\\r\\n        print(\"NOT FOUND. Make sure you name your variable according to the prompt.\")\\r\\n      \\r\\n    return score\\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a1_1_squad': 'from cs110 import autograder\\nimport random, math\\n\\nnum_tests_passed = 0\\nnum_tests_run = 0\\n\\ndef run_test():\\n    global num_tests_run, num_tests_passed\\n        \\n    num_tests_run += 1\\n    \\n    squad_list = [(\"Warhawks\", 21.2, 40), (\"Barnstormers\", 19.2, 23), (\"Black Panthers\", 20.7, 29), (\"Dogs of War\", 21.1, 3)]\\n    squad = squad_list[random.randint(0, len(squad_list) - 1)]\\n    solution = \"The \\\\\"%s\\\\\" has an average cadet age of %1.1f and is Squadron %i.\" % (squad[0], squad[1], squad[2])\\n    \\n    output, error_message = autograder.run_script(\"a1_1_squad.py\", [squad[0], squad[1], squad[2]])\\n        \\n    if output.strip() == solution:\\n        print(\"SUCCESS!\\\\n\")\\n        num_tests_passed += 1\\n    else:\\n        print(\"INCORRECT. Expected:\", solution)\\n        print(\"\\\\n\")\\n\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    run_test()\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\n\\n        \\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_1_icbm': '#import cs110,\\r\\nimport random, math\\r\\nfrom cs110 import autograder\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test():\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    icbm_list = [(\"Peacekeeper\", 21.8, 88450), (\"Minuteman\", 16.36, 29000), (\"Titan\", 31.394, 155000)]\\r\\n    icbm = icbm_list[random.randint(0, len(icbm_list) - 1)]\\r\\n    solution = \"The %s has a total length of %1.1f meters and it weighs %d kilograms.\" % (icbm[0], icbm[1], icbm[2])\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_1_icbm.py\", [icbm[0], icbm[1], icbm[2]])\\r\\n        \\r\\n    if output.strip() == solution:\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test()\\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_1_dorms': 'from cs110 import autograder\\nimport random, math\\n\\nnum_tests_passed = 0\\nnum_tests_run = 0\\n\\ndef run_test():\\n    global num_tests_run, num_tests_passed\\n        \\n    num_tests_run += 1\\n    \\n    dorm_list = [(\"Vandenburg\", 111874.79, 2212), (\"Sijan\", 124488.97, 2112)]\\n    dorm = dorm_list[random.randint(0, len(dorm_list) - 1)]\\n    solution = \"The %s dormitory has an area of %1.1f square feet and has %d cadets living in it.\" % (dorm[0], dorm[1], dorm[2])\\n    \\n    output, error_message = autograder.run_script(\"a1_1_dorms.py\", [dorm[0], dorm[1], dorm[2]])\\n        \\n    if output.strip() == solution:\\n        print(\"SUCCESS!\\\\n\")\\n        num_tests_passed += 1\\n    else:\\n        print(\"INCORRECT. Expected:\", solution)\\n        print(\"\\\\n\")\\n\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    run_test()\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\n\\n        \\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_1_bases': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test():\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    base_list = [(\"Travis\", 1874.79, 1288), (\"Barksdale\", 1488.97, 1680), (\"Eglin\", 1611.08, 1388)]\\r\\n    base = base_list[random.randint(0, len(base_list) - 1)]\\r\\n    solution = \"%s Air Force Base sits on %1.1f acres and has %d buildings on it.\" % (base[0], base[1], base[2])\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_1_bases.py\", [base[0], base[1], base[2]])\\r\\n        \\r\\n    if output.strip() == solution:\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test()\\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_1_aircraft': '#import cs110,\\r\\nimport random, math\\r\\nfrom cs110 import autograder\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test():\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    aircraft_list = [(\"F-15\", 1874.79, 288), (\"F-16\", 1488.97, 680), (\"F-22\", 1611.08, 88)]\\r\\n    aircraft = aircraft_list[random.randint(0, len(aircraft_list) - 1)]\\r\\n    solution = \"The %s has a top speed of %1.1f MPH.  The USAF has %d in its inventory.\" % (aircraft[0], aircraft[1], aircraft[2])\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_1_aircraft.py\", [aircraft[0], aircraft[1], aircraft[2]])\\r\\n        \\r\\n    if output.strip() == solution:\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test()\\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'Airstrike': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef feedback_string_formatter(feedback_line, line_num):\\r\\n    return \"Feedback \" + str(line_num) + \")\\\\t\" + feedback_line + \"\\\\n\"\\r\\n\\r\\ndef parse_file_contents():\\r\\n    #initiates provided inputs and expected inputs should be hard coded based on each test case\\r\\n    numInputs = 0\\r\\n    expectedInputs = 0\\r\\n    \\r\\n    #change file name to whatever the test file name is without \\'_test\\'\\r\\n    file = open(\"Airstrike.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    lines = file_contents.split(\"\\\\n\")\\r\\n    \\r\\n    count_mission_complete = 0\\r\\n    count_get_scan_results = 0\\r\\n    count_set_destination = 0\\r\\n    \\r\\n    # parses each line to check for key components\\r\\n    for line in lines:\\r\\n        if len(line) > 0 and line[0] != \\'#\\':        \\r\\n            if \"mission_complete()\" in line:\\r\\n                count_mission_complete +=1\\r\\n                \\r\\n            if (\"get_scan_results()\" in line) and \\'#\\' not in line:\\r\\n                count_get_scan_results += 1\\r\\n                \\r\\n            if \"set_destination(\" in line and \\'#\\' not in line:\\r\\n                count_set_destination += 1\\r\\n   \\r\\n    output_message = \"\"\\r\\n    \\r\\n    message_count = 0\\r\\n   \\r\\n    if count_mission_complete > 0:\\r\\n        output_message += feedback_string_formatter(\"Good job including mission complete\", message_count)\\r\\n        message_count += 1\\r\\n    else:\\r\\n        output_message += feedback_string_formatter(\"Ensure you have a mission_complete()\", message_count)\\r\\n        message_count += 1\\r\\n        \\r\\n    if count_get_scan_results == 0:\\r\\n        output_message += feedback_string_formatter(\"You aren\\'t scanning the environment. That\\'s a critical step.\", message_count)\\r\\n        message_count += 1\\r\\n        \\r\\n    if count_set_destination == 0:\\r\\n        output_message += feedback_string_formatter(\"You still need to navigate your drone!\", message_count)\\r\\n        message_count += 1\\r\\n        \\r\\n    output_message += feedback_string_formatter(\"You have run your Recon file against Autograder, make sure to Document and Comment before submission!\", message_count)\\r\\n    output_message += \"IMPORTANT: To see your drone fly, run it again and type \\'n\\' to open the graphics window!\\\\n\"\\r\\n    output_message += \"IMPORTANT: The Autograder score will always be 0, your instructor will manually grade all submissions.\\\\n\"\\r\\n    return output_message\\r\\n\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Sample Unit Test\\r\\n# ---------------------------------------------------------------------\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef parse_file_contents():\\r\\n    print(too_many_inputs())\\r\\n    \\r\\n    return 0\\r\\n        \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()',\n",
       "  'lsn21_bouncingball': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn21_bouncingball.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn21_bouncingtriangle': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn21_bouncingtriangle.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn12_fastestcar': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn12_fastestcar\\r\\n\\r\\ndef solution(car1, car2):\\r\\n\\r\\n    if car1[2] > car2[2]:\\r\\n        return car1[0]\\r\\n    elif car2[2] > car1[2]:\\r\\n        return car2[0]\\r\\n    else:\\r\\n        return \"Same speed\"\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    # 5 test strategies\\r\\n    cars_list = []\\r\\n    cars_list.append([\"Honda Civic\", 18983.20, 127])\\r\\n    cars_list.append([\"Acura NSX\", 157500.39, 191])\\r\\n    cars_list.append([\"VW Golf GTI\", 28595.83, 130])\\r\\n    cars_list.append([\"Ford F-150 Raptor\", 45290.82, 107])\\r\\n    cars_list.append([\"Subaru BRZ\", 28955.38, 140])\\r\\n    cars_list.append([\"Mazda Mazdaspeed3\", 17424.30, 130])\\r\\n    \\r\\n    test_vals = []\\r\\n    \\r\\n    index_permutations = []\\r\\n    # build all possible permutations except those with the same vehicle\\r\\n    for i in range(len(cars_list)):\\r\\n        for j in range(len(cars_list)):\\r\\n            if i != j:\\r\\n                index_permutations.append((i,j))\\r\\n    \\r\\n    # randomly choose 4 of the permutations\\r\\n    for i in range(4):\\r\\n        car_idx_pair = index_permutations[random.randint(0,len(index_permutations)-1)]\\r\\n        first_car_idx = car_idx_pair[0]\\r\\n        second_car_idx = car_idx_pair[1]\\r\\n        \\r\\n        index_permutations.remove(car_idx_pair)\\r\\n        \\r\\n        test_vals.append([cars_list[first_car_idx], cars_list[second_car_idx]])\\r\\n\\r\\n    # same speed\\r\\n    test_vals.append((cars_list[2], cars_list[5]))\\r\\n  \\r\\n    i = 0\\r\\n    total_score = 0.0\\r\\n    \\r\\n    for val in test_vals:\\r\\n        print(\\'-\\'*10 + \"Test #\" + str(i) + \\'-\\'*10)\\r\\n        \\r\\n        output = lsn12_fastestcar.fastest_car(val[0], val[1])\\r\\n        expected_output = solution(val[0], val[1])\\r\\n\\r\\n        print(\"Your Program\\'s Output:\")\\r\\n        print(output)\\r\\n\\r\\n        if output == None:\\r\\n            print(\"INCORRECT - Your function did not return anything. Expected:\")\\r\\n            print(str(expected_output))\\r\\n        elif output.strip() == expected_output.strip():\\r\\n            print(\"CORRECT\")\\r\\n            total_score += 100.0 / len(test_vals)\\r\\n        else:\\r\\n            print(\"INCORRECT - Expected:\")\\r\\n            print(str(expected_output))\\r\\n            \\r\\n        print()\\r\\n        i += 1\\r\\n    \\r\\n    return total_score\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn12_listrange': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(test_start, test_stop):\\r\\n    result = []\\r\\n    \\r\\n    result.append(list(range(test_start, test_stop+1)))\\r\\n    result.append(len(range(test_start, test_stop+1)))\\r\\n        \\r\\n    return result\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    # 5 test strategies\\r\\n    test_vals = []\\r\\n    \\r\\n    for j in range(5):\\r\\n        test_val_start = random.randint(0,2048)\\r\\n        test_val_stop = test_val_start + random.randint(9,16)\\r\\n        test_vals.append((test_val_start, test_val_stop))\\r\\n  \\r\\n    i = 0\\r\\n    total_score = 0.0\\r\\n    \\r\\n    for val in test_vals:\\r\\n        print(\\'-\\'*10 + \"Test #\" + str(i) + \\'-\\'*10)\\r\\n        \\r\\n        output, error_message = autograder.run_script(\"lsn12_listrange.py\", [val[0], val[1]])\\r\\n        expected_output = solution(val[0], val[1])\\r\\n        \\r\\n        lines = output.strip().split(\\'\\\\n\\')\\r\\n        \\r\\n        if lines[0].strip() == str(expected_output[0]) and autograder.equals(int(lines[1]), expected_output[1]):\\r\\n            print(\"CORRECT\")\\r\\n            total_score += 100.0 / len(test_vals)\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n            \\r\\n        print()\\r\\n        i += 1\\r\\n    \\r\\n    return total_score\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn22_paint': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn22_paint.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn12_pftscores': 'from cs110 import autograder\\r\\nimport random, math\\r\\n#import lsn12_pftscores\\r\\n\\r\\npft_scores = [243, 394, 143, 288, 303, 473, 325, 273, 284, 198, 70, 289, 437, 329]\\r\\n\\r\\n\\r\\ndef solution(new_num):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    # Append number to num_list ONLY IF IT IS A valid number > 0\\r\\n    if new_num >= 0 and new_num <= 500:\\r\\n\\r\\n        temp_scores = pft_scores.copy()\\r\\n        temp_scores.append(new_num)\\r\\n        \\r\\n        average = sum(temp_scores) / len(temp_scores)\\r\\n        num_range = max(temp_scores) - min(temp_scores)\\r\\n        \\r\\n        result += str(average) + \\'\\\\n\\'\\r\\n        result += str(num_range) + \\'\\\\n\\'\\r\\n    else:\\r\\n        result += \"Invalid score provided\"\\r\\n        \\r\\n    return result\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    # 5 test strategies\\r\\n    # 1) invalid, out of range low\\r\\n    # 2) invalid, out of range high\\r\\n    # 3) rand num that doesn\\'t affect range\\r\\n    # 4) rand num lower than current lowest, but valid\\r\\n    # 5) rand num higher than current highest, but valid\\r\\n    \\r\\n    min_score = min(pft_scores)\\r\\n    max_score = max(pft_scores)\\r\\n    \\r\\n    test_vals = []\\r\\n    \\r\\n    # random_low_invalid\\r\\n    test_vals.append(random.randint(-1010,-1))\\r\\n    #random_high_invalid\\r\\n    test_vals.append(random.randint(501,5000))\\r\\n    #random_mid_num\\r\\n    test_vals.append(random.randint(min_score, max_score))\\r\\n    #random_low\\r\\n    test_vals.append(random.randint(0, min_score-1))\\r\\n    #random_high\\r\\n    test_vals.append(random.randint(max_score + 1, 500))\\r\\n    \\r\\n    i = 0\\r\\n    total_score = 0.0\\r\\n    \\r\\n    for val in test_vals:\\r\\n        print(\\'-\\'*10 + \"Test #\" + str(i) + \\'-\\'*10)\\r\\n        \\r\\n        output, error_message = autograder.run_script(\"lsn12_pftscores.py\", [val])\\r\\n        expected_output = solution(val)\\r\\n        \\r\\n        lines = output.strip().split(\\'\\\\n\\')\\r\\n        \\r\\n        if expected_output.strip() == \"Invalid score provided\":\\r\\n            if output.strip() == expected_output.strip():\\r\\n                print(\"CORRECT\")\\r\\n                total_score += 100 / len(test_vals)\\r\\n            else:\\r\\n                print(\"INCORRECT. Expected the following:\")\\r\\n                print(expected_output)\\r\\n        else:\\r\\n            expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n            \\r\\n            if autograder.equals(float(expected_lines[0]), float(lines[0]), 0.99) and autograder.equals(float(expected_lines[1]), float(lines[1]), 0.99):\\r\\n                print(\"CORRECT\")\\r\\n                total_score += 100 / len(test_vals)\\r\\n            else:\\r\\n                print(\"INCORRECT. Expected the following:\")\\r\\n                print(expected_output)\\r\\n            \\r\\n        print()\\r\\n        i += 1\\r\\n    \\r\\n    return total_score\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'Recon': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef feedback_string_formatter(feedback_line, line_num):\\r\\n    return \"Feedback \" + str(line_num) + \")\\\\t\" + feedback_line + \"\\\\n\"\\r\\n\\r\\ndef too_many_inputs():\\r\\n    #initiates provided inputs and expected inputs should be hard coded based on each test case\\r\\n    numInputs = 0\\r\\n    expectedInputs = 0\\r\\n    \\r\\n    #change file name to whatever the test file name is without \\'_test\\'\\r\\n    file = open(\"Recon.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    lines = file_contents.split(\"\\\\n\")\\r\\n    \\r\\n    count_mission_complete = 0\\r\\n    count_get_scan_results = 0\\r\\n    count_set_destination = 0\\r\\n    \\r\\n    # parses each line to check for key components\\r\\n    for line in lines:\\r\\n        if len(line) > 0 and line[0] != \\'#\\':        \\r\\n            if \"mission_complete()\" in line:\\r\\n                count_mission_complete +=1\\r\\n                \\r\\n            if (\"get_scan_results()\" in line) and \\'#\\' not in line:\\r\\n                count_get_scan_results += 1\\r\\n                \\r\\n            if \"set_destination(\" in line and \\'#\\' not in line:\\r\\n                count_set_destination += 1\\r\\n   \\r\\n    output_message = \"\"\\r\\n    \\r\\n    message_count = 0\\r\\n   \\r\\n    if count_mission_complete > 0:\\r\\n        output_message += feedback_string_formatter(\"Good job including mission complete\", message_count)\\r\\n        message_count += 1\\r\\n    else:\\r\\n        output_message += feedback_string_formatter(\"Ensure you have a mission_complete()\", message_count)\\r\\n        message_count += 1\\r\\n        \\r\\n    if count_get_scan_results == 0:\\r\\n        output_message += feedback_string_formatter(\"You aren\\'t scanning the environment. That\\'s a critical step.\", message_count)\\r\\n        message_count += 1\\r\\n        \\r\\n    if count_set_destination == 0:\\r\\n        output_message += feedback_string_formatter(\"You still need to navigate your drone!\", message_count)\\r\\n        message_count += 1\\r\\n        \\r\\n    output_message += feedback_string_formatter(\"You have run your Recon file against Autograder, make sure to Document and Comment before submission!\", message_count)\\r\\n    output_message += \"IMPORTANT: To see your drone fly, run it again and type \\'n\\' to open the graphics window!\\\\n\"\\r\\n    output_message += \"IMPORTANT: The Autograder score will always be 0, your instructor will manually grade all submissions.\\\\n\"\\r\\n    return output_message\\r\\n\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Sample Unit Test\\r\\n# ---------------------------------------------------------------------\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    print(too_many_inputs())\\r\\n    \\r\\n    return 0\\r\\n    \\r\\n        \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Skywriter': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef feedback_string_formatter(feedback_line, line_num):\\r\\n    return \"Feedback \" + str(line_num) + \")\\\\t\" + feedback_line + \"\\\\n\"\\r\\n\\r\\ndef too_many_inputs():\\r\\n    #initiates provided inputs and expected inputs should be hard coded based on each test case\\r\\n    numInputs = 0\\r\\n    expectedInputs = 0\\r\\n    \\r\\n    #change file name to whatever the test file name is without \\'_test\\'\\r\\n    file = open(\"Skywriter.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    lines = file_contents.split(\"\\\\n\")\\r\\n    \\r\\n    count_mission_complete = 0\\r\\n    count_get_x_or_y = 0\\r\\n    count_smoke = 0\\r\\n    \\r\\n    # parses each line to check for key components\\r\\n    for line in lines:\\r\\n        if len(line) > 0 and line[0] != \\'#\\':        \\r\\n            if \"mission_complete()\" in line:\\r\\n                count_mission_complete +=1\\r\\n                \\r\\n            if (\"get_x_location()\" in line or \"get_y_location()\" in line) and \\'#\\' not in line:\\r\\n                count_get_x_or_y += 1\\r\\n                \\r\\n            if \"smoke_on()\" in line or \"smoke_off()\" in line:\\r\\n                count_smoke += 1\\r\\n   \\r\\n    output_message = \"\"\\r\\n    \\r\\n    message_count = 0\\r\\n   \\r\\n    if count_mission_complete > 0:\\r\\n        output_message += feedback_string_formatter(\"Good job including mission complete\", message_count)\\r\\n        message_count += 1\\r\\n    else:\\r\\n        output_message += feedback_string_formatter(\"Ensure you have a mission_complete()\", message_count)\\r\\n        message_count += 1\\r\\n        \\r\\n    if count_get_x_or_y == 0:\\r\\n        output_message += feedback_string_formatter(\"You don\\'t check the drone\\'s location using get_x_location() or get_y_location(). That\\'s a critical step.\", message_count)\\r\\n        message_count += 1\\r\\n        \\r\\n    if count_smoke == 0:\\r\\n        output_message += feedback_string_formatter(\"You will need to turn smoke on or off at least once.\", message_count)\\r\\n        message_count += 1\\r\\n        \\r\\n    output_message += feedback_string_formatter(\"You have run your Skywriter file against Autograder, if this is the project, make sure to Document and Comment!\", message_count)\\r\\n    output_message += \"IMPORTANT: To see your drone fly, run it again and type \\'n\\' to open the graphics window!\\\\n\"\\r\\n    output_message += \"IMPORTANT: The Autograder score will always be 0, your instructor will manually grade all submissions.\\\\n\"\\r\\n    return output_message\\r\\n\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Sample Unit Test\\r\\n# ---------------------------------------------------------------------\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    print(too_many_inputs())\\r\\n    \\r\\n    return 0\\r\\n    \\r\\n        \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn22_soundboard': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn22_soundboard.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn8_practice4': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef solution(area_1, area_2, area_3):\\r\\n    area_1 = area_1 * 0.0015625\\r\\n    area_3 = area_3 * 0.386102\\r\\n\\r\\n    if area_1 > area_2 and area_1 > area_3:\\r\\n        return \"Plot 1 is the biggest\"\\r\\n    elif area_2 > area_1 and area_2 > area_3:\\r\\n        return \"Plot 2 is the biggest\"\\r\\n    elif area_3 > area_1 and area_3 > area_2:\\r\\n        return \"Plot 3 is the biggest\"\\r\\n    \\r\\n    return \"This should never return\"\\r\\n\\r\\ndef run_test(area1, area2, area3):\\r\\n    global num_tests_run, num_tests_passed\\r\\n    \\r\\n    num_tests_run += 1\\r\\n    expected_output = solution(area1, area2, area3)\\r\\n        \\r\\n    print(\"--------------------------------------------\")\\r\\n    print(\"Comparing %1.1f acres, %1.1f sq miles, and %1.1f sq km\" % (area1, area2, area3))\\r\\n    print(\"--------------------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn8_practice4.py\", [area1, area2, area3])\\r\\n    \\r\\n    if output.strip() == expected_output:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", expected_output)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(random.uniform(100, 1000), random.uniform(0.1, 2.0), random.uniform(0.1, 5.0))\\r\\n    run_test(random.uniform(100, 1000), random.uniform(0.1, 2.0), random.uniform(0.1, 5.0))\\r\\n    run_test(random.uniform(100, 1000), random.uniform(0.1, 2.0), random.uniform(0.1, 5.0))\\r\\n\\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn8_practice3': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(dollar_amount):\\r\\n\\r\\n    \\r\\n    return result\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    total_score = 0\\r\\n    \\r\\n    test_values = [209.66, 0.95, 44.46, 652.08]\\r\\n    \\r\\n    for idx, dollar_amount in enumerate(test_values):\\r\\n        print(\"\\\\n-----------------------------\")\\r\\n        print(\"     Test Case \" + str(idx+1))\\r\\n        print(\"-----------------------------\")\\r\\n        \\r\\n        result = 0.0\\r\\n    \\r\\n        pound_amount = dollar_amount / 1.25\\r\\n        won_amount = dollar_amount / 0.00083\\r\\n        peso_amount = won_amount / 53.81\\r\\n        \\r\\n        output, error_message = autograder.run_script(\"lsn8_practice3.py\", [dollar_amount])   \\r\\n        lines = output.split(\\'\\\\n\\')\\r\\n        \\r\\n        if len(lines) > 0 and autograder.equals(lines[0], pound_amount):\\r\\n            print(\"Correct Pound Conversion\")\\r\\n            result += 33\\r\\n        else:\\r\\n            print(\"Incorrect Pound Conversion.  Expected\", pound_amount)\\r\\n            \\r\\n        if len(lines) > 1 and autograder.equals(lines[1], won_amount):\\r\\n            print(\"Correct Won Conversion\")\\r\\n            result += 33\\r\\n        else:\\r\\n            print(\"Incorrect Won Conversion.  Expected\", won_amount)\\r\\n            \\r\\n        if len(lines) > 2 and autograder.equals(lines[2], peso_amount):\\r\\n            print(\"Correct Peso Conversion\")\\r\\n            result += 34\\r\\n        else:\\r\\n            print(\"Incorrect Peso Conversion.  Expected\", peso_amount)\\r\\n        \\r\\n        total_score += result\\r\\n    \\r\\n    print()\\r\\n    \\r\\n    return int(total_score * (1 / len(test_values)))\\r\\n        \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn8_practice2': 'from cs110 import autograder\\nimport random, math\\n\\nnum_tests_passed = 0\\nnum_tests_run = 0\\n\\ndef run_test():\\n    global num_tests_run, num_tests_passed\\n    \\n    x1 = round(random.uniform(-10, 10), 1)\\n    y1 = round(random.uniform(-10, 10), 1)\\n    x2 = round(random.uniform(-10, 10), 1)\\n    y2 = round(random.uniform(-10, 10), 1)\\n    \\n    num_tests_run += 1\\n    solution = math.sqrt(abs(x1-x2)**2 + abs(y1-y2)**2)\\n    \\n    print(\"--------------------------------------------\")\\n    print(\"Calculating distance between (%1.1f, %1.1f) and (%1.1f, %1.1f)\" % (x1, y1, x2, y2))\\n    print(\"--------------------------------------------\")\\n    output, error_message = autograder.run_script(\"lsn8_practice2.py\", [x1, y1, x2, y2])\\n    print(\"Your Output:\", output.strip())\\n    \\n    if autograder.equals(output, solution):\\n        print(\"CORRECT!\\\\n\")\\n        num_tests_passed += 1\\n    else:\\n        print(\"INCORRECT\")    \\n        print(\"Expected:\", solution)\\n        print(\"\\\\n\")\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    run_test()\\n    run_test()\\n\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\n\\n        \\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn8_practice1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(class_year):\\r\\n    global num_tests_run, num_tests_passed\\r\\n    \\r\\n    num_tests_run += 1\\r\\n    solution = \"Members of the class of \" + str(class_year) + \" arrived at USAFA in \" + str(class_year - 4)\\r\\n    \\r\\n    print(\"--------------------------------------------\")\\r\\n    print(\"Testing Class Year =\", class_year)\\r\\n    print(\"--------------------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn8_practice1.py\", [class_year])\\r\\n        \\r\\n    if output.strip() == solution:\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT\")\\r\\n        print(\"Your Output:\", output.strip())\\r\\n        print(\"Expected:\", solution)\\r\\n        if \".0\" in output.strip():\\r\\n            print(\"*** HINT:  Is year a floating point number? ***\")\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(random.randint(1959, 2024))\\r\\n    run_test(random.randint(1959, 2024))\\r\\n\\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn4_skill2': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n       \\r\\n    # Generates Random Values\\r\\n    distance = random.uniform(100, 200)\\r\\n    speed = random.uniform(20, 50)\\r\\n    time = distance / speed\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_skill2.py\", [distance, speed])\\r\\n    \\r\\n    if autograder.equals(output, time):\\r\\n        print(\"PASSED\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"Incorrect Output, Expected\", time)\\r\\n        return 0\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn4_skill1': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n       \\r\\n    points_earned = 0   \\r\\n    \\r\\n    output, error = autograder.run_script(\"lsn4_skill1.py\", [\\'abc\\', 123, 123.45])\\r\\n    \\r\\n    lines = output.split(\"\\\\n\")\\r\\n    \\r\\n    if (lines[0] == \"<class \\'str\\'>\"):\\r\\n        points_earned += 33\\r\\n        print(\"my_string correct!\")\\r\\n    else:\\r\\n        print(\"my_string is either not present, or is not the correct data type\")\\r\\n    \\r\\n    if (lines[1] == \"<class \\'int\\'>\"):\\r\\n        points_earned += 33\\r\\n        print(\"my_integer correct!\")\\r\\n    else:\\r\\n        print(\"my_integer is either not present, or is not the correct data type\")\\r\\n        \\r\\n    if (lines[2] == \"<class \\'float\\'>\"):\\r\\n        points_earned += 34\\r\\n        print(\"my_float correct!\")\\r\\n    else:\\r\\n        print(\"my_float is either not present, or is not the correct data type\")\\r\\n        \\r\\n    return points_earned\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn4_scoreaverage': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    score1 = random.randint(0, 100)\\r\\n    score2 = random.randint(0, 100)\\r\\n    score3 = random.randint(0, 100)\\r\\n    average = (score1 + score2 + score3) / 3.0\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_scoreaverage.py\", [score1, score2, score3])\\r\\n    \\r\\n    if autograder.equals(output, average):\\r\\n        print(\"PASSED!\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"Value doesn\\'t match.\\\\nExpected: \" + str(average))\\r\\n        return 0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn4_pointspread': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    score1 = random.randint(0, 50)\\r\\n    score2 = random.randint(score1, 100)\\r\\n    spread = abs(score1 - score2)\\r\\n\\r\\n    points_earned = 0\\r\\n\\r\\n    # Trial #1:  score 1 > score2\\r\\n    print(\"Testing when score 1 is bigger than score 2 . . .\")\\r\\n    output, error_message = autograder.run_script(\"lsn4_pointspread.py\", [score1, score2])\\r\\n    \\r\\n    if autograder.equals(output, spread):\\r\\n        print(\"PASSED!\\\\n\")\\r\\n        points_earned += 50\\r\\n    else:\\r\\n        print(\"Value doesn\\'t match.\\\\nExpected: \" + str(spread)  + \"\\\\n\")\\r\\n        \\r\\n    # Trial #2:  score 2 > score1\\r\\n    print(\"Testing when score 2 is bigger than score 1 . . .\")\\r\\n    output, error_message = autograder.run_script(\"lsn4_pointspread.py\", [score2, score1])\\r\\n    \\r\\n    if autograder.equals(output, spread):\\r\\n        print(\"PASSED!\")\\r\\n        points_earned += 50\\r\\n    else:\\r\\n        print(\"Value doesn\\'t match.\\\\nExpected: \" + str(spread))\\r\\n    \\r\\n    return points_earned\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn4_madlib': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    first_names = [\\'Adrian\\', \\'Troy\\', \\'Dave\\', \\'Paul\\', \\'Kelly\\', \\'Steve\\', \\'Barry\\']\\r\\n    generic_locations = [\\'Best Buy\\', \\'AAFES\\', \\'Target\\', \\'THE Walmart\\', \\'Home Depot\\']\\r\\n    nouns = [\\'Video Games\\', \\'Board Games\\', \\'Nintendo Switches\\', \\'Sony PS4s\\', \\'Microsoft (Ugh) Xbox Ones\\']\\r\\n    \\r\\n    first_name = first_names[random.randint(0, len(first_names) - 1)]\\r\\n    generic_location = generic_locations[random.randint(0, len(generic_locations) - 1)]\\r\\n    whole_number = random.randint(0, 100)\\r\\n    plural_noun = nouns[random.randint(0, len(nouns) - 1)]\\r\\n\\r\\n    expected_output = first_name + \\' went to \\' + generic_location + \\' to buy \\' + str(whole_number) + \\' different types of \\' + plural_noun + \"\\\\n\"\\r\\n\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_madlib.py\", [first_name, generic_location, whole_number, plural_noun])\\r\\n    \\r\\n    if output == expected_output:\\r\\n        print(\"PASSED!\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"String doesn\\'t match.\\\\nExpected: \" + expected_output)\\r\\n        return 0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn4_girlscouts': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    dollar_amount = round(random.uniform(10.00, 100.00), 2)\\r\\n    super_six_amount = (dollar_amount // 5)\\r\\n    specialty_amount = (dollar_amount // 6)\\r\\n    score = 0\\r\\n    \\r\\n    line_1 = str(int(super_six_amount)) + \" boxes of Thin Mints, Samoas, Tagalongs, Do-Si-Dos, Trefoils, or Savannah Smiles\"\\r\\n    line_2 = str(int(specialty_amount)) + \" boxes of S\\'mores and Toffee-tastic\"\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_girlscouts.py\", [dollar_amount])\\r\\n    output_lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if line_1 == output_lines[0]:\\r\\n        print(\"First Line is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"First Line is Incorrect.  Expected:\", line_1)\\r\\n    \\r\\n    if line_2 == output_lines[1]:\\r\\n        print(\"Second Line is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Second Line is Incorrect.  Expected:\", line_2)\\r\\n    \\r\\n    return score\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn4_arrivaltime': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    distance = round(random.random() * 1000, 1)\\r\\n    speed = round(random.random() * 60, 1)\\r\\n    time = distance / speed\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_arrivaltime.py\", [distance, speed])\\r\\n    \\r\\n    if autograder.equals(output, time):\\r\\n        print(\"PASSED!\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"Value doesn\\'t match.\\\\nExpected: \" + str(time))\\r\\n        return 0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn23_tokens': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(filename, t):\\r\\n    # Opens the file\\r\\n    file = open(filename, \"r\")\\r\\n\\r\\n    # Extracts ALL of the text as one big string\\r\\n    file_contents = file.read()\\r\\n\\r\\n    # Splits the entire document into tokens\\r\\n    list_of_tokens = file_contents.split(\\' \\')\\r\\n\\r\\n    # Creates a Dictionary to Store All Tokens\\r\\n    token_dictionary = {}\\r\\n\\r\\n    for token in list_of_tokens:\\r\\n        if token not in token_dictionary:\\r\\n            token_dictionary[token] = 1\\r\\n        else:\\r\\n            token_dictionary[token] = token_dictionary[token] + 1\\r\\n    \\r\\n    if t in token_dictionary:\\r\\n        return token_dictionary[t]\\r\\n    else:\\r\\n        return 0\\r\\n    \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_correct = 0\\r\\n    \\r\\n    # Test #1:\\r\\n    print(\"------------------------------------------\")\\r\\n    print(\"Test 1\")\\r\\n    print(\"------------------------------------------\")\\r\\n    answer, error = autograder.run_script(\"lsn23_tokens.py\", [\"review.txt\", \"Fit\"])\\r\\n    expected_answer = solution(\"review.txt\", \"Fit\")\\r\\n    \\r\\n    if autograder.equals(answer, expected_answer):\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        num_correct += 1\\r\\n    else:\\r\\n        print(\"INCORRECT, Expected:\", expected_answer, \"\\\\n\")\\r\\n    \\r\\n    \\r\\n    # Test #2:\\r\\n    print(\"------------------------------------------\")\\r\\n    print(\"Test 2\")\\r\\n    print(\"------------------------------------------\")\\r\\n    answer, error = autograder.run_script(\"lsn23_tokens.py\", [\"article.txt\", \"plastic\"])\\r\\n    expected_answer = solution(\"article.txt\", \"plastic\")\\r\\n    \\r\\n    if autograder.equals(answer, expected_answer):\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        num_correct += 1\\r\\n    else:\\r\\n        print(\"INCORRECT, Expected:\", expected_answer, \"\\\\n\")\\r\\n        \\r\\n    # Test #3:\\r\\n    print(\"------------------------------------------\")\\r\\n    print(\"Test 3\")\\r\\n    print(\"------------------------------------------\")\\r\\n    answer, error = autograder.run_script(\"lsn23_tokens.py\", [\"article2.txt\", \"environment\"])\\r\\n    expected_answer = solution(\"article2.txt\", \"environment\")\\r\\n    \\r\\n    if autograder.equals(answer, expected_answer):\\r\\n        print(\"CORRECT\")\\r\\n        num_correct += 1\\r\\n    else:\\r\\n        print(\"INCORRECT, Expected:\", expected_answer)\\r\\n    \\r\\n    return round(100 / 3 * num_correct, 1)\\r\\n    \\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn23_skill2': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn23_skill2\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    a = random.randint(0, 5)\\r\\n    b = random.randint(6, 10)\\r\\n    c = random.randint(100, 200)\\r\\n    d = random.randint(0, 99)\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    print(\"Test #1.  Calling mini_sort(%d, %d)\" % (a, b))\\r\\n    output = lsn23_skill2.mini_sort(a, b)\\r\\n    print(\"  Your Function Returned:\", output)\\r\\n    if output == (a, b):\\r\\n        print(\"  CORRECT\\\\n\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"  INCORRECT.  Expected\", (a, b), \"\\\\n\")\\r\\n        \\r\\n    print(\"Test #2.  Calling mini_sort(%d, %d)\" % (c, d))\\r\\n    output = lsn23_skill2.mini_sort(c, d)\\r\\n    print(\"  Your Function Returned:\", output)\\r\\n    if output == (d, c):\\r\\n        print(\"  CORRECT\\\\n\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"  INCORRECT.  Expected\", (d, c), \"\\\\n\")\\r\\n    \\r\\n    return score\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn23_crashes': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn23_crashes\\r\\n\\r\\ndef solution(filename):\\r\\n    # Opens the file\\r\\n    file = open(filename, \"r\")\\r\\n\\r\\n    # Extracts ALL of the text as one big string\\r\\n    file_contents = file.read()\\r\\n\\r\\n    # Splits the big string into individual lines\\r\\n    lines = file_contents.split(\\'\\\\n\\')\\r\\n\\r\\n    # Creates a Set\\r\\n    collision_types = set()\\r\\n\\r\\n    # Looks at every row, and adds the collision type to the set\\r\\n    # The set automagically prevents duplicates from being added!\\r\\n    for line in lines:\\r\\n        columns = line.split(\\',\\')\\r\\n        collision_types.add(columns[4])\\r\\n\\r\\n    # Returns the set\\r\\n    return collision_types\\r\\n\\r\\n# Runs the test\\r\\ndef run_test(filename):\\r\\n    global tests_passed\\r\\n    \\r\\n    result = lsn23_crashes.get_accident_types(filename)\\r\\n    expected_value = solution(filename)\\r\\n    \\r\\n    if result is None:\\r\\n        print(\"Failed on file %s.  Your function did not return anything.\" % (filename))\\r\\n    elif type(result) is not set:\\r\\n        print(\"Failed on file %s.  Your function did not return a set.\" % (filename))\\r\\n    elif result == expected_value:\\r\\n        print(\"Passed Test on file\", filename, \"-- set =\", result)\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"Passed Test on file\", filename, \"-- Your function returned \", result, \", but the answer is\", expected_value)\\r\\n\\r\\n    return 0.0\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    return run_test(\"crashdata_2003.csv\") and run_test(\"crashdata_2011.csv\") and run_test(\"crashdata_2015.csv\")\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn18_triangle': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn18_triangle.py\", doraise=True)\\r\\n        print(\"----------------------------------------------------------------------\")\\r\\n        print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n        print(\"----------------------------------------------------------------------\\\\n\")\\r\\n        \\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn18_stamp': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn18_stamp.py\", doraise=True)\\r\\n        print(\"----------------------------------------------------------------------\")\\r\\n        print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n        print(\"----------------------------------------------------------------------\\\\n\")\\r\\n        \\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn18_simpledrawing': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    drawing_functions = [\"draw_arc\", \"draw_image\", \"draw_rectangle\", \"draw_circle\", \"draw_ellipse\", \"draw_line\", \"draw_pixel\", \"draw_text\", \"write_text\"]\\r\\n    drawing_functions_called = []\\r\\n    \\r\\n    print(\"----------------------------------------------------------------------\")\\r\\n    print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n    print(\"----------------------------------------------------------------------\\\\n\")\\r\\n    \\r\\n    file = open(\"lsn18_simpledrawing.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    for f in drawing_functions:\\r\\n        if f in file_contents and f not in drawing_functions_called:\\r\\n            drawing_functions_called.append(f)\\r\\n    \\r\\n    if len(drawing_functions_called) >= 4 and \"draw_image\" in drawing_functions_called:\\r\\n        print(\"Good Job!\")\\r\\n        return 100.0\\r\\n    elif len(drawing_functions_called) >= 4 and \"draw_image\" not in drawing_functions_called:\\r\\n        print(\"Missing at least one call of draw_image\")\\r\\n        return 90.0\\r\\n    else:\\r\\n        print(\"Not enough different drawing functions.  Need 4 unique (including draw_image) calls.\")\\r\\n        return 25 * len(drawing_functions_called)\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn18_randomcircles': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:\\r\\n        py_compile.compile(\"lsn18_randomcircles.py\", doraise=True)\\r\\n        print(\"----------------------------------------------------------------------\")\\r\\n        print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n        print(\"----------------------------------------------------------------------\\\\n\")\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn11_in_circle': 'import lsn11_in_circle\\nfrom cs110 import autograder\\nimport random, math\\n\\nNUM_SUBTESTS = 5\\n   \\ndef soln(x, y, cir_x, cir_y, radius):\\n    distance = math.sqrt((cir_x - x)**2 + (cir_y - y)**2)\\n    return distance <= radius\\n\\ndef test_passed():\\n    \\n    passed = 0\\n    for i in range(NUM_SUBTESTS):\\n        print(\\'Running sub test %d of %d: \\' % (i+1 , NUM_SUBTESTS), end=\\'\\')\\n        if i == 0:\\n            x = 6.04\\n            y = 2.43\\n            cir_x = 43.4\\n            cir_y = 52.2\\n            radius = 74.1\\n        else:\\n            x = random.random() * 10.0\\n            y = random.random() * 10.0\\n            cir_x = random.random() * 100.0\\n            cir_y = random.random() * 100.0\\n            radius = random.random() * 100.0\\n        #print(in_circle(x, y, cir_x, cir_y, radius), soln(x, y, cir_x, cir_y, radius))\\n        if lsn11_in_circle.in_circle(x, y, cir_x, cir_y, radius) == soln(x, y, cir_x, cir_y, radius):\\n            print(\"CORRECT!\")\\n            passed += 1\\n        else:\\n            print(\\'INCORRECT:  in_circle(%f, %f, %f, %f, %f) incorrectly returned %s\\' % (x, y, cir_x, cir_y, radius, lsn11_in_circle.in_circle(x, y, cir_x, cir_y, radius)))\\n    \\n    return (100 / NUM_SUBTESTS) * passed\\n\\n\\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn11_distance': 'from lsn11_distance import dist_points\\r\\nfrom cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nNUM_SUBTESTS = 5\\r\\n\\r\\ndef soln(x1, y1, x2, y2):\\r\\n    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    passed = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    \\r\\n    for i in range(NUM_SUBTESTS):\\r\\n        print(\\'Running sub test %d of %d: \\' % (i+1 , NUM_SUBTESTS), end=\\'\\')\\r\\n        x1 = round(random.uniform(-10, 10), 1)\\r\\n        y1 = round(random.uniform(-10, 10), 1)\\r\\n        x2 = round(random.uniform(-10, 10), 1)\\r\\n        y2 = round(random.uniform(-10, 10), 1)\\r\\n        if autograder.equals(dist_points(x1, y1, x2, y2), soln(x1, y1, x2, y2)):\\r\\n            print(\"PASSED!\")\\r\\n            passed += 1\\r\\n        else:\\r\\n            print(\\'FAILED: dist_point(%1.1f, %1.1f, %1.1f, %1.1f) incorrectly returned\\' % (x1, y1, x2, y2), dist_points(x1, y1, x2, y2))\\r\\n    \\r\\n    return round(100 / NUM_SUBTESTS, 1) * passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn11_circle': 'import lsn11_circle\\r\\nfrom cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nNUM_SUBTESTS = 5\\r\\n\\r\\n# Helper method to see if a numeric value is within a specified delta\\r\\ndef soln(radius):\\r\\n    return math.pi * radius * radius\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    passed = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    \\r\\n    for i in range(NUM_SUBTESTS):\\r\\n        print(\\'Running sub test %d of %d: \\' % (i+1 , NUM_SUBTESTS), end=\\'\\')\\r\\n        radius = random.random() * 100.0\\r\\n        if autograder.equals(lsn11_circle.area_circle(radius), soln(radius)):\\r\\n            print(\"CORRECT!\")\\r\\n            passed += 1\\r\\n        else:\\r\\n            print(\\'area_circle(%d) incorrectly returned\\' % (radius), lsn11_circle.area_circle(radius))\\r\\n        \\r\\n    return round(100 / NUM_SUBTESTS, 1) * passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn11_asteroids': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn11_asteroids \\r\\n\\r\\ndef soln(ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r):\\r\\n    distance = math.sqrt((ship_x - asteroid_x)**2 + (ship_y - asteroid_y)**2)\\r\\n    return distance < asteroid_r + ship_r\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 4\\r\\n    num_tests_passed = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    score = 0\\r\\n        \\r\\n    if \"dist_points\" in dir(lsn11_asteroids):\\r\\n        score += 20\\r\\n        print(\"dist_points function found\")\\r\\n    else:\\r\\n        print(\"dist_points function not being utilized.  Don\\'t reinvent the wheel!\")\\r\\n        #score += 20\\r\\n        \\r\\n    for i in range(NUM_TESTS):\\r\\n        print(\\'Running test %d of %d: \\' % (i+1 , NUM_TESTS), end=\\'\\')\\r\\n        \\r\\n        if i == 0:\\r\\n            ship_x = 2.3\\r\\n            ship_y = 0.2\\r\\n            ship_r = 3\\r\\n            asteroid_x = -4\\r\\n            asteroid_y = 3.4\\r\\n            asteroid_r = 6\\r\\n        else:\\r\\n            ship_x = round(random.uniform(-50, 50), 1)\\r\\n            ship_y = round(random.uniform(-50, 50), 1)\\r\\n            ship_r = 3\\r\\n            asteroid_x = round(random.uniform(-50, 50), 1)\\r\\n            asteroid_y = round(random.uniform(-50, 50), 1)\\r\\n            asteroid_r = 6\\r\\n        \\r\\n        #print(in_circle(x, y, cir_x, cir_y, radius), soln(x, y, cir_x, cir_y, radius))\\r\\n        if lsn11_asteroids.detect_collision(ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r) == soln(ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r):\\r\\n            print(\"CORRECT\")\\r\\n            score += 20\\r\\n        else:\\r\\n            print(\\'detect_collision(%f, %f, %f, %f, %f, %f) incorrectly returned %s\\' % (ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r, lsn11_asteroids.detect_collision(ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r)))\\r\\n    \\r\\n    return score\\r\\n            \\r\\n            \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn10_skill2': 'from cs110 import autograder\\r\\nimport random, math\\r\\nfrom lsn10_skill2 import *\\r\\n\\r\\ndef solution(temp_in_f):\\r\\n    temp_in_k = ((temp_in_f - 32) / 1.8) + 273.15\\r\\n    return temp_in_k\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    print(\"Looking for a function called fahrenheit_to_kelvin . . .\", end=\"\")\\r\\n    \\r\\n    if \"fahrenheit_to_kelvin\" in globals():\\r\\n        print(\"FOUND!\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"NOT FOUND\")\\r\\n    \\r\\n    random_temp = round(random.uniform(0, 100), 1)\\r\\n    \\r\\n    print(\"Testing function when temperature =\", random_temp, \"F . . . \", end=\"\")\\r\\n    if \"fahrenheit_to_kelvin\" in globals() and fahrenheit_to_kelvin(random_temp) == solution(random_temp):\\r\\n        print(\"CORRECT!\")\\r\\n        score += 50\\r\\n    elif \"fahrenheit_to_kelvin\" in globals() and fahrenheit_to_kelvin(random_temp) != solution(random_temp):\\r\\n        print(\"INCORRECT.  Expected\", solution(random_temp), \"instead of\", fahrenheit_to_kelvin(random_temp))\\r\\n    else:\\r\\n        print(\"Could not evaluate the function\\'s returned value because the function does not exist\")\\r\\n        \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn10_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\nfrom lsn10_skill1 import *\\r\\n\\r\\ndef get_fuel_consumption(distance_in_kilometers):\\r\\n    distance_in_miles = distance_in_kilometers * 0.621\\r\\n    return 5 * distance_in_miles\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    file = open(\"lsn10_skill1.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    num_calls_function1 = file_contents.count(\"get_fuel_consumption(1500\")\\r\\n    num_calls_function2 = file_contents.count(\"get_fuel_consumption( 1500\")\\r\\n    num_calls_function3 = file_contents.count(\"get_fuel_consumption (1500\")\\r\\n    num_calls_function4 = file_contents.count(\"get_fuel_consumption ( 1500\")\\r\\n    num_calls = num_calls_function1 + num_calls_function2 + num_calls_function3 + num_calls_function4\\r\\n\\r\\n    output, error_message = autograder.run_script(\"lsn10_skill1.py\", [])\\r\\n    \\r\\n    if num_calls >= 1:\\r\\n        print(\"get_fuel_consumption called successfully\")\\r\\n        score += 33\\r\\n    else:\\r\\n        print(\"get_fuel_consumption was not called successfully\")\\r\\n    \\r\\n    if \"fuel_consumed\" in globals():\\r\\n        print(\"fuel_consumed variable successfully created\")\\r\\n        score += 33\\r\\n    else:\\r\\n        print(\"Did not find a variable called fuel_consumed\")\\r\\n        \\r\\n    if \"fuel_consumed\" in globals() and fuel_consumed == get_fuel_consumption(1500):\\r\\n        print(\"fuel_consumed contains the correct value\")\\r\\n        score += 34\\r\\n    elif \"fuel_consumed\" in globals() and fuel_consumed != get_fuel_consumption(1500):\\r\\n        print(\"fuel_consumed contains\", fuel_consumed, \"instead of\", get_fuel_consumption(1500))\\r\\n    else:\\r\\n        print(\"Cannot check the value of fuel_consumed because it does not exist\")\\r\\n        \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a3_6_situps': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef script_name():\\r\\n    return \"a3_6_situps.py\"\\r\\n\\r\\n# There should be two outputs:\\r\\n#    The average followed by a count.\\r\\n# The test cases should be constructed so that:\\r\\n#    The average is >= 30\\r\\n#    The count   is <= 20\\r\\n\\r\\n# AUTOGRADER RUBRIC for scoring one test:\\r\\n\\r\\n# Number of outputs (10 pt):\\r\\n# 10 pt Output consists of exactly two values\\r\\n#  5 pt Output consists of one value or more than two values\\r\\n#  0 pt Output consists of either zero\\r\\n\\r\\n# Output of average (45 pt):\\r\\n# 45 pt Exactly correct and is first value in list\\r\\n# 30 pt Within 0.1 and is first value in list\\r\\n# 30 pt Exactly correct but is not first value in list\\r\\n# 15 pt Within 0.1 but is not first value in list\\r\\n\\r\\n# Output of count (45 pt):\\r\\n# 45 pt Exactly correct and is first value in list\\r\\n# 30 pt Within 1 and is first value in list\\r\\n# 30 pt Exactly correct but is not first value in list\\r\\n# 15 pt Within 1 but is not first value in list\\r\\n\\r\\ndef base_name(name_of_script):\\r\\n    return (name_of_script.split(\\'.\\')[0]).split(\\'_\\')[2]\\r\\n\\r\\ndef solution(input_list):\\r\\n\\r\\n    # Input is a count followed by that many values\\r\\n    # Create a list of just the values\\r\\n    items_list = input_list[1:]\\r\\n    \\r\\n    # Determine the average of the values\\r\\n    average = sum(items_list) / len(items_list)\\r\\n    \\r\\n    # Count the number of items that meet the criteria\\r\\n    # This depends on the specific variant of the problem\\r\\n    base_script = base_name(script_name())\\r\\n    count = 0\\r\\n    for score in items_list:\\r\\n        if base_script == \"situps\" and score > average:\\r\\n            count += 1\\r\\n        if base_script == \"sami\" and score > average:\\r\\n            count += 1\\r\\n        if base_script == \"tests\" and score < average:\\r\\n            count += 1\\r\\n    \\r\\n    # Output is average (rounded to 1 decimal place) and count \\r\\n    return [str(round(average,1)), str(count)]\\r\\n\\r\\ndef is_value(s):\\r\\n    try:\\r\\n        float(s)\\r\\n        return True\\r\\n    except ValueError:\\r\\n        return False\\r\\n    \\r\\n# Returns the position and distance of the closes user value from the solution value.\\r\\n# Returns found=False if list from user contains no numeric values\\r\\ndef matchup_numeric(value, from_user):\\r\\n    value = float(value)\\r\\n    found = False\\r\\n    position = -1\\r\\n    within = 1E10\\r\\n    for i in range(len(from_user)):\\r\\n        item = from_user[i]\\r\\n        if is_value(item):\\r\\n            found = True\\r\\n            user_value = float(item)\\r\\n            distance = abs(value - user_value)\\r\\n            if  distance < within:\\r\\n                within = distance\\r\\n                position = i \\r\\n                \\r\\n    return (found, position, within)\\r\\n\\r\\ndef decimal_places(float_string):\\r\\n    if is_value(float_string):\\r\\n        decimal_point_index = float_string.find(\\'.\\')\\r\\n        if decimal_point_index == -1:\\r\\n            return 0\\r\\n        else:\\r\\n            return len(float_string) - (decimal_point_index + 1)\\r\\n    else:\\r\\n        return -1\\r\\n    \\r\\ndef grade_item(name, correct_position, places, tolerance, from_soln, from_user):\\r\\n    score = 0\\r\\n    \\r\\n    value_from_soln = from_soln[correct_position]\\r\\n    \\r\\n    (found, position, within) = matchup_numeric(value_from_soln, from_user)\\r\\n    if not found:\\r\\n        print(name, \"not found.  Expected: \", value_from_soln)\\r\\n        score += 0\\r\\n    else:\\r\\n        if   (position == correct_position) and (within <= tolerance[0]):\\r\\n            print(name, \"appears correct.\")\\r\\n            score += 45\\r\\n        elif (position == correct_position) and (within <= tolerance[1]):\\r\\n            print(name, \"is close.  Expected: \", value_from_soln)\\r\\n            score += 30\\r\\n        elif (position != correct_position) and (within <= tolerance[0]):\\r\\n            print(name, \"appears correct, but in wrong position.\")\\r\\n            score += 30\\r\\n        elif  (position != correct_position) and (within <= tolerance[1]):\\r\\n            print(name, \"is close, but in wrong position.  Expected: \", value_from_soln)\\r\\n            score += 15\\r\\n        else:\\r\\n            print(name, \"is not close and probably in wrong position.  Expected: \", value_from_soln)\\r\\n            score += 0\\r\\n            \\r\\n    return score            \\r\\n\\r\\ndef run_1_test(script_being_tested, input_list):\\r\\n\\r\\n    (output, error) = autograder.run_script(script_being_tested, input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_output = solution(input_list)\\r\\n    \\r\\n    score = 0\\r\\n\\r\\n    # Number of outputs\\r\\n    if len(lines) == 2:\\r\\n        print(\"Number of output lines is correct.\")\\r\\n        score += 10\\r\\n    elif len(lines) == 1:\\r\\n        print(\"Number of output lines is not quite correct.\")\\r\\n        score += 5\\r\\n    else:\\r\\n        print(\"Number of output lines is not correct.\")\\r\\n        score += 0\\r\\n    \\r\\n    score += grade_item(\"Average\", 0, 1, [0.1, 10], expected_output, lines)\\r\\n    score += grade_item(\"Count\", 1, 0, [0, 1], expected_output, lines)\\r\\n    \\r\\n    print(\\'-----------------------------\\')\\r\\n\\r\\n    return score\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    script_being_tested = script_name()\\r\\n    score = 0\\r\\n    cum_weight = 0.0\\r\\n\\r\\n    # Corner Case #1 (5%) -- only a single score\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n    \\r\\n    random_people = 1\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    for i in range(random_people):\\r\\n        random_score = random.randint(30, 100)\\r\\n        input_list.append(random_score)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n\\r\\n    # Corner Case #2 (5%) -- multiple all scores that are all the same\\r\\n    weight = 5.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    random_people = random.randint(5, 10)\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    random_score = random.randint(30, 100)\\r\\n    for i in range(random_people):\\r\\n        input_list.append(random_score)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n\\r\\n    # Corner Case #3 (10%) -- scores exist that exactly match average\\r\\n    weight = 10.0\\r\\n    runs = 1\\r\\n    cum_weight += runs * weight\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    random_people = random.randint(7,15)\\r\\n    input_list = [random_people]\\r\\n        \\r\\n    random_mean = random.randint(50, 70)\\r\\n    \\r\\n    for i in range(random_people % 3):\\r\\n        input_list.append(random_mean)\\r\\n        \\r\\n    for i in range(random_people // 3):\\r\\n        random_step = random.randint(3,20)\\r\\n        input_list.append(random_mean)\\r\\n        input_list.append(random_mean + random_step)\\r\\n        input_list.append(random_mean - random_step)\\r\\n    \\r\\n    score += weight * run_1_test(script_being_tested, input_list)\\r\\n    \\r\\n    # General Case (80%) -- 4 runs @ 20% each\\r\\n    runs = 2\\r\\n    weight = (100.0 - cum_weight)\\r\\n    weight /= runs * 100.0\\r\\n\\r\\n    \\r\\n    for run in range(runs):\\r\\n        random_people = random.randint(2, 20)\\r\\n        input_list = [random_people]\\r\\n            \\r\\n        for i in range(random_people):\\r\\n            random_score = random.randint(30, 100)\\r\\n            input_list.append(random_score)\\r\\n        \\r\\n        score += weight * run_1_test(script_being_tested, input_list)\\r\\n    \\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a3_5_connect': 'import random\\r\\nfrom cs110 import autograder\\r\\n\\r\\n## EDITED 15 MAR 2022 by Capt Ben McGraw\\r\\n\\r\\nconnect_4   =      [[\\'X\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\'],\\r\\n                    [\\'X\\', \\'_\\', \\'X\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\'],\\r\\n                    [\\'0\\', \\'_\\', \\'X\\', \\'_\\', \\'_\\', \\'_\\', \\'_\\'],\\r\\n                    [\\'0\\', \\'_\\', \\'0\\', \\'X\\', \\'_\\', \\'_\\', \\'0\\'],\\r\\n                    [\\'0\\', \\'_\\', \\'0\\', \\'0\\', \\'X\\', \\'_\\', \\'X\\'],\\r\\n                    [\\'X\\', \\'_\\', \\'X\\', \\'0\\', \\'0\\', \\'X\\', \\'X\\']]\\r\\n\\r\\n\\r\\ndef check_location(row, col):\\r\\n    print(\"-----------------------------\")\\r\\n    print(\"Checking row:{} col:{}\".format(row, col))\\r\\n    print(\"-----------------------------\")\\r\\n\\r\\n    output, error = autograder.run_script(\"a3_5_connect.py\", [row, col])\\r\\n\\r\\n    if connect_4[row][col] == output.strip():\\r\\n        print(\"Correct\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected:\", connect_4[row][col], \"\\\\n\")\\r\\n        return False\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n\\r\\n    if (check_location(0,\\r\\n                       2)):\\r\\n        score += 20\\r\\n\\r\\n    if (check_location(1,\\r\\n                       random.randint(0, len(connect_4[0])-1))):\\r\\n        score += 20\\r\\n\\r\\n    if (check_location(5,\\r\\n                       random.randint(0, len(connect_4[0])-1))):\\r\\n        score += 20\\r\\n\\r\\n    if (check_location(random.randint(0, len(connect_4)-1),\\r\\n                       random.randint(0, len(connect_4[0])-1))):\\r\\n        score += 20\\r\\n\\r\\n    if (check_location(random.randint(0, len(connect_4)-1),\\r\\n                       random.randint(0, len(connect_4[0])-1))):\\r\\n        score += 20\\r\\n\\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':\\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a3_4_testscores': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nSTUDENT_FILE = \"a3_4_testscores.py\"\\r\\nANSWER = 6092\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    output, error = autograder.run_script(STUDENT_FILE, [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    score = 0\\r\\n    \\r\\n    if len(lines) >= 1:           \\r\\n        if autograder.equals(lines[0], ANSWER):\\r\\n            print(\"CORRECT: Range Looks Good!\")\\r\\n            score += 100\\r\\n        else:\\r\\n            print(\"Incorrect range.  Remember that the range is the difference between the max and the min\")\\r\\n            \\r\\n    else:\\r\\n        print(\"More lines expected in your answer.  Make sure you are printing out the range.\")\\r\\n    \\r\\n    return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a3_3_dogs': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nlist_of_dogs = [\"Pug\", \"Lab\", \"Yorkie\", \"Pit Bull\", \"Poodle\", \"Great Dane\"]\\r\\n\\r\\ndef solution():\\r\\n    result = []\\r\\n    \\r\\n    for item in list_of_dogs:\\r\\n        result.append(item)\\r\\n    \\r\\n    return result\\r\\n             \\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    output, error = autograder.run_script(\"a3_3_dogs.py\", [])\\r\\n    expected_output = solution()\\r\\n    num_matches = autograder.compare_strings(output.strip().split(\\'\\\\n\\'), expected_output)\\r\\n    \\r\\n    return round(100 / len(expected_output) * num_matches, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a3_1_light_aircraft': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nlist_of_aircraft = [\"F-16\",\"F-15\",\"F-22\",\"F-35\", \"A-10\", \"B-1\",\"B-2\", \"B-52\" ]\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    index_list = [1, random.randint(2, len(list_of_aircraft)-2), len(list_of_aircraft)]\\r\\n    tests_passed = 0\\r\\n\\r\\n    for i in range(len(index_list)):\\r\\n        print(\"----------------------------------------------------------\")\\r\\n        print(\"Testing item #\" + str(index_list[i]) + \": \")\\r\\n        print(\"----------------------------------------------------------\")\\r\\n               \\r\\n        # Runs the Script\\r\\n        output, error_message = autograder.run_script(\"a3_1_light_aircraft.py\", [index_list[i]])\\r\\n\\r\\n        # Test Goes Here\\r\\n        lines = output.split(\"\\\\n\")\\r\\n        \\r\\n        if lines[0] == list_of_aircraft[index_list[i]-1]:\\r\\n            print(\"Looks Good!\")\\r\\n            tests_passed += 1\\r\\n        elif error_message == \\'\\' and lines[0] != list_of_aircraft[index_list[i]-1]:\\r\\n            print(\"Unexpected Output (Expected \" + str(list_of_aircraft[index_list[i]-1]) + \")\")\\r\\n    \\r\\n        print()\\r\\n    \\r\\n    return (100 / len(index_list)) * tests_passed\\r\\n\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_6_lowest_spec_def': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nsolution_filename = \"a2_6_lowest_spec_def.py\"\\r\\n\\r\\n# def solution(pokemon_type):\\r\\n#     file = open(\"pokemon.csv\", \"r\")\\r\\n#     file_contents = file.read()\\r\\n#     lines = file_contents.split(\\'\\\\n\\')\\r\\n# \\r\\n#     lowest_value = 999\\r\\n#     lowest_name = \"UNKNOWN\"\\r\\n# \\r\\n#     for line in lines:\\r\\n#         columns = line.split(\\',\\')\\r\\n#         p_name  = columns[1]\\r\\n#         p_type  = columns[2]\\r\\n#         p_value = float(columns[7])\\r\\n#         \\r\\n#         if p_type == pokemon_type:\\r\\n#             if p_value < lowest_value:\\r\\n#                 lowest_value = p_value\\r\\n#                 lowest_name = p_name\\r\\n# \\r\\n#     return (lowest_value, lowest_name)\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():    \\r\\n    # static input and corresponding expected output\\r\\n    test_cases = dict()\\r\\n    test_cases[\"Electric\"] = (32.0, \"Blitzle\")\\r\\n    test_cases[\"Fire\"] = (40.0, \"Slugma\")\\r\\n    test_cases[\"Dark\"] = (30.0, \"Poochyena\")\\r\\n    test_cases[\"Dragon\"] = (30.0, \"Bagon\")\\r\\n    test_cases[\"Rock\"] = (25.0, \"Roggenrola\")\\r\\n    test_cases[\"Fairy\"] = (40.0, \"Snubbull\")\\r\\n    test_cases[\"Ghost\"] = (33.0, \"Shuppet\")\\r\\n    test_cases[\"Normal\"] = (20.0, \"Igglybuff\")\\r\\n    \\r\\n    # shuffle the possible inputs    \\r\\n    test_case_input = list(test_cases.keys())\\r\\n    case_order = list(range(len(test_case_input)))\\r\\n    random.shuffle(case_order)\\r\\n    \\r\\n    # choose 5 of the randomly sorted \\r\\n    case_indices_used = case_order[:5]\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    test_run_num = 1\\r\\n    for idx in case_indices_used:\\r\\n        print(\\'\\\\n\\' + \\'=\\'*30)\\r\\n        print(\" \"*10+\"Test Case #\" + str(test_run_num))\\r\\n        print(\\'=\\'*30)\\r\\n        \\r\\n        try:\\r\\n            output, error = autograder.run_script(solution_filename, [test_case_input[idx]])\\r\\n            expected_output = test_cases[test_case_input[idx]]  \\r\\n            \\r\\n            lines = output.strip().split(\\'\\\\n\\')\\r\\n            \\r\\n            if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n                print(\"Lowest Value Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"Lowest Value Incorrect or not in the expected location.  Expected:\", expected_output[0])\\r\\n            \\r\\n            if len(lines) > 1 and lines[1] == expected_output[1]:\\r\\n                print(\"Name is Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            elif len(lines) > 0 and expected_output[1] in lines:\\r\\n                print(\"Name is Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"Name is Incorrect or not in the expected location.  Expected:\", expected_output[1])\\r\\n                \\r\\n        except Exception as e:\\r\\n            print(\"ERROR occured when running your solution.\")\\r\\n            print(e)\\r\\n                \\r\\n        test_run_num += 1\\r\\n    \\r\\n    return score\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_6_lowest_spec_attack': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nsolution_filename = \"a2_6_lowest_spec_attack.py\"\\r\\n\\r\\n# def solution(pokemon_type):\\r\\n#     file = open(\"pokemon.csv\", \"r\")\\r\\n#     file_contents = file.read()\\r\\n#     lines = file_contents.split(\\'\\\\n\\')\\r\\n# \\r\\n#     lowest_value = 999\\r\\n#     lowest_name = \"UNKNOWN\"\\r\\n# \\r\\n#     for line in lines:\\r\\n#         columns = line.split(\\',\\')\\r\\n#         p_name  = columns[1]\\r\\n#         p_type  = columns[2]\\r\\n#         p_value = float(columns[6])\\r\\n#         \\r\\n#         if p_type == pokemon_type:\\r\\n#             if p_value < lowest_value:\\r\\n#                 lowest_value = p_value\\r\\n#                 lowest_name = p_name\\r\\n# \\r\\n#     return (lowest_value, lowest_name)\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # static input and corresponding expected output    \\r\\n    test_cases = dict()\\r\\n    test_cases[\"Electric\"] = (35.0, \"Pichu\")\\r\\n    test_cases[\"Fire\"] = (15.0, \"Darumaka\")\\r\\n    test_cases[\"Dark\"] = (30.0, \"Poochyena\")\\r\\n    test_cases[\"Dragon\"] = (30.0, \"Axew\")\\r\\n    test_cases[\"Rock\"] = (10.0, \"Bonsly\")\\r\\n    test_cases[\"Ghost\"] = (30.0, \"Duskull\")\\r\\n    test_cases[\"Normal\"] = (15.0, \"Happiny\")\\r\\n    test_cases[\"Bug\"] = (10.0, \"Shuckle\")\\r\\n\\r\\n    # shuffle the possible inputs    \\r\\n    test_case_input = list(test_cases.keys())\\r\\n    case_order = list(range(len(test_case_input)))\\r\\n    random.shuffle(case_order)\\r\\n    \\r\\n    # choose 5 of the randomly sorted \\r\\n    case_indices_used = case_order[:5]\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    test_run_num = 1\\r\\n    for idx in case_indices_used:\\r\\n        print(\\'\\\\n\\' + \\'=\\'*30)\\r\\n        print(\" \"*10+\"Test Case #\" + str(test_run_num))\\r\\n        print(\\'=\\'*30)\\r\\n        \\r\\n        try:\\r\\n            output, error = autograder.run_script(solution_filename, [test_case_input[idx]])\\r\\n            expected_output = test_cases[test_case_input[idx]]  \\r\\n            \\r\\n            lines = output.strip().split(\\'\\\\n\\')\\r\\n            \\r\\n            if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n                print(\"Lowest Value Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"Lowest Value Incorrect or not in the expected location.  Expected:\", expected_output[0])\\r\\n            \\r\\n            if len(lines) > 1 and lines[1] == expected_output[1]:\\r\\n                print(\"Name is Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            elif len(lines) > 0 and expected_output[1] in lines:\\r\\n                print(\"Name is Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"Name is Incorrect or not in the expected location.  Expected:\", expected_output[1])              \\r\\n        except Exception as e:\\r\\n            print(\"ERROR occured when running your solution.\")\\r\\n            print(e)\\r\\n                \\r\\n        test_run_num += 1\\r\\n    \\r\\n    return score\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_6_lowest_defense': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nsolution_filename = \"a2_6_lowest_defense.py\"\\r\\n\\r\\n# def solution(pokemon_type):\\r\\n#     file = open(\"pokemon.csv\", \"r\")\\r\\n#     file_contents = file.read()\\r\\n#     lines = file_contents.split(\\'\\\\n\\')\\r\\n# \\r\\n#     lowest_value = 999\\r\\n#     lowest_name = \"UNKNOWN\"\\r\\n# \\r\\n#     for line in lines:\\r\\n#         columns = line.split(\\',\\')\\r\\n#         p_name  = columns[1]\\r\\n#         p_type  = columns[2]\\r\\n#         p_value = float(columns[5])\\r\\n#         \\r\\n#         if p_type == pokemon_type:\\r\\n#             if p_value < lowest_value:\\r\\n#                 lowest_value = p_value\\r\\n#                 lowest_name = p_name\\r\\n# \\r\\n#     return (lowest_value, lowest_name)\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    # static input and corresponding expected output\\r\\n    test_cases = dict()\\r\\n    test_cases[\"Poison\"] = (35.0, \"Zubat\")\\r\\n    test_cases[\"Electric\"] = (15.0, \"Pichu\")\\r\\n    test_cases[\"Grass\"] = (30.0, \"Sunkern\")\\r\\n    test_cases[\"Fire\"] = (37.0, \"Magby\")\\r\\n    test_cases[\"Ground\"] = (25.0, \"Diglett\")\\r\\n    test_cases[\"Dark\"] = (30.0, \"Houndour\")\\r\\n    test_cases[\"Dragon\"] = (35.0, \"Goomy\")\\r\\n    test_cases[\"Psychic\"] = (15.0, \"Abra\")\\r\\n    test_cases[\"Rock\"] = (40.0, \"Cranidos\")\\r\\n    \\r\\n    # shuffle the possible inputs    \\r\\n    test_case_input = list(test_cases.keys())\\r\\n    case_order = list(range(len(test_case_input)))\\r\\n    random.shuffle(case_order)\\r\\n    \\r\\n    # choose 5 of the randomly sorted \\r\\n    case_indices_used = case_order[:5]\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    test_run_num = 1\\r\\n    for idx in case_indices_used:\\r\\n        print(\\'\\\\n\\' + \\'=\\'*30)\\r\\n        print(\" \"*10+\"Test Case #\" + str(test_run_num))\\r\\n        print(\\'=\\'*30)\\r\\n        \\r\\n        try:\\r\\n            output, error = autograder.run_script(solution_filename, [test_case_input[idx]])\\r\\n            expected_output = test_cases[test_case_input[idx]]  \\r\\n            \\r\\n            lines = output.strip().split(\\'\\\\n\\')\\r\\n            \\r\\n            if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n                print(\"Lowest Value Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"Lowest Value Incorrect or not in the expected location.  Expected:\", expected_output[0])\\r\\n            \\r\\n            if len(lines) > 1 and lines[1] == expected_output[1]:\\r\\n                print(\"Name is Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            elif len(lines) > 0 and expected_output[1] in lines:\\r\\n                print(\"Name is Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"Name is Incorrect or not in the expected location.  Expected:\", expected_output[1])\\r\\n        except Exception as e:\\r\\n            print(\"ERROR occured when running your solution.\")\\r\\n            print(e)\\r\\n                \\r\\n        test_run_num += 1\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_6_highest_hp': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nsolution_filename = \"a2_6_highest_hp.py\"\\r\\n\\r\\n# def solution(pokemon_type):\\r\\n#     file = open(\"pokemon.csv\", \"r\")\\r\\n#     file_contents = file.read()\\r\\n#     lines = file_contents.split(\\'\\\\n\\')\\r\\n# \\r\\n#     highest_value = -999\\r\\n#     highest_name = \"UNKNOWN\"\\r\\n# \\r\\n#     for line in lines:\\r\\n#         columns = line.split(\\',\\')\\r\\n#         p_name  = columns[1]\\r\\n#         p_type  = columns[2]\\r\\n#         p_value = float(columns[3])\\r\\n#         \\r\\n#         if p_type == pokemon_type:\\r\\n#             if p_value > highest_value:\\r\\n#                 highest_value = p_value\\r\\n#                 highest_name = p_name\\r\\n# \\r\\n#     return (highest_value, highest_name)\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # static input and corresponding expected output\\r\\n    test_cases = dict()\\r\\n    test_cases[\"Poison\"] = (105.0, \"Muk\")\\r\\n    test_cases[\"Electric\"] = (90.0, \"Zapdos\")\\r\\n    test_cases[\"Grass\"] = (123.0, \"Gogoat\")\\r\\n    test_cases[\"Fire\"] = (115.0, \"Entei\")\\r\\n    test_cases[\"Bug\"] = (86.0, \"Yanmega\")\\r\\n    test_cases[\"Water\"] = (170.0, \"Wailord\")\\r\\n    test_cases[\"Ground\"] = (115.0, \"Rhyperior\")\\r\\n    test_cases[\"Normal\"] = (255.0, \"Blissey\")\\r\\n        \\r\\n    # shuffle the possible inputs\\r\\n    test_case_input = list(test_cases.keys())\\r\\n    case_order = list(range(len(test_case_input)))\\r\\n    random.shuffle(case_order)\\r\\n    \\r\\n    # choose 5 of the randomly sorted \\r\\n    case_indices_used = case_order[:5]\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    test_run_num = 1\\r\\n    for idx in case_indices_used:\\r\\n        print(\\'\\\\n\\' + \\'=\\'*30)\\r\\n        print(\" \"*10+\"Test Case #\" + str(test_run_num))\\r\\n        print(\\'=\\'*30)\\r\\n        \\r\\n        try:\\r\\n            output, error = autograder.run_script(solution_filename, [test_case_input[idx]])\\r\\n            expected_output = test_cases[test_case_input[idx]]  \\r\\n            \\r\\n            lines = output.strip().split(\\'\\\\n\\')\\r\\n            \\r\\n            if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n                print(\"Highest Value Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"Highest Value Incorrect or not in the expected location.  Expected:\", expected_output[0])\\r\\n            \\r\\n            if len(lines) > 1 and lines[1] == expected_output[1]:\\r\\n                print(\"Name is Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            elif len(lines) > 0 and expected_output[1] in lines:\\r\\n                print(\"Name is Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"Name is Incorrect or not in the expected location.  Expected:\", expected_output[1])\\r\\n        except Exception as e:\\r\\n            print(\"ERROR occured when running your solution.\")\\r\\n            print(e)\\r\\n                \\r\\n        test_run_num += 1\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_6_fastest': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nsolution_filename = \"a2_6_fastest.py\"\\r\\n\\r\\n# def solution(pokemon_type):\\r\\n#     file = open(\"pokemon.csv\", \"r\")\\r\\n#     file_contents = file.read()\\r\\n#     lines = file_contents.split(\\'\\\\n\\')\\r\\n# \\r\\n#     fastest_value = 0\\r\\n#     fastest_name = \"UNKNOWN\"\\r\\n# \\r\\n#     for line in lines:\\r\\n#         columns = line.split(\\',\\')\\r\\n#         p_name  = columns[1]\\r\\n#         p_type  = columns[2]\\r\\n#         p_value = float(columns[8])\\r\\n#         \\r\\n#         if p_type == pokemon_type:\\r\\n#             if p_value > fastest_value:\\r\\n#                 fastest_value = p_value\\r\\n#                 fastest_name = p_name\\r\\n# \\r\\n#     return (fastest_value, fastest_name)\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    # static input and corresponding expected output\\r\\n    test_cases = dict()\\r\\n    test_cases[\"Poison\"] = (130.0, \"Crobat\")\\r\\n    test_cases[\"Electric\"] = (140.0, \"Electrode\")\\r\\n    test_cases[\"Fire\"] = (126.0, \"Talonflame\")\\r\\n    test_cases[\"Bug\"] = (160.0, \"Ninjask\")\\r\\n    test_cases[\"Water\"] = (122.0, \"Greninja\")\\r\\n    test_cases[\"Ground\"] = (120.0, \"Dugtrio\")\\r\\n    test_cases[\"Fairy\"] = (99.0, \"Xerneas\")\\r\\n    test_cases[\"Fighting\"] = (118.0, \"Hawlucha\")\\r\\n        \\r\\n    # shuffle the possible inputs\\r\\n    test_case_input = list(test_cases.keys())\\r\\n    case_order = list(range(len(test_case_input)))\\r\\n    random.shuffle(case_order)\\r\\n    \\r\\n    # choose 5 of the randomly sorted \\r\\n    case_indices_used = case_order[:5]\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    test_run_num = 1\\r\\n    for idx in case_indices_used:\\r\\n        print(\\'\\\\n\\' + \\'=\\'*30)\\r\\n        print(\" \"*10+\"Test Case #\" + str(test_run_num))\\r\\n        print(\\'=\\'*30)\\r\\n        \\r\\n        try:\\r\\n            output, error = autograder.run_script(solution_filename, [test_case_input[idx]])\\r\\n            expected_output = test_cases[test_case_input[idx]]  \\r\\n            \\r\\n            lines = output.strip().split(\\'\\\\n\\')\\r\\n            \\r\\n            if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n                print(\"Highest Value Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"Highest Value Incorrect or not in the expected location.  Expected:\", expected_output[0])\\r\\n            \\r\\n            if len(lines) > 1 and lines[1] == expected_output[1]:\\r\\n                print(\"Name is Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            elif len(lines) > 0 and expected_output[1] in lines:\\r\\n                print(\"Name is Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"Name is Incorrect or not in the expected location.  Expected:\", expected_output[1])\\r\\n        except Exception as e:\\r\\n            print(\"ERROR occured when running your solution.\")\\r\\n            print(e)\\r\\n                \\r\\n        test_run_num += 1\\r\\n    \\r\\n    return score\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_6_attack': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nsolution_filename = \"a2_6_attack.py\"\\r\\n\\r\\n# def solution(pokemon_type):\\r\\n#     file = open(\"pokemon.csv\", \"r\")\\r\\n#     file_contents = file.read()\\r\\n#     lines = file_contents.split(\\'\\\\n\\')\\r\\n# \\r\\n#     highest_value = -999\\r\\n#     highest_name = \"UNKNOWN\"\\r\\n# \\r\\n#     for line in lines:\\r\\n#         columns = line.split(\\',\\')\\r\\n#         p_name  = columns[1]\\r\\n#         p_type  = columns[2]\\r\\n#         p_value = float(columns[4])\\r\\n#         \\r\\n#         if p_type == pokemon_type:\\r\\n#             if p_value > highest_value:\\r\\n#                 highest_value = p_value\\r\\n#                 highest_name = p_name\\r\\n# \\r\\n#     return (highest_value, highest_name)\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    # static input and corresponding expected output\\r\\n    test_cases = dict()\\r\\n    test_cases[\"Steel\"] = (150.0, \"AegislashBlade Forme\")\\r\\n    test_cases[\"Rock\"] = (165.0, \"Rampardos\")\\r\\n    test_cases[\"Ice\"] = (130.0, \"Mamoswine\")\\r\\n    test_cases[\"Fairy\"] = (131.0, \"Xerneas\")\\r\\n    test_cases[\"Water\"] = (155.0, \"GyaradosMega Gyarados\")\\r\\n    test_cases[\"Bug\"] = (185.0, \"HeracrossMega Heracross\")\\r\\n    test_cases[\"Dark\"] = (150.0, \"AbsolMega Absol\")\\r\\n    test_cases[\"Dragon\"] = (180.0, \"RayquazaMega Rayquaza\")\\r\\n    \\r\\n        \\r\\n    # shuffle the possible inputs\\r\\n    test_case_input = list(test_cases.keys())\\r\\n    case_order = list(range(len(test_case_input)))\\r\\n    random.shuffle(case_order)\\r\\n    \\r\\n    # choose 5 of the randomly sorted \\r\\n    case_indices_used = case_order[:5]\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    test_run_num = 1\\r\\n    for idx in case_indices_used:\\r\\n        print(\\'\\\\n\\' + \\'=\\'*30)\\r\\n        print(\" \"*10+\"Test Case #\" + str(test_run_num))\\r\\n        print(\\'=\\'*30)\\r\\n        \\r\\n        try:\\r\\n            output, error = autograder.run_script(solution_filename, [test_case_input[idx]])\\r\\n            expected_output = test_cases[test_case_input[idx]]  \\r\\n            \\r\\n            lines = output.strip().split(\\'\\\\n\\')\\r\\n            \\r\\n            if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n                print(\"Highest Value Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"Highest Value Incorrect or not in the expected location.  Expected:\", expected_output[0])\\r\\n            \\r\\n            if len(lines) > 1 and lines[1] == expected_output[1]:\\r\\n                print(\"Name is Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            elif len(lines) > 0 and expected_output[1] in lines:\\r\\n                print(\"Name is Correct\")\\r\\n                score += 50 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"Name is Incorrect or not in the expected location.  Expected:\", expected_output[1])\\r\\n        except Exception as e:\\r\\n            print(\"ERROR occured when running your solution.\")\\r\\n            print(e)\\r\\n                \\r\\n        test_run_num += 1\\r\\n    \\r\\n    return score    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_5_virus': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(num_violating, num_people):    \\r\\n    inputs = [num_people]\\r\\n    \\r\\n    for i in range(num_people):\\r\\n        if i < num_violating:\\r\\n            if (i + 1 == num_violating):\\r\\n                inputs.append(6)\\r\\n            else:\\r\\n                inputs.append(round(random.uniform(0, 6), 1))\\r\\n        else:\\r\\n            inputs.append(round(random.uniform(7, 20), 1))\\r\\n\\r\\n    # Generates Expected Answer\\r\\n    if num_violating == 0:\\r\\n        answer = \"All Clear\"\\r\\n    elif num_violating <= 2:\\r\\n        answer = \"Warning\"\\r\\n    else:\\r\\n        answer = \"Find Another Place\"\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"a2_5_virus.py\", inputs)\\r\\n    \\r\\n    print(\"Testing when\", num_violating, \"out of\", num_people, \"are violating . . . \")\\r\\n    print(\"  Inputs:\", inputs)\\r\\n    print(\"  Result: \", end=\\'\\')\\r\\n    \\r\\n    if answer.strip() == output.strip():\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected: \\'\" + answer + \"\\' instead of \\'\" + output + \"\\'\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_passed = 0\\r\\n    \\r\\n    if (run_test(0, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(1, random.randint(1, 2))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(2, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(3, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n        \\r\\n    return (100 / 4) * num_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_5_traffic_lights': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(num_over, traffic):    \\r\\n    inputs = [traffic]\\r\\n    \\r\\n    for i in range(traffic):\\r\\n        if i < num_over:\\r\\n            if (i + 1 == num_over):\\r\\n                inputs.append(15)\\r\\n            else:\\r\\n                inputs.append(round(random.uniform(15, 30), 1))\\r\\n        else:\\r\\n            inputs.append(round(random.uniform(1, 15), 1))\\r\\n\\r\\n    # Generates Expected Answer\\r\\n    if num_over == 0:\\r\\n        answer = \"Regular Schedule\"\\r\\n    elif num_over <= 2:\\r\\n        answer = \"Prepare Activation\"\\r\\n    else:\\r\\n        answer = \"Activate New Schedule\"\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"a2_5_traffic_lights.py\", inputs)\\r\\n    \\r\\n    print(\"Testing when\", num_over, \"out of\", traffic, \"\\\\\"time periods\\\\\" are experiencing heavy traffic . . . \")\\r\\n    print(\"  Inputs:\", inputs)\\r\\n    print(\"  Result: \", end=\\'\\')\\r\\n    \\r\\n    if answer.strip() == output.strip():\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected: \\'\" + answer + \"\\' instead of \\'\" + output + \"\\'\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_passed = 0\\r\\n    \\r\\n    if (run_test(0, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(1, random.randint(1, 2))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(2, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(3, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n        \\r\\n    return (100 / 4) * num_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_5_network_traffic': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(num_over, traffic):    \\r\\n    inputs = [traffic]\\r\\n    \\r\\n    for i in range(traffic):\\r\\n        if i < num_over:\\r\\n            if (i + 1 == num_over):\\r\\n                inputs.append(512.1)\\r\\n            else:\\r\\n                inputs.append(round(random.uniform(512, 1024), 1))\\r\\n        else:\\r\\n            inputs.append(round(random.uniform(256, 512), 1))\\r\\n\\r\\n    # Generates Expected Answer\\r\\n    if num_over == 0:\\r\\n        answer = \"Ops Normal\"\\r\\n    elif num_over <= 2:\\r\\n        answer = \"Initialize NLB\"\\r\\n    else:\\r\\n        answer = \"Activate NLB\"\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"a2_5_network_traffic.py\", inputs)\\r\\n    \\r\\n    print(\"Testing when\", num_over, \"out of\", traffic, \"\\\\\"snapshots\\\\\" have high volume of network traffic . . . \")\\r\\n    print(\"  Inputs:\", inputs)\\r\\n    print(\"  Result: \", end=\\'\\')\\r\\n    \\r\\n    if answer.strip() == output.strip():\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected: \\'\" + answer + \"\\' instead of \\'\" + output + \"\\'\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_passed = 0\\r\\n    \\r\\n    if (run_test(0, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(1, random.randint(1, 2))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(2, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(3, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n        \\r\\n    return (100 / 4) * num_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a2_5_grades': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(num_failures, num_papers):    \\r\\n    inputs = [num_papers]\\r\\n    \\r\\n    for i in range(num_papers):\\r\\n        if i < num_failures:\\r\\n            inputs.append(round(random.uniform(0, 70), 1))\\r\\n        else:\\r\\n            if (i == num_failures):\\r\\n                inputs.append(70)\\r\\n            else:\\r\\n                inputs.append(round(random.uniform(70, 100), 1))\\r\\n\\r\\n    # Generates Expected Answer\\r\\n    if num_failures == 0:\\r\\n        answer = \"Excellent\"\\r\\n    elif num_failures >= 1 and num_failures <= 2:\\r\\n        answer = \"Satisfactory\"\\r\\n    else:\\r\\n        answer = \"Unsatisfactory\"\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"a2_5_grades.py\", inputs)\\r\\n    \\r\\n    print(\"Testing when\", num_failures, \"out of\", num_papers, \"failed . . . \")\\r\\n    print(\"  Inputs:\", inputs)\\r\\n    print(\"  Result: \", end=\\'\\')\\r\\n    \\r\\n    if answer.strip() == output.strip():\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected: \\'\" + answer + \"\\' instead of \\'\" + output + \"\\'\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_passed = 0\\r\\n    \\r\\n    if (run_test(0, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(1, random.randint(1, 2))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(2, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(3, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n        \\r\\n    return (100 / 4) * num_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_5_gameday': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(num_close, num_strikes):    \\r\\n    inputs = [num_strikes]\\r\\n    \\r\\n    for i in range(num_strikes):\\r\\n        if i < num_close:\\r\\n            if (i + 1 == num_close):\\r\\n                inputs.append(15)\\r\\n            else:\\r\\n                inputs.append(round(random.uniform(0, 15), 1))\\r\\n        else:\\r\\n            inputs.append(round(random.uniform(15, 50), 1))\\r\\n\\r\\n    # Generates Expected Answer\\r\\n    if num_close == 0:\\r\\n        answer = \"All Clear\"\\r\\n    elif num_close <= 2:\\r\\n        answer = \"Weather Warning\"\\r\\n    else:\\r\\n        answer = \"Game Delay\"\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"a2_5_gameday.py\", inputs)\\r\\n    \\r\\n    print(\"Testing when\", num_close, \"out of\", num_strikes, \"\\\\\"strikes\\\\\" are are close . . . \")\\r\\n    print(\"  Inputs:\", inputs)\\r\\n    print(\"  Result: \", end=\\'\\')\\r\\n    \\r\\n    if answer.strip() == output.strip():\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected: \\'\" + answer + \"\\' instead of \\'\" + output + \"\\'\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_passed = 0\\r\\n    \\r\\n    if (run_test(0, random.randint(2, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(1, random.randint(1, 2))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(2, random.randint(4, 6))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(4, random.randint(4, 6))):\\r\\n        num_passed += 1\\r\\n        \\r\\n    return (100 / 4) * num_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_5_combat': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(num_close, num_planes):    \\r\\n    inputs = [num_planes]\\r\\n    \\r\\n    for i in range(num_planes):\\r\\n        if i < num_close:\\r\\n            if (i + 1 == num_close):\\r\\n                inputs.append(20)\\r\\n            else:\\r\\n                inputs.append(round(random.uniform(0, 20), 1))\\r\\n        else:\\r\\n            inputs.append(round(random.uniform(20, 50), 1))\\r\\n\\r\\n    # Generates Expected Answer\\r\\n    if num_close == 0:\\r\\n        answer = \"All Clear\"\\r\\n    elif num_close <= 2:\\r\\n        answer = \"Warning\"\\r\\n    else:\\r\\n        answer = \"Evasive Action\"\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"a2_5_combat.py\", inputs)\\r\\n    \\r\\n    print(\"Testing when\", num_close, \"out of\", num_planes, \"are close . . . \")\\r\\n    print(\"  Inputs:\", inputs)\\r\\n    print(\"  Result: \", end=\\'\\')\\r\\n    \\r\\n    if answer.strip() == output.strip():\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected: \\'\" + answer + \"\\' instead of \\'\" + output + \"\\'\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    num_passed = 0\\r\\n    \\r\\n    if (run_test(0, random.randint(1, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(1, random.randint(1, 2))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(2, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n    \\r\\n    if (run_test(3, random.randint(3, 5))):\\r\\n        num_passed += 1\\r\\n        \\r\\n    return (100 / 4) * num_passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_4_pipe': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\nvariant = \"pipe\"\\r\\nverbose = False\\r\\n\\r\\nvariants = {\\r\\n            \"validate\": {\"delimiter\": \\'.\\'}, \\r\\n            \"comma\"   : {\"delimiter\": \\',\\'},\\r\\n            \"pipe\"    : {\"delimiter\": \\'|\\'}, #\\r\\n            \"amp\"     : {\"delimiter\": \\'&\\'}, #\\r\\n            \"caret\"   : {\"delimiter\": \\'^\\'}, #\\r\\n            \"dollar\"  : {\"delimiter\": \\'$\\'}, #\\r\\n            \"hash\"    : {\"delimiter\": \\'#\\'}, #\\r\\n            \"ques\"    : {\"delimiter\": \\'?\\'}, #\\r\\n            \"semic\"   : {\"delimiter\": \\';\\'}, #\\r\\n            \"slash\"   : {\"delimiter\": \\'/\\'}, #\\r\\n            \"star\"    : {\"delimiter\": \\'*\\'}, #\\r\\n            \"colon\"   : {\"delimiter\": \\':\\'}, #\\r\\n            \"hyphen\"  : {\"delimiter\": \\'-\\'}, #\\r\\n            \"score\"   : {\"delimiter\": \\'_\\'}, #\\r\\n           }\\r\\n\\r\\ndelimiter_proper = variants[variant][\"delimiter\"]\\r\\n\\r\\ndef generate_test_string(delimiter):\\r\\n    \\r\\n    random_lists = [\\r\\n                    [\"booker12\",\"9012\",\"12se74\",\"rb9012\",\"Rachel\",\"Booker\",\"Sales\",\"Coventry\"],\\r\\n                    [\"grey07\",\"2070\",\"04ap67\",\"lg2070\",\"Laura\",\"Grey\",\"Depot\",\"London\"],\\r\\n                    [\"johnson81\",\"4081\",\"30no86\",\"cj4081\",\"Craig\",\"Johnson\",\"Shipping\",\"Westminster\"],\\r\\n                    [\"jenkins46\",\"9346\",\"14ju73\",\"mj9346\",\"Mary\",\"Jenkins\",\"Engineering\",\"Liverpool\"],\\r\\n                    [\"smith79\",\"5079\",\"09ja61\",\"js5079\",\"Jamie\",\"Smith\",\"Testing\",\"Manchester\"]\\r\\n                   ]\\r\\n    \\r\\n    random_list = random_lists[random.randrange(len(random_lists))]\\r\\n    random_column = random.randrange(len(random_list))\\r\\n    test_string = \"\"\\r\\n    for field in random_list:\\r\\n        if test_string != \"\":\\r\\n            test_string += delimiter\\r\\n        test_string += field\\r\\n    return test_string, random_column\\r\\n\\r\\ndef solution(delimiter, string, column_num):\\r\\n    \\r\\n    #print(\"SOLUTION:\", string, delimiter, column_num, sep=\"\\\\n\")\\r\\n    columns = string.split(delimiter)\\r\\n    output = str(len(columns)) + \\'\\\\n\\'\\r\\n    output += columns[column_num] + \\'\\\\n\\'\\r\\n        \\r\\n    return output\\r\\n\\r\\ndef print_test_results(test_score, actual_output, expected_output):\\r\\n\\r\\n    if verbose:\\r\\n        \\r\\n        if test_score == 100:\\r\\n            print(\"CORRECT: %.1f%%\" % (test_score))\\r\\n        else:\\r\\n            print(\"INCORRECT: %.1f%%\" % (test_score))\\r\\n            print(\"Expected:\")\\r\\n            print(expected_output)\\r\\n\\r\\n    else:\\r\\n\\r\\n        if test_score == 100:\\r\\n            print(\"CORRECT\")\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n            print(\"Expected:\")\\r\\n            print(expected_output)\\r\\n\\r\\ndef run1test(delimiter):\\r\\n\\r\\n    # Rubric\\r\\n    # 1 Runs without errors\\r\\n    # 1 Prints out the correct item count (regardless of order)\\r\\n    # 1 Prints out the correct item value (regardless of order)\\r\\n    # 1 Prints out the items in the correct order (0.5 for each)\\r\\n\\r\\n    test_score = 0\\r\\n    test_max = 4\\r\\n    \\r\\n    test_string, random_column = generate_test_string(delimiter)\\r\\n    output, error = autograder.run_script(\"a2_4_%s.py\" % (variant), [ test_string, random_column ])\\r\\n    expected_output = solution(delimiter, test_string, random_column)\\r\\n\\r\\n    if error == \"\":\\r\\n        test_score += 1\\r\\n    \\r\\n    returned_lines = output.strip().split(\\'\\\\n\\')\\r\\n    returned_count = None\\r\\n    returned_item = None\\r\\n    if len(returned_lines) > 0:\\r\\n        returned_count = returned_lines[0]\\r\\n    if len(returned_lines) > 1:\\r\\n        returned_item = returned_lines[1]\\r\\n    \\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    expected_count = expected_lines[0]\\r\\n    expected_item = expected_lines[1]\\r\\n\\r\\n    if returned_count in expected_lines:\\r\\n        test_score += 1\\r\\n    if returned_count == expected_count:\\r\\n        test_score += 0.5\\r\\n    \\r\\n    if returned_item in expected_lines:\\r\\n        test_score += 1\\r\\n    if returned_item == expected_item:\\r\\n        test_score += 0.5\\r\\n\\r\\n    test_score = round(100 * (test_score / test_max), 1)\\r\\n    print_test_results(test_score, output, expected_output)\\r\\n    \\r\\n    return test_score\\r\\n\\r\\ndef initial_test():\\r\\n    global delimiter_used\\r\\n    \\r\\n    test_max = 12\\r\\n\\r\\n    test_score = 1 # For testing against the server\\r\\n\\r\\n    sensor_string = \"sensor.validate.,comma,|pipe|#hash#$dollar$^caret^:colon:;semic;*star*&amp&?ques?-hyphen-/slash/_score_end\"\\r\\n    delimiter_column = 1\\r\\n\\r\\n    detection_failed = False\\r\\n    output, error   = autograder.run_script(\"a2_4_%s.py\" % (variant), [ sensor_string, delimiter_column ])\\r\\n    \\r\\n    if error == \"\":\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Running without error.\")\\r\\n    expected_output = solution(delimiter_proper, sensor_string, delimiter_column)\\r\\n\\r\\n    returned_lines = output.strip().split(\\'\\\\n\\')\\r\\n    returned_count = None\\r\\n    returned_item = None\\r\\n    if len(returned_lines) > 0:\\r\\n        returned_count = returned_lines[0]\\r\\n    if len(returned_lines) > 1:\\r\\n        returned_item = returned_lines[1]\\r\\n\\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    #expected_count = expected_lines[0]\\r\\n    #expected_item = expected_lines[1]\\r\\n\\r\\n    if len(returned_lines) >= 1 and returned_lines[0] != \\'\\':\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 At least one line of output.\")\\r\\n    if len(returned_lines) == 2:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Exactly two lines of output.\")\\r\\n        \\r\\n    if returned_count in expected_lines:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Count contained in output somewhere.\")\\r\\n    if returned_item in expected_lines:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Requested item contained in output somewhere.\")\\r\\n\\r\\n    detection_failed = len(returned_lines) < 2\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"Delimiter Detection:\")\\r\\n        if detection_failed:\\r\\n            print(\"Failed:\", returned_lines)\\r\\n        else:\\r\\n            print(\"Detected delimiter: \", returned_lines[1])\\r\\n            print(\"Sensor fields: \", returned_lines[0])\\r\\n    \\r\\n    if variant in returned_lines:\\r\\n        test_score += 3\\r\\n        if verbose: print(\"+3 Detected delimiter is correct.\")\\r\\n\\r\\n    delimiter_used = None\\r\\n    if (not detection_failed) and (returned_lines[1] in variants):\\r\\n        delimiter_used = variants[returned_lines[1]][\"delimiter\"]\\r\\n\\r\\n    if delimiter_used == delimiter_proper:\\r\\n        test_score += 3\\r\\n        if verbose: print(\"+3 Detected delimiter is proper.\")\\r\\n\\r\\n    if delimiter_used == None:\\r\\n        delimiter_used = delimiter_proper\\r\\n        \\r\\n    test_score = round(100 * (test_score / test_max), 1)\\r\\n    print_test_results(test_score, output, expected_output)\\r\\n\\r\\n    return test_score\\r\\n    \\r\\ndef test_passed():\\r\\n\\r\\n    test_weights = [20, 12,4,4]\\r\\n    test_total = sum(test_weights) - test_weights[0]\\r\\n    if test_total != test_weights[0]:\\r\\n        print(\"Individual tests do not add to total value.\\\\n\")\\r\\n        \\r\\n    score = 0\\r\\n    test_num = 0\\r\\n    #------------------------------------------------\\r\\n    # Test #1: Sense delimiter used\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(test_weights[test_num]/test_total)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n        \\r\\n    test_score = initial_test()\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n    \\r\\n    #------------------------------------------------\\r\\n    # Test #2: Using detected delimiter\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(4/20)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    \\r\\n    test_score = run1test(delimiter_used)\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n\\r\\n    #------------------------------------------------\\r\\n    # Test #3: Use correct delimiter\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(4/20)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n        \\r\\n    test_score = run1test(delimiter_proper)\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n\\r\\n    #------------------------------------------------\\r\\n    # End of Test\\r\\n    #------------------------------------------------\\r\\n    \\r\\n    print(\"\\\\nOVERALL SCORE:\")\\r\\n    return round(score,1)\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':   \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_4_hyphen': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\nvariant = \"hyphen\"\\r\\nverbose = False\\r\\n\\r\\nvariants = {\\r\\n            \"validate\": {\"delimiter\": \\'.\\'}, \\r\\n            \"comma\"   : {\"delimiter\": \\',\\'},\\r\\n            \"pipe\"    : {\"delimiter\": \\'|\\'}, #\\r\\n            \"amp\"     : {\"delimiter\": \\'&\\'}, #\\r\\n            \"caret\"   : {\"delimiter\": \\'^\\'}, #\\r\\n            \"dollar\"  : {\"delimiter\": \\'$\\'}, #\\r\\n            \"hash\"    : {\"delimiter\": \\'#\\'}, #\\r\\n            \"ques\"    : {\"delimiter\": \\'?\\'}, #\\r\\n            \"semic\"   : {\"delimiter\": \\';\\'}, #\\r\\n            \"slash\"   : {\"delimiter\": \\'/\\'}, #\\r\\n            \"star\"    : {\"delimiter\": \\'*\\'}, #\\r\\n            \"colon\"   : {\"delimiter\": \\':\\'}, #\\r\\n            \"hyphen\"  : {\"delimiter\": \\'-\\'}, #\\r\\n            \"score\"   : {\"delimiter\": \\'_\\'}, #\\r\\n           }\\r\\n\\r\\ndelimiter_proper = variants[variant][\"delimiter\"]\\r\\n\\r\\ndef generate_test_string(delimiter):\\r\\n    \\r\\n    random_lists = [\\r\\n                    [\"booker12\",\"9012\",\"12se74\",\"rb9012\",\"Rachel\",\"Booker\",\"Sales\",\"Coventry\"],\\r\\n                    [\"grey07\",\"2070\",\"04ap67\",\"lg2070\",\"Laura\",\"Grey\",\"Depot\",\"London\"],\\r\\n                    [\"johnson81\",\"4081\",\"30no86\",\"cj4081\",\"Craig\",\"Johnson\",\"Shipping\",\"Westminster\"],\\r\\n                    [\"jenkins46\",\"9346\",\"14ju73\",\"mj9346\",\"Mary\",\"Jenkins\",\"Engineering\",\"Liverpool\"],\\r\\n                    [\"smith79\",\"5079\",\"09ja61\",\"js5079\",\"Jamie\",\"Smith\",\"Testing\",\"Manchester\"]\\r\\n                   ]\\r\\n    \\r\\n    random_list = random_lists[random.randrange(len(random_lists))]\\r\\n    random_column = random.randrange(len(random_list))\\r\\n    test_string = \"\"\\r\\n    for field in random_list:\\r\\n        if test_string != \"\":\\r\\n            test_string += delimiter\\r\\n        test_string += field\\r\\n    return test_string, random_column\\r\\n\\r\\ndef solution(delimiter, string, column_num):\\r\\n    \\r\\n    #print(\"SOLUTION:\", string, delimiter, column_num, sep=\"\\\\n\")\\r\\n    columns = string.split(delimiter)\\r\\n    output = str(len(columns)) + \\'\\\\n\\'\\r\\n    output += columns[column_num] + \\'\\\\n\\'\\r\\n        \\r\\n    return output\\r\\n\\r\\ndef print_test_results(test_score, actual_output, expected_output):\\r\\n\\r\\n    if verbose:\\r\\n        \\r\\n        if test_score == 100:\\r\\n            print(\"CORRECT: %.1f%%\" % (test_score))\\r\\n        else:\\r\\n            print(\"INCORRECT: %.1f%%\" % (test_score))\\r\\n            print(\"Expected:\")\\r\\n            print(expected_output)\\r\\n\\r\\n    else:\\r\\n\\r\\n        if test_score == 100:\\r\\n            print(\"CORRECT\")\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n            print(\"Expected:\")\\r\\n            print(expected_output)\\r\\n\\r\\ndef run1test(delimiter):\\r\\n\\r\\n    # Rubric\\r\\n    # 1 Runs without errors\\r\\n    # 1 Prints out the correct item count (regardless of order)\\r\\n    # 1 Prints out the correct item value (regardless of order)\\r\\n    # 1 Prints out the items in the correct order (0.5 for each)\\r\\n\\r\\n    test_score = 0\\r\\n    test_max = 4\\r\\n    \\r\\n    test_string, random_column = generate_test_string(delimiter)\\r\\n    output, error = autograder.run_script(\"a2_4_%s.py\" % (variant), [ test_string, random_column ])\\r\\n    expected_output = solution(delimiter, test_string, random_column)\\r\\n\\r\\n    if error == \"\":\\r\\n        test_score += 1\\r\\n    \\r\\n    returned_lines = output.strip().split(\\'\\\\n\\')\\r\\n    returned_count = None\\r\\n    returned_item = None\\r\\n    if len(returned_lines) > 0:\\r\\n        returned_count = returned_lines[0]\\r\\n    if len(returned_lines) > 1:\\r\\n        returned_item = returned_lines[1]\\r\\n    \\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    expected_count = expected_lines[0]\\r\\n    expected_item = expected_lines[1]\\r\\n\\r\\n    if returned_count in expected_lines:\\r\\n        test_score += 1\\r\\n    if returned_count == expected_count:\\r\\n        test_score += 0.5\\r\\n    \\r\\n    if returned_item in expected_lines:\\r\\n        test_score += 1\\r\\n    if returned_item == expected_item:\\r\\n        test_score += 0.5\\r\\n\\r\\n    test_score = round(100 * (test_score / test_max), 1)\\r\\n    print_test_results(test_score, output, expected_output)\\r\\n    \\r\\n    return test_score\\r\\n\\r\\ndef initial_test():\\r\\n    global delimiter_used\\r\\n    \\r\\n    test_max = 12\\r\\n\\r\\n    test_score = 1 # For testing against the server\\r\\n\\r\\n    sensor_string = \"sensor.validate.,comma,|pipe|#hash#$dollar$^caret^:colon:;semic;*star*&amp&?ques?-hyphen-/slash/_score_end\"\\r\\n    delimiter_column = 1\\r\\n\\r\\n    detection_failed = False\\r\\n    output, error   = autograder.run_script(\"a2_4_%s.py\" % (variant), [ sensor_string, delimiter_column ])\\r\\n    \\r\\n    if error == \"\":\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Running without error.\")\\r\\n    expected_output = solution(delimiter_proper, sensor_string, delimiter_column)\\r\\n\\r\\n    returned_lines = output.strip().split(\\'\\\\n\\')\\r\\n    returned_count = None\\r\\n    returned_item = None\\r\\n    if len(returned_lines) > 0:\\r\\n        returned_count = returned_lines[0]\\r\\n    if len(returned_lines) > 1:\\r\\n        returned_item = returned_lines[1]\\r\\n\\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    #expected_count = expected_lines[0]\\r\\n    #expected_item = expected_lines[1]\\r\\n\\r\\n    if len(returned_lines) >= 1 and returned_lines[0] != \\'\\':\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 At least one line of output.\")\\r\\n    if len(returned_lines) == 2:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Exactly two lines of output.\")\\r\\n        \\r\\n    if returned_count in expected_lines:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Count contained in output somewhere.\")\\r\\n    if returned_item in expected_lines:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Requested item contained in output somewhere.\")\\r\\n\\r\\n    detection_failed = len(returned_lines) < 2\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"Delimiter Detection:\")\\r\\n        if detection_failed:\\r\\n            print(\"Failed:\", returned_lines)\\r\\n        else:\\r\\n            print(\"Detected delimiter: \", returned_lines[1])\\r\\n            print(\"Sensor fields: \", returned_lines[0])\\r\\n    \\r\\n    if variant in returned_lines:\\r\\n        test_score += 3\\r\\n        if verbose: print(\"+3 Detected delimiter is correct.\")\\r\\n\\r\\n    delimiter_used = None\\r\\n    if (not detection_failed) and (returned_lines[1] in variants):\\r\\n        delimiter_used = variants[returned_lines[1]][\"delimiter\"]\\r\\n\\r\\n    if delimiter_used == delimiter_proper:\\r\\n        test_score += 3\\r\\n        if verbose: print(\"+3 Detected delimiter is proper.\")\\r\\n\\r\\n    if delimiter_used == None:\\r\\n        delimiter_used = delimiter_proper\\r\\n        \\r\\n    test_score = round(100 * (test_score / test_max), 1)\\r\\n    print_test_results(test_score, output, expected_output)\\r\\n\\r\\n    return test_score\\r\\n    \\r\\ndef test_passed():\\r\\n\\r\\n    test_weights = [20, 12,4,4]\\r\\n    test_total = sum(test_weights) - test_weights[0]\\r\\n    if test_total != test_weights[0]:\\r\\n        print(\"Individual tests do not add to total value.\\\\n\")\\r\\n        \\r\\n    score = 0\\r\\n    test_num = 0\\r\\n    #------------------------------------------------\\r\\n    # Test #1: Sense delimiter used\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(test_weights[test_num]/test_total)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n        \\r\\n    test_score = initial_test()\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n    \\r\\n    #------------------------------------------------\\r\\n    # Test #2: Using detected delimiter\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(4/20)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    \\r\\n    test_score = run1test(delimiter_used)\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n\\r\\n    #------------------------------------------------\\r\\n    # Test #3: Use correct delimiter\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(4/20)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n        \\r\\n    test_score = run1test(delimiter_proper)\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n\\r\\n    #------------------------------------------------\\r\\n    # End of Test\\r\\n    #------------------------------------------------\\r\\n    \\r\\n    print(\"\\\\nOVERALL SCORE:\")\\r\\n    return round(score,1)\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':   \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_4_hash': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\nvariant = \"hash\"\\r\\nverbose = False\\r\\n\\r\\nvariants = {\\r\\n            \"validate\": {\"delimiter\": \\'.\\'}, \\r\\n            \"comma\"   : {\"delimiter\": \\',\\'},\\r\\n            \"pipe\"    : {\"delimiter\": \\'|\\'}, #\\r\\n            \"amp\"     : {\"delimiter\": \\'&\\'}, #\\r\\n            \"caret\"   : {\"delimiter\": \\'^\\'}, #\\r\\n            \"dollar\"  : {\"delimiter\": \\'$\\'}, #\\r\\n            \"hash\"    : {\"delimiter\": \\'#\\'}, #\\r\\n            \"ques\"    : {\"delimiter\": \\'?\\'}, #\\r\\n            \"semic\"   : {\"delimiter\": \\';\\'}, #\\r\\n            \"slash\"   : {\"delimiter\": \\'/\\'}, #\\r\\n            \"star\"    : {\"delimiter\": \\'*\\'}, #\\r\\n            \"colon\"   : {\"delimiter\": \\':\\'}, #\\r\\n            \"hyphen\"  : {\"delimiter\": \\'-\\'}, #\\r\\n            \"score\"   : {\"delimiter\": \\'_\\'}, #\\r\\n           }\\r\\n\\r\\ndelimiter_proper = variants[variant][\"delimiter\"]\\r\\n\\r\\ndef generate_test_string(delimiter):\\r\\n    \\r\\n    random_lists = [\\r\\n                    [\"booker12\",\"9012\",\"12se74\",\"rb9012\",\"Rachel\",\"Booker\",\"Sales\",\"Coventry\"],\\r\\n                    [\"grey07\",\"2070\",\"04ap67\",\"lg2070\",\"Laura\",\"Grey\",\"Depot\",\"London\"],\\r\\n                    [\"johnson81\",\"4081\",\"30no86\",\"cj4081\",\"Craig\",\"Johnson\",\"Shipping\",\"Westminster\"],\\r\\n                    [\"jenkins46\",\"9346\",\"14ju73\",\"mj9346\",\"Mary\",\"Jenkins\",\"Engineering\",\"Liverpool\"],\\r\\n                    [\"smith79\",\"5079\",\"09ja61\",\"js5079\",\"Jamie\",\"Smith\",\"Testing\",\"Manchester\"]\\r\\n                   ]\\r\\n    \\r\\n    random_list = random_lists[random.randrange(len(random_lists))]\\r\\n    random_column = random.randrange(len(random_list))\\r\\n    test_string = \"\"\\r\\n    for field in random_list:\\r\\n        if test_string != \"\":\\r\\n            test_string += delimiter\\r\\n        test_string += field\\r\\n    return test_string, random_column\\r\\n\\r\\ndef solution(delimiter, string, column_num):\\r\\n    \\r\\n    #print(\"SOLUTION:\", string, delimiter, column_num, sep=\"\\\\n\")\\r\\n    columns = string.split(delimiter)\\r\\n    output = str(len(columns)) + \\'\\\\n\\'\\r\\n    output += columns[column_num] + \\'\\\\n\\'\\r\\n        \\r\\n    return output\\r\\n\\r\\ndef print_test_results(test_score, actual_output, expected_output):\\r\\n\\r\\n    if verbose:\\r\\n        \\r\\n        if test_score == 100:\\r\\n            print(\"CORRECT: %.1f%%\" % (test_score))\\r\\n        else:\\r\\n            print(\"INCORRECT: %.1f%%\" % (test_score))\\r\\n            print(\"Expected:\")\\r\\n            print(expected_output)\\r\\n\\r\\n    else:\\r\\n\\r\\n        if test_score == 100:\\r\\n            print(\"CORRECT\")\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n            print(\"Expected:\")\\r\\n            print(expected_output)\\r\\n\\r\\ndef run1test(delimiter):\\r\\n\\r\\n    # Rubric\\r\\n    # 1 Runs without errors\\r\\n    # 1 Prints out the correct item count (regardless of order)\\r\\n    # 1 Prints out the correct item value (regardless of order)\\r\\n    # 1 Prints out the items in the correct order (0.5 for each)\\r\\n\\r\\n    test_score = 0\\r\\n    test_max = 4\\r\\n    \\r\\n    test_string, random_column = generate_test_string(delimiter)\\r\\n    output, error = autograder.run_script(\"a2_4_%s.py\" % (variant), [ test_string, random_column ])\\r\\n    expected_output = solution(delimiter, test_string, random_column)\\r\\n\\r\\n    if error == \"\":\\r\\n        test_score += 1\\r\\n    \\r\\n    returned_lines = output.strip().split(\\'\\\\n\\')\\r\\n    returned_count = None\\r\\n    returned_item = None\\r\\n    if len(returned_lines) > 0:\\r\\n        returned_count = returned_lines[0]\\r\\n    if len(returned_lines) > 1:\\r\\n        returned_item = returned_lines[1]\\r\\n    \\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    expected_count = expected_lines[0]\\r\\n    expected_item = expected_lines[1]\\r\\n\\r\\n    if returned_count in expected_lines:\\r\\n        test_score += 1\\r\\n    if returned_count == expected_count:\\r\\n        test_score += 0.5\\r\\n    \\r\\n    if returned_item in expected_lines:\\r\\n        test_score += 1\\r\\n    if returned_item == expected_item:\\r\\n        test_score += 0.5\\r\\n\\r\\n    test_score = round(100 * (test_score / test_max), 1)\\r\\n    print_test_results(test_score, output, expected_output)\\r\\n    \\r\\n    return test_score\\r\\n\\r\\ndef initial_test():\\r\\n    global delimiter_used\\r\\n    \\r\\n    test_max = 12\\r\\n\\r\\n    test_score = 1 # For testing against the server\\r\\n\\r\\n    sensor_string = \"sensor.validate.,comma,|pipe|#hash#$dollar$^caret^:colon:;semic;*star*&amp&?ques?-hyphen-/slash/_score_end\"\\r\\n    delimiter_column = 1\\r\\n\\r\\n    detection_failed = False\\r\\n    output, error   = autograder.run_script(\"a2_4_%s.py\" % (variant), [ sensor_string, delimiter_column ])\\r\\n    \\r\\n    if error == \"\":\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Running without error.\")\\r\\n    expected_output = solution(delimiter_proper, sensor_string, delimiter_column)\\r\\n\\r\\n    returned_lines = output.strip().split(\\'\\\\n\\')\\r\\n    returned_count = None\\r\\n    returned_item = None\\r\\n    if len(returned_lines) > 0:\\r\\n        returned_count = returned_lines[0]\\r\\n    if len(returned_lines) > 1:\\r\\n        returned_item = returned_lines[1]\\r\\n\\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    #expected_count = expected_lines[0]\\r\\n    #expected_item = expected_lines[1]\\r\\n\\r\\n    if len(returned_lines) >= 1 and returned_lines[0] != \\'\\':\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 At least one line of output.\")\\r\\n    if len(returned_lines) == 2:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Exactly two lines of output.\")\\r\\n        \\r\\n    if returned_count in expected_lines:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Count contained in output somewhere.\")\\r\\n    if returned_item in expected_lines:\\r\\n        test_score += 1\\r\\n        if verbose: print(\"+1 Requested item contained in output somewhere.\")\\r\\n\\r\\n    detection_failed = len(returned_lines) < 2\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"Delimiter Detection:\")\\r\\n        if detection_failed:\\r\\n            print(\"Failed:\", returned_lines)\\r\\n        else:\\r\\n            print(\"Detected delimiter: \", returned_lines[1])\\r\\n            print(\"Sensor fields: \", returned_lines[0])\\r\\n    \\r\\n    if variant in returned_lines:\\r\\n        test_score += 3\\r\\n        if verbose: print(\"+3 Detected delimiter is correct.\")\\r\\n\\r\\n    delimiter_used = None\\r\\n    if (not detection_failed) and (returned_lines[1] in variants):\\r\\n        delimiter_used = variants[returned_lines[1]][\"delimiter\"]\\r\\n\\r\\n    if delimiter_used == delimiter_proper:\\r\\n        test_score += 3\\r\\n        if verbose: print(\"+3 Detected delimiter is proper.\")\\r\\n\\r\\n    if delimiter_used == None:\\r\\n        delimiter_used = delimiter_proper\\r\\n        \\r\\n    test_score = round(100 * (test_score / test_max), 1)\\r\\n    print_test_results(test_score, output, expected_output)\\r\\n\\r\\n    return test_score\\r\\n    \\r\\ndef test_passed():\\r\\n\\r\\n    test_weights = [20, 12,4,4]\\r\\n    test_total = sum(test_weights) - test_weights[0]\\r\\n    if test_total != test_weights[0]:\\r\\n        print(\"Individual tests do not add to total value.\\\\n\")\\r\\n        \\r\\n    score = 0\\r\\n    test_num = 0\\r\\n    #------------------------------------------------\\r\\n    # Test #1: Sense delimiter used\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(test_weights[test_num]/test_total)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n        \\r\\n    test_score = initial_test()\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n    \\r\\n    #------------------------------------------------\\r\\n    # Test #2: Using detected delimiter\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(4/20)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    \\r\\n    test_score = run1test(delimiter_used)\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n\\r\\n    #------------------------------------------------\\r\\n    # Test #3: Use correct delimiter\\r\\n    #------------------------------------------------\\r\\n    test_num += 1\\r\\n    test_weight = 100*(4/20)\\r\\n    \\r\\n    if verbose:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n    else:\\r\\n        print(\"\\\\nTEST #%d (weight: %.1f%%)\" % (test_num, test_weight))\\r\\n        \\r\\n    test_score = run1test(delimiter_proper)\\r\\n    \\r\\n    score += (test_score/100) * test_weight\\r\\n\\r\\n    #------------------------------------------------\\r\\n    # End of Test\\r\\n    #------------------------------------------------\\r\\n    \\r\\n    print(\"\\\\nOVERALL SCORE:\")\\r\\n    return round(score,1)\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':   \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_3_thirteen': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(starting_num):\\r\\n    result = \\'\\'\\r\\n    i = starting_num\\r\\n    \\r\\n    while i >= 0:\\r\\n    \\r\\n        result += str(i) + \"\\\\n\"\\r\\n        \\r\\n        i = i - 13\\r\\n    return result\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    random_number = 78 + 13 * random.randint(1, 15)\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_3_thirteen.py\", [random_number])\\r\\n    expected_string = solution(random_number)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_string.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    #Exactly correct\\r\\n    if output.strip() == expected_string.strip():\\r\\n        print(\"CORRECT\")\\r\\n        score += 100\\r\\n    #Mostly correct but added an extra value or included one less value: -2 points\\r\\n    elif output.strip().split(\\'\\\\n\\') == expected_lines[:-1] or \\\\\\r\\n         output.strip().split(\\'\\\\n\\')[:-1] == expected_lines:\\r\\n        print(\"INCORRECT.  Expected:\\\\n\"+expected_string)\\r\\n        score+=90\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\\\\n\"+expected_string)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_3_nineteen': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(starting_num):\\r\\n    result = \\'\\'\\r\\n    i = starting_num\\r\\n    \\r\\n    while i >= 0:\\r\\n    \\r\\n        result += str(i) + \"\\\\n\"\\r\\n        \\r\\n        i = i - 19\\r\\n    return result\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    random_number = 114 + 19 * random.randint(1, 20)\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_3_nineteen.py\", [random_number])\\r\\n    expected_string = solution(random_number)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_string.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    #Exactly correct\\r\\n    if output.strip() == expected_string.strip():\\r\\n        print(\"CORRECT\")\\r\\n        score += 100\\r\\n    #Mostly correct but added an extra value or included one less value: -2 points\\r\\n    elif output.strip().split(\\'\\\\n\\') == expected_lines[:-1] or \\\\\\r\\n         output.strip().split(\\'\\\\n\\')[:-1] == expected_lines:\\r\\n        print(\"INCORRECT.  Expected:\\\\n\"+expected_string)\\r\\n        score+=90\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\\\\n\"+expected_string)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_3_nine': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(starting_num):\\r\\n    result = \\'\\'\\r\\n    i = starting_num\\r\\n    \\r\\n    while i >= 0:\\r\\n    \\r\\n        result += str(i) + \"\\\\n\"\\r\\n        \\r\\n        i = i - 9\\r\\n    return result\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    random_number = 81 + 9 * random.randint(1, 30)\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_3_nine.py\", [random_number])\\r\\n    expected_string = solution(random_number)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_string.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    #Exactly correct\\r\\n    if output.strip() == expected_string.strip():\\r\\n        print(\"CORRECT\")\\r\\n        score += 100\\r\\n    #Mostly correct but added an extra value or included one less value: -2 points\\r\\n    elif output.strip().split(\\'\\\\n\\') == expected_lines[:-1] or \\\\\\r\\n         output.strip().split(\\'\\\\n\\')[:-1] == expected_lines:\\r\\n        print(\"INCORRECT.  Expected:\\\\n\"+expected_string)\\r\\n        score+=90\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\\\\n\"+expected_string)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_3_eighteen': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(starting_num):\\r\\n    result = \\'\\'\\r\\n    i = starting_num\\r\\n    \\r\\n    while i >= 0:\\r\\n    \\r\\n        result += str(i) + \"\\\\n\"\\r\\n        \\r\\n        i = i - 18\\r\\n    return result\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    random_number = 108 + 18 * random.randint(1, 15)\\r\\n    \\r\\n    output, error = autograder.run_script(\"a2_3_eighteen.py\", [random_number])\\r\\n    expected_string = solution(random_number)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_string.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    #Exactly correct\\r\\n    if output.strip() == expected_string.strip():\\r\\n        print(\"CORRECT\")\\r\\n        score += 100\\r\\n    #Mostly correct but added an extra value or included one less value: -2 points\\r\\n    elif output.strip().split(\\'\\\\n\\') == expected_lines[:-1] or \\\\\\r\\n         output.strip().split(\\'\\\\n\\')[:-1] == expected_lines:\\r\\n        print(\"INCORRECT.  Expected:\\\\n\"+expected_string)\\r\\n        score+=90\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\\\\n\"+expected_string)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a2_2_orbit': 'from cs110 import autograder\\r\\nimport a2_2_orbit\\r\\n\\r\\ndef solution(D, V):\\r\\n    return (D*3.14)/V\\r\\n\\r\\n\\r\\ndef test_passed():    \\r\\n    score = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    \\r\\n    if \\'orbit_period\\' in dir(a2_2_orbit):\\r\\n        print(\"Function Defined\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function Not Defined\")\\r\\n    \\r\\n    if \\'orbit_period\\' in dir(a2_2_orbit) and a2_2_orbit.orbit_period(15, 0.22) == solution(15, 0.22):\\r\\n        print(\"Function Returns Correct Value\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function Does NOT Return the Correct Value\")\\r\\n\\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a2_1_right_triangle': 'from cs110 import autograder\\nfrom a2_1_right_triangle import *  \\n\\ndef calculate_hypotenuse(side_1, side_2):\\n    return (side_1**2+side_2**2)**.5\\n\\n\\ndef test_passed():\\n    solution = calculate_hypotenuse(15, 6.786)\\n    \\n    print(\"Feedback:\")\\n        \\n    if \\'result\\' in globals() and abs(result - solution) < 0.1:\\n        print(\"PASSED\")\\n        return 100\\n    elif \\'result\\' not in globals():\\n        print(\"FAILED.  Could not find variable \\'result\\'\")\\n    elif result != solution:\\n        print(\"FAILED.  Variable \\'result\\' has the wrong value \" + str(result))\\n    else:\\n        print(\"FAILED.  Something unexpected happened.\")\\n    \\n    return 0\\n\\n        \\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    test_case_result = test_passed()\\n    print(\"Unit Test Returned:\", test_case_result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_6_pilot_quals': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n\\r\\ndef solution(hours):\\r\\n    result = \"\"\\r\\n\\r\\n    if hours < 600:\\r\\n        result += \"Co-Pilot\\\\n\"\\r\\n\\r\\n    if hours >= 600:\\r\\n        result += \"Upgrade Pilot\\\\n\"\\r\\n\\r\\n    if hours >= 800:\\r\\n        result += \"Aircraft Commander\\\\n\"\\r\\n        \\r\\n    if hours >= 1000:\\r\\n        result += \"Formation Lead\\\\n\"\\r\\n\\r\\n    if hours >=1250:\\r\\n        result += \"Instructor Pilot\\\\n\"\\r\\n\\r\\n    if hours >= 1500:\\r\\n        result += \"Evaluator Pilot\\\\n\"\\r\\n\\r\\n    \\r\\n    return result.strip().split(\\'\\\\n\\')\\r\\n\\r\\n\\r\\ndef run_test(hours):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"------------------------------\")\\r\\n    print(\"Test\", num_tests_run, \"-\", hours, \"hours\")\\r\\n    print(\"------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_6_pilot_quals.py\", [hours], True)\\r\\n    lines = output.strip().split(\"\\\\n\")\\r\\n    expected_answer = solution(hours)\\r\\n    \\r\\n    count = 0\\r\\n    \\r\\n    for answer in expected_answer:\\r\\n        if answer in lines:\\r\\n            print(\"Expecting\", answer, \" . . . FOUND!\")\\r\\n            count += 1\\r\\n        else:\\r\\n            print(\"Expecting\", answer, \" . . . MISSING!\")\\r\\n            \\r\\n    if count == len(expected_answer) and len(expected_answer) == len(lines):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    elif len(expected_answer) < len(lines):\\r\\n        print(\"Problems Detected - Your output has more lines than expected.\\\\n\")\\r\\n    else:\\r\\n        print(\"Problems Detected - Your output is missing one or more expected outputs.\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(0, 600), 1))\\r\\n    run_test(600)\\r\\n    run_test(round(random.uniform(600, 799), 1))\\r\\n    run_test(800)\\r\\n    run_test(round(random.uniform(800, 999), 1))\\r\\n    run_test(1000)\\r\\n    run_test(round(random.uniform(1000, 1249), 1))\\r\\n    run_test(1250)\\r\\n    run_test(round(random.uniform(1250, 1499), 1))\\r\\n    run_test(1500)\\r\\n    run_test(2750)\\r\\n    \\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\nif __name__ == \\'__main__\\':\\r\\n    class Console:\\r\\n        def write(self, txt):\\r\\n            print(txt, end=\\'\\')\\r\\n    \\r\\n    test_passed()\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_6_payload': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n\\r\\ndef solution(payload_weight):\\r\\n    result = \"\"\\r\\n    \\r\\n    if payload_weight <= 6000:\\r\\n        result += \"V-22 Osprey\\\\n\"\\r\\n\\r\\n    if payload_weight <= 42000:\\r\\n        result += \"C-130 Hercules\\\\n\"\\r\\n        \\r\\n    if payload_weight <= 169000:\\r\\n        result += \"KC-10 Extender\\\\n\"\\r\\n\\r\\n    if payload_weight <= 170900:\\r\\n        result += \"C-17 Globemaster\\\\n\"\\r\\n\\r\\n    if payload_weight <= 285000:\\r\\n        result += \"C-5 Galaxy\\\\n\"\\r\\n\\r\\n    if payload_weight > 285000:\\r\\n        result += \"Too Heavy for Airlift\\\\n\"\\r\\n    \\r\\n    return result.strip().split(\\'\\\\n\\')\\r\\n\\r\\n\\r\\ndef run_test(payload_weight):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"------------------------------\")\\r\\n    print(\"Test\", num_tests_run, \"-\", payload_weight, \"lbs\")\\r\\n    print(\"------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_6_payload.py\", [payload_weight], True)\\r\\n    lines = output.strip().split(\"\\\\n\")\\r\\n    expected_answer = solution(payload_weight)\\r\\n    \\r\\n    count = 0\\r\\n    \\r\\n    for answer in expected_answer:\\r\\n        if answer in lines:\\r\\n            print(\"Expecting\", answer, \" . . . FOUND!\")\\r\\n            count += 1\\r\\n        else:\\r\\n            print(\"Expecting\", answer, \" . . . MISSING!\")\\r\\n            \\r\\n    if count == len(expected_answer) and len(expected_answer) == len(lines):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    elif len(expected_answer) < len(lines):\\r\\n        print(\"Problems Detected - Your output has more lines than expected.\\\\n\")\\r\\n    else:\\r\\n        print(\"Problems Detected - Your output is missing one or more expected outputs.\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(0, 5999), 1))\\r\\n    run_test(6000)\\r\\n    run_test(round(random.uniform(6001, 41999), 1))\\r\\n    run_test(42000)\\r\\n    run_test(round(random.uniform(42001, 168999), 1))\\r\\n    run_test(169000)\\r\\n    run_test(round(random.uniform(169001, 170899), 1))\\r\\n    run_test(170900)\\r\\n    run_test(round(random.uniform(170901, 284999), 1))\\r\\n    run_test(285000)\\r\\n    run_test(300000)\\r\\n    \\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\nif __name__ == \\'__main__\\':\\r\\n    class Console:\\r\\n        def write(self, txt):\\r\\n            print(txt, end=\\'\\')\\r\\n    \\r\\n    test_passed()\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_6_missilethreat': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n\\r\\ndef solution(target_range):\\r\\n    result = \"\"\\r\\n    \\r\\n    if target_range <= 500:\\r\\n        result += \"Hwasong-6\\\\n\"\\r\\n\\r\\n    if target_range <= 1200:\\r\\n        result += \"KN-11\\\\n\"\\r\\n        \\r\\n    if target_range <= 4000:\\r\\n        result += \"Musudan BM-25\\\\n\"\\r\\n\\r\\n    if target_range <= 8000:\\r\\n        result += \"Hwasong-14\\\\n\"\\r\\n\\r\\n    if target_range <= 12000:\\r\\n        result += \"Taepodong-2\\\\n\"\\r\\n\\r\\n    if target_range > 12000:\\r\\n        result += \"Not in range\\\\n\"\\r\\n    \\r\\n    return result.strip().split(\\'\\\\n\\')\\r\\n\\r\\n\\r\\ndef run_test(target_range):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"------------------------------\")\\r\\n    print(\"Test\", num_tests_run, \"-\", target_range, \"kilometers\")\\r\\n    print(\"------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_6_missilethreat.py\", [target_range], True)\\r\\n    lines = output.strip().split(\"\\\\n\")\\r\\n    expected_answer = solution(target_range)\\r\\n    \\r\\n    count = 0\\r\\n    \\r\\n    for answer in expected_answer:\\r\\n        if answer in lines:\\r\\n            print(\"Expecting\", answer, \" . . . FOUND!\")\\r\\n            count += 1\\r\\n        else:\\r\\n            print(\"Expecting\", answer, \" . . . MISSING!\")\\r\\n            \\r\\n    if count == len(expected_answer) and len(expected_answer) == len(lines):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    elif len(expected_answer) < len(lines):\\r\\n        print(\"Problems Detected - Your output has more lines than expected.\\\\n\")\\r\\n    else:\\r\\n        print(\"Problems Detected - Your output is missing one or more expected outputs.\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(0, 499), 1))\\r\\n    run_test(500)\\r\\n    run_test(round(random.uniform(501, 1199), 1))\\r\\n    run_test(1200)\\r\\n    run_test(round(random.uniform(1201, 3999), 1))\\r\\n    run_test(4000)\\r\\n    run_test(round(random.uniform(4001, 7999), 1))\\r\\n    run_test(8000)\\r\\n    run_test(round(random.uniform(8001, 11999), 1))\\r\\n    run_test(12000)\\r\\n    run_test(12001)\\r\\n    \\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\nif __name__ == \\'__main__\\':\\r\\n    class Console:\\r\\n        def write(self, txt):\\r\\n            print(txt, end=\\'\\')\\r\\n    \\r\\n    test_passed()\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_6_evacuation': 'from cs110 import autograder\\nimport random, math\\n\\nnum_tests_passed = 0\\nnum_tests_run = 0\\n\\n\\ndef solution(target_range):\\n    result = \"\"\\n    \\n    if target_range <= 850:\\n        result += \"Pipe Bomb\\\\n\"\\n\\n    if target_range <= 1850:\\n        result += \"Suitcase Bomb\\\\n\"\\n        \\n    if target_range <= 2000:\\n        result += \"Sedan\\\\n\"\\n\\n    if target_range <= 2750:\\n        result += \"Cargo Van\\\\n\"\\n\\n    if target_range <= 7000:\\n        result += \"Semi-Trailer\\\\n\"\\n\\n    if target_range > 7000:\\n        result += \"Not in range\\\\n\"\\n    \\n    return result.strip().split(\\'\\\\n\\')\\n\\n\\ndef run_test(target_range):\\n    global num_tests_run, num_tests_passed\\n        \\n    num_tests_run += 1\\n    \\n    print(\"------------------------------\")\\n    print(\"Test\", num_tests_run, \"-\", target_range, \"feet\")\\n    print(\"------------------------------\")\\n    \\n    output, error_message = autograder.run_script(\"a1_6_evacuation.py\", [target_range], True)\\n    lines = output.strip().split(\"\\\\n\")\\n    expected_answer = solution(target_range)\\n    \\n    count = 0\\n    \\n    for answer in expected_answer:\\n        if answer in lines:\\n            print(\"Expecting\", answer, \" . . . FOUND!\")\\n            count += 1\\n        else:\\n            print(\"Expecting\", answer, \" . . . MISSING!\")\\n            \\n    if count == len(expected_answer) and len(expected_answer) == len(lines):\\n        print(\"SUCCESS!\\\\n\")\\n        num_tests_passed += 1\\n    elif len(expected_answer) < len(lines):\\n        print(\"Problems Detected - Your output has more lines than expected.\\\\n\")\\n    else:\\n        print(\"Problems Detected - Your output is missing one or more expected outputs.\\\\n\")\\n\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    run_test(round(random.uniform(0, 899), 1))\\n    run_test(850)\\n    run_test(round(random.uniform(851, 1849), 1))\\n    run_test(1850)\\n    run_test(round(random.uniform(1851, 1999), 1))\\n    run_test(2000)\\n    run_test(round(random.uniform(2001, 2749), 1))\\n    run_test(2750)\\n    run_test(round(random.uniform(2751, 7999), 1))\\n    run_test(7000)\\n    run_test(7001)\\n    \\n    \\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\n\\n        \\n# Testbench (to run on outside of zyBooks)\\nif __name__ == \\'__main__\\':\\n    class Console:\\n        def write(self, txt):\\n            print(txt, end=\\'\\')\\n    \\n    test_passed()\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_6_digitalstorage': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n\\r\\ndef solution(num_images):\\r\\n    result = \"\"\\r\\n    \\r\\n    if num_images <= 116:\\r\\n        result += \"CD\\\\n\"\\r\\n\\r\\n    if num_images <= 780:\\r\\n        result += \"DVD\\\\n\"\\r\\n        \\r\\n    if num_images <= 2660:\\r\\n        result += \"USB Small\\\\n\"\\r\\n\\r\\n    if num_images <= 10600:\\r\\n        result += \"USB Large\\\\n\"\\r\\n\\r\\n    if num_images <= 42600:\\r\\n        result += \"Portable HDD\\\\n\"\\r\\n\\r\\n    if num_images > 42600:\\r\\n        result += \"Consider Cloud Storage\\\\n\"\\r\\n    \\r\\n    return result.strip().split(\\'\\\\n\\')\\r\\n\\r\\n\\r\\ndef run_test(num_images):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"------------------------------\")\\r\\n    print(\"Test\", num_tests_run, \"-\", num_images, \"images\")\\r\\n    print(\"------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_6_digitalstorage.py\", [num_images], True)\\r\\n    lines = output.strip().split(\"\\\\n\")\\r\\n    expected_answer = solution(num_images)\\r\\n    \\r\\n    count = 0\\r\\n    \\r\\n    for answer in expected_answer:\\r\\n        if answer in lines:\\r\\n            print(\"Expecting\", answer, \" . . . FOUND!\")\\r\\n            count += 1\\r\\n        else:\\r\\n            print(\"Expecting\", answer, \" . . . MISSING!\")\\r\\n            \\r\\n    if count == len(expected_answer) and len(expected_answer) == len(lines):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    elif len(expected_answer) < len(lines):\\r\\n        print(\"Problems Detected - Your output has more lines than expected.\\\\n\")\\r\\n    else:\\r\\n        print(\"Problems Detected - Your output is missing one or more expected outputs.\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(int(random.uniform(0, 115)))\\r\\n    run_test(116)\\r\\n    run_test(int(random.uniform(117, 779)))\\r\\n    run_test(780)\\r\\n    run_test(int(random.uniform(781, 2659)))\\r\\n    run_test(2660)\\r\\n    run_test(int(random.uniform(2661, 10599)))\\r\\n    run_test(10600)\\r\\n    run_test(int(random.uniform(10601, 42599)))\\r\\n    run_test(42600)\\r\\n    run_test(45000)\\r\\n    \\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\nif __name__ == \\'__main__\\':\\r\\n    class Console:\\r\\n        def write(self, txt):\\r\\n            print(txt, end=\\'\\')\\r\\n    \\r\\n    test_passed()\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_6_broadband': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\n\\r\\ndef solution(speed):\\r\\n    result = \"\"\\r\\n    \\r\\n    if speed >= 1000:\\r\\n        result += \"Social Media\\\\n\"\\r\\n\\r\\n    if speed >= 4000:\\r\\n        result += \"Gaming\\\\n\"\\r\\n        \\r\\n    if speed >= 6000:\\r\\n        result += \"Video Conferencing\\\\n\"\\r\\n\\r\\n    if speed >= 10000:\\r\\n        result += \"File Downloads\\\\n\"\\r\\n\\r\\n    if speed >= 25000:\\r\\n        result += \"HD 4K Video\\\\n\"\\r\\n\\r\\n    if speed < 1000:\\r\\n        result += \"Upgrade to Broadband\\\\n\"\\r\\n    \\r\\n    return result.strip().split(\\'\\\\n\\')\\r\\n\\r\\n\\r\\ndef run_test(speed):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"------------------------------\")\\r\\n    print(\"Test\", num_tests_run, \"-\", speed, \"Kbps\")\\r\\n    print(\"------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_6_broadband.py\", [speed], True)\\r\\n    lines = output.strip().split(\"\\\\n\")\\r\\n    expected_answer = solution(speed)\\r\\n    \\r\\n    count = 0\\r\\n    \\r\\n    for answer in expected_answer:\\r\\n        if answer in lines:\\r\\n            print(\"Expecting\", answer, \" . . . FOUND!\")\\r\\n            count += 1\\r\\n        else:\\r\\n            print(\"Expecting\", answer, \" . . . MISSING!\")\\r\\n            \\r\\n    if count == len(expected_answer) and len(expected_answer) == len(lines):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    elif len(expected_answer) < len(lines):\\r\\n        print(\"Problems Detected - Your output has more lines than expected.\\\\n\")\\r\\n    else:\\r\\n        print(\"Problems Detected - Your output is missing one or more expected outputs.\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(0, 999), 1))\\r\\n    run_test(1000)\\r\\n    run_test(round(random.uniform(1001, 4999), 1))\\r\\n    run_test(4000)\\r\\n    run_test(round(random.uniform(4001, 5999), 1))\\r\\n    run_test(6000)\\r\\n    run_test(round(random.uniform(6001, 9999), 1))\\r\\n    run_test(10000)\\r\\n    run_test(round(random.uniform(10001, 24999), 1))\\r\\n    run_test(25000)\\r\\n    run_test(30000)\\r\\n    \\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\nif __name__ == \\'__main__\\':\\r\\n    class Console:\\r\\n        def write(self, txt):\\r\\n            print(txt, end=\\'\\')\\r\\n    \\r\\n    test_passed()\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_5_scuba': 'from cs110 import autograder\\nimport random, math\\n\\nnum_tests_passed = 0\\nnum_tests_run = 0\\n\\ndef run_test(target_minutes, budget):\\n    global num_tests_run, num_tests_passed\\n        \\n    num_tests_run += 1\\n    \\n    print(\"----------------------------------\")\\n    print(\"Test #\" + str(num_tests_run))\\n    print(\"----------------------------------\")\\n    \\n    \\n    total_liters = target_minutes*14.5\\n    total_cost = total_liters*.02\\n        \\n    if total_cost > budget:\\n        expected_output = \"Over Budget\"\\n    else:\\n        expected_output = \"Within Budget\"\\n    \\n    output, error_message = autograder.run_script(\"a1_5_scuba.py\", [target_minutes, budget])\\n    \\n    lines = output.split(\"\\\\n\")\\n    \\n    # Length of Materials\\n    if len(lines) >= 1 and autograder.equals(lines[0], total_liters):\\n        print(\"Amount of Air Looks Good!\")\\n        num_tests_passed += 0.33\\n    else:\\n        print(\"Incorrect Amount. Expected:\", total_liters)\\n\\n    # Cost of Materials\\n    if len(lines) >= 2 and autograder.equals(lines[1], total_cost):\\n        print(\"Cost of Air Looks Good!\")\\n        num_tests_passed += 0.33\\n    else:\\n        print(\"Incorrect Cost. Expected:\", total_cost)\\n        \\n    # Cost Analysis\\n    if len(lines) >= 3 and lines[2].strip() == expected_output:\\n        print(\"Correct Budget Analysis\\\\n\")\\n        num_tests_passed += 0.34\\n    else:\\n        print(\"Incorrect Budget Analysis. Expected:\", expected_output, \"\\\\n\")\\n\\n    return round((num_tests_passed / num_tests_run) * 100.0, 1)\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n    for x in range(4):\\n        run_test(round(random.uniform(10,100), 1), random.randint(10, 50))\\n    run_test(round(random.uniform(10,100), 1), 0)\\n    \\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\n\\n        \\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_5_runway': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(runway_length, budget):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Test #\" + str(num_tests_run))\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    tons_of_concrete = 2.5 * runway_length\\r\\n    cost_of_materials = 75.50 * tons_of_concrete\\r\\n    if cost_of_materials > budget:\\r\\n        expected_output = \"Over Budget\"\\r\\n    else:\\r\\n        expected_output = \"Within Budget\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_5_runway.py\", [runway_length, budget])\\r\\n    \\r\\n    lines = output.split(\"\\\\n\")\\r\\n    \\r\\n    # Length of Materials\\r\\n    if len(lines) >= 1 and autograder.equals(lines[0], tons_of_concrete):\\r\\n        print(\"Amount of Concrete Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Amount. Expected:\", tons_of_concrete)\\r\\n\\r\\n    # Cost of Materials\\r\\n    if len(lines) >= 2 and autograder.equals(lines[1], cost_of_materials):\\r\\n        print(\"Cost of Materials Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Cost. Expected:\", cost_of_materials)\\r\\n        \\r\\n    # Cost Analysis\\r\\n    if len(lines) >= 3 and lines[2].strip() == expected_output:\\r\\n        print(\"Correct Budget Analysis\\\\n\")\\r\\n        num_tests_passed += 0.34\\r\\n    else:\\r\\n        print(\"Incorrect Budget Analysis. Expected:\", expected_output, \"\\\\n\")\\r\\n\\r\\n    return round((num_tests_passed / num_tests_run) * 100.0, 1)\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(500, 3000), 1), random.randint(100000, 500000))\\r\\n    run_test(round(random.uniform(500, 3000), 1), 0)\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_5_printer': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(volume, budget):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Test #\" + str(num_tests_run))\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    length_of_materials = 0.312 * volume\\r\\n    cost_of_materials = 0.063 * length_of_materials\\r\\n    if cost_of_materials > budget:\\r\\n        expected_output = \"Over Budget\"\\r\\n    else:\\r\\n        expected_output = \"Within Budget\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_5_printer.py\", [volume, budget])\\r\\n    \\r\\n    lines = output.split(\"\\\\n\")\\r\\n    \\r\\n    # Length of Materials\\r\\n    if len(lines) >= 1 and autograder.equals(lines[0], length_of_materials):\\r\\n        print(\"Length of Materials Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Length. Expected:\", length_of_materials)\\r\\n\\r\\n    # Cost of Materials\\r\\n    if len(lines) >= 2 and autograder.equals(lines[1], cost_of_materials):\\r\\n        print(\"Cost of Materials Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Cost. Expected:\", cost_of_materials)\\r\\n        \\r\\n    # Cost Analysis\\r\\n    if len(lines) >= 3 and lines[2].strip() == expected_output:\\r\\n        print(\"Correct Budget Analysis\\\\n\")\\r\\n        num_tests_passed += 0.34\\r\\n    else:\\r\\n        print(\"Incorrect Budget Analysis. Expected:\", expected_output, \"\\\\n\")\\r\\n\\r\\n    return round((num_tests_passed / num_tests_run) * 100.0, 1)\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(0, 100), 1), random.randint(10, 50))\\r\\n    run_test(round(random.uniform(0, 100), 1), 0)\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_5_paint': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(target_distance, budget):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Test #\" + str(num_tests_run))\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    fuel_required = target_distance / 15\\r\\n    cost_of_materials = 12.23 * fuel_required\\r\\n    \\r\\n    if cost_of_materials > budget:\\r\\n        expected_output = \"Over Budget\"\\r\\n    else:\\r\\n        expected_output = \"Within Budget\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_5_paint.py\", [target_distance, budget])\\r\\n    \\r\\n    lines = output.split(\"\\\\n\")\\r\\n    \\r\\n    # Length of Materials\\r\\n    if len(lines) >= 1 and autograder.equals(lines[0], fuel_required):\\r\\n        print(\"Amount of Paint Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Amount of Paint. Expected:\", fuel_required)\\r\\n\\r\\n    # Cost of Materials\\r\\n    if len(lines) >= 2 and autograder.equals(lines[1], cost_of_materials):\\r\\n        print(\"Cost of Paint Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Cost of Paint. Expected:\", cost_of_materials)\\r\\n        \\r\\n    # Cost Analysis\\r\\n    if len(lines) >= 3 and lines[2].strip() == expected_output:\\r\\n        print(\"Correct Budget Analysis\\\\n\")\\r\\n        num_tests_passed += 0.34\\r\\n    else:\\r\\n        print(\"Incorrect Budget Analysis. Expected:\", expected_output, \"\\\\n\")\\r\\n\\r\\n    return round((num_tests_passed / num_tests_run) * 100.0, 1)\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(500, 3000), 1), random.randint(100000, 500000))\\r\\n    run_test(round(random.uniform(500, 3000), 1), 0)\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_5_fueldepot': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(target_distance, budget):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Test #\" + str(num_tests_run))\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    fuel_required = target_distance / 12.5\\r\\n    cost_of_materials = 3.73 * fuel_required\\r\\n    \\r\\n    if cost_of_materials > budget:\\r\\n        expected_output = \"Over Budget\"\\r\\n    else:\\r\\n        expected_output = \"Within Budget\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_5_fueldepot.py\", [target_distance, budget])\\r\\n    \\r\\n    lines = output.split(\"\\\\n\")\\r\\n    \\r\\n    # Length of Materials\\r\\n    if len(lines) >= 1 and autograder.equals(lines[0], fuel_required):\\r\\n        print(\"Amount of Fuel Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Amount. Expected:\", fuel_required)\\r\\n\\r\\n    # Cost of Materials\\r\\n    if len(lines) >= 2 and autograder.equals(lines[1], cost_of_materials):\\r\\n        print(\"Cost of Materials Looks Good!\")\\r\\n        num_tests_passed += 0.33\\r\\n    else:\\r\\n        print(\"Incorrect Cost. Expected:\", cost_of_materials)\\r\\n        \\r\\n    # Cost Analysis\\r\\n    if len(lines) >= 3 and lines[2].strip() == expected_output:\\r\\n        print(\"Correct Budget Analysis\\\\n\")\\r\\n        num_tests_passed += 0.34\\r\\n    else:\\r\\n        print(\"Incorrect Budget Analysis. Expected:\", expected_output, \"\\\\n\")\\r\\n\\r\\n    return round((num_tests_passed / num_tests_run) * 100.0, 1)\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(500, 3000), 1), random.randint(100000, 500000))\\r\\n    run_test(round(random.uniform(500, 3000), 1), 0)\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_4_sickness': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(temperature, body_aches, loss_of_smell, expected_output):\\r\\n    output, error = autograder.run_script(\"a1_4_sickness.py\", [temperature, body_aches, loss_of_smell])\\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) >= 4:\\r\\n        if lines[3] == expected_output:\\r\\n            print(\"Correct Output\\\\n\")\\r\\n            return True\\r\\n        else:\\r\\n            print(\"Incorrect Output.  Expected\", expected_output, \\'\\\\n\\')\\r\\n            return False\\r\\n    else:\\r\\n        print(\"No Output Found\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    num_tests_passed = 0\\r\\n    \\r\\n    testcase_library = [(round(random.uniform(98.0, 99.9), 1), \"yes\", \"no\", \"Low Risk\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"yes\", \"yes\", \"High Risk\"),\\r\\n                        (round(random.uniform(98.0, 99.9), 1), \"yes\", \"yes\", \"High Risk\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"no\", \"no\", \"High Risk\")]\\r\\n    \\r\\n    for i in range(len(testcase_library)):\\r\\n        print(\"-------------------\")\\r\\n        print(\"Test\", i+1, \"of\", len(testcase_library))\\r\\n        print(\"-------------------\")\\r\\n        if run_test(testcase_library[i][0], testcase_library[i][1], testcase_library[i][2], testcase_library[i][3]):\\r\\n            num_tests_passed += 1\\r\\n    \\r\\n    return round(100 / len(testcase_library) * num_tests_passed, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_4_run': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(temperature, daytime, raining, expected_output):\\r\\n    output, error = autograder.run_script(\"a1_4_run.py\", [temperature, daytime, raining])\\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) >= 4:\\r\\n        if lines[3] == expected_output:\\r\\n            print(\"Correct Output\\\\n\")\\r\\n            return True\\r\\n        else:\\r\\n            print(\"Incorrect Output.  Expected\", expected_output, \\'\\\\n\\')\\r\\n            return False\\r\\n    else:\\r\\n        print(\"No Output Found\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    num_tests_passed = 0\\r\\n    \\r\\n    testcase_library = [(round(random.uniform(93.0, 94.9), 1), \"yes\", \"no\", \"Go Run\"),\\r\\n                        (round(random.uniform(93.0, 94.9), 1), \"no\", \"yes\", \"Do Not Run\"),\\r\\n                        (round(random.uniform(93.0, 94.9), 1), \"no\", \"no\", \"Do Not Run\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"no\", \"yes\", \"Do Not Run\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"yes\", \"yes\", \"Do Not Run\"),\\r\\n                        (95.0, \"yes\", \"no\", \"Go Run\")]\\r\\n    \\r\\n    for i in range(len(testcase_library)):\\r\\n        print(\"-------------------\")\\r\\n        print(\"Test\", i+1, \"of\", len(testcase_library))\\r\\n        print(\"-------------------\")\\r\\n        if run_test(testcase_library[i][0], testcase_library[i][1], testcase_library[i][2], testcase_library[i][3]):\\r\\n            num_tests_passed += 1\\r\\n    \\r\\n    return round(100 / len(testcase_library) * num_tests_passed, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_4_pt': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(temperature, raining, winds, expected_output):\\r\\n    output, error = autograder.run_script(\"a1_4_pt.py\", [temperature, raining, winds])\\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) >= 4:\\r\\n        if lines[3] == expected_output:\\r\\n            print(\"Correct Output\\\\n\")\\r\\n            return True\\r\\n        else:\\r\\n            print(\"Incorrect Output.  Expected\", expected_output, \\'\\\\n\\')\\r\\n            return False\\r\\n    else:\\r\\n        print(\"No Output Found\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    num_tests_passed = 0\\r\\n    \\r\\n    testcase_library = [(round(random.uniform(72.0, 90), 1), \"no\", \"no\", \"PT is a Go\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"yes\", \"yes\", \"PT Cancelled\"),\\r\\n                        (round(random.uniform(72.0, 90), 1), \"yes\", \"no\", \"PT is a Go\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"no\", \"no\", \"PT Cancelled\"),\\r\\n                        (round(random.uniform(72.0, 90), 1), \"yes\", \"yes\", \"PT Cancelled\")]\\r\\n    \\r\\n    for i in range(len(testcase_library)):\\r\\n        print(\"-------------------\")\\r\\n        print(\"Test\", i+1, \"of\", len(testcase_library))\\r\\n        print(\"-------------------\")\\r\\n        if run_test(testcase_library[i][0], testcase_library[i][1], testcase_library[i][2], testcase_library[i][3]):\\r\\n            num_tests_passed += 1\\r\\n    \\r\\n    return round(100 / len(testcase_library) * num_tests_passed, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_4_dog': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef run_test(temperature, raining, daytime, expected_output):\\r\\n    output, error = autograder.run_script(\"a1_4_dog.py\", [temperature, raining, daytime])\\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) >= 4:\\r\\n        if lines[3] == expected_output:\\r\\n            print(\"Correct Output\\\\n\")\\r\\n            return True\\r\\n        else:\\r\\n            print(\"Incorrect Output.  Expected\", expected_output, \\'\\\\n\\')\\r\\n            return False\\r\\n    else:\\r\\n        print(\"No Output Found\\\\n\")\\r\\n        return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    num_tests_passed = 0\\r\\n    \\r\\n    testcase_library = [(round(random.uniform(83.0, 84.9), 1), \"no\", \"yes\", \"Dog Outside\"),\\r\\n                        (round(random.uniform(83.0, 84.9), 1), \"yes\", \"no\", \"Dog Inside\"),\\r\\n                        (round(random.uniform(83.0, 84.9), 1), \"no\", \"no\", \"Dog Outside\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"no\", \"yes\", \"Dog Inside\"),\\r\\n                        (round(random.uniform(100.5, 102.0), 1), \"yes\", \"yes\", \"Dog Inside\"),\\r\\n                        (85.0, \"yes\", \"yes\", \"Dog Outside\")]\\r\\n    \\r\\n    for i in range(len(testcase_library)):\\r\\n        print(\"-------------------\")\\r\\n        print(\"Test\", i+1, \"of\", len(testcase_library))\\r\\n        print(\"-------------------\")\\r\\n        if run_test(testcase_library[i][0], testcase_library[i][1], testcase_library[i][2], testcase_library[i][3]):\\r\\n            num_tests_passed += 1\\r\\n    \\r\\n    return round(100 / len(testcase_library) * num_tests_passed, 1)\\r\\n    \\r\\n    \\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'a1_3_vspeed': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(speed):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Testing speed =\", speed, \"MPH\")\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    if speed > 65:\\r\\n        solution = \"Too fast, slow down!\"\\r\\n    elif speed == 65:\\r\\n        solution = \"Maintain Speed\"\\r\\n    else:\\r\\n        solution = \"Too slow, speed up!\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_3_vspeed.py\", [speed])\\r\\n    \\r\\n    if output.strip() == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(66, 150), 1))\\r\\n    run_test(65)\\r\\n    run_test(round(random.uniform(0.0, 64), 1))\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_3_speed': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(speed):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Testing speed =\", speed, \"MPH\")\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    if speed > 767.269:\\r\\n        solution = \"Faster than Mach 1\"\\r\\n    elif speed == 767.269:\\r\\n        solution = \"Mach 1\"\\r\\n    else:\\r\\n        solution = \"Slower than Mach 1\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_3_speed.py\", [speed])\\r\\n    \\r\\n    if output.strip() == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(768.0, 1000.0), 1))\\r\\n    run_test(767.269)\\r\\n    run_test(round(random.uniform(0.0, 767.0), 1))\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_3_satellite': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(speed):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Testing speed =\", speed, \"km/s\")\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    if speed > 7.8:\\r\\n        solution = \"Lost to Space\"\\r\\n    elif speed == 7.8:\\r\\n        solution = \"In Orbit\"\\r\\n    else:\\r\\n        solution = \"Crashed to Earth\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_3_satellite.py\", [speed])\\r\\n    \\r\\n    if output.strip() == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(7.8, 20), 1))\\r\\n    run_test(7.8)\\r\\n    run_test(round(random.uniform(0.0, 7.7), 1))\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_3_goldilocks': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(temp):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Testing temperature =\", temp, \"degrees\")\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    if temp > 105:\\r\\n        solution = \"Too Hot\"\\r\\n    elif temp == 105:\\r\\n        solution = \"Just Right\"\\r\\n    else:\\r\\n        solution = \"Too Cold\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_3_goldilocks.py\", [temp])\\r\\n    \\r\\n    if output.strip() == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(106, 130), 1))\\r\\n    run_test(105)\\r\\n    run_test(round(random.uniform(80, 104), 1))\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_3_cards': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(num_cards):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Testing number of cards =\", num_cards, \"cards\")\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    if num_cards > 52:\\r\\n        solution = \"Too many cards\"\\r\\n    elif num_cards == 52:\\r\\n        solution = \"Full deck\"\\r\\n    else:\\r\\n        solution = \"Not enough cards\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_3_cards.py\", [num_cards])\\r\\n    \\r\\n    if output.strip() == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(53, 60)))\\r\\n    run_test(52)\\r\\n    run_test(round(random.uniform(0, 51)))\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_3_arrow': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test(height):\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    print(\"----------------------------------\")\\r\\n    print(\"Testing height =\", height, \"feet\")\\r\\n    print(\"----------------------------------\")\\r\\n    \\r\\n    if height > 6.2:\\r\\n        solution = \"Arrow too high\"\\r\\n    elif height == 6.2:\\r\\n        solution = \"Direct hit\"\\r\\n    else:\\r\\n        solution = \"Arrow too low\"\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"a1_3_arrow.py\", [height])\\r\\n    \\r\\n    if output.strip() == solution:\\r\\n        print(\"CORRECT!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(round(random.uniform(6.2, 20), 1))\\r\\n    run_test(6.2)\\r\\n    run_test(round(random.uniform(0.0, 6.1), 1))\\r\\n    \\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_2_spheres': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nfrom a1_2_spheres import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    answer = math.pi * (4/3) * (radius**3)*total\\r\\n    file = open(\"a1_2_spheres.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    print(\"Checking to see if variable \\'volume\\' exists . . . \", end=\\'\\')\\r\\n    if \\'volume\\' in globals():\\r\\n        print(\"FOUND!\")\\r\\n        score += 10\\r\\n        \\r\\n        print(\"Checking mathematical formula . . . \", end=\\'\\')\\r\\n        if \\'*\\' in file_contents and \\'math.pi\\' in file_contents and (\\'**\\' in file_contents or \\'math.pow\\' in file_contents or \\'pow\\' in file_contents):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 60\\r\\n        else:\\r\\n            print(\"NOT FOUND. Make sure you are using the formula.\")\\r\\n        \\r\\n        print(\"Checking the value of \\'volume\\' . . . \", end=\\'\\')\\r\\n        if \\'volume\\' in globals() and autograder.equals(volume, answer):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 30\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n    else:\\r\\n        print(\"NOT FOUND. Make sure you name your variable according to the prompt.\")\\r\\n      \\r\\n    return score\\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_2_radius': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nfrom a1_2_radius import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    answer = math.pi * (radius**2) * height * total\\r\\n    file = open(\"a1_2_radius.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    print(\"Checking to see areif variable \\'volume\\' exists . . . \", end=\\'\\')\\r\\n    if \\'volume\\' in globals():\\r\\n        print(\"FOUND!\")\\r\\n        score += 10\\r\\n        \\r\\n        print(\"Checking mathematical formula . . . \", end=\\'\\')\\r\\n        if \\'*\\' in file_contents and \\'math.pi\\' in file_contents and (\\'**\\' in file_contents or \\'math.pow\\' in file_contents or \\'pow\\' in file_contents):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 60\\r\\n        else:\\r\\n            print(\"NOT FOUND. Make sure you are using the formula.\")\\r\\n        \\r\\n        print(\"Checking the value of \\'volume\\' . . . \", end=\\'\\')\\r\\n        if \\'volume\\' in globals() and autograder.equals(volume, answer):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 30\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n    else:\\r\\n        print(\"NOT FOUND. Make sure you name your variable according to the prompt.\")\\r\\n      \\r\\n    return score\\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_2_interest': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nfrom a1_2_interest import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    answer = principal_amount * math.e**(interest_rate * time)\\r\\n    file = open(\"a1_2_interest.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    print(\"Checking to see if variable \\'amount\\' exists . . . \", end=\\'\\')\\r\\n    if \\'amount\\' in globals():\\r\\n        print(\"FOUND!\")\\r\\n        score += 10\\r\\n        \\r\\n        print(\"Checking mathematical formula . . . \", end=\\'\\')\\r\\n        if \\'*\\' in file_contents and \\'math.e\\' in file_contents and (\\'**\\' in file_contents or \\'math.pow\\' in file_contents or \\'pow\\' in file_contents):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 60\\r\\n        else:\\r\\n            print(\"NOT FOUND. Make sure you are using the formula.\")\\r\\n        \\r\\n        print(\"Checking the value of \\'amount\\' . . . \", end=\\'\\')\\r\\n        if \\'amount\\' in globals() and autograder.equals(amount, answer):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 30\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n    else:\\r\\n        print(\"NOT FOUND. Make sure you name your variable according to the prompt.\")\\r\\n      \\r\\n    return score\\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_2_cones': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nfrom a1_2_cones import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    answer = math.pi * (radius**2) * (height/3) * total\\r\\n    file = open(\"a1_2_cones.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    print(\"Checking to see if variable \\'volume\\' exists . . . \", end=\\'\\')\\r\\n    if \\'volume\\' in globals():\\r\\n        print(\"FOUND!\")\\r\\n        score += 10\\r\\n        \\r\\n        print(\"Checking mathematical formula . . . \", end=\\'\\')\\r\\n        if \\'*\\' in file_contents and \\'math.pi\\' in file_contents and (\\'**\\' in file_contents or \\'math.pow\\' in file_contents or \\'pow\\' in file_contents):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 60\\r\\n        else:\\r\\n            print(\"NOT FOUND. Make sure you are using the formula.\")\\r\\n        \\r\\n        print(\"Checking the value of \\'volume\\' . . . \", end=\\'\\')\\r\\n        if \\'volume\\' in globals() and autograder.equals(volume, answer):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 30\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n    else:\\r\\n        print(\"NOT FOUND. Make sure you name your variable according to the prompt.\")\\r\\n      \\r\\n    return score\\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a1_2_circles': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nfrom a1_2_circles import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    answer = math.pi * (radius**2)*total\\r\\n    file = open(\"a1_2_circles.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    print(\"Checking to see if variable \\'area\\' exists . . . \", end=\\'\\')\\r\\n    if \\'area\\' in globals():\\r\\n        print(\"FOUND!\")\\r\\n        score += 10\\r\\n        \\r\\n        print(\"Checking mathematical formula . . . \", end=\\'\\')\\r\\n        if \\'*\\' in file_contents and \\'math.pi\\' in file_contents and (\\'**\\' in file_contents or \\'math.pow\\' in file_contents or \\'pow\\' in file_contents):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 60\\r\\n        else:\\r\\n            print(\"NOT FOUND. Make sure you are using the formula.\")\\r\\n        \\r\\n        print(\"Checking the value of \\'area\\' . . . \", end=\\'\\')\\r\\n        if \\'area\\' in globals() and autograder.equals(area, answer):\\r\\n            print(\"CORRECT!\")\\r\\n            score += 30\\r\\n        else:\\r\\n            print(\"INCORRECT\")\\r\\n    else:\\r\\n        print(\"NOT FOUND. Make sure you name your variable according to the prompt.\")\\r\\n      \\r\\n    return score\\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'a1_1_cadet': '#import cs110,\\r\\nimport random, math\\r\\nfrom cs110 import autograder\\r\\nnum_tests_passed = 0\\r\\nnum_tests_run = 0\\r\\n\\r\\ndef run_test():\\r\\n    global num_tests_run, num_tests_passed\\r\\n        \\r\\n    num_tests_run += 1\\r\\n    \\r\\n    cadet_list = [(\"Snuffy\", 2.1, 185), (\"Smith\", 1.9, 205), (\"Green\", 2.0, 155)]\\r\\n    cadet = cadet_list[random.randint(0, len(cadet_list) - 1)]\\r\\n    solution = \"Cadet %s is %1.1f meters tall and weighs %d lbs.\" % (cadet[0], cadet[1], cadet[2])\\r\\n        \\r\\n    output, error_message = autograder.run_script(\"a1_1_cadet.py\", [cadet[0], cadet[1], cadet[2]])\\r\\n        \\r\\n    if output.strip() == solution:\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT. Expected:\", solution)\\r\\n        print(\"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test()\\r\\n    return round(num_tests_passed * (100 / num_tests_run), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'CS110_Ingenuity_Simulator_Spiral_1': 'from cs110 import autograder\\nimport random, math\\n\\n# ---------------------------------------------------------------------\\n# Sample Unit Test\\n# ---------------------------------------------------------------------\\n\\n# OPTIONAL: Custom Behavior Flags\\n# Used by the Autograder to Customize its Runtime Behavior\\n__flags__ = {\"audit\":True,\\n             \"show_input\":True,\\n             \"show_output\":True,\\n             \"show_error\":True,\\n             \"show_feedback\":True,\\n             \"show_score\":True}\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n\\n    print(\"Ran test\")\\n        \\n    return 100.0\\n        \\n\\n# ---------------------------------------------------------------------\\n# Optional\\n# Runs your code in an IDE (for testing purposes)\\n# ---------------------------------------------------------------------\\nif __name__ == \\'__main__\\':\\n    # Deprecated:  Just calls test_passed() directly\\n    # Flags will not be processed this way\\n    #points_earned = test_passed()\\n    \\n    # New Way to Run Testcases (if you have flags)\\n    autograder.run_testcases(test_passed, {}, __flags__, False)\\n    \\n    # Alternative Way to Run Testcases (if you just want to use the default flags)\\n    #autograder.run_testcases(test_passed, {}, {}, False)',\n",
       "  'CS110_Ingenuity_Simulator_Spiral_2': 'from cs110 import autograder\\nimport random, math\\n\\n# ---------------------------------------------------------------------\\n# Sample Unit Test\\n# ---------------------------------------------------------------------\\n\\n# OPTIONAL: Custom Behavior Flags\\n# Used by the Autograder to Customize its Runtime Behavior\\n__flags__ = {\"audit\":True,\\n             \"show_input\":True,\\n             \"show_output\":True,\\n             \"show_error\":True,\\n             \"show_feedback\":True,\\n             \"show_score\":True}\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n\\n    print(\"Ran test\")\\n        \\n    return 100.0\\n        \\n\\n# ---------------------------------------------------------------------\\n# Optional\\n# Runs your code in an IDE (for testing purposes)\\n# ---------------------------------------------------------------------\\nif __name__ == \\'__main__\\':\\n    # Deprecated:  Just calls test_passed() directly\\n    # Flags will not be processed this way\\n    #points_earned = test_passed()\\n    \\n    # New Way to Run Testcases (if you have flags)\\n    autograder.run_testcases(test_passed, {}, __flags__, False)\\n    \\n    # Alternative Way to Run Testcases (if you just want to use the default flags)\\n    #autograder.run_testcases(test_passed, {}, {}, False)',\n",
       "  'CS110_Ingenuity_Simulator_Spiral_3': 'from cs110 import autograder\\nimport random, math\\n\\n# ---------------------------------------------------------------------\\n# Sample Unit Test\\n# ---------------------------------------------------------------------\\n\\n# OPTIONAL: Custom Behavior Flags\\n# Used by the Autograder to Customize its Runtime Behavior\\n__flags__ = {\"audit\":True,\\n             \"show_input\":True,\\n             \"show_output\":True,\\n             \"show_error\":True,\\n             \"show_feedback\":True,\\n             \"show_score\":True}\\n\\n# Runs the Python script and sees if it passes the test(s)\\ndef test_passed():\\n\\n    print(\"Ran test\")\\n        \\n    return 100.0\\n        \\n\\n# ---------------------------------------------------------------------\\n# Optional\\n# Runs your code in an IDE (for testing purposes)\\n# ---------------------------------------------------------------------\\nif __name__ == \\'__main__\\':\\n    # Deprecated:  Just calls test_passed() directly\\n    # Flags will not be processed this way\\n    #points_earned = test_passed()\\n    \\n    # New Way to Run Testcases (if you have flags)\\n    autograder.run_testcases(test_passed, {}, __flags__, False)\\n    \\n    # Alternative Way to Run Testcases (if you just want to use the default flags)\\n    #autograder.run_testcases(test_passed, {}, {}, False)',\n",
       "  'PA2_practice4': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n\\r\\n    num_tests_passed = 0\\r\\n    test_cases = [(\"Regular\", 37, 2.938), (\"Midgrade\", 37, 3.098), (\"Premium\", 37, 3.208), (\"Diesel\", 32, 3.242)]\\r\\n\\r\\n    for test_case in test_cases:\\r\\n        print(\"# -----------------------------------\")\\r\\n        print(\"# Testing\", test_case[0])\\r\\n        print(\"# -----------------------------------\")\\r\\n        output, error = autograder.run_script(\"PA2_practice4.py\", [test_case[0]])\\r\\n    \\r\\n        lines = output.strip().split(\\'\\\\n\\')\\r\\n        \\r\\n        if len(lines) > 0:\\r\\n            if autograder.equals(lines[0], test_case[2]):\\r\\n                print(\"CORRECT\")\\r\\n                num_tests_passed += 1\\r\\n            elif len(lines) > 1 and autograder.equals(lines[0], test_case[1]) and autograder.equals(lines[1], test_case[2]):\\r\\n                print(\"CORRECT\")\\r\\n                num_tests_passed += 1\\r\\n            else:\\r\\n                print(\"INCORRECT\")\\r\\n            print()\\r\\n                    \\r\\n    return round(100 / len(test_cases), 1) * num_tests_passed\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'PA2_practice3': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(weights, heights):\\r\\n    num_thin = 0\\r\\n    num_healthy = 0\\r\\n    num_overweight = 0\\r\\n    num_obese = 0\\r\\n    \\r\\n    for i in range(len(weights)):\\r\\n        bmi = 703 * (weights[i] / heights[i]**2)\\r\\n\\r\\n        if bmi <= 18.5:\\r\\n            num_thin += 1\\r\\n        elif bmi <= 25:\\r\\n            num_healthy += 1\\r\\n        elif bmi <= 30:\\r\\n            num_overweight += 1\\r\\n        else:\\r\\n            num_obese += 1\\r\\n    \\r\\n    return (num_thin, num_healthy, num_overweight, num_obese)\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n\\r\\n    score = 0\\r\\n\\r\\n    # Generates the Test Set\\r\\n    num_students = random.randint(5, 10)\\r\\n    inputs = [num_students]\\r\\n    weights = []\\r\\n    heights = []\\r\\n    \\r\\n    for i in range(num_students):\\r\\n        random_weight = random.randint(120, 200)\\r\\n        random_height = random.randint(55, 76)\\r\\n        \\r\\n        weights.append(random_weight)\\r\\n        heights.append(random_height)\\r\\n        \\r\\n        inputs.append(random_weight)\\r\\n        inputs.append(random_height)\\r\\n    \\r\\n    output, error = autograder.run_script(\"PA2_practice3.py\", inputs)\\r\\n    expected_output = solution(weights, heights)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Thin is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Thin is Incorrect.  Expected\", expected_output[0])\\r\\n\\r\\n    if len(lines) > 1 and autograder.equals(lines[1], expected_output[1]):\\r\\n        print(\"Healthy is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Healthy is Incorrect.  Expected\", expected_output[1])\\r\\n    \\r\\n    if len(lines) > 2 and autograder.equals(lines[2], expected_output[2]):\\r\\n        print(\"Overweight is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Overweight is Incorrect.  Expected\", expected_output[2])\\r\\n    \\r\\n    if len(lines) > 3 and autograder.equals(lines[3], expected_output[3]):\\r\\n        print(\"Obese is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Obese is Incorrect.  Expected\", expected_output[0])\\r\\n        \\r\\n    return score\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'PA2_practice2': 'from cs110 import autograder\\r\\nimport random, math, traceback\\r\\n\\r\\nsolution_filename = \"PA2_practice2.py\"\\r\\n\\r\\ndef test_passed():\\r\\n    test_cases_prev = dict()\\r\\n    test_cases_prev[1] = (3,5,7,9,11,13)\\r\\n    test_cases_prev[100] = (201,203,205,207,209,211)\\r\\n    test_cases_prev[1000] = (2001,2003,2005,2007,2009,2011)\\r\\n    test_cases_prev[42] = (85,87,89,91,93,95)    \\r\\n    test_cases_prev[87] = (175,177,179,181,183,185)\\r\\n\\r\\n    # test_cases[input] = (expected_result_1, \"expected_result_2\")\\r\\n    \\r\\n    test_cases = dict()\\r\\n    test_cases[1] = (1,2,3,4,5,6)\\r\\n    test_cases[100] = (100,101,102,103,104,105)\\r\\n    test_cases[1000] = (1000,1001,1002,1003,1004,1005)\\r\\n    test_cases[42] = (42,43,44,45,46,47)\\r\\n    test_cases[87] = (87,88,89,90,91,92)\\r\\n\\r\\n    \\r\\n    # shuffle the possible inputs    \\r\\n    test_case_input = list(test_cases.keys())\\r\\n    case_order = list(range(len(test_case_input)))\\r\\n    random.shuffle(case_order)\\r\\n    \\r\\n    # choose 5 of the randomly sorted \\r\\n    case_indices_used = case_order[:5]\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    test_run_num = 1\\r\\n    for idx in case_indices_used:\\r\\n        print(\\'\\\\n\\' + \\'=\\'*30)\\r\\n        print(\" \"*10+\"Test Case #\" + str(test_run_num))\\r\\n        print(\\'=\\'*30)\\r\\n        \\r\\n        try:\\r\\n            output, error = autograder.run_script(solution_filename, [test_case_input[idx]])\\r\\n            \\r\\n            expected_output = \"\"\\r\\n            for num in test_cases[test_case_input[idx]]:\\r\\n                expected_output += str(num) + \"\\\\n\"\\r\\n            \\r\\n            expected_output_prev = \"\"\\r\\n            for num in test_cases_prev[test_case_input[idx]]:\\r\\n                expected_output_prev += str(num) + \"\\\\n\"\\r\\n            \\r\\n            lines = output.strip().split(\\'\\\\n\\')\\r\\n            \\r\\n            if output.strip() == expected_output.strip():\\r\\n                print(\"CORRECT\")\\r\\n                score += 100.0 / len(case_indices_used)\\r\\n            elif output.strip() == expected_output_prev.strip():\\r\\n                print(\"CORRECT\")\\r\\n                score += 100.0 / len(case_indices_used)\\r\\n            else:\\r\\n                print(\"INCORRECT. Expected:\")\\r\\n                expected_lines = expected_output.split(\"\\\\n\")\\r\\n                expected_prev_lines = expected_output_prev.split(\"\\\\n\")\\r\\n                for line_idx in range(len(expected_lines)):\\r\\n                    if line_idx == 2:\\r\\n                        center_col = \"     OR     \"\\r\\n                    else:\\r\\n                        center_col = \"            \"\\r\\n                    \\r\\n                    print(expected_prev_lines[line_idx].strip()) # + center_col + expected_prev_lines[line_idx].strip())\\r\\n\\r\\n        except Exception as e:\\r\\n            print(\"ERROR occured when running your solution!\")\\r\\n            print(e)\\r\\n            print(traceback.format_exc())\\r\\n            \\r\\n        test_run_num += 1        \\r\\n    \\r\\n#     random_value = random.randint(5, 15)\\r\\n#     output, error = autograder.run_script(\"PA2_practice2.py\", [random_value])\\r\\n#     expected_output = solution(random_value)\\r\\n#     \\r\\n#     if output.strip() == expected_output.strip():\\r\\n#         print(\"CORRECT\")\\r\\n#         return 100.0\\r\\n#     else:\\r\\n#         print(\"INCORRECT.  Expected:\")\\r\\n#         print(expected_output)\\r\\n    \\r\\n    return score\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'PA2_practice1': 'from cs110 import autograder\\r\\nimport PA2_practice1\\r\\n\\r\\ndef add_values(x, y, z):\\r\\n    return x + y + z\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    if \\'add_values\\' in dir(PA2_practice1) and add_values(1, 2, 3) == PA2_practice1.add_values(1, 2, 3):\\r\\n        print(\"PASSED\")\\r\\n        return 100.0\\r\\n    elif \\'add_values\\' not in dir(PA2_practice1):\\r\\n        print(\"FAILED.  Could not find function \\'add_values\\'\")\\r\\n    elif result != solution:\\r\\n        print(\"FAILED.  Function \\'add_values\\' did not return the correct value\")\\r\\n    else:\\r\\n        print(\"FAILED.  Something unexpected happened.\")\\r\\n    \\r\\n    return 0.0\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn9_triangle': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn9_triangle\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    base = round(random.uniform(1.0, 10.0), 1)\\r\\n    height = round(random.uniform(1.0, 10.0), 1)\\r\\n    output, error_message = autograder.run_script(\"lsn9_triangle.py\", [base, height])\\r\\n    \\r\\n    area = (base * height) / 2.0\\r\\n    score = 0\\r\\n    \\r\\n    if \"area_triangle\" in dir(lsn9_triangle):\\r\\n        print(\"Function Correctly Defined\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function does not exist.  Check to make sure the name matches the prompt\")\\r\\n    \\r\\n    if autograder.equals(output, area):\\r\\n        print(\"Function produces correct output\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function produces incorrect output. Expected:\", area)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn9_skill3': 'from cs110 import autograder\\r\\nimport random, math\\r\\nimport lsn9_skill3\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    output, error = autograder.run_script(\"lsn9_skill3.py\", [])\\r\\n    score = 0\\r\\n    \\r\\n    if \"print_hello\" in dir(lsn9_skill3):\\r\\n        print(\"Function found!\")\\r\\n        score += 50\\r\\n        \\r\\n        if len(output) > 0:\\r\\n            print(\"Output Found!\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"Function does not appear to be printing out anything\")\\r\\n    else:\\r\\n        print(\"Function does not appear to be defined.  Check the name and make sure it matches the prompt\")\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn9_skill2': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# The Actual Solution\\r\\ndef draw_tree(num_times):\\r\\n    result = \"\"\\r\\n    for i in range(num_times):\\r\\n        result += \"  *  \\\\n\"\\r\\n        result += \" *** \\\\n\"\\r\\n        result += \"*****\\\\n\"\\r\\n        result += \"  |  \\\\n\"\\r\\n    return result;\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    num_passed = 0\\r\\n    num_tests = 3\\r\\n    \\r\\n    for i in range(num_tests):\\r\\n        print(\"-------------------------------------------\")\\r\\n        print(\"Test\", i+1)\\r\\n        print(\"-------------------------------------------\")\\r\\n        num_trees = random.randint(0, 5)\\r\\n        output, error_message = autograder.run_script(\"lsn9_skill2.py\", [num_trees])\\r\\n        expected_output = draw_tree(num_trees)\\r\\n        \\r\\n        if output == expected_output:\\r\\n            print(\"Good Job!\\\\n\")\\r\\n            num_passed += 1\\r\\n        else:\\r\\n            print(\"Incorrect Output. Expected the following:\")\\r\\n            print(expected_output, \"\\\\n\")\\r\\n    \\r\\n    return round((100 / num_tests) * num_passed, 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn9_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# The Actual Solution\\r\\ndef draw_tree():\\r\\n    result =  \"  *  \\\\n\"\\r\\n    result += \" *** \\\\n\"\\r\\n    result += \"*****\\\\n\"\\r\\n    result += \"  |  \\\\n\"\\r\\n    return result;\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    output, error_message = autograder.run_script(\"lsn9_skill1.py\", [])\\r\\n    \\r\\n    expected_output = draw_tree() + draw_tree () + draw_tree()\\r\\n    \\r\\n    if output == expected_output:\\r\\n        print(\"Good Job!\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"Incorrect Output. Expected the following:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn9_imagesize': 'from cs110 import autograder\\r\\nimport lsn9_imagesize, random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    base = random.randint(1024, 1980)\\r\\n    height = random.randint(1024, 1980)\\r\\n    bd = 2**random.randint(3, 7)\\r\\n    output, error_message = autograder.run_script(\"lsn9_imagesize.py\", [base, height, bd])\\r\\n    \\r\\n    filesize = (base * height * bd) / 8 / 1024\\r\\n    score = 0\\r\\n    \\r\\n    if \"calculate_size_of_image\" in dir(lsn9_imagesize):\\r\\n        print(\"Function Correctly Defined\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function does not exist.  Check to make sure the name matches the prompt\")\\r\\n    \\r\\n    if autograder.equals(output, filesize):\\r\\n        print(\"Function produces correct output\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Function produces incorrect output. Expected:\", filesize)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn9_callme': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# This function takes a string and prints it backwards\\r\\ndef get_reverse(s):\\r\\n    result = \\'\\'\\r\\n    for i in range(len(s)-1, -1, -1):\\r\\n        result += s[i]\\r\\n    return result\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    base = round(random.uniform(1.0, 100.0), 1)\\r\\n    height = round(random.uniform(1.0, 100.0), 1)\\r\\n\\r\\n    string_list = [\\'abcde\\', \\'defgh\\', \\'xzy\\', \\'abba\\']\\r\\n    test_string = string_list[random.randint(0, len(string_list)-1)]\\r\\n\\r\\n    file = open(\"lsn9_callme.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    num_calls_area_rectangle = file_contents.count(\"area_rectangle\")\\r\\n    num_calls_print_backwards = file_contents.count(\"print_backwards\")\\r\\n    num_calls_positive = file_contents.count(\"positive_or_negative\")\\r\\n\\r\\n    output, error_message = autograder.run_script(\"lsn9_callme.py\", [base, height, test_string])\\r\\n    \\r\\n    area = (base * height)\\r\\n    score = 0\\r\\n    \\r\\n    lines = output.split(\"\\\\n\")\\r\\n    \\r\\n    if autograder.equals(lines[0], area) and num_calls_area_rectangle > 1:\\r\\n        print(\"area_rectangle called successfully\")\\r\\n        score += 33\\r\\n    else:\\r\\n        print(\"area_rectangle was not called successfully\")\\r\\n    \\r\\n    if len(lines) > 1 and lines[1].strip() == get_reverse(test_string) and num_calls_print_backwards > 1:\\r\\n        print(\"print_backwards called successfully\")\\r\\n        score += 33\\r\\n    else:\\r\\n        print(\"print_backwards was not called successfully\")\\r\\n    \\r\\n    if len(lines) > 2 and lines[2].strip() == \"Positive\" and num_calls_positive > 1:\\r\\n        print(\"positive_or_negative called successfully\")\\r\\n        score += 34\\r\\n    else:\\r\\n        print(\"positive_or_negative was not called successfully\")\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn7_triangle': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn7_triangle.py\", doraise=True)\\r\\n        print(\"----------------------------------------------------------------------\")\\r\\n        print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n        print(\"----------------------------------------------------------------------\\\\n\")\\r\\n        \\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn7_stamp': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"lsn7_stamp.py\", doraise=True)\\r\\n        print(\"----------------------------------------------------------------------\")\\r\\n        print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n        print(\"----------------------------------------------------------------------\\\\n\")\\r\\n        \\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn7_simpledrawing': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    drawing_functions = [\"draw_arc\", \"draw_image\", \"draw_rectangle\", \"draw_circle\", \"draw_ellipse\", \"draw_line\", \"draw_pixel\", \"draw_text\", \"write_text\"]\\r\\n    drawing_functions_called = []\\r\\n    \\r\\n    print(\"----------------------------------------------------------------------\")\\r\\n    print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n    print(\"----------------------------------------------------------------------\\\\n\")\\r\\n    \\r\\n    file = open(\"lsn7_simpledrawing.py\", \"r\")\\r\\n    file_contents = file.read()\\r\\n    \\r\\n    for f in drawing_functions:\\r\\n        if f in file_contents and f not in drawing_functions_called:\\r\\n            drawing_functions_called.append(f)\\r\\n    \\r\\n    if len(drawing_functions_called) >= 4 and \"draw_image\" in drawing_functions_called:\\r\\n        print(\"Good Job!\")\\r\\n        return 100.0\\r\\n    elif len(drawing_functions_called) >= 4 and \"draw_image\" not in drawing_functions_called:\\r\\n        print(\"Missing at least one call of draw_image\")\\r\\n        return 90.0\\r\\n    else:\\r\\n        print(\"Not enough different drawing functions.  Need 4 unique (including draw_image) calls.\")\\r\\n        return 25 * len(drawing_functions_called)\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn7_randomcircles': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:\\r\\n        py_compile.compile(\"lsn7_randomcircles.py\", doraise=True)\\r\\n        print(\"----------------------------------------------------------------------\")\\r\\n        print(\"*** To Actually See Your Graphics, Rerun this Program and Type \\'N\\' ***\")\\r\\n        print(\"----------------------------------------------------------------------\\\\n\")\\r\\n        \\r\\n        file = open(\"lsn7_randomcircles.py\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        lines = file_contents.split(\"\\\\n\")\\r\\n        \\r\\n        pg_draw_used = False\\r\\n        random_used = False\\r\\n        \\r\\n        for line in lines:\\r\\n            if len(line.strip()) > 0 and line.strip()[0] != \\'#\\':      \\r\\n                if \"random.rand\" in line:\\r\\n                    random_used = True\\r\\n                    \\r\\n                if \"draw_circle(\" in line:\\r\\n                    pg_draw_used = True\\r\\n        \\r\\n        if pg_draw_used and random_used:\\r\\n            print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n            return 100.0\\r\\n        elif pg_draw_used and not random_used:\\r\\n            print(\"Looks like you drew a circle but didn\\'t use random values for size or location.\")\\r\\n            return 50.0\\r\\n        elif not pg_draw_used and random_used:\\r\\n            print(\"Looks like you created random variables but didn\\'t actually draw any circles.\")\\r\\n            return 50.0\\r\\n        else:\\r\\n            print(\"Doesn\\'t look like you created random variables or drew any circles.\")\\r\\n            return 0.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn6_uod': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\n\\r\\n# The Actual Solution\\r\\ndef solution(temp, wind):\\r\\n    if temp < 40:\\r\\n        if wind < 15:\\r\\n            return \"Parkas\"\\r\\n        else:\\r\\n            return \"OCPs\"\\r\\n    elif temp == 40:\\r\\n        if wind < 15:\\r\\n            return \\'A-Jackets\\'\\r\\n        else:\\r\\n            return \\'OCPs\\'\\r\\n    elif temp > 40 and temp <= 60:\\r\\n        if wind < 15:\\r\\n            return \\'A-Jackets\\'\\r\\n        else:\\r\\n            return \\'Parkas\\'\\r\\n    else:\\r\\n        if wind <= 15:\\r\\n            return \\'Blues\\'\\r\\n        else:\\r\\n            return \\'A-Jackets\\'\\r\\n\\r\\n\\r\\ndef run_test(temp, wind):\\r\\n    global num_tests_passed\\r\\n    \\r\\n    print(\"Testing Temp =\", temp, \\'and Wind =\\', wind)\\r\\n    output, error_message = autograder.run_script(\"lsn6_uod.py\", [temp, wind])\\r\\n    \\r\\n    print(\"Output:\", output.strip())\\r\\n    \\r\\n    if output.strip() == solution(temp, wind):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\", solution(temp, wind), \"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(39, 14)\\r\\n    run_test(39, 15)\\r\\n    run_test(39, 16)\\r\\n    run_test(40, 14)\\r\\n    run_test(40, 15)\\r\\n    run_test(40, 16)\\r\\n    run_test(50, 14)\\r\\n    run_test(50, 15)\\r\\n    run_test(50, 16)\\r\\n    run_test(60, 14)\\r\\n    run_test(60, 15)\\r\\n    run_test(60, 16)\\r\\n    run_test(61, 14)\\r\\n    run_test(61, 15)\\r\\n    run_test(61, 16)\\r\\n    \\r\\n    return round(num_tests_passed * (100 / 15), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn6_speeding': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# The Actual Solution\\r\\ndef solution(speed):\\r\\n    # Determines what to return based on the table\\r\\n    if (speed <= 65):\\r\\n        return \"No Ticket\"\\r\\n    elif (speed >65 and speed <= 70):\\r\\n        return \"Warning\"\\r\\n    elif (speed > 70 and speed <= 75):\\r\\n        return \"Speeding\"  \\r\\n    elif (speed >75 and speed <= 80):\\r\\n        return \"Reckless Driving\"\\r\\n    elif (speed > 80):\\r\\n        return \"Reckless Endangerment\"\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    num_tests_passed = 0\\r\\n    \\r\\n    SPEEDS_TO_TEST = [random.randint(0, 65),\\r\\n                      65,\\r\\n                      random.randint(66, 70),\\r\\n                      70,\\r\\n                      random.randint(71, 75),\\r\\n                      75,\\r\\n                      random.randint(76, 80),\\r\\n                      80,\\r\\n                      random.randint(81, 100)]\\r\\n    \\r\\n    for i in range(0, len(SPEEDS_TO_TEST)):\\r\\n        print(\"-------------------------------\")\\r\\n        print(\"Test\", i+1)\\r\\n        print(\"-------------------------------\")\\r\\n        speed = SPEEDS_TO_TEST[i]\\r\\n        output, error_message = autograder.run_script(\"lsn6_speeding.py\", [speed])\\r\\n        \\r\\n        if output.strip() == solution(speed):\\r\\n            print(\"SUCCESS!\\\\n\")\\r\\n            num_tests_passed += 1\\r\\n        else:\\r\\n            print(\"INCORRECT.  Expected:\", solution(speed), \"\\\\n\")\\r\\n    \\r\\n    return round(num_tests_passed * (100 / len(SPEEDS_TO_TEST)), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn6_roundtrip': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    points_earned = 0\\r\\n            \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 1\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn6_roundtrip.py\", [100,10,30])\\r\\n    \\r\\n    if output.strip() == \"No Refueling Needed\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 33\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: No Refueling Needed\\\\n\")\\r\\n        \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 2\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn6_roundtrip.py\", [100,5,20])\\r\\n    \\r\\n    if output.strip() == \"Refuel on Way Back\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 33\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Refuel on Way Back\\\\n\")\\r\\n    \\r\\n        # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 3\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn6_roundtrip.py\", [100,7,10])\\r\\n    \\r\\n    if output.strip() == \"Refuel En Route\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 34\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Refuel En Route\\\\n\")\\r\\n\\r\\n    return points_earned\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn6_lists': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nnum_tests_passed = 0\\r\\n\\r\\n# The Actual Solution\\r\\ndef solution(gpa, apa, mpa):\\r\\n    answer = \"\"\\r\\n    \\r\\n    # Determines what output to present (note how we are using the \" character because of the \\'s)\\r\\n    if (gpa < 3.0 and apa < 3.0 and mpa < 3.0):\\r\\n        answer += \"No List\\\\n\"\\r\\n    elif (gpa >= 3.0 and apa >= 3.0 and mpa >= 3.0):\\r\\n        answer += \"Superintendent\\'s List\\\\n\"\\r\\n    else:\\r\\n        # Note that these are 3 separate if statements; we do this because we don\\'t know what list(s) the cadet is on\\r\\n        if (gpa >= 3.0):\\r\\n            answer += \"Dean\\'s List\\\\n\"\\r\\n        \\r\\n        if (apa >= 3.0):\\r\\n            answer += \"Athletic Director\\'s List\\\\n\"\\r\\n        \\r\\n        if (mpa >= 3.0):\\r\\n            answer += \"Commandant\\'s List\\\\n\"\\r\\n\\r\\n    return answer.strip()\\r\\n\\r\\n\\r\\ndef run_test(gpa, apa, mpa):\\r\\n    global num_tests_passed\\r\\n    \\r\\n    print(\"--------------------------------------------\")\\r\\n    print(\"Testing GPA =\", str(gpa) + \";\", \"APA =\", str(apa) + \";\", \"MPA =\", mpa)\\r\\n    print(\"--------------------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn6_lists.py\", [gpa, apa, mpa])\\r\\n        \\r\\n    if output.strip() == solution(gpa, apa, mpa):\\r\\n        print(\"SUCCESS!\\\\n\")\\r\\n        num_tests_passed += 1\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected:\", solution(gpa, apa, mpa), \"\\\\n\")\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    run_test(2.8, 2.6, 2.5)\\r\\n    run_test(3.5, 3.2, 2.8)\\r\\n    run_test(3.3, 2.8, 3.4)\\r\\n    run_test(3.6, 3.8, 3.2)\\r\\n    run_test(2.8, 3.5, 3.8)\\r\\n    \\r\\n    return round(num_tests_passed * (100 / 5), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn6_fuel': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    points_earned = 0\\r\\n            \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 1\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn6_fuel.py\", [30,60])\\r\\n    \\r\\n    if output.strip() == \"Return to base\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 25\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Return to base\\\\n\")\\r\\n        \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 2\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn6_fuel.py\", [60,60])\\r\\n    \\r\\n    if output.strip() == \"Resume flight\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 25\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Resume flight\\\\n\")\\r\\n    \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 3\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn6_fuel.py\", [40,80])\\r\\n    \\r\\n    if output.strip() == \"Resume flight\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 25\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Resume flight\\\\n\")\\r\\n\\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"Test 4\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn6_fuel.py\", [60,80])\\r\\n    \\r\\n    if output.strip() == \"Resume flight\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 25\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected: Resume flight\\\\n\")\\r\\n\\r\\n    return points_earned\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn5_positive': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    points_earned = 0\\r\\n    \\r\\n    # Generates Random Values\\r\\n    negative_value = random.randint(-100, -1)\\r\\n    positive_value = random.randint(1, 100)\\r\\n        \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"# Test 1 - Positive Number\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn5_positive.py\", [positive_value])\\r\\n    \\r\\n    if output.strip() == \"POSITIVE\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 33\\r\\n    else:\\r\\n        print(\"Incorrect Output:\", output)\\r\\n        print(\"Expected POSITIVE\\\\n\")\\r\\n        \\r\\n    \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"# Test 2 - Negative Number\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn5_positive.py\", [negative_value])\\r\\n    \\r\\n    if output.strip() == \"NOT POSITIVE\":\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        points_earned += 33\\r\\n    else:\\r\\n        print(\"Incorrect Output:\", output)\\r\\n        print(\"Expected NOT POSITIVE\\\\n\")\\r\\n        \\r\\n    \\r\\n    # Runs the Script\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"# Test 3 - Zero\")\\r\\n    print(\"-------------------------------\")\\r\\n    output, error_message = autograder.run_script(\"lsn5_positive.py\", [0])\\r\\n    \\r\\n    if output.strip() == \"NOT POSITIVE\":\\r\\n        print(\"CORRECT\")\\r\\n        points_earned += 34\\r\\n    else:\\r\\n        print(\"Incorrect Output:\", output)\\r\\n        print(\"Expected NOT POSITIVE\\\\n\")\\r\\n\\r\\n    return points_earned\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn5_largest': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef run_test(num1, num2, num3):\\r\\n    print(\"-------------------------------\")\\r\\n    print(\"# Testing: \" + str(num1) + \" \" + str(num2) + \" \" + str(num3))\\r\\n    print(\"-------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"lsn5_largest.py\", [num1, num2, num3])\\r\\n    \\r\\n    if autograder.equals(output, max(num1, num2, num3)):\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"Incorrect.  Expected\", max(num1, num2, num3))\\r\\n        return False\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    tests_passed = 0\\r\\n    \\r\\n    # Generate 3 Random Numbers\\r\\n    num1 = 0\\r\\n    num2 = 0\\r\\n    num3 = 0\\r\\n    \\r\\n    # Ensures that the 3 Numbers are Different\\r\\n    while num1 == num2 or num1 == num3 or num2 == num3:\\r\\n        num1 = random.randint(0, 100)\\r\\n        num2 = random.randint(0, 100)\\r\\n        num3 = random.randint(0, 100)\\r\\n    \\r\\n    # Sorts the numbers\\r\\n    # This is needed so that we can test relationships between numbers\\r\\n    numbers = [num1, num2, num3]\\r\\n    numbers.sort()\\r\\n    num1 = numbers[0]\\r\\n    num2 = numbers[1]\\r\\n    num3 = numbers[2]\\r\\n    \\r\\n    # Test 1:  num1, num2, num3\\r\\n    if run_test(num1, num2, num3):\\r\\n        tests_passed += 1\\r\\n\\r\\n    # Test 2:  num1, num3, num2\\r\\n    if run_test(num1, num3, num2):\\r\\n        tests_passed += 1\\r\\n        \\r\\n    # Test 3:  num2, num3, num1\\r\\n    if run_test(num2, num3, num1):\\r\\n        tests_passed += 1\\r\\n    \\r\\n    # Test 4:  num3, num1, num2\\r\\n    if run_test(num3, num1, num2):\\r\\n        tests_passed += 1\\r\\n\\r\\n    # Test 5:  num2, num1, num3\\r\\n    if run_test(num2, num1, num3):\\r\\n        tests_passed += 1\\r\\n    \\r\\n    # Test 6:  3 Equal Numbers\\r\\n    if run_test(num1, num1, num1):\\r\\n        tests_passed += 1\\r\\n            \\r\\n    print(\"Passed \" + str(tests_passed) + \" out of 6 tests\")\\r\\n    return round(tests_passed * (100 / 6), 1)\\r\\n    \\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn5_classyear': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(class_year):\\r\\n    if class_year < 2022:\\r\\n        return \"Graduate\"\\r\\n    elif class_year == 2022:\\r\\n        return \"Firstie\"\\r\\n    elif class_year == 2023:\\r\\n        return \"Two Degree\"\\r\\n    elif class_year == 2024:\\r\\n        return \"Three Degree\"\\r\\n    elif class_year == 2025:\\r\\n        return \"Four Degree\"\\r\\n    else:\\r\\n        return \"Not a Cadet\"\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    START_YEAR = 2021\\r\\n    END_YEAR = 2026\\r\\n    number_correct = 0\\r\\n    \\r\\n    for year in range(START_YEAR, END_YEAR + 1):\\r\\n        print(\"------------------------------\")\\r\\n        print(\"Testing: \" + str(year))\\r\\n        print(\"------------------------------\")\\r\\n        \\r\\n        # Runs the Script\\r\\n        output, error_message = autograder.run_script(\"lsn5_classyear.py\", [year])\\r\\n                \\r\\n        lines = output.split(\"\\\\n\")\\r\\n               \\r\\n        if lines[0] == solution(year):\\r\\n            print(\"PASS\\\\n\")\\r\\n            number_correct += 1\\r\\n        else:\\r\\n            print(\"FAIL\\\\n\")\\r\\n    \\r\\n    print(\"Passed \" + str(number_correct) + \" out of \" + str(END_YEAR - START_YEAR + 1) + \" tests\")\\r\\n    return round(number_correct * (100 / (END_YEAR - START_YEAR + 1)), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn5_atmosphere': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(altitude):\\r\\n    if altitude >= 0:\\r\\n        if altitude <= 10:\\r\\n            return \"Troposphere\"\\r\\n    if altitude >= 11:\\r\\n        if altitude <= 50:\\r\\n            return \"Stratosphere\"\\r\\n    if altitude >= 51:\\r\\n        if altitude <= 85:\\r\\n            return \"Mesosphere\"\\r\\n    if altitude >= 86:\\r\\n        if altitude <= 1000:\\r\\n            return \"Thermosphere\"\\r\\n    if altitude >= 1001:\\r\\n        if altitude <= 100000:\\r\\n            return \"Exosphere\"\\r\\n        else:\\r\\n            return \"Space\"\\r\\n        \\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    TEST_VALUES = [0, 1, 10, 11, 50, 51, 85, 86, 1000, 1001, 100000, 100001]\\r\\n    tests_passed = 0\\r\\n    \\r\\n    for altitude in TEST_VALUES:\\r\\n        print(\"--------------------------\")\\r\\n        print(\"Testing \" + str(altitude) + \" km\")\\r\\n        print(\"--------------------------\")\\r\\n        \\r\\n        # Runs the Script\\r\\n        output, error_message = autograder.run_script(\"lsn5_atmosphere.py\", [altitude])\\r\\n                               \\r\\n        # Your Test Goes Here (Return True if Pass, False Otherwise)   \\r\\n        if output.strip() == solution(altitude):\\r\\n            print(\"Passed\\\\n\")\\r\\n            tests_passed += 1\\r\\n        else:\\r\\n            print(\"Failed (Expected: \" + solution(altitude) + \")\\\\n\")\\r\\n    \\r\\n    print(\"Passed\", tests_passed, \"out of\", len(TEST_VALUES), \"tests.\")\\r\\n    return round(tests_passed * (100 / len(TEST_VALUES)), 2)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn4_temperature': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    degrees_farenheit = random.random() * 451.0\\r\\n    degrees_celsius = (degrees_farenheit - 32.0) * 5/9\\r\\n    degrees_kelvin = degrees_celsius + 273.15\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_temperature.py\", [degrees_farenheit])\\r\\n    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if autograder.equals(lines[0], degrees_kelvin):\\r\\n        print(\"Conversion to Kelvin looks good.\")\\r\\n        if autograder.equals(lines[1], degrees_celsius):\\r\\n            print(\"Conversion to Celsius looks good.\")\\r\\n            return 100.0\\r\\n        else:\\r\\n            print(\"Conversion to Celsius incorrect.\\\\nYour result: \" + str(lines[1]) + \"\\\\nExpected: \" + str(degrees_celsius))\\r\\n            return 50.0\\r\\n    else:\\r\\n        if autograder.equals(lines[0], degrees_celsius):\\r\\n            print(\"Looks like you swapped the order of your output. Look at the Problem Statement and try again.\")\\r\\n        else:\\r\\n            print(\"Conversion to Kelvin incorrect.\\\\nYour result: \" + str(lines[0]) + \"\\\\nExpected: \" + str(degrees_kelvin))\\r\\n        return 0.0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn4_projectile': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 5\\r\\n    num_correct = 0\\r\\n    \\r\\n    for i in range(NUM_TESTS):\\r\\n        # Generates Random Values\\r\\n        velocity = random.randint(400, 900)\\r\\n        theta = random.random() * 90.0\\r\\n        answer = (velocity**2 * math.sin(2 * theta * math.pi/180.0)) / 9.8\\r\\n        incorrect_degrees_answer = (velocity**2 * math.sin(2 * theta)) / 9.8\\r\\n            \\r\\n        print(\"----------------------------------------\")\\r\\n        print(\"TEST CASE\", i+1)\\r\\n        print(\"----------------------------------------\")\\r\\n        \\r\\n        # Runs the Script\\r\\n        output, error_message = autograder.run_script(\"lsn4_projectile.py\", [velocity, theta])\\r\\n\\r\\n        # Optional:  Displays the Error Message (if one is provided)\\r\\n        if error_message != \\'\\':\\r\\n            print(\"Error Occurred: \" + error_message)    \\r\\n        \\r\\n        lines = output.split(\\'\\\\n\\')\\r\\n        \\r\\n        if autograder.equals(lines[0], answer, 10.0):\\r\\n            print(\"CORRECT.\\\\n\\\\n\")\\r\\n            num_correct += 1\\r\\n        elif autograder.equals(lines[0], incorrect_degrees_answer, 10.0):\\r\\n            print(\"INCORRECT BUT CLOSE: Using Degrees Instead of Radians for math.sin()\")\\r\\n        else:\\r\\n            print(\"INCORRECT (Expected: \" + str(answer) + \")\\\\n\\\\n\")\\r\\n    \\r\\n    return (100 / NUM_TESTS) * num_correct\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn4_math': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num1 = random.random() * 100.0\\r\\n    num2 = random.random() * 100.0\\r\\n    num3 = random.random() * 10.0\\r\\n    \\r\\n    part1 = round(math.sqrt(num1), 2)\\r\\n    part2 = round(math.fabs(num2 - num3), 2)\\r\\n    part3 = round(math.factorial(math.ceil(num3)), 2)\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_math.py\", [num1, num2, num3])\\r\\n    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    correct = [0,0,0]\\r\\n    \\r\\n    if autograder.equals(lines[0], part1, 0.001):\\r\\n        correct[0]=1\\r\\n        print(\"Calculation 1 Correct!\")\\r\\n    else:\\r\\n        print(\"Calculation 1 Incorrect. Expected: \" + str(part1) + \"<-- Did you forget to use round()?\")\\r\\n    if autograder.equals(lines[1], part2, 0.001):\\r\\n        correct[1]=1\\r\\n        print(\"Calculation 2 Correct!\")\\r\\n    else:\\r\\n        print(\"Calculation 2 Incorrect. Expected: \" + str(part2) + \"<-- Did you forget to use round()?\")\\r\\n    if autograder.equals(lines[2], part3, 0.001):\\r\\n        correct[2]=1\\r\\n        print(\"Calculation 3 Correct!\")\\r\\n    else:\\r\\n        print(\"Calculation 3 Incorrect. Expected: \" + str(part3) + \"<-- Did you forget to use round()?\")\\r\\n    \\r\\n    amt_correct = len([elem for elem in correct if elem==1])\\r\\n    \\r\\n    return round(amt_correct/3*100,2)\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn4_calories': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    age_years = random.randint(10, 99)\\r\\n    weight_pounds = random.randint(80, 400)\\r\\n    heart_bpm = random.randint(50, 140)\\r\\n    time_minutes = random.randint(15, 90)\\r\\n    \\r\\n    calories_man   = ( (age_years * 0.2017) + (weight_pounds * 0.09036) + (heart_bpm * 0.6309) - 55.0969 )  * time_minutes / 4.184\\r\\n    calories_woman = ( (age_years * 0.074)  + (weight_pounds * 0.05741) + (heart_bpm * 0.4472) - 20.4022 ) * time_minutes / 4.184\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_calories.py\", [age_years, weight_pounds, heart_bpm, time_minutes])\\r\\n      \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n      \\r\\n    if autograder.equals(lines[0], calories_man):\\r\\n        print(\"Male Calorie Calculations Look Good.\")\\r\\n        if autograder.equals(lines[1], calories_woman):\\r\\n            print(\"Female Calorie Calculations Look Good.\")\\r\\n            return 100.0\\r\\n        else:\\r\\n            print(\"Female Calorie Calculation is Incorrect.\\\\nExpected: \" + str(calories_woman))\\r\\n            return 50.0\\r\\n    else:\\r\\n        print(\"Male Calorie Calculation is Incorrect.\\\\nExpected: \" + str(calories_man))\\r\\n        return 0.0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn4_bits_to_kmg': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num_bits = random.randint(1, 1000000)\\r\\n    num_bytes = num_bits / 8\\r\\n    num_kb = num_bytes / 1024\\r\\n    num_mb = num_kb / 1024\\r\\n    num_gb = num_mb / 1024\\r\\n        \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_bits_to_kmg.py\", [num_bits])\\r\\n      \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n      \\r\\n    if autograder.equals(lines[0], num_kb):\\r\\n        print(\"Kilobyte Conversion Looks Good.\")\\r\\n        if autograder.equals(lines[1], num_mb):\\r\\n            print(\"Megabyte Conversion Looks Good.\")\\r\\n            if autograder.equals(lines[2], num_gb):\\r\\n                print(\"Gigabyte Conversion Looks Good.\")\\r\\n                return 100.0\\r\\n            else:\\r\\n                print(\"Num GB is Incorrect.\\\\n  Expected: \" + str(num_gb))\\r\\n                return 67.0\\r\\n        else:\\r\\n            print(\"Num MB is Incorrect.\\\\n  Expected: \" + str(num_mb))\\r\\n            return 33.0\\r\\n    else:\\r\\n        print(\"Num KB is Incorrect.\\\\n  Expected: \" + str(num_kb))\\r\\n        return 0.0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn4_bits_to_bytes': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num_bits = random.randint(1, 1000000)\\r\\n    num_bytes = num_bits / 8\\r\\n\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_bits_to_bytes.py\", [num_bits])\\r\\n      \\r\\n    if autograder.equals(output, num_bytes):\\r\\n        print(\"Num Bytes Looks Good.\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"Num Bytes is Incorrect.\\\\nExpected: \" + str(num_bytes))\\r\\n        return 0.0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn4_bit_representation': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num_bits = random.randint(1, 32)\\r\\n    num_colors = 2 ** num_bits\\r\\n\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn4_bit_representation.py\", [num_bits])\\r\\n      \\r\\n    if autograder.equals(output, num_colors):\\r\\n        print(\"Num Colors Looks Good.\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"Num Colors is Incorrect.\\\\nExpected: \" + str(num_colors))\\r\\n        return 0.0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn3_skill2': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n       \\r\\n    # Generates Random Values\\r\\n    age = random.randint(18, 30)\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn3_skill2.py\", [age])\\r\\n    \\r\\n    if autograder.equals(output, age+4):\\r\\n        print(\"PASSED\")\\r\\n        return 100\\r\\n    elif autograder.equals(output, age):\\r\\n        print(\"Close!  You forgot to add 4 to the age before printing it out\")\\r\\n        return 50\\r\\n    else:\\r\\n        print(\"Incorrect Output, Expected\", age+4)\\r\\n        return 0\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn3_skill1': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\nfrom lsn3_skill1 import *\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n       \\r\\n    points_earned = 0   \\r\\n    \\r\\n    print(\"Looking for a variable called \\'name\\' . . . \", end=\\'\\')\\r\\n    \\r\\n    if \\'name\\' in globals():\\r\\n        points_earned += 50\\r\\n        print(\"FOUND!\")\\r\\n        print(\"Now, checking to make sure your name is a string\")\\r\\n        \\r\\n        if type(name).__name__ == \\'str\\':\\r\\n            points_earned += 50\\r\\n            print(\"Good Job\", name + \"!\")\\r\\n        else:\\r\\n            print(\"Make sure you are surrounding your name with quotation marks\")\\r\\n    else:\\r\\n        print(\"NOT FOUND :(\")\\r\\n        \\r\\n    return points_earned\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn3_scoreaverage': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    score1 = random.randint(0, 100)\\r\\n    score2 = random.randint(0, 100)\\r\\n    score3 = random.randint(0, 100)\\r\\n    average = (score1 + score2 + score3) / 3.0\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn3_scoreaverage.py\", [score1, score2, score3])\\r\\n    \\r\\n    if autograder.equals(output, average):\\r\\n        print(\"PASSED!\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"Value doesn\\'t match.\\\\nExpected: \" + str(average))\\r\\n        return 0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn3_pointspread': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    score1 = random.randint(0, 50)\\r\\n    score2 = random.randint(score1, 100)\\r\\n    spread = abs(score1 - score2)\\r\\n\\r\\n    points_earned = 0\\r\\n\\r\\n    # Trial #1:  score 1 > score2\\r\\n    print(\"Testing when score 1 is bigger than score 2 . . .\")\\r\\n    output, error_message = autograder.run_script(\"lsn3_pointspread.py\", [score1, score2])\\r\\n    \\r\\n    if autograder.equals(output, spread):\\r\\n        print(\"PASSED!\\\\n\")\\r\\n        points_earned += 50\\r\\n    else:\\r\\n        print(\"Value doesn\\'t match.\\\\nExpected: \" + str(spread)  + \"\\\\n\")\\r\\n        \\r\\n    # Trial #2:  score 2 > score1\\r\\n    print(\"Testing when score 2 is bigger than score 1 . . .\")\\r\\n    output, error_message = autograder.run_script(\"lsn3_pointspread.py\", [score2, score1])\\r\\n    \\r\\n    if autograder.equals(output, spread):\\r\\n        print(\"PASSED!\")\\r\\n        points_earned += 50\\r\\n    else:\\r\\n        print(\"Value doesn\\'t match.\\\\nExpected: \" + str(spread))\\r\\n    \\r\\n    return points_earned\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn3_madlib': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    first_names = [\\'Adrian\\', \\'Troy\\', \\'Dave\\', \\'Paul\\', \\'Kelly\\', \\'Steve\\', \\'Barry\\']\\r\\n    generic_locations = [\\'Best Buy\\', \\'AAFES\\', \\'Target\\', \\'THE Walmart\\', \\'Home Depot\\']\\r\\n    nouns = [\\'Video Games\\', \\'Board Games\\', \\'Nintendo Switches\\', \\'Sony PS4s\\', \\'Microsoft (Ugh) Xbox Ones\\']\\r\\n    \\r\\n    first_name = first_names[random.randint(0, len(first_names) - 1)]\\r\\n    generic_location = generic_locations[random.randint(0, len(generic_locations) - 1)]\\r\\n    whole_number = random.randint(0, 100)\\r\\n    plural_noun = nouns[random.randint(0, len(nouns) - 1)]\\r\\n\\r\\n    expected_output = first_name + \\' went to \\' + generic_location + \\' to buy \\' + str(whole_number) + \\' different types of \\' + plural_noun + \"\\\\n\"\\r\\n\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn3_madlib.py\", [first_name, generic_location, whole_number, plural_noun])\\r\\n    \\r\\n    if output == expected_output:\\r\\n        print(\"PASSED!\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"String doesn\\'t match.\\\\nExpected: \" + expected_output)\\r\\n        return 0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn3_girlscouts': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    dollar_amount = round(random.uniform(10.00, 100.00), 2)\\r\\n    super_six_amount = (dollar_amount // 5)\\r\\n    specialty_amount = (dollar_amount // 6)\\r\\n    score = 0\\r\\n    \\r\\n    line_1 = str(int(super_six_amount)) + \" boxes of Thin Mints, Samoas, Tagalongs, Do-Si-Dos, Trefoils, or Savannah Smiles\"\\r\\n    line_2 = str(int(specialty_amount)) + \" boxes of S\\'mores and Toffee-tastic\"\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn3_girlscouts.py\", [dollar_amount])\\r\\n    output_lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if line_1 == output_lines[0]:\\r\\n        print(\"First Line is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"First Line is Incorrect.  Expected:\", line_1)\\r\\n    \\r\\n    if line_2 == output_lines[1]:\\r\\n        print(\"Second Line is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Second Line is Incorrect.  Expected:\", line_2)\\r\\n    \\r\\n    return score\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn3_arrivaltime': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    distance = round(random.random() * 1000, 1)\\r\\n    speed = round(random.random() * 60, 1)\\r\\n    time = distance / speed\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn3_arrivaltime.py\", [distance, speed])\\r\\n    \\r\\n    if autograder.equals(output, time):\\r\\n        print(\"PASSED!\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"Value doesn\\'t match.\\\\nExpected: \" + str(time))\\r\\n        return 0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn24_starmap': 'from cs110 import autograder\\r\\nimport random, math, traceback\\r\\n\\r\\nSTUDENT_SOLUTION_FILENAME = \"lsn24_starmap.py\"\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    test_cases = dict()\\r\\n    test_cases[(0,0)] = \"Moon\" \\r\\n    test_cases[(0,1)] = \"Nothing\"   \\r\\n    test_cases[(4,1)] = \"Satellite\"\\r\\n    test_cases[(1,4)] = \"Planet\"\\r\\n    test_cases[(3,1)] = \"Planet\"\\r\\n    test_cases[(2,4)] = \"Moon\"\\r\\n    test_cases[(2,2)] = \"Nothing\"\\r\\n    test_cases[(4,3)] = \"Satellite\"\\r\\n    test_cases[(0,4)] = \"Star\"\\r\\n    test_cases[(3,2)] = \"Star\"\\r\\n    \\r\\n    \\r\\n    test_case_input = list(test_cases.keys())\\r\\n    case_order = list(range(len(test_case_input)))\\r\\n    #random.shuffle(case_order)\\r\\n    \\r\\n    score = 0\\r\\n    i = 1\\r\\n    \\r\\n    for idx in case_order:\\r\\n        print(\\'\\\\n\\' + \\'=\\'*30)\\r\\n        print(\"Test Case:\", i)\\r\\n        print(\\'=\\'*30)\\r\\n        \\r\\n        try: \\r\\n            output, error = autograder.run_script(STUDENT_SOLUTION_FILENAME, test_case_input[case_order[idx]])        \\r\\n            expected_output = test_cases[test_case_input[case_order[idx]]]\\r\\n                        \\r\\n            test_case_score = 0\\r\\n            \\r\\n            output = output.strip()\\r\\n            \\r\\n            if len(output.split(\\'\\\\n\\')) == 0:\\r\\n                print(\"No Output Detected. Expected:\")\\r\\n                print(expected_output)\\r\\n            elif len(output.split(\\'\\\\n\\')) > 1:\\r\\n                print(\"Your program printed too many lines. Expected:\")\\r\\n                print(expected_output)\\r\\n            elif output.strip() == expected_output.strip():\\r\\n                print(\"CORRECT!\")\\r\\n                test_case_score = 100.0 / len(test_cases)\\r\\n            else:\\r\\n                print(\"INCORRECT. Expected:\")\\r\\n                print(expected_output)\\r\\n            \\r\\n            score += test_case_score\\r\\n            i += 1\\r\\n        except Exception as e:\\r\\n            score += 0\\r\\n            i += 1\\r\\n            \\r\\n            print(\"An ERROR Occured:\", e)\\r\\n            print(traceback.print_exc())    \\r\\n\\r\\n\\r\\n    return score\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':\\r\\n    try:\\r\\n        result = test_passed()\\r\\n    except Exception as e:\\r\\n        result = 0\\r\\n        print(\"An ERROR Occured:\", e)\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn2_printpractice': 'from cs110 import autograder\\r\\n\\r\\ndef test_passed():\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn2_printpractice.py\", [])\\r\\n\\r\\n    student_output = output.strip().split(\\'\\\\n\\')\\r\\n    expected_output = [\\'Welcome to Computer Science 110!\\', \\'921600.0\\', \\'Liam is 8 years old\\', \\'F-15  Eagle\\', \\'F-16  Fighting Falcon\\', \\'B-2   Spirit\\', \\'C-141 Starlifter\\']\\r\\n    num_matches = autograder.compare_strings(student_output, expected_output)\\r\\n    \\r\\n    return round(num_matches * (100 / len(expected_output)), 1)\\r\\n\\r\\n\\r\\n# Testbench (to be run in an IDE)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn2_parking': 'from cs110 import autograder\\r\\n\\r\\ndef test_passed():\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn2_parking.py\", [])\\r\\n        \\r\\n    if output.startswith(\"  NO PARKING\\\\n\"):\\r\\n        if output == \"  NO PARKING\\\\n1:00 - 5:00 a.m.\\\\n\" or \"  NO PARKING\\\\n1:00 - 5:00 a.m.\":\\r\\n            print(\"Passed!\")\\r\\n            return 100\\r\\n        else:\\r\\n            print(\"Something is wrong with the second line.\")\\r\\n            return 50\\r\\n    else:\\r\\n        print(\"Something is wrong with the first line.\")\\r\\n        return 0\\r\\n\\r\\n# Testbench (to be run in an IDE)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'lsn2_ascii': 'from cs110 import autograder\\r\\n\\r\\ndef test_passed():\\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"lsn2_ascii.py\", [])\\r\\n    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    # Checks for the Cat\\r\\n    if lines[0].rstrip() == \\'/\\\\\\\\   /\\\\\\\\\\':\\r\\n        #test_feedback.write(\\'1\\')\\r\\n        if lines[1].rstrip() == \\'  o o\\':\\r\\n            #test_feedback.write(\\'2\\')\\r\\n            if lines[2].rstrip() == \\' =   =\\':\\r\\n                #test_feedback.write(\\'3\\')\\r\\n                if lines[3].rstrip() == \\'  ---\\':\\r\\n                    #test_feedback.write(\\'4\\')\\r\\n                    print(\\'Cat Looks Good!\\\\n\\')\\r\\n                    return 100\\r\\n                else:\\r\\n                    print(\\'Problem in the fourth line of the cat\\') \\r\\n            else:\\r\\n                print(\\'Problem in the third line of the cat\\')  \\r\\n        else:\\r\\n            print(\\'Problem in the second line of the cat\\')  \\r\\n    else:\\r\\n        print(\\'Problem in the first line of the cat\\')\\r\\n    \\r\\n    return 0\\r\\n\\r\\n# Testbench (to be run in an IDE)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn17_skill1': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0.0\\r\\n    \\r\\n    if autograder.code_compiles(\"lsn17_skill1.py\"):\\r\\n        file = open(\"lsn17_skill1.py\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        \\r\\n        if \"draw_circle(\" in file_contents:\\r\\n            print(\"draw_circle called\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"draw_circle does not appear to be called.  You need to call it in the draw() function\")\\r\\n            \\r\\n        if file_contents.count(\"ball_x\") + file_contents.count(\"ball_y\") > 5:\\r\\n            print(\"Looks like you are using ball_x and/or ball_y\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"Make sure you are changing the value of ball_x and ball_y in update().\")\\r\\n            \\r\\n    else:\\r\\n        print(\"There appears to be an error in your python Script that is preventing it from running\")\\r\\n    \\r\\n    print(\"\\\\nThank you for your submission.  Your instructor will let you know if there is an issue.\")\\r\\n    return score        \\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn10_in_circle': 'import lsn10_in_circle\\nfrom cs110 import autograder\\nimport random, math, traceback\\n\\nNUM_SUBTESTS = 5\\n   \\ndef soln(x, y, cir_x, cir_y, radius):\\n    distance = math.sqrt((cir_x - x)**2 + (cir_y - y)**2)\\n    return distance <= radius\\n\\ndef test_passed():\\n    \\n    passed = 0\\n    for i in range(NUM_SUBTESTS):\\n        print(\\'Running sub test %d of %d: \\' % (i+1 , NUM_SUBTESTS), end=\\'\\')\\n        if i == 0:\\n            x = 6.04\\n            y = 2.43\\n            cir_x = 43.4\\n            cir_y = 52.2\\n            radius = 74.1\\n        else:\\n            x = random.random() * 10.0\\n            y = random.random() * 10.0\\n            cir_x = random.random() * 100.0\\n            cir_y = random.random() * 100.0\\n            radius = random.random() * 100.0\\n        #print(in_circle(x, y, cir_x, cir_y, radius), soln(x, y, cir_x, cir_y, radius))\\n        try:\\n            if lsn10_in_circle.in_circle(x, y, cir_x, cir_y, radius) == soln(x, y, cir_x, cir_y, radius):\\n                print(\"CORRECT!\")\\n                passed += 1\\n            else:\\n                print(\\'INCORRECT:  in_circle(%f, %f, %f, %f, %f) incorrectly returned %s\\' % (x, y, cir_x, cir_y, radius, lsn10_in_circle.in_circle(x, y, cir_x, cir_y, radius)))\\n        except Exception as e:\\n            print()\\n            print(\"Your program encountered an ERROR:\", e)\\n            print(traceback.print_exc())        \\n    \\n    return (100 / NUM_SUBTESTS) * passed\\n\\n\\n# Runs your code in an IDE (for testing purposes)\\nif __name__ == \\'__main__\\':    \\n    result = test_passed()\\n    print(\"Unit Test Returned:\", result)\\n\\n\\n# --------------------------------------------------\\n# Downloaded from https://www.autograder.net\\n# --------------------------------------------------',\n",
       "  'lsn10_distance': 'import random, math, traceback\\r\\n\\r\\ntry:\\r\\n    from lsn10_distance import dist_points\\r\\nexcept ImportError:\\r\\n    print(\"ERROR: The dist_points() function is missing or incorrect.\")\\r\\n    print(\"Check your spelling of the function.\")\\r\\nfrom cs110 import autograder\\r\\n\\r\\n\\r\\n\\r\\nNUM_SUBTESTS = 5\\r\\n\\r\\ndef soln(x1, y1, x2, y2):\\r\\n    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    passed = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    \\r\\n    for i in range(NUM_SUBTESTS):\\r\\n        x1 = round(random.uniform(-10, 10), 1)\\r\\n        y1 = round(random.uniform(-10, 10), 1)\\r\\n        x2 = round(random.uniform(-10, 10), 1)\\r\\n        y2 = round(random.uniform(-10, 10), 1)\\r\\n        \\r\\n        print(\\'\\\\n\\' + \\'-\\'*50)\\r\\n        print(\\'Test %d of %d, dist_points(%1.1f, %1.1f, %1.1f, %1.1f): \\' % (i+1 , NUM_SUBTESTS, x1, y1, x2, y2))\\r\\n        print(\\'-\\'*50)\\r\\n\\r\\n        try:\\r\\n            expected_solution = soln(x1, y1, x2, y2)\\r\\n            \\r\\n            if autograder.equals(dist_points(x1, y1, x2, y2), expected_solution):\\r\\n                print(\"PASSED!\")\\r\\n                passed += 1\\r\\n            else:\\r\\n                print(\\'FAILED: incorrectly returned %1.5f\\' % (dist_points(x1, y1, x2, y2)))\\r\\n                print(\\'Expected value to return:  %1.5f\\' % expected_solution)\\r\\n        except Exception as e:\\r\\n            print(\"Your program encountered an ERROR:\", e)\\r\\n            print(traceback.print_exc())\\r\\n    \\r\\n        \\r\\n    return round(100 / NUM_SUBTESTS, 1) * passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn10_circle': 'import lsn10_circle\\r\\nfrom cs110 import autograder\\r\\nimport random, math, traceback\\r\\n\\r\\nNUM_SUBTESTS = 5\\r\\n\\r\\n# Helper method to see if a numeric value is within a specified delta\\r\\ndef soln(radius):\\r\\n    return math.pi * radius * radius\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    passed = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    \\r\\n    for i in range(NUM_SUBTESTS):\\r\\n        print(\\'Running sub test %d of %d: \\' % (i+1 , NUM_SUBTESTS), end=\\'\\')\\r\\n        radius = random.random() * 100.0\\r\\n        try:\\r\\n            if autograder.equals(lsn10_circle.area_circle(radius), soln(radius)):\\r\\n                print(\"CORRECT!\")\\r\\n                passed += 1\\r\\n            else:\\r\\n                print(\\'area_circle(%d) incorrectly returned\\' % (radius), lsn10_circle.area_circle(radius))\\r\\n        except Exception as e:\\r\\n            print()\\r\\n            print(\"Your program encountered an ERROR:\", e)\\r\\n            print(traceback.print_exc())        \\r\\n        \\r\\n    return round(100 / NUM_SUBTESTS, 1) * passed\\r\\n\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'lsn10_asteroids': 'from cs110 import autograder\\r\\nimport random, math, traceback\\r\\nimport lsn10_asteroids\\r\\n\\r\\n\\r\\ndef soln(ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r):\\r\\n    distance = math.sqrt((ship_x - asteroid_x)**2 + (ship_y - asteroid_y)**2)\\r\\n    return distance < asteroid_r + ship_r\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 4\\r\\n    num_tests_passed = 0\\r\\n    \\r\\n    print(\"Feedback:\")\\r\\n    score = 0\\r\\n        \\r\\n    if \"dist_points\" in dir(lsn10_asteroids):\\r\\n        score += 20\\r\\n        print(\"dist_points function found.\")\\r\\n    else:\\r\\n        print(\"dist_points function not found.  Use your previous dist_points work!\")\\r\\n        score += 20\\r\\n        \\r\\n    for i in range(NUM_TESTS):       \\r\\n        if i == 0:\\r\\n            ship_x = 2.3\\r\\n            ship_y = 0.2\\r\\n            ship_r = 3\\r\\n            asteroid_x = -4\\r\\n            asteroid_y = 3.4\\r\\n            asteroid_r = 6\\r\\n        else:\\r\\n            ship_x = round(random.uniform(-50, 50), 1)\\r\\n            ship_y = round(random.uniform(-50, 50), 1)\\r\\n            ship_r = 3\\r\\n            asteroid_x = round(random.uniform(-50, 50), 1)\\r\\n            asteroid_y = round(random.uniform(-50, 50), 1)\\r\\n            asteroid_r = 6\\r\\n        \\r\\n        print(\\'-\\'*60)\\r\\n        print(\\'Test %d/%d: detect_collision(%2.1f, %2.1f, %2.1f, %2.1f, %2.1f, %2.1f)\\' % (i+1 , NUM_TESTS, ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r))\\r\\n        print(\\'-\\'*60)\\r\\n\\r\\n        try:\\r\\n            #print(in_circle(x, y, cir_x, cir_y, radius), soln(x, y, cir_x, cir_y, radius))\\r\\n            if lsn10_asteroids.detect_collision(ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r) == soln(ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r):\\r\\n                print(\"CORRECT\")\\r\\n                score += 20\\r\\n            else:\\r\\n                print(\\'detect_collision(%f, %f, %f, %f, %f, %f) incorrectly returned %s\\' % (ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r, lsn10_asteroids.detect_collision(ship_x, ship_y, ship_r, asteroid_x, asteroid_y, asteroid_r)))\\r\\n        except Exception as e:\\r\\n            print(\"Your program encountered an ERROR:\", e)\\r\\n            print(traceback.print_exc())\\r\\n    \\r\\n    return score\\r\\n            \\r\\n            \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Lists3_unpopularnames': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nexpected_output_male = [\"ALDO\", \"ALIJAH\", \"ALLAN\", \"ANGEL\", \"ARTURO\", \"AUGUSTUS\", \"BENNETT\", \"BERISH\", \"CADEN\", \"CHRIS\", \"CODY\", \"COREY\", \"DERRICK\", \"DEVON\", \"DONOVAN\", \"EASON\", \"EDWARD\", \"ELLIS\", \"GIOVANI\", \"HASSAN\",]\\r\\nexpected_output_female = [\"ABBY\", \"AIZA\", \"ALISHA\", \"ANGELICA\", \"ANGIE\", \"ARIANNY\", \"ARIELA\", \"ATARA\", \"AUBREY\", \"AUTUMN\", \"AYLA\", \"BIANCA\", \"BONNIE\", \"BRIANNY\", \"CASSANDRA\", \"CELIA\", \"CHAVY\", \"CHEYENNE\", \"CORA\", \"CRISTINA\"]\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    if (random.random() > 0.5):\\r\\n        gender = \"MALE\"\\r\\n        expected_output = expected_output_male\\r\\n    else:\\r\\n        gender = \"FEMALE\"\\r\\n        expected_output = expected_output_female\\r\\n        \\r\\n    num_to_print = random.randint(5, 20)\\r\\n    output, error = autograder.run_script(\"Lists3_unpopularnames.py\", [gender, num_to_print])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    num_matches = autograder.compare_strings(lines, expected_output[:num_to_print])\\r\\n    \\r\\n    print()\\r\\n    \\r\\n    if len(lines) == 0:\\r\\n        return 0\\r\\n    elif len(lines) > len(expected_output[:num_to_print]):\\r\\n        print(\"Your program printed more lines than we expected\")\\r\\n        return round(100 * num_matches / len(lines), 1)\\r\\n    else:\\r\\n        return round(100.0/len(expected_output[:num_to_print]) * num_matches, 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Lists3_sat': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution():  \\r\\n    result = \\'\\'\\r\\n    file = open(\"sat.csv\", \"r\")\\r\\n    contents = file.read()\\r\\n    lines = contents.split(\"\\\\n\")\\r\\n\\r\\n    sat_table = []\\r\\n    total = 0\\r\\n\\r\\n    for line in lines:\\r\\n        line_components = line.split(\\',\\')\\r\\n        \\r\\n        school = line_components[0]\\r\\n        sat_score = int(line_components[1]) + int(line_components[2]) + int(line_components[3])\\r\\n        total += sat_score\\r\\n        row = [school, sat_score]\\r\\n        sat_table.append(row)\\r\\n\\r\\n    average = total / len(sat_table)\\r\\n\\r\\n    for row in sat_table:\\r\\n        if row[1] < average:\\r\\n            result += str(row[0]) + \"\\\\n\"\\r\\n\\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    expected_output = solution().strip().split(\\'\\\\n\\')\\r\\n    output, error = autograder.run_script(\"Lists3_sat.py\", [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    num_matches = autograder.compare_strings(lines, expected_output)\\r\\n    \\r\\n    print()\\r\\n    \\r\\n    if len(lines) == 0:\\r\\n        return 0\\r\\n    elif len(lines) > len(expected_output):\\r\\n        print(\"Your program printed more lines than we expected\")\\r\\n        return round(100 * num_matches / len(lines), 1)\\r\\n    else:\\r\\n        return round(100.0/len(expected_output) * num_matches, 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Lists3_popularnames': 'from cs110 import autograder\\r\\nimport random, math, traceback\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    test_cases = dict()\\r\\n    test_cases[(\"FEMALE\", 120)] = \"15\\\\n2670\"\\r\\n    test_cases[(\"FEMALE\", 98)] = \"25\\\\n3742\"   \\r\\n    test_cases[(\"MALE\", 190)] = \"1\\\\n224\"\\r\\n    test_cases[(\"MALE\", 130)] = \"7\\\\n1149\"\\r\\n\\r\\n    \\r\\n    test_case_input = list(test_cases.keys())\\r\\n    case_order = list(range(len(test_case_input)))\\r\\n    \\r\\n    score = 0\\r\\n    i = 1\\r\\n    \\r\\n    for idx in case_order:\\r\\n        print(\\'\\\\n\\' + \\'=\\'*30)\\r\\n        print(\"Test Case:\", i)\\r\\n        print(\\'=\\'*30)\\r\\n        \\r\\n        try: \\r\\n            output, error = autograder.run_script(\"Lists3_popularnames.py\", test_case_input[case_order[idx]])        \\r\\n            expected_output = test_cases[test_case_input[case_order[idx]]]\\r\\n            \\r\\n            lines = output.strip().split(\\'\\\\n\\')\\r\\n            expected_line_1 = expected_output.strip().split(\\'\\\\n\\')[0]\\r\\n            expected_line_2 = expected_output.strip().split(\\'\\\\n\\')[1]\\r\\n            \\r\\n            test_case_score = 0\\r\\n            if len(lines) == 0:\\r\\n                print(\"No Output Detected. Expected:\")\\r\\n                print(expected_output)\\r\\n            elif len(lines) > len(expected_output.split(\\'\\\\n\\')):\\r\\n                print(\"Your program printed too many lines. Expected:\")\\r\\n                print(expected_output)\\r\\n            elif len(lines) == 2 and expected_line_1 == lines[0] and expected_line_2 == lines[1]:\\r\\n                print(\"CORRECT!\")\\r\\n                test_case_score = 100.0 / len(test_cases)\\r\\n            elif expected_line_1 in lines:\\r\\n                print(\"PARTIALLY CORRECT! Count of names above threshold right. Expected:\")\\r\\n                test_case_score = 100.0 / len(test_cases) / 2\\r\\n                print(expected_output)\\r\\n            elif expected_line_2 in lines:\\r\\n                print(\"PARTIALLY CORRECT! Total number of children named found. Expected:\")\\r\\n                test_case_score = 100.0 / len(test_cases) / 2\\r\\n                print(expected_output)\\r\\n            else:\\r\\n                print(\"INCORRECT. Expected:\")\\r\\n                print(expected_output)\\r\\n            \\r\\n            score += test_case_score\\r\\n            i += 1\\r\\n        except Exception as e:\\r\\n            score += 0\\r\\n            i += 1\\r\\n            \\r\\n            print(\"An ERROR Occured:\", e)\\r\\n            print(traceback.print_exc())    \\r\\n\\r\\n\\r\\n    return score\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':\\r\\n    try:\\r\\n        result = test_passed()\\r\\n    except Exception as e:\\r\\n        result = 0\\r\\n        print(\"An ERROR Occured:\", e)\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Lists3_lowvolume': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nexpected_output = [\\r\\n\"700\",\\r\\n\"Harbor Ave\",\\r\\n\"Woodlawn Ave\",\\r\\n\"Root St\",\\r\\n\"Calumet Ave\",\\r\\n\"Financial PL\",\\r\\n\"16th St\",\\r\\n\"Racine Ave\",\\r\\n\"60th St\",\\r\\n\"Wentworth Ave\",\\r\\n\"Parnell Ave\",\\r\\n\"Ashland Ave\",\\r\\n\"Federal St\",\\r\\n\"Hamlin Ave\",\\r\\n\"Pitney Ct\",\\r\\n\"109th St\",\\r\\n\"Loomis St\",\\r\\n\"Harrison St\",\\r\\n\"24th St\",\\r\\n\"La Salle St\",\\r\\n\"83rd Pl\",\\r\\n\"Homan Ave\"]\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    \\r\\n    output, error = autograder.run_script(\"Lists3_lowvolume.py\", [])    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if \"700\" in lines[0]:\\r\\n        score += 50.0\\r\\n    \\r\\n        lines = set(lines[1:])\\r\\n        matches = (len(lines.intersection(expected_output)))\\r\\n        score += round((matches/21)*50.0,1)\\r\\n    else:\\r\\n        lines = set(lines)\\r\\n        matches = (len(lines.intersection(expected_output)))\\r\\n        score += round((matches/22)*50.0,1)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Lists3_averagetraffic': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nexpected_output = [\"525\"]\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    output, error = autograder.run_script(\"Lists3_averagetraffic.py\", [])\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_output)\\r\\n       \\r\\n    return round(num_matches * (100.0 / len(expected_output)), 1)\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Lists2_population': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\ndef solution(population):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    cities_table = [\\r\\n        [\\'Tokyo\\', 37435191],\\r\\n        [\\'Delhi\\', 29399141],\\r\\n        [\\'Shanghai\\', 25647805],\\r\\n        [\\'Sao Paulo\\', 21846507],\\r\\n        [\\'Mexico City\\', 21671908],\\r\\n        [\\'Cairo\\', 20484965],\\r\\n        [\\'Dhaka\\', 20283552],\\r\\n        [\\'Mumbai\\', 20185064],\\r\\n        [\\'Beijing\\', 20035455],\\r\\n        [\\'Osaka\\', 19222665]]\\r\\n    \\r\\n    for row in cities_table:\\r\\n        if row[1] >= population:\\r\\n            result += row[0] + \\'\\\\n\\'\\r\\n    \\r\\n    return result.strip()\\r\\n\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    random_population_size = random.randint(19, 30) * 1000000\\r\\n    \\r\\n    output, error = autograder.run_script(\"Lists2_population.py\", [random_population_size])\\r\\n    answer = solution(random_population_size)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, answer.strip().split(\\'\\\\n\\'))\\r\\n    \\r\\n    if num_matches == len(lines):\\r\\n        print(\"\\\\nCORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"\\\\nOne or more outputs were incorrect.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Lists2_movies': 'from cs110 import autograder\\r\\nimport random\\r\\ntry:\\r\\n    import Lists2_movies\\r\\nexcept:\\r\\n    import lists2_movies as Lists2_movies\\r\\n\\r\\ndef solution(movies_table, rating, runtime):\\r\\n    count = 0\\r\\n    \\r\\n    for row in movies_table:\\r\\n        if row[2] == rating and row[3] >= runtime:\\r\\n            count += 1\\r\\n    \\r\\n    return count\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    ratings = [\\'PG\\', \\'PG-13\\', \\'R\\']\\r\\n    num_passed = 0\\r\\n    \\r\\n    for rating in ratings:\\r\\n        movies_table = [\\r\\n            [\"Star Wars: A New Hope\", 1977, \"PG\", 121],\\r\\n            [\"Star Trek: The Motion Picture\", 1979, \"G\", 132],\\r\\n            [\"Raiders of the Lost Ark\", 1989, \"PG\", 115],\\r\\n            [\"Indiana Jones and the Temple of Doom\", 1984, \"PG\", 118],\\r\\n            [\"Indiana Jones and the Last Crusade\", 1989, \"PG-13\", 127],\\r\\n            [\"Serenity\", 2005, \"PG-13\", 119],\\r\\n            [\"Joker\", 2019, \"R\", 122],\\r\\n            [\"The Terminator\", 1984, \"R\", 107]\\r\\n            ]\\r\\n        test_table = []\\r\\n        runtime = random.randint(90, 120)\\r\\n        \\r\\n        for j in range(random.randint(2, 5)):\\r\\n            index = random.randint(0, len(movies_table)-1)\\r\\n            test_table.append(movies_table[index])\\r\\n            movies_table.remove(movies_table[index])\\r\\n        \\r\\n        print(\"Testing (Rating = \" + rating + \"):\\\\n\" + \"  Movie Table: \" + str(test_table) + \"\\\\n\" + \"  Runtime: \" + str(runtime))\\r\\n        print(\"  Expecting: \" + str(solution(test_table, rating, runtime)) + \"\\\\n  Your Function\\'s Output: \" + str(Lists2_movies.get_movies(test_table, rating, runtime)))\\r\\n        \\r\\n        if solution(test_table, rating, runtime) == Lists2_movies.get_movies(test_table, rating, runtime):\\r\\n            print(\"PASSED!\\\\n\")\\r\\n            num_passed += 1\\r\\n        else:\\r\\n            print(\"INCORRECT\\\\n\")\\r\\n            \\r\\n    \\r\\n    return (num_passed / len(ratings)) * 100.0\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Lists2_golf': 'from cs110 import autograder\\r\\nimport random, statistics\\r\\n\\r\\nsolution_name = \"Lists2_golf.py\"\\r\\n\\r\\n# random_names = [\\'Mcllroy\\', \\'Koepka\\', \\'Rahm\\', \\'Woods\\', \\'Thomas\\', \\'Johnson\\', \\'Cantlay\\', \\'Simpson\\']\\r\\n# \\r\\n# def get_random_name():\\r\\n#     global random_names\\r\\n#     name = random_names[random.randint(0, len(random_names)-1)]\\r\\n#     random_names.remove(name)\\r\\n#     return name\\r\\n# \\r\\n# \\r\\n# def solution(data):\\r\\n#     min_value = 99999\\r\\n#     min_name = \"\"\\r\\n#     count = 0\\r\\n#     \\r\\n#     for row in data:\\r\\n#         if row[1] < min_value:\\r\\n#             min_value = row[1]\\r\\n#             min_name = row[0]\\r\\n#     \\r\\n#     for row in data:\\r\\n#         if row[1] <= min_value + 5:\\r\\n#             count += 1\\r\\n# \\r\\n#     return min_name, (count / len(data) * 100.0)\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n       \\r\\n    test_cases = dict()\\r\\n    test_cases[(\"Simpson\", 70, \"Rahm\", 83, \"END\")] = \"Simpson\\\\n50.0\\\\n\"\\r\\n    test_cases[(\"Cantlay\", 80, \"Mcllroy\", 65, \"Rahm\", 66, \"END\")] = \"Mcllroy\\\\n66.7\\\\n\"\\r\\n    test_cases[(\"Koepka\", 74, \"Johnson\", 85, \"Thomas\", 84, \"Simpson\", 86, \"END\")] = \"Koepka\\\\n25.0\\\\n\"\\r\\n    test_cases[(\"Mcllroy\", 90, \"Koepka\", 80, \"Woods\", 84, \"Cantlay\", 72, \"Simpson\", 83, \"END\")] = \"Cantlay\\\\n20.0\\\\n\"\\r\\n    \\r\\n    test_case_input = list(test_cases.keys())\\r\\n    case_order = list(range(len(test_case_input)))\\r\\n    random.shuffle(case_order)\\r\\n    \\r\\n    score = 0\\r\\n\\r\\n    test_case_num = 1\\r\\n    for idx in case_order:\\r\\n        print(\\'\\\\n\\' + \\'=\\'*30)\\r\\n        print(\"Test Case:\", test_case_num)\\r\\n        print(\\'=\\'*30)\\r\\n        output, error_message = autograder.run_script(solution_name, test_case_input[case_order[idx]])\\r\\n        expected_output = test_cases[test_case_input[case_order[idx]]]  # solution(test_case_input[case_order[0]][0], test_case_input[case_order[0]][1], test_case_input[case_order[0]][2])\\r\\n        \\r\\n        lines = output.strip().split(\\'\\\\n\\')\\r\\n        expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n        if len(lines) == 1:\\r\\n            try:\\r\\n                student_output = float(lines[0])\\r\\n                if abs(student_output - float(expected_lines[1])) < 1.0:\\r\\n                    print(\"PARTIALLY CORRECT. Only Percentage Correct, Expected:\")\\r\\n                    score += 100.0 / len(test_cases) / 2\\r\\n            except:          \\r\\n                if lines[0] == expected_lines[0]:\\r\\n                    print(\"PARTIALLY CORRECT. Only Name Correct, Expected:\")\\r\\n                    score += 100.0 / len(test_cases) / 2               \\r\\n                else:\\r\\n                    print(\"INCORRECT: Expected the following:\")\\r\\n            print(expected_output)         \\r\\n        elif len(lines) == 2:\\r\\n            name_check_passed = lines[0] == expected_lines[0]\\r\\n            try:\\r\\n                percent_check_passed = abs(float(lines[1]) - float(expected_lines[1])) < 1.0\\r\\n            except:\\r\\n                percent_check_passed = False\\r\\n                print(\"Second Output NOT A VALID NUMBER\")\\r\\n            \\r\\n            if name_check_passed and percent_check_passed:\\r\\n                print(\"CORRECT Name and Percentage!\")\\r\\n                score += 100.0 / len(test_cases)\\r\\n            else:\\r\\n                if name_check_passed:\\r\\n                    print(\"PARTIALLY CORRECT. Only Name Correct, Expected:\")\\r\\n                    score += 100.0 / len(test_cases) / 2\\r\\n                elif percent_check_passed:\\r\\n                    print(\"PARTIALLY CORRECT. Only Percentage Correct, Expected:\")\\r\\n                    score += 100.0 / len(test_cases) / 2\\r\\n                else:\\r\\n                    print(\"INCORRECT: Expected the following:\")\\r\\n                print(expected_output)\\r\\n        else:\\r\\n            if len(lines) < 2:\\r\\n                print(\"Not Enough Lines. Expected:\")\\r\\n            else:\\r\\n                print(\"INCORRECT.  Expected the following:\")\\r\\n            print(expected_output)\\r\\n        \\r\\n        test_case_num += 1\\r\\n    \\r\\n    return score\\r\\n    \\r\\n    # Generates Random Values\\r\\n#     num_inputs = random.randint(2, 5)\\r\\n#     input_list = []\\r\\n#     data = []\\r\\n#         \\r\\n#     for i in range(num_inputs):\\r\\n#         new_row = [get_random_name(), random.randint(70, 90)]\\r\\n#         input_list.append(new_row[0])\\r\\n#         input_list.append(new_row[1])\\r\\n#         data.append(new_row)\\r\\n#     input_list.append(\"END\")\\r\\n#     \\r\\n#     lowest_name, percent = solution(data)\\r\\n#     \\r\\n#     # Runs the Script\\r\\n#     output, error_message = autograder.run_script(\"Lists2_golf.py\", input_list)\\r\\n#     lines = output.strip().split(\\'\\\\n\\')\\r\\n# \\r\\n#     # Checks Min\\r\\n#     if len(lines) < 2:\\r\\n#         print(\"Number of output lines does not match\")\\r\\n#         return 0\\r\\n#     else:\\r\\n#         if not lowest_name == lines[0]:\\r\\n#             print(\"Incorrect Name.  Expected \" + str(lowest_name))\\r\\n#             return 0\\r\\n#         if not autograder.equals(percent, lines[1]):\\r\\n#             print(\"Incorrect Percent.  Expected \" + str(percent))\\r\\n#             return 50\\r\\n#         \\r\\n#     print(\"PASSED!\")\\r\\n#     return 100\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'Lists2_credit': 'from cs110 import autograder\\r\\nimport random, statistics\\r\\n\\r\\nrandom_names = [\\'Gates\\', \\'Bezos\\', \\'Zuckerberg\\', \\'Ellison\\', \\'Page\\', \\'Brin\\', \\'Huateng\\', \\'Dell\\', \\'Musk\\', \\'Allen\\']\\r\\n\\r\\ndef get_random_name():\\r\\n    global random_names\\r\\n    name = random_names[random.randint(0, len(random_names)-1)]\\r\\n    random_names.remove(name)\\r\\n    return name\\r\\n\\r\\n\\r\\ndef solution(data):\\r\\n    highest_value = -99999\\r\\n    highest_name = \"\"\\r\\n    count = 0\\r\\n    \\r\\n    for row in data:\\r\\n        if row[1] > highest_value:\\r\\n            highest_value = row[1]\\r\\n            highest_name = row[0]\\r\\n    \\r\\n    for row in data:\\r\\n        if row[1] >= highest_value - 10000:\\r\\n            count += 1\\r\\n\\r\\n    return highest_name, (count / len(data) * 100.0)\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num_inputs = random.randint(5, 7)\\r\\n    input_list = []\\r\\n    data = []\\r\\n        \\r\\n    for i in range(num_inputs):\\r\\n        new_row = [get_random_name(), random.randint(5000, 35000)]\\r\\n        input_list.append(new_row[0])\\r\\n        input_list.append(new_row[1])\\r\\n        data.append(new_row)\\r\\n    input_list.append(\"DONE\")\\r\\n    \\r\\n    highest_balance, percent = solution(data)\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"Lists2_credit.py\", input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    # Checks Min\\r\\n    if len(lines) < 2:\\r\\n        print(\"Number of output lines does not match\")\\r\\n        return 0\\r\\n    else:\\r\\n        if not highest_balance == lines[0]:\\r\\n            print(\"Incorrect Highest Balance.  Expected \" + str(highest_balance))\\r\\n            return 0\\r\\n        if not autograder.equals(percent, lines[1]):\\r\\n            print(\"Incorrect Percent.  Expected \" + str(percent))\\r\\n            return 50\\r\\n        \\r\\n    print(\"PASSED!\")\\r\\n    return 100\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Lists2_100m': 'from cs110 import autograder\\r\\nimport random, statistics\\r\\n\\r\\nrandom_names = [\\'Alice\\', \\'Bob\\', \\'Courtney\\', \\'Devon\\', \\'Frank\\', \\'Genie\\']\\r\\n\\r\\ndef get_random_name():\\r\\n    global random_names\\r\\n    name = random_names[random.randint(0, len(random_names)-1)]\\r\\n    random_names.remove(name)\\r\\n    return name\\r\\n\\r\\ndef solution(data):\\r\\n    fastest_time = 99999\\r\\n    fastest_squadron = 0\\r\\n    total = 0\\r\\n    count = 0\\r\\n    \\r\\n    for row in data:\\r\\n        total += row[2]\\r\\n        if row[2] <= fastest_time:\\r\\n            fastest_time = row[2]\\r\\n            fastest_squadron = row[1]\\r\\n            \\r\\n    average = total / len(data)\\r\\n    \\r\\n    for row in data:\\r\\n        if row[2] <= average:\\r\\n            count += 1\\r\\n    \\r\\n    return fastest_squadron, fastest_time, count\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    # Generates Random Values\\r\\n    num_inputs = random.randint(2, 5)\\r\\n    input_list = [num_inputs]\\r\\n    data = []\\r\\n        \\r\\n    for i in range(num_inputs):\\r\\n        new_row = [get_random_name(), random.randint(1, 40), round(random.uniform(12, 18), 1)]\\r\\n        input_list.append(new_row[0])\\r\\n        input_list.append(new_row[1])\\r\\n        input_list.append(new_row[2])\\r\\n        data.append(new_row)\\r\\n    \\r\\n    fastest_squadron, fastest_time, count = solution(data)\\r\\n    \\r\\n    # Runs the Script\\r\\n    output, error_message = autograder.run_script(\"Lists2_100m.py\", input_list)\\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    # Checks Min\\r\\n    if len(lines) != 3:\\r\\n        print(\"Number of output lines does not match\")\\r\\n        return 0\\r\\n    else:\\r\\n        if not autograder.equals(fastest_squadron, lines[0]):\\r\\n            print(\"Incorrect Squadron.  Expected \" + str(fastest_squadron))\\r\\n            return 0\\r\\n        if not autograder.equals(fastest_time, lines[1]):\\r\\n            print(\"Incorrect Time.  Expected \" + str(fastest_time))\\r\\n            return 33\\r\\n        if not autograder.equals(count, lines[2]):\\r\\n            print(\"Incorrect Count.  Expected \" + str(count))\\r\\n            return 67\\r\\n        \\r\\n    print(\"PASSED!\")\\r\\n    return 100\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Lists1_pftscores': 'from cs110 import autograder\\r\\nimport random, math\\r\\n#import Lists1_pftscores\\r\\n\\r\\npft_scores = [243, 394, 143, 288, 303, 473, 325, 273, 284, 198, 70, 289, 437, 329]\\r\\n\\r\\n\\r\\ndef solution(new_num):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    # Append number to num_list ONLY IF IT IS A valid number > 0\\r\\n    if new_num >= 0 and new_num <= 500:\\r\\n\\r\\n        temp_scores = pft_scores.copy()\\r\\n        temp_scores.append(new_num)\\r\\n        \\r\\n        average = sum(temp_scores) / len(temp_scores)\\r\\n        num_range = max(temp_scores) - min(temp_scores)\\r\\n        \\r\\n        result += str(average) + \\'\\\\n\\'\\r\\n        result += str(num_range) + \\'\\\\n\\'\\r\\n    else:\\r\\n        result += \"Invalid score provided\"\\r\\n        \\r\\n    return result\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    # 5 test strategies\\r\\n    # 1) invalid, out of range low\\r\\n    # 2) invalid, out of range high\\r\\n    # 3) rand num that doesn\\'t affect range\\r\\n    # 4) rand num lower than current lowest, but valid\\r\\n    # 5) rand num higher than current highest, but valid\\r\\n    \\r\\n    min_score = min(pft_scores)\\r\\n    max_score = max(pft_scores)\\r\\n    \\r\\n    test_vals = []\\r\\n    \\r\\n    # random_low_invalid\\r\\n    test_vals.append(random.randint(-1010,-1))\\r\\n    #random_high_invalid\\r\\n    test_vals.append(random.randint(501,5000))\\r\\n    #random_mid_num\\r\\n    test_vals.append(random.randint(min_score, max_score))\\r\\n    #random_low\\r\\n    test_vals.append(random.randint(0, min_score-1))\\r\\n    #random_high\\r\\n    test_vals.append(random.randint(max_score + 1, 500))\\r\\n    \\r\\n    i = 0\\r\\n    total_score = 0.0\\r\\n    \\r\\n    for val in test_vals:\\r\\n        print(\\'-\\'*10 + \"Test #\" + str(i) + \\'-\\'*10)\\r\\n        \\r\\n        output, error_message = autograder.run_script(\"Lists1_pftscores.py\", [val])\\r\\n        expected_output = solution(val)\\r\\n        \\r\\n        lines = output.strip().split(\\'\\\\n\\')\\r\\n        \\r\\n        if expected_output.strip() == \"Invalid score provided\":\\r\\n            if output.strip() == expected_output.strip():\\r\\n                print(\"CORRECT\")\\r\\n                total_score += 100 / len(test_vals)\\r\\n            else:\\r\\n                print(\"INCORRECT. Expected the following:\")\\r\\n                print(expected_output)\\r\\n        else:\\r\\n            expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n            \\r\\n            if autograder.equals(float(expected_lines[0]), float(lines[0]), 0.99) and autograder.equals(float(expected_lines[1]), float(lines[1]), 0.99):\\r\\n                print(\"CORRECT\")\\r\\n                total_score += 100 / len(test_vals)\\r\\n            else:\\r\\n                print(\"INCORRECT. Expected the following:\")\\r\\n                print(expected_output)\\r\\n            \\r\\n        print()\\r\\n        i += 1\\r\\n    \\r\\n    return total_score\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Lists1_listrange': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n\\r\\ndef solution(test_start, test_stop):\\r\\n    result = []\\r\\n    \\r\\n    result.append(list(range(test_start, test_stop+1)))\\r\\n    result.append(len(range(test_start, test_stop+1)))\\r\\n        \\r\\n    return result\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    # 5 test strategies\\r\\n    test_vals = []\\r\\n    \\r\\n    for j in range(5):\\r\\n        test_val_start = random.randint(0,2048)\\r\\n        test_val_stop = test_val_start + random.randint(9,16)\\r\\n        test_vals.append((test_val_start, test_val_stop))\\r\\n  \\r\\n    i = 0\\r\\n    total_score = 0.0\\r\\n    \\r\\n    for val in test_vals:\\r\\n        print(\\'-\\'*10 + \"Test #\" + str(i) + \\'-\\'*10)\\r\\n        \\r\\n        output, error_message = autograder.run_script(\"Lists1_listrange.py\", [val[0], val[1]])\\r\\n        expected_output = solution(val[0], val[1])\\r\\n        \\r\\n        lines = output.strip().split(\\'\\\\n\\')\\r\\n        \\r\\n        idx = 0\\r\\n        count_correct_lines = 0\\r\\n        if len(lines) != 2:\\r\\n            print(\"Missing/Extra Output - Expecting a list and then its length on next line\")\\r\\n            \\r\\n        for line in lines:\\r\\n            if line.strip() == str(expected_output[idx]): # and autograder.equals(int(lines[1]), expected_output[1]):\\r\\n                total_score += 50.0 / len(test_vals)\\r\\n                count_correct_lines += 1\\r\\n            else:\\r\\n                print(\"INCORRECT Value:\", line)\\r\\n                print(\"Expecting Value:\", expected_output[idx])\\r\\n            \\r\\n            idx += 1\\r\\n            \\r\\n        if count_correct_lines == 2:\\r\\n            print(\"CORRECT\")\\r\\n        print()\\r\\n        i += 1\\r\\n    \\r\\n    return total_score\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Lists1_fastestcar': 'from cs110 import autograder\\r\\nimport random, math\\r\\ntry:\\r\\n    import Lists1_fastestcar as student_module\\r\\nexcept:\\r\\n    try:\\r\\n        import lists1_fastestcar as student_module\\r\\n    except Exception as e:\\r\\n        print(\"Import ERROR:\", e)\\r\\n\\r\\ndef solution(car1, car2):\\r\\n\\r\\n    if car1[2] > car2[2]:\\r\\n        return car1[0]\\r\\n    elif car2[2] > car1[2]:\\r\\n        return car2[0]\\r\\n    else:\\r\\n        return \"Same speed\"\\r\\n\\r\\ndef test_passed():\\r\\n    \\r\\n    # 5 test strategies\\r\\n    cars_list = []\\r\\n    cars_list.append([\"Honda Civic\", 18983.20, 127])\\r\\n    cars_list.append([\"Acura NSX\", 157500.39, 191])\\r\\n    cars_list.append([\"VW Golf GTI\", 28595.83, 130])\\r\\n    cars_list.append([\"Ford F-150 Raptor\", 45290.82, 107])\\r\\n    cars_list.append([\"Subaru BRZ\", 28955.38, 140])\\r\\n    cars_list.append([\"Mazda Mazdaspeed3\", 17424.30, 130])\\r\\n    \\r\\n    test_vals = []\\r\\n    \\r\\n    index_permutations = []\\r\\n    # build all possible permutations except those with the same vehicle\\r\\n    for i in range(len(cars_list)):\\r\\n        for j in range(len(cars_list)):\\r\\n            if i != j:\\r\\n                index_permutations.append((i,j))\\r\\n    \\r\\n    # randomly choose 4 of the permutations\\r\\n    for i in range(4):\\r\\n        car_idx_pair = index_permutations[random.randint(0,len(index_permutations)-1)]\\r\\n        first_car_idx = car_idx_pair[0]\\r\\n        second_car_idx = car_idx_pair[1]\\r\\n        \\r\\n        index_permutations.remove(car_idx_pair)\\r\\n        \\r\\n        test_vals.append([cars_list[first_car_idx], cars_list[second_car_idx]])\\r\\n\\r\\n    # same speed\\r\\n    test_vals.append((cars_list[2], cars_list[5]))\\r\\n  \\r\\n    i = 0\\r\\n    total_score = 0.0\\r\\n    \\r\\n    for val in test_vals:\\r\\n        print(\\'-\\'*10 + \"Test #\" + str(i) + \\'-\\'*10)\\r\\n        \\r\\n        try:\\r\\n            output = student_module.fastest_car(val[0], val[1])\\r\\n            expected_output = solution(val[0], val[1])\\r\\n\\r\\n            print(\"Your Program\\'s Output:\")\\r\\n            print(output)\\r\\n\\r\\n            if output == None:\\r\\n                print(\"INCORRECT - Your function did not return anything. \\\\nExpected:\")\\r\\n                print(str(expected_output))\\r\\n            elif output.strip() == expected_output.strip():\\r\\n                print(\"CORRECT\")\\r\\n                total_score += 100.0 / len(test_vals)\\r\\n            else:\\r\\n                print(\"INCORRECT - Expected:\")\\r\\n                print(str(expected_output))\\r\\n        except Exception as e:\\r\\n            print(\"There was an error when testing your solution.\")\\r\\n            print(e)\\r\\n            \\r\\n        print()\\r\\n        i += 1\\r\\n    \\r\\n    return total_score\\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'IterLogic2_timestable': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(multiple):\\r\\n    result = \\'\\'\\r\\n    i = 1\\r\\n    \\r\\n    while i <= 10:\\r\\n        result += str(i * multiple) + \"\\\\n\"\\r\\n        i += 1\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_multiple = random.randint(1, 20)\\r\\n\\r\\n    output, error_message = autograder.run_script(\"IterLogic2_timestable.py\", [random_multiple])\\r\\n    expected_output = solution(random_multiple)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'IterLogic2_printchars': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(start_char, end_char):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    start_char = ord(start_char)\\r\\n    end_char = ord(end_char)\\r\\n    \\r\\n    if start_char < end_char:\\r\\n        for i in range(start_char, end_char+1, 1):\\r\\n            result += chr(i) + \\'\\\\n\\'\\r\\n    else:\\r\\n        for i in range(start_char, end_char-1, -1):\\r\\n            result += chr(i) + \\'\\\\n\\'\\r\\n\\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    print(\"# ------------------------------------------\")\\r\\n    print(\"# Test 1:  First letter lower than second\")\\r\\n    print(\"# ------------------------------------------\")\\r\\n    start_char = chr(random.randint(65, 85))\\r\\n    end_char   = chr(random.randint(ord(start_char), 90))\\r\\n\\r\\n    output, error_message = autograder.run_script(\"IterLogic2_printchars.py\", [start_char, end_char])\\r\\n    expected_output = solution(start_char, end_char)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n        \\r\\n    \\r\\n    print(\"# ------------------------------------------\")\\r\\n    print(\"# Test 2:  First letter higher than second\")\\r\\n    print(\"# ------------------------------------------\")\\r\\n    start_char = chr(random.randint(85, 90))\\r\\n    end_char   = chr(random.randint(65, 84))\\r\\n\\r\\n    output, error_message = autograder.run_script(\"IterLogic2_printchars.py\", [start_char, end_char])\\r\\n    expected_output = solution(start_char, end_char)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'IterLogic2_football': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    num_entries = random.randint(1, 6)\\r\\n    num_above_5000 = random.randint(0, num_entries)\\r\\n    list_of_values = [num_entries]\\r\\n    \\r\\n    for i in range(num_entries):\\r\\n        if i < num_above_5000:\\r\\n            list_of_values.append(random.randint(5001, 8000))\\r\\n        elif i == num_above_5000:\\r\\n            list_of_values.append(5000)\\r\\n        else:\\r\\n            list_of_values.append(random.randint(1, 5000))\\r\\n    \\r\\n    average = sum(list_of_values[1:])/num_entries\\r\\n    min_value = min(list_of_values[1:])\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"IterLogic2_football.py\", list_of_values)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if len(lines) >= 1 and autograder.equals(lines[0], num_above_5000):\\r\\n        print(\"Number Above 5000 Looks Good\")\\r\\n        score += 33\\r\\n    else:\\r\\n        print(\"Number Above 5000 is Incorrect (or Missing)\")\\r\\n    \\r\\n    if len(lines) >= 2 and autograder.equals(lines[1], average):\\r\\n        print(\"Average Looks Good\")\\r\\n        score += 33\\r\\n    else:\\r\\n        print(\"Average is Incorrect (or Missing)\")\\r\\n    \\r\\n    if len(lines) >= 3 and autograder.equals(lines[2], min_value):\\r\\n        print(\"Min Value Looks Good\")\\r\\n        score += 34\\r\\n    else:\\r\\n        print(\"Min Value is Incorrect (or Missing)\")\\r\\n        \\r\\n    return score\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'IterLogic2_counting': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# def solution(random_start, random_end, random_increment):\\r\\n#     result = \\'\\'\\r\\n# \\r\\n#     for i in range(random_start, random_end+1, random_increment):\\r\\n#         result += str(i) + \"\\\\n\"\\r\\n#         print(\"Result adding:\", i)\\r\\n# \\r\\n#     return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_start = random.randint(0, 10)\\r\\n    random_end = random.randint(50, 100)\\r\\n    random_increment = random.randint(2, 9)\\r\\n    \\r\\n    test_cases = dict()\\r\\n    test_cases[(42, 47, 1)] = \"42\\\\n43\\\\n44\\\\n45\\\\n46\\\\n47\\\\n\"\\r\\n    test_cases[(8, 92, 7)] = \"8\\\\n15\\\\n22\\\\n29\\\\n36\\\\n43\\\\n50\\\\n57\\\\n64\\\\n71\\\\n78\\\\n85\\\\n92\\\\n\"\\r\\n    test_cases[(5, 62, 8)] = \"5\\\\n13\\\\n21\\\\n29\\\\n37\\\\n45\\\\n53\\\\n61\\\\n\"\\r\\n    test_cases[(10, 64, 9)] = \"10\\\\n19\\\\n28\\\\n37\\\\n46\\\\n55\\\\n64\\\\n\"\\r\\n    test_cases[(5, -7, -2)] = \"5\\\\n3\\\\n1\\\\n-1\\\\n-3\\\\n-5\\\\n-7\\\\n\"\\r\\n    \\r\\n    test_case_input = list(test_cases.keys())\\r\\n    case_order = list(range(len(test_case_input)))\\r\\n    random.shuffle(case_order)\\r\\n    \\r\\n    score = 0\\r\\n\\r\\n    i = 1\\r\\n    for idx in case_order:\\r\\n        print(\\'\\\\n\\' + \\'=\\'*30)\\r\\n        print(\"Test Case:\", i)\\r\\n        print(\\'=\\'*30)\\r\\n        output, error_message = autograder.run_script(\"IterLogic2_counting.py\", test_case_input[case_order[idx]])\\r\\n        expected_output = test_cases[test_case_input[case_order[idx]]]  # solution(test_case_input[case_order[0]][0], test_case_input[case_order[0]][1], test_case_input[case_order[0]][2])\\r\\n        \\r\\n        lines = output.strip().split(\\'\\\\n\\')\\r\\n        last_line = lines[len(lines)-1]\\r\\n\\r\\n        if output.strip() == expected_output.strip():\\r\\n            print(\"CORRECT\")\\r\\n            score += 20\\r\\n        else:\\r\\n            print(\"INCORRECT.  Expected the following:\")\\r\\n            print(expected_output)\\r\\n        \\r\\n        i += 1\\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)',\n",
       "  'IterLogic2_coordinates': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(start_x, end_x, start_y, end_y):\\r\\n    result = \\'\\'\\r\\n\\r\\n    for y in range(start_y, end_y+1):\\r\\n        for x in range(start_x, end_x+1):\\r\\n            result += str(x) + \" \" + str(y) + \"\\\\n\"\\r\\n\\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    start_x = random.randint(-2, -1)\\r\\n    end_x = random.randint(1, 2)\\r\\n    start_y = random.randint(-3, -1)\\r\\n    end_y = random.randint(1, 3)\\r\\n\\r\\n    output, error_message = autograder.run_script(\"IterLogic2_coordinates.py\", [start_x, end_x, start_y, end_y])\\r\\n    expected_output = solution(start_x, end_x, start_y, end_y)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    num_matches = autograder.compare_strings(lines, expected_output.strip().split(\\'\\\\n\\'))\\r\\n\\r\\n    return 100 * (num_matches / len(lines))\\r\\n\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'IterLogic2_class2017': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    num_entries = random.randint(1, 6)\\r\\n    num_in_2017 = random.randint(0, num_entries)\\r\\n    list_of_values = [num_entries]\\r\\n    \\r\\n    for i in range(num_entries):\\r\\n        if i < num_in_2017:\\r\\n            list_of_values.append(2017)\\r\\n        else:\\r\\n            list_of_values.append(random.randint(2018, 2024))\\r\\n        \\r\\n    output, error_message = autograder.run_script(\"IterLogic2_class2017.py\", list_of_values)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n\\r\\n    if len(lines) >= 1 and autograder.equals(lines[0], num_in_2017):\\r\\n        print(\"CORRECT\")\\r\\n        score += 100\\r\\n    else:\\r\\n        print(\"Expected\", num_in_2017)\\r\\n        \\r\\n    return score\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'IterLogic1_waittimes': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0.0\\r\\n    \\r\\n    possible_tests = [[30, 45, 15, 5, 5, -999], [15, 30, 31, 29, 120, 90, -999]]\\r\\n    possible_output = [[5, 1], [15, 3]]\\r\\n    \\r\\n    # Generates a Random Test\\r\\n    random_index = random.randint(0, len(possible_tests)-1)\\r\\n    random_test = possible_tests[random_index]\\r\\n    expected_output = possible_output[random_index]\\r\\n            \\r\\n    output, error = autograder.run_script(\"IterLogic1_waittimes.py\", random_test)\\r\\n    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Min Wait Time is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Min Wait Time is Incorrect.  Expected\", expected_output[0])\\r\\n        \\r\\n    if len(lines) > 1 and autograder.equals(lines[1], expected_output[1]):\\r\\n        print(\"Number of Lines With Over 30 Minute Wait Times is Correct\")\\r\\n        score += 50\\r\\n    else:\\r\\n        print(\"Number of Lines With Over 30 Minute Wait Times is Incorrect.  Expected\", expected_output[1])\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'IterLogic1_squadrons': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0.0\\r\\n    \\r\\n    possible_tests = [[5, 10, 20, 30, 40, 19], [8, 3, 1, 23, 37, 40, 7, 6, 25]]\\r\\n    possible_output = [[1, 2, 1, 1], [4, 0, 2, 2]]\\r\\n    \\r\\n    # Generates a Random Test\\r\\n    random_index = random.randint(0, len(possible_tests)-1)\\r\\n    random_test = possible_tests[random_index]\\r\\n    expected_output = possible_output[random_index]\\r\\n            \\r\\n    output, error = autograder.run_script(\"IterLogic1_squadrons.py\", random_test)\\r\\n    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Num in Group One is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Num in Group One is Incorrect.  Expected\", expected_output[0])\\r\\n        \\r\\n    if len(lines) > 1 and autograder.equals(lines[1], expected_output[1]):\\r\\n        print(\"Num in Group Two is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Num in Group Two is Incorrect.  Expected\", expected_output[1])\\r\\n    \\r\\n    if len(lines) > 2 and autograder.equals(lines[2], expected_output[2]):\\r\\n        print(\"Num in Group Three is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Num in Group Three is Incorrect.  Expected\", expected_output[2])\\r\\n    \\r\\n    if len(lines) > 3 and autograder.equals(lines[3], expected_output[3]):\\r\\n        print(\"Num in Group Four is Correct\")\\r\\n        score += 25\\r\\n    else:\\r\\n        print(\"Num in Group Four is Incorrect.  Expected\", expected_output[3])\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'IterLogic1_dvc': 'from IterLogic1_dvc import get_years_until\\r\\nfrom cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\nNUM_SUBTESTS = 5\\r\\n\\r\\ndef soln(target_value):\\r\\n    maintenance_fee = 623.00\\r\\n    interest_rate = 0.015\\r\\n    count = 0\\r\\n\\r\\n    while maintenance_fee < target_value:\\r\\n        count += 1\\r\\n        maintenance_fee = maintenance_fee * (1 + interest_rate)\\r\\n    \\r\\n    return count\\r\\n\\r\\ndef test_passed():\\r\\n    passed = 0\\r\\n    for i in range(NUM_SUBTESTS):\\r\\n        print(\\'Running test %d of %d:\\' % (i+1 , NUM_SUBTESTS), end=\\'\\')\\r\\n        target_amount = random.randint(650, 1100)\\r\\n        if autograder.equals(get_years_until(target_amount), soln(target_amount)):\\r\\n            print(\"  It will take \" + str(get_years_until(target_amount)) + \" years until the maintenance fee exceeds $\" + str(target_amount))\\r\\n            passed += 1\\r\\n        else:\\r\\n            print(\\'  get_years_until(%d) incorrectly returned %d instead of %d\\\\n\\' % (target_amount, get_years_until(target_amount), soln(target_amount)))\\r\\n    \\r\\n    return round((100 / NUM_SUBTESTS), 1) * passed\\r\\n\\r\\n\\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'IterLogic1_countby10s': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(starting_value, value_to_count_to):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    if value_to_count_to < starting_value:\\r\\n        return \"Second integer can\\'t be less than the first.\"\\r\\n    else:\\r\\n        i = starting_value\\r\\n        \\r\\n        while i <= value_to_count_to:\\r\\n            result += str(i) + \"\\\\n\"\\r\\n            i += 10\\r\\n        \\r\\n        return result\\r\\n\\r\\ndef run_test(random_starting_number, random_ending_number):\\r\\n    print(\"#--------------------------------------------\")\\r\\n    print(\"# Testing\", random_starting_number, \"to\", random_ending_number)\\r\\n    print(\"#--------------------------------------------\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"IterLogic1_countby10s.py\", [random_starting_number, random_ending_number])\\r\\n    expected_output = solution(random_starting_number, random_ending_number)\\r\\n    \\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\\\\n\")\\r\\n        return True\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n        print()\\r\\n    \\r\\n    return False\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    \\r\\n    if run_test(10 * random.randint(1, 5), 60 + 10 * random.randint(1, 20)):\\r\\n        score += 40\\r\\n        \\r\\n    if run_test(random.randint(0, 30), random.randint(31, 200)):\\r\\n        score += 40\\r\\n    \\r\\n    if run_test(random.randint(50, 100), random.randint(0, 10)):\\r\\n        score += 20\\r\\n    \\r\\n    \\r\\n    return score\\r\\n\\r\\n        \\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'IterLogic1_count': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(value_to_count_to, increment):\\r\\n    result = \\'\\'\\r\\n    i = 0\\r\\n    \\r\\n    while i <= value_to_count_to:\\r\\n        result += str(i) + \"\\\\n\"\\r\\n        i += increment\\r\\n    \\r\\n    return result\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_ending_number = 10 + 2 * random.randint(1, 10)\\r\\n    random_increment = 2\\r\\n\\r\\n    output, error_message = autograder.run_script(\"IterLogic1_count.py\", [random_ending_number, random_increment])\\r\\n    expected_output = solution(random_ending_number, random_increment)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    last_line = lines[len(lines)-1]\\r\\n\\r\\n    if output.strip() == expected_output.strip():\\r\\n        print(\"CORRECT\")\\r\\n        return 100\\r\\n    else:\\r\\n        print(\"INCORRECT.  Expected the following:\")\\r\\n        print(expected_output)\\r\\n    \\r\\n    return 0\\r\\n\\r\\n        \\r\\n# Testbench (to run on outside of zyBooks)\\r\\nif __name__ == \\'__main__\\':   \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'IterLogic1_cargocapacity': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0.0\\r\\n    \\r\\n    possible_tests = [[8000, 12000, 25000, 10000, 7500, -1], [5000, 9000, 22000, 10000, 8700, -1], [9999, 5000, 3000, -1]]\\r\\n    possible_output = [[7500, 25000, 3], [5000, 22000, 2], [3000, 9999, 0]]\\r\\n    \\r\\n    # Generates a Random Test\\r\\n    random_index = random.randint(0, len(possible_tests)-1)\\r\\n    random_test = possible_tests[random_index]\\r\\n    expected_output = possible_output[random_index]\\r\\n            \\r\\n    output, error = autograder.run_script(\"IterLogic1_cargocapacity.py\", random_test)\\r\\n    \\r\\n    lines = output.split(\\'\\\\n\\')\\r\\n    \\r\\n    if len(lines) > 0 and autograder.equals(lines[0], expected_output[0]):\\r\\n        print(\"Min Value is Correct\")\\r\\n        score += 30\\r\\n    else:\\r\\n        print(\"Min Value is Incorrect.  Expected\", expected_output[0])\\r\\n    \\r\\n    if len(lines) > 1 and autograder.equals(lines[1], expected_output[1]):\\r\\n        print(\"Max Value is Correct\")\\r\\n        score += 30\\r\\n    else:\\r\\n        print(\"Max Value is Incorrect.  Expected\", expected_output[1])\\r\\n        \\r\\n    if len(lines) > 2 and autograder.equals(lines[2], expected_output[2]):\\r\\n        print(\"Number of Aircraft with At Least 10000 lbs is Correct\")\\r\\n        score += 40\\r\\n    else:\\r\\n        print(\"Number of Aircraft with At Least 10000 lbs is Incorrect.  Expected\", expected_output[2])\\r\\n    \\r\\n    return score\\r\\n\\r\\n\\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'IterLogic1_averagerun': 'from cs110 import autograder\\r\\nimport random\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    NUM_TESTS = 5\\r\\n    num_tests_passed = 0\\r\\n\\r\\n    for i in range(NUM_TESTS):\\r\\n        print(\"Running Test \" + str(i) + \":\")\\r\\n        \\r\\n        num_inputs = random.randint(2, 11)\\r\\n        inputs = [num_inputs]\\r\\n        sum = 0\\r\\n        \\r\\n        for j in range(num_inputs):\\r\\n            value = random.randint(70, 130)\\r\\n            sum += value\\r\\n            inputs.append(value)\\r\\n               \\r\\n        avg = sum / (len(inputs) - 1)   \\r\\n               \\r\\n        # Runs the Script\\r\\n        output, error_message = autograder.run_script(\"IterLogic1_averagerun.py\", inputs)\\r\\n        \\r\\n        # Extracts the Output\\r\\n        lines = output.split(\"\\\\n\")\\r\\n        \\r\\n        if (len(lines) > 0):            \\r\\n            if (autograder.equals(lines[0], avg)):\\r\\n                print(\"CORRECT\\\\n\")\\r\\n                num_tests_passed += 1\\r\\n            else:\\r\\n                print(\"INCORRECT.  Expected: \" + str(avg) + \"\\\\n\")\\r\\n\\r\\n    # Result\\r\\n    return (100 / NUM_TESTS) * num_tests_passed\\r\\n            \\r\\n\\r\\n# Testbench (to be run on windows)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Graphics3_soundboard': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"Graphics3_soundboard.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Graphics3_paint': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"Graphics3_paint.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Graphics2_bouncingtriangle': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"Graphics2_bouncingtriangle.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'Graphics2_bouncingball': 'from cs110 import autograder\\r\\nimport random, math, py_compile\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    try:       \\r\\n        py_compile.compile(\"Graphics2_bouncingball.py\", doraise=True)\\r\\n        print(\"Thank you for your submission. Your instructor will let you know if there is a problem.\")\\r\\n        return 100.0\\r\\n    except:\\r\\n        print(\"There appears to be a syntax error in your code.\")\\r\\n        return 0.0\\r\\n    \\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'FileIO_titanicsurvivor': 'from cs110 import autograder\\r\\nimport random, math, os.path\\r\\n\\r\\nlowest_fare = 9999999\\r\\nlowest_fare_name = \\'\\'\\r\\n\\r\\ndef solution(filename):\\r\\n    global lowest_fare, lowest_fare_name\\r\\n\\r\\n    file = open(filename, \\'r\\')\\r\\n    file_contents = file.read()\\r\\n    lines_in_file = file_contents.split(\\'\\\\n\\')\\r\\n    result = \\'\\'\\r\\n\\r\\n    for line in lines_in_file:\\r\\n        line_components = line.split(\\',\\')\\r\\n        \\r\\n        survived = line_components[0] == \\'1\\'\\r\\n        name = line_components[2]\\r\\n        fare = float(line_components[7])\\r\\n        \\r\\n        if survived == True:\\r\\n            if fare < lowest_fare:\\r\\n                lowest_fare = fare\\r\\n                lowest_fare_name = name\\r\\n\\r\\n    file.close()\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n   \\r\\n    \\r\\n    # Deletes Result.txt if it already exists\\r\\n    if (os.path.exists(\"result.txt\")):\\r\\n        os.remove(\"result.txt\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"FileIO_titanicsurvivor.py\", [\"titanic2.csv\"])\\r\\n    \\r\\n    # Checks to see if the file was created by the program\\r\\n    if (not os.path.exists(\"result.txt\")):\\r\\n        print(\"result.txt is missing\")\\r\\n    else:\\r\\n        solution(\"titanic2.csv\")\\r\\n        \\r\\n        file = open(\"result.txt\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        lines = file_contents.strip().split(\\'\\\\n\\')\\r\\n        \\r\\n        if len(lines) < 2:\\r\\n            print(\"ERROR: Missing lines in result.txt file, Expected 2!\")\\r\\n        else:\\r\\n            if lines[0] == lowest_fare_name:\\r\\n                print(\"Correct Passenger\")\\r\\n                score += 50\\r\\n            else:\\r\\n                print(\"Incorrect Passenger\", lowest_fare_name)\\r\\n            \\r\\n            if autograder.equals(lines[1], lowest_fare):\\r\\n                print(\"Correct Lowest Fare\")\\r\\n                score += 50\\r\\n            else:\\r\\n                print(\"Incorrect Lowest Fare.\", lowest_fare)\\r\\n    \\r\\n    return score\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'FileIO_titanicfares': 'from cs110 import autograder\\r\\nimport random, math, os.path\\r\\n\\r\\nhighest_fare = 0\\r\\nlowest_fare = 9999999\\r\\n\\r\\ndef solution(filename, passenger_class):\\r\\n    global highest_fare, lowest_fare\\r\\n\\r\\n    file = open(filename, \\'r\\')\\r\\n    file_contents = file.read()\\r\\n    lines_in_file = file_contents.split(\\'\\\\n\\')\\r\\n    result = \\'\\'\\r\\n\\r\\n    for line in lines_in_file:\\r\\n        line_components = line.split(\\',\\')\\r\\n        \\r\\n        p_class = int(line_components[1])\\r\\n        fare = float(line_components[7])\\r\\n        \\r\\n        if passenger_class == p_class:\\r\\n            if fare > highest_fare:\\r\\n                highest_fare = fare\\r\\n            if fare < lowest_fare:\\r\\n                lowest_fare = fare\\r\\n\\r\\n    file.close()\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    random_passenger_class = random.randint(1, 3)\\r\\n    \\r\\n    # Deletes Result.txt if it already exists\\r\\n    if (os.path.exists(\"result.txt\")):\\r\\n        os.remove(\"result.txt\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"FileIO_titanicfares.py\", [\"titanic2.csv\", random_passenger_class])\\r\\n    \\r\\n    # Checks to see if the file was created by the program\\r\\n    if (not os.path.exists(\"result.txt\")):\\r\\n        print(\"result.txt is missing\")\\r\\n    else:\\r\\n        solution(\"titanic2.csv\", random_passenger_class)\\r\\n        \\r\\n        file = open(\"result.txt\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        lines = file_contents.strip().split(\\'\\\\n\\')\\r\\n        if len(lines) < 2:\\r\\n            print(\"Not enough lines in result.txt\")\\r\\n        \\r\\n        if autograder.equals(lines[0], highest_fare):\\r\\n            print(\"Correct Highest Fare\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"Incorrect Highest Fare.  Expected:\", highest_fare)\\r\\n        \\r\\n        if autograder.equals(lines[1], lowest_fare):\\r\\n            print(\"Correct Lowest Fare\")\\r\\n            score += 50\\r\\n        else:\\r\\n            print(\"Incorrect Lowest Fare.  Expected:\", lowest_fare)\\r\\n    \\r\\n    return score\\r\\n    \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'FileIO_survivors_by_gender': 'from cs110 import autograder\\r\\nimport random, math, os.path\\r\\n\\r\\nnum_males = 0\\r\\nnum_females = 0\\r\\n\\r\\ndef solution(filename):\\r\\n    global num_males, num_females\\r\\n\\r\\n    input_file = open(filename, \"r\")\\r\\n    contents = input_file.read()\\r\\n    lines = contents.split(\"\\\\n\")\\r\\n\\r\\n    for line in lines:\\r\\n        line_components = line.split(\\',\\')\\r\\n        \\r\\n        if line_components[0] == \\'1\\' and line_components[3] == \\'male\\':\\r\\n            num_males += 1\\r\\n        if line_components[0] == \\'1\\' and line_components[3] == \\'female\\':\\r\\n            num_females += 1\\r\\n\\r\\n    input_file.close()\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    score = 0\\r\\n    \\r\\n    # Deletes Result.txt if it already exists\\r\\n    if (os.path.exists(\"result.txt\")):\\r\\n        os.remove(\"result.txt\")\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"FileIO_survivors_by_gender.py\", [\"titanic.csv\"])\\r\\n    \\r\\n    # Checks to see if the file was created by the program\\r\\n    if (not os.path.exists(\"result.txt\")):\\r\\n        print(\"result.txt is missing\")\\r\\n    else:\\r\\n        solution(\"titanic.csv\")\\r\\n        \\r\\n        file = open(\"result.txt\", \"r\")\\r\\n        file_contents = file.read()\\r\\n        lines = file_contents.strip().split(\\'\\\\n\\')\\r\\n        if len(lines) < 2:\\r\\n            print(\"Not enough lines in result.txt\")\\r\\n        else:    \\r\\n            if autograder.equals(lines[0], num_males):\\r\\n                print(\"Correct Number of Males:\")\\r\\n                score += 50\\r\\n            else:\\r\\n                print(\"Incorrect Number of Males\")\\r\\n            \\r\\n            if autograder.equals(lines[1], num_females):\\r\\n                print(\"Correct Number of Females\")\\r\\n                score += 50\\r\\n            else:\\r\\n                print(\"Incorrect Number of Females\")\\r\\n    \\r\\n    return score\\r\\n    \\r\\n    \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'FileIO_runways': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(filename, length, width):\\r\\n    file = open(filename, \\'r\\')\\r\\n    file_contents = file.read()\\r\\n    lines_in_file = file_contents.split(\\'\\\\n\\')\\r\\n    result = \\'\\'\\r\\n\\r\\n    for line in lines_in_file:\\r\\n        columns = line.split(\\',\\')\\r\\n        if length <= float(columns[2]) and width <= float(columns[3]):\\r\\n            result += columns[0] + \"\\\\n\"\\r\\n\\r\\n    file.close()\\r\\n    \\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_length = random.randint(3000, 4000)\\r\\n    random_width = random.randint(100, 200)\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"FileIO_runways.py\", [\"runways.csv\", random_length, random_width])\\r\\n    expected_output = solution(\"runways.csv\", random_length, random_width)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_lines)\\r\\n    \\r\\n    if num_matches == len(lines):\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT\")\\r\\n        return 0.0\\r\\n        \\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'FileIO_echo': 'from cs110 import autograder\\r\\nimport random, math\\r\\n\\r\\ndef solution(filename, letter):\\r\\n    result = \\'\\'\\r\\n    \\r\\n    file = open(filename, \"r\")\\r\\n    contents = file.read()\\r\\n    lines = contents.split(\"\\\\n\")\\r\\n\\r\\n    for line in lines:\\r\\n        if line[0] == letter:\\r\\n            result += line + \"\\\\n\"\\r\\n\\r\\n    file.close()\\r\\n\\r\\n    return result\\r\\n\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    \\r\\n    random_letter = chr(random.randint(97, 122))\\r\\n    \\r\\n    output, error_message = autograder.run_script(\"FileIO_echo.py\", [\"file.txt\", random_letter])\\r\\n    expected_output = solution(\"file.txt\", random_letter)\\r\\n    \\r\\n    lines = output.strip().split(\\'\\\\n\\')\\r\\n    expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n    \\r\\n    num_matches = autograder.compare_strings(lines, expected_lines)\\r\\n    \\r\\n    if num_matches == len(lines):\\r\\n        print(\"CORRECT\")\\r\\n        return 100.0\\r\\n    else:\\r\\n        print(\"INCORRECT\")\\r\\n        return 0.0\\r\\n        \\r\\n\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a3_3_chars3': 'from cs110 import autograder\\r\\nimport random, math, traceback\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    try:        \\r\\n        output, error = autograder.run_script(\"a3_3_chars3.py\", [])\\r\\n        expected_output = \"sp\\\\njm\\\\nbt\\\\ncv\\\\nti\\\\nnn\\\\nig\\\\nau\\\\nhi\\\\nvc\\\\nom\\\\npf\\\\ntk\\\\nve\\\\nxd\\\\nsj\\\\nbg\\\\npk\\\\nrk\\\\nvy\\\\nuz\\\\nuv\\\\njp\\\\nwg\\\\nzi\\\\neg\\\\nov\\\\nzt\\\\nsb\\\\nki\\\\nua\\\\nft\\\\nhq\\\\nik\\\\nxq\\\\nhz\\\\ndh\\\\ngx\\\\ngg\\\\njg\\\\ndm\\\\npb\\\\noq\\\\ntm\\\\nmx\\\\nnh\\\\nkv\\\\nqk\\\\nml\\\\nli\\\\ndi\\\\niy\\\\nsr\\\\nps\\\\nrz\\\\njl\\\\nmr\\\\nna\\\\nax\\\\nqb\\\\nxt\\\\nfe\\\\nay\\\\niv\\\\nkn\\\\nky\\\\nuh\\\\ndq\\\\nib\\\\njz\\\\nvb\\\\nfq\\\\nje\\\\ncy\\\\nwy\\\\nxo\\\\nex\\\\ntg\\\\njw\\\\nii\\\\ncd\\\\ndo\\\\nnw\\\\nzh\\\\nel\\\\ntu\\\\nit\\\\nkb\\\\nwp\\\\njs\\\\nei\\\\nfz\\\\nea\\\\nie\\\\nts\\\\nmd\\\\npx\\\\nsq\\\\nnm\\\\ngi\\\\n\"\\r\\n        \\r\\n        if error == \"\":\\r\\n            student_lines = output.strip().split(\\'\\\\n\\')\\r\\n            expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n                \\r\\n            for idx in range(len(student_lines)):\\r\\n                if idx < len(student_lines) and idx < len(expected_lines):\\r\\n                    if student_lines[idx] == expected_lines[idx]:\\r\\n                        score += 100 / len(expected_lines)\\r\\n            \\r\\n            if score < 100.0:\\r\\n                print(\"**** Start of Expected Output ****\")\\r\\n                print(expected_output)\\r\\n                print(\"INCORRECT: Missing Entries, Expected the above ^^\")\\r\\n            else:\\r\\n                print(\"CORRECT!\")\\r\\n            \\r\\n            return round(score, 1)\\r\\n        else:\\r\\n            print(\"INCORRECT: There was an error while running your code.\\\\n\")\\r\\n            print(error)\\r\\n            \\r\\n            return 0\\r\\n    \\r\\n    except Exception as e:\\r\\n        print(\"There was an error while running your code.\")\\r\\n        print(traceback.print_exc())\\r\\n        if score == 100:\\r\\n            return 90\\r\\n        else:\\r\\n            return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a3_3_chars2': 'from cs110 import autograder\\r\\nimport random, math, traceback\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    try:        \\r\\n        output, error = autograder.run_script(\"a3_3_chars2.py\", [])\\r\\n        expected_output = \"ao\\\\nrh\\\\nvs\\\\nrf\\\\net\\\\nsm\\\\neg\\\\nwf\\\\npp\\\\nmr\\\\niq\\\\nti\\\\npn\\\\npm\\\\nlx\\\\nie\\\\nqh\\\\nls\\\\ngy\\\\nzv\\\\nop\\\\ntc\\\\nlt\\\\nvb\\\\nwh\\\\nxk\\\\nqx\\\\nud\\\\nrv\\\\noa\\\\ndr\\\\ngk\\\\nqk\\\\ner\\\\nmw\\\\nea\\\\ndg\\\\nby\\\\nxa\\\\ngn\\\\nbr\\\\nve\\\\npr\\\\noy\\\\nxw\\\\nwy\\\\nxi\\\\nbs\\\\nae\\\\nlz\\\\nnb\\\\niy\\\\nsz\\\\nyf\\\\ngs\\\\njc\\\\nzy\\\\nxv\\\\nnn\\\\nvm\\\\nxt\\\\nup\\\\nrn\\\\nit\\\\nyc\\\\nwn\\\\nhp\\\\nzp\\\\ney\\\\nfy\\\\nld\\\\ngd\\\\nis\\\\nyk\\\\nfi\\\\nvi\\\\nqq\\\\nyo\\\\ntj\\\\nen\\\\nzm\\\\nrc\\\\nos\\\\nqz\\\\nyu\\\\nmv\\\\nke\\\\nmy\\\\nqe\\\\naz\\\\nun\\\\nox\\\\nvy\\\\nou\\\\nia\\\\nyh\\\\nne\\\\nwd\\\\nbb\\\\ndt\\\\n\"\\r\\n\\r\\n        if error == \"\":\\r\\n            student_lines = output.strip().split(\\'\\\\n\\')\\r\\n            expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n            \\r\\n            for idx in range(len(student_lines)):\\r\\n                if idx < len(student_lines) and idx < len(expected_lines):\\r\\n                    if student_lines[idx] == expected_lines[idx]:\\r\\n                        score += 100 / len(expected_lines)\\r\\n            \\r\\n            if score < 100.0:\\r\\n                print(\"**** Start of Expected Output ****\")\\r\\n                print(expected_output)\\r\\n                print(\"INCORRECT: Missing Entries, Expected the above ^^\")\\r\\n            else:\\r\\n                print(\"CORRECT!\")\\r\\n            \\r\\n            return round(score, 1)\\r\\n        else:\\r\\n            print(\"INCORRECT: There was an error while running your code.\\\\n\")\\r\\n            print(error)\\r\\n            \\r\\n            return 0\\r\\n    \\r\\n    except Exception as e:\\r\\n        print(\"There was an error while running your code.\")\\r\\n        print(traceback.print_exc())\\r\\n        return score\\r\\n\\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------',\n",
       "  'a3_3_chars1': 'from cs110 import autograder\\r\\nimport random, math, traceback\\r\\n\\r\\n# Runs the Python script and sees if it passes the test(s)\\r\\ndef test_passed():\\r\\n    score = 0\\r\\n    try:        \\r\\n        output, error = autograder.run_script(\"a3_3_chars1.py\", [])\\r\\n        expected_output = \"mz\\\\nnz\\\\noe\\\\npq\\\\nzy\\\\nuu\\\\nir\\\\ngy\\\\ntl\\\\npd\\\\nlb\\\\nks\\\\nuf\\\\nvj\\\\nas\\\\nkh\\\\npr\\\\nam\\\\ncd\\\\nlh\\\\nci\\\\nsg\\\\nzt\\\\nwn\\\\nnp\\\\nvt\\\\nme\\\\ngs\\\\nqs\\\\nwe\\\\nxt\\\\nrc\\\\nkw\\\\nxw\\\\nyk\\\\nin\\\\neq\\\\nkt\\\\nfr\\\\nwi\\\\nku\\\\naj\\\\nor\\\\noz\\\\npo\\\\nvo\\\\ngo\\\\nxo\\\\nxx\\\\nca\\\\nxj\\\\ncj\\\\nwj\\\\nxp\\\\njd\\\\nfo\\\\nxq\\\\nnj\\\\nbq\\\\nlr\\\\ndw\\\\nmy\\\\nhj\\\\nve\\\\ncq\\\\ndo\\\\njq\\\\nld\\\\nkl\\\\neu\\\\ngw\\\\njy\\\\nvd\\\\nau\\\\nwq\\\\nnt\\\\ngd\\\\nvx\\\\nxz\\\\nao\\\\ntu\\\\nxb\\\\nyd\\\\nki\\\\nkj\\\\nns\\\\nda\\\\npv\\\\nrq\\\\nvf\\\\nxi\\\\nlo\\\\nue\\\\naa\\\\nct\\\\nxr\\\\nxn\\\\nmr\\\\niv\\\\nmu\\\\n\"\\r\\n        \\r\\n        if error == \"\":\\r\\n            student_lines = output.strip().split(\\'\\\\n\\')\\r\\n            expected_lines = expected_output.strip().split(\\'\\\\n\\')\\r\\n                \\r\\n            for idx in range(len(student_lines)):\\r\\n                if idx < len(student_lines) and idx < len(expected_lines):\\r\\n                    if student_lines[idx] == expected_lines[idx]:\\r\\n                        score += 100 / len(expected_lines)\\r\\n            \\r\\n            if score < 100.0:\\r\\n                print(\"**** Start of Expected Output ****\")\\r\\n                print(expected_output)\\r\\n                print(\"INCORRECT: Missing Entries, Expected the above ^^\")\\r\\n            else:\\r\\n                print(\"CORRECT!\")\\r\\n            \\r\\n            return round(score, 1)\\r\\n        else:\\r\\n            print(\"INCORRECT: There was an error while running your code.\\\\n\")\\r\\n            print(error)\\r\\n            \\r\\n            return 0\\r\\n    \\r\\n    except Exception as e:\\r\\n        print(\"There was an error while running your code.\")\\r\\n        print(traceback.print_exc())\\r\\n        return score\\r\\n    \\r\\n# ---------------------------------------------------------------------\\r\\n# Optional\\r\\n# Runs your code in an IDE (for testing purposes)\\r\\n# ---------------------------------------------------------------------\\r\\nif __name__ == \\'__main__\\':    \\r\\n    result = test_passed()\\r\\n    print(\"Unit Test Returned:\", result)\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------\\r\\n\\r\\n\\r\\n# --------------------------------------------------\\r\\n# Downloaded from https://www.autograder.net\\r\\n# --------------------------------------------------'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_id_to_testcase(problems_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 'b', 'c': 'k'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = [{\"a\": \"b\"}]\n",
    "for d in g:\n",
    "    d[\"c\"] = \"k\"\n",
    "    \n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learnlab2023)",
   "language": "python",
   "name": "learnlab2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
