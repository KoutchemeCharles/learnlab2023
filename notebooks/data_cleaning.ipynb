{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "import pandas as pd \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.TableConverter import md\n",
    "\n",
    "class Falcon():\n",
    "\n",
    "    def __init__(self, dir_path) -> None:\n",
    "        self.dir_path = dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/scratch/work/koutchc1/datasets/falconcode/falconcode_v1_table_problems.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subset_with_missing_data(df):\n",
    "    # Remove duplicate ids for project (same content, multiple semesters)\n",
    "    df = df.drop_duplicates(\"id\")\n",
    "    df = df.fillna(\"\")\n",
    "    df = df.sort_values(by=\"id\")\n",
    "    # We do not have access to the external ressources (all the projects full description)\n",
    "    # for assignments of type project, and they will be graded manually by instructors anyway \n",
    "    df = df[df.type != \"project\"]\n",
    "    # So far, we do not care about the skills for annotation\n",
    "    df = df.loc[:, :'max_score']\n",
    "    # Format the prompt for readability\n",
    "    df[\"prompt\"] = df[\"prompt\"].apply(md)\n",
    "    df = df[[\"You have been provided with\" in prompt for prompt in df[\"prompt\"]]]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "sub_df = load_subset_with_missing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[[\".csv\" in testcase for testcase in df[\"testcase\"]]].prompt.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation loop\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def annotate(missing_data_df):\n",
    "    missing = []\n",
    "    for i, row in tqdm(missing_data_df.iterrows()):\n",
    "        \n",
    "        print(\"**TESTING SCRIPT**\")\n",
    "        print(row[\"testcase\"])\n",
    "        print()\n",
    "        print(row[\"prompt\"])\n",
    "        print()\n",
    "        \n",
    "        missing_files = input(\"Missing files (including startercode)\")\n",
    "        missing.append({\"files\": missing_files})\n",
    "        print(\"------------\")\n",
    "        print()\n",
    "            \n",
    "    missing = pd.DataFrame(missing)\n",
    "    print(missing)\n",
    "    \n",
    "    return pd.concat([missing_data_df, missing], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_what_was_provided(statement, n_words=5):\n",
    "    start = statement.find(\"You have been provided with\")\n",
    "    provided = statement[start:].split(\" \")[5:]\n",
    "    if provided[0] == 'a': provided = provided[1:] \n",
    "    provided = provided[:n_words]\n",
    "    provided = \" \".join(provided)\n",
    "    return provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provided.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_provided_to_category(subdf):\n",
    "    subdf[\"extract\"] = sub_df.prompt.apply(extract_what_was_provided)\n",
    "    categories = [\"function\", \"program\", \"file\", \"data_structure\"]\n",
    "    missing = []\n",
    "    for provided, testcase in subdf[[\"extract\", \"testcase\"]].to_numpy():\n",
    "        file = \"\"\n",
    "        words = testcase.split(\" \")\n",
    "        file = list(set([w for w in words if '.csv' in w or '.txt' in w]))\n",
    "        if not file:\n",
    "            words = provided.split(\" \")\n",
    "            file = list(set([w for w in words if '.csv' in w or '.txt' in w]))\n",
    "        \n",
    "        file = \",\".join(file) if file else \"startercode\"\n",
    "        information = {\"name\": file}\n",
    "        missing.append(information)\n",
    "        \n",
    "    return pd.concat([subdf, pd.DataFrame(missing)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_df = map_provided_to_category(sub_df)\n",
    "missing_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_df = missing_data_df[[\"id\", \"course_id\", \"type\", \"extract\", \"name\"]]\n",
    "missing_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_df.to_csv(\"problems_df_missing_information.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_df.name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of which tables are useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df.problem_id == \"Airstrike\"][\"prompt\"])\n",
    "print(df.loc[df.problem_id == \"Airstrike\"][\"testcase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/scratch/work/koutchc1/datasets/falconcode/falconcode_v1_merged.csv\"\n",
    "runs_df = pd.read_csv(path, index_col=0)\n",
    "runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(runs_df.loc[df.problem_id == \"Airstrike\"][\"source_code\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learnlab2023)",
   "language": "python",
   "name": "learnlab2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
